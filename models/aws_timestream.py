from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_timestream.CfnInfluxDBInstance.LogDeliveryConfigurationProperty
class CfnInfluxDBInstance_LogDeliveryConfigurationPropertyDef(BaseStruct):
    s3_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_timestream.CfnInfluxDBInstance_S3ConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Configuration for S3 bucket log delivery.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-influxdbinstance-logdeliveryconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    log_delivery_configuration_property = timestream.CfnInfluxDBInstance.LogDeliveryConfigurationProperty(\n        s3_configuration=timestream.CfnInfluxDBInstance.S3ConfigurationProperty(\n            bucket_name="bucketName",\n            enabled=False\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['s3_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnInfluxDBInstance.LogDeliveryConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnInfluxDBInstance.S3ConfigurationProperty
class CfnInfluxDBInstance_S3ConfigurationPropertyDef(BaseStruct):
    bucket_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The bucket name of the customer S3 bucket.\n')
    enabled: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Indicates whether log delivery to the S3 bucket is enabled.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-influxdbinstance-s3configuration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    s3_configuration_property = timestream.CfnInfluxDBInstance.S3ConfigurationProperty(\n        bucket_name="bucketName",\n        enabled=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket_name', 'enabled']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnInfluxDBInstance.S3ConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery.DimensionMappingProperty
class CfnScheduledQuery_DimensionMappingPropertyDef(BaseStruct):
    dimension_value_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Type for the dimension: VARCHAR.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Column name from query result.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-scheduledquery-dimensionmapping.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    dimension_mapping_property = timestream.CfnScheduledQuery.DimensionMappingProperty(\n        dimension_value_type="dimensionValueType",\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['dimension_value_type', 'name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery.DimensionMappingProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery.ErrorReportConfigurationProperty
class CfnScheduledQuery_ErrorReportConfigurationPropertyDef(BaseStruct):
    s3_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_S3ConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The S3 configuration for the error reports.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-scheduledquery-errorreportconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    error_report_configuration_property = timestream.CfnScheduledQuery.ErrorReportConfigurationProperty(\n        s3_configuration=timestream.CfnScheduledQuery.S3ConfigurationProperty(\n            bucket_name="bucketName",\n\n            # the properties below are optional\n            encryption_option="encryptionOption",\n            object_key_prefix="objectKeyPrefix"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['s3_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery.ErrorReportConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery.MixedMeasureMappingProperty
class CfnScheduledQuery_MixedMeasureMappingPropertyDef(BaseStruct):
    measure_value_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Type of the value that is to be read from sourceColumn. If the mapping is for MULTI, use MeasureValueType.MULTI.\n')
    measure_name: typing.Optional[str] = pydantic.Field(None, description='Refers to the value of measure_name in a result row. This field is required if MeasureNameColumn is provided.\n')
    multi_measure_attribute_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_MultiMeasureAttributeMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Required when measureValueType is MULTI. Attribute mappings for MULTI value measures.\n')
    source_column: typing.Optional[str] = pydantic.Field(None, description='This field refers to the source column from which measure-value is to be read for result materialization.\n')
    target_measure_name: typing.Optional[str] = pydantic.Field(None, description='Target measure name to be used. If not provided, the target measure name by default would be measure-name if provided, or sourceColumn otherwise.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-scheduledquery-mixedmeasuremapping.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    mixed_measure_mapping_property = timestream.CfnScheduledQuery.MixedMeasureMappingProperty(\n        measure_value_type="measureValueType",\n\n        # the properties below are optional\n        measure_name="measureName",\n        multi_measure_attribute_mappings=[timestream.CfnScheduledQuery.MultiMeasureAttributeMappingProperty(\n            measure_value_type="measureValueType",\n            source_column="sourceColumn",\n\n            # the properties below are optional\n            target_multi_measure_attribute_name="targetMultiMeasureAttributeName"\n        )],\n        source_column="sourceColumn",\n        target_measure_name="targetMeasureName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['measure_value_type', 'measure_name', 'multi_measure_attribute_mappings', 'source_column', 'target_measure_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery.MixedMeasureMappingProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery.MultiMeasureAttributeMappingProperty
class CfnScheduledQuery_MultiMeasureAttributeMappingPropertyDef(BaseStruct):
    measure_value_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Type of the attribute to be read from the source column.\n')
    source_column: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Source column from where the attribute value is to be read.\n')
    target_multi_measure_attribute_name: typing.Optional[str] = pydantic.Field(None, description='Custom name to be used for attribute name in derived table. If not provided, source column name would be used.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-scheduledquery-multimeasureattributemapping.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    multi_measure_attribute_mapping_property = timestream.CfnScheduledQuery.MultiMeasureAttributeMappingProperty(\n        measure_value_type="measureValueType",\n        source_column="sourceColumn",\n\n        # the properties below are optional\n        target_multi_measure_attribute_name="targetMultiMeasureAttributeName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['measure_value_type', 'source_column', 'target_multi_measure_attribute_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery.MultiMeasureAttributeMappingProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery.MultiMeasureMappingsProperty
class CfnScheduledQuery_MultiMeasureMappingsPropertyDef(BaseStruct):
    multi_measure_attribute_mappings: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_MultiMeasureAttributeMappingPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Required. Attribute mappings to be used for mapping query results to ingest data for multi-measure attributes.\n')
    target_multi_measure_name: typing.Optional[str] = pydantic.Field(None, description='The name of the target multi-measure name in the derived table. This input is required when measureNameColumn is not provided. If MeasureNameColumn is provided, then value from that column will be used as multi-measure name.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-scheduledquery-multimeasuremappings.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    multi_measure_mappings_property = timestream.CfnScheduledQuery.MultiMeasureMappingsProperty(\n        multi_measure_attribute_mappings=[timestream.CfnScheduledQuery.MultiMeasureAttributeMappingProperty(\n            measure_value_type="measureValueType",\n            source_column="sourceColumn",\n\n            # the properties below are optional\n            target_multi_measure_attribute_name="targetMultiMeasureAttributeName"\n        )],\n\n        # the properties below are optional\n        target_multi_measure_name="targetMultiMeasureName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['multi_measure_attribute_mappings', 'target_multi_measure_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery.MultiMeasureMappingsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery.NotificationConfigurationProperty
class CfnScheduledQuery_NotificationConfigurationPropertyDef(BaseStruct):
    sns_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_SnsConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Details on SNS configuration.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-scheduledquery-notificationconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    notification_configuration_property = timestream.CfnScheduledQuery.NotificationConfigurationProperty(\n        sns_configuration=timestream.CfnScheduledQuery.SnsConfigurationProperty(\n            topic_arn="topicArn"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['sns_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery.NotificationConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery.S3ConfigurationProperty
class CfnScheduledQuery_S3ConfigurationPropertyDef(BaseStruct):
    bucket_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Name of the S3 bucket under which error reports will be created.\n')
    encryption_option: typing.Optional[str] = pydantic.Field(None, description='Encryption at rest options for the error reports. If no encryption option is specified, Timestream will choose SSE_S3 as default.\n')
    object_key_prefix: typing.Optional[str] = pydantic.Field(None, description='Prefix for the error report key. Timestream by default adds the following prefix to the error report path.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-scheduledquery-s3configuration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    s3_configuration_property = timestream.CfnScheduledQuery.S3ConfigurationProperty(\n        bucket_name="bucketName",\n\n        # the properties below are optional\n        encryption_option="encryptionOption",\n        object_key_prefix="objectKeyPrefix"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket_name', 'encryption_option', 'object_key_prefix']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery.S3ConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery.ScheduleConfigurationProperty
class CfnScheduledQuery_ScheduleConfigurationPropertyDef(BaseStruct):
    schedule_expression: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='An expression that denotes when to trigger the scheduled query run. This can be a cron expression or a rate expression.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-scheduledquery-scheduleconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    schedule_configuration_property = timestream.CfnScheduledQuery.ScheduleConfigurationProperty(\n        schedule_expression="scheduleExpression"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['schedule_expression']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery.ScheduleConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery.SnsConfigurationProperty
class CfnScheduledQuery_SnsConfigurationPropertyDef(BaseStruct):
    topic_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='SNS topic ARN that the scheduled query status notifications will be sent to.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-scheduledquery-snsconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    sns_configuration_property = timestream.CfnScheduledQuery.SnsConfigurationProperty(\n        topic_arn="topicArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['topic_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery.SnsConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery.TargetConfigurationProperty
class CfnScheduledQuery_TargetConfigurationPropertyDef(BaseStruct):
    timestream_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_TimestreamConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Configuration needed to write data into the Timestream database and table.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-scheduledquery-targetconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    target_configuration_property = timestream.CfnScheduledQuery.TargetConfigurationProperty(\n        timestream_configuration=timestream.CfnScheduledQuery.TimestreamConfigurationProperty(\n            database_name="databaseName",\n            dimension_mappings=[timestream.CfnScheduledQuery.DimensionMappingProperty(\n                dimension_value_type="dimensionValueType",\n                name="name"\n            )],\n            table_name="tableName",\n            time_column="timeColumn",\n\n            # the properties below are optional\n            measure_name_column="measureNameColumn",\n            mixed_measure_mappings=[timestream.CfnScheduledQuery.MixedMeasureMappingProperty(\n                measure_value_type="measureValueType",\n\n                # the properties below are optional\n                measure_name="measureName",\n                multi_measure_attribute_mappings=[timestream.CfnScheduledQuery.MultiMeasureAttributeMappingProperty(\n                    measure_value_type="measureValueType",\n                    source_column="sourceColumn",\n\n                    # the properties below are optional\n                    target_multi_measure_attribute_name="targetMultiMeasureAttributeName"\n                )],\n                source_column="sourceColumn",\n                target_measure_name="targetMeasureName"\n            )],\n            multi_measure_mappings=timestream.CfnScheduledQuery.MultiMeasureMappingsProperty(\n                multi_measure_attribute_mappings=[timestream.CfnScheduledQuery.MultiMeasureAttributeMappingProperty(\n                    measure_value_type="measureValueType",\n                    source_column="sourceColumn",\n\n                    # the properties below are optional\n                    target_multi_measure_attribute_name="targetMultiMeasureAttributeName"\n                )],\n\n                # the properties below are optional\n                target_multi_measure_name="targetMultiMeasureName"\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['timestream_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery.TargetConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery.TimestreamConfigurationProperty
class CfnScheduledQuery_TimestreamConfigurationPropertyDef(BaseStruct):
    database_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Name of Timestream database to which the query result will be written.\n')
    dimension_mappings: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_DimensionMappingPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='This is to allow mapping column(s) from the query result to the dimension in the destination table.\n')
    table_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Name of Timestream table that the query result will be written to. The table should be within the same database that is provided in Timestream configuration.\n')
    time_column: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Column from query result that should be used as the time column in destination table. Column type for this should be TIMESTAMP.\n')
    measure_name_column: typing.Optional[str] = pydantic.Field(None, description='Name of the measure column. Also see ``MultiMeasureMappings`` and ``MixedMeasureMappings`` for how measure name properties on those relate to ``MeasureNameColumn`` .\n')
    mixed_measure_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_MixedMeasureMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Specifies how to map measures to multi-measure records.\n')
    multi_measure_mappings: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_MultiMeasureMappingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Multi-measure mappings.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-scheduledquery-timestreamconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    timestream_configuration_property = timestream.CfnScheduledQuery.TimestreamConfigurationProperty(\n        database_name="databaseName",\n        dimension_mappings=[timestream.CfnScheduledQuery.DimensionMappingProperty(\n            dimension_value_type="dimensionValueType",\n            name="name"\n        )],\n        table_name="tableName",\n        time_column="timeColumn",\n\n        # the properties below are optional\n        measure_name_column="measureNameColumn",\n        mixed_measure_mappings=[timestream.CfnScheduledQuery.MixedMeasureMappingProperty(\n            measure_value_type="measureValueType",\n\n            # the properties below are optional\n            measure_name="measureName",\n            multi_measure_attribute_mappings=[timestream.CfnScheduledQuery.MultiMeasureAttributeMappingProperty(\n                measure_value_type="measureValueType",\n                source_column="sourceColumn",\n\n                # the properties below are optional\n                target_multi_measure_attribute_name="targetMultiMeasureAttributeName"\n            )],\n            source_column="sourceColumn",\n            target_measure_name="targetMeasureName"\n        )],\n        multi_measure_mappings=timestream.CfnScheduledQuery.MultiMeasureMappingsProperty(\n            multi_measure_attribute_mappings=[timestream.CfnScheduledQuery.MultiMeasureAttributeMappingProperty(\n                measure_value_type="measureValueType",\n                source_column="sourceColumn",\n\n                # the properties below are optional\n                target_multi_measure_attribute_name="targetMultiMeasureAttributeName"\n            )],\n\n            # the properties below are optional\n            target_multi_measure_name="targetMultiMeasureName"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['database_name', 'dimension_mappings', 'table_name', 'time_column', 'measure_name_column', 'mixed_measure_mappings', 'multi_measure_mappings']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery.TimestreamConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnTable.MagneticStoreRejectedDataLocationProperty
class CfnTable_MagneticStoreRejectedDataLocationPropertyDef(BaseStruct):
    s3_configuration: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnTable_S3ConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configuration of an S3 location to write error reports for records rejected, asynchronously, during magnetic store writes.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-table-magneticstorerejecteddatalocation.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    magnetic_store_rejected_data_location_property = timestream.CfnTable.MagneticStoreRejectedDataLocationProperty(\n        s3_configuration=timestream.CfnTable.S3ConfigurationProperty(\n            bucket_name="bucketName",\n            encryption_option="encryptionOption",\n\n            # the properties below are optional\n            kms_key_id="kmsKeyId",\n            object_key_prefix="objectKeyPrefix"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['s3_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnTable.MagneticStoreRejectedDataLocationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnTable.MagneticStoreWritePropertiesProperty
class CfnTable_MagneticStoreWritePropertiesPropertyDef(BaseStruct):
    enable_magnetic_store_writes: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='A flag to enable magnetic store writes.\n')
    magnetic_store_rejected_data_location: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnTable_MagneticStoreRejectedDataLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The location to write error reports for records rejected asynchronously during magnetic store writes.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-table-magneticstorewriteproperties.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    magnetic_store_write_properties_property = timestream.CfnTable.MagneticStoreWritePropertiesProperty(\n        enable_magnetic_store_writes=False,\n\n        # the properties below are optional\n        magnetic_store_rejected_data_location=timestream.CfnTable.MagneticStoreRejectedDataLocationProperty(\n            s3_configuration=timestream.CfnTable.S3ConfigurationProperty(\n                bucket_name="bucketName",\n                encryption_option="encryptionOption",\n\n                # the properties below are optional\n                kms_key_id="kmsKeyId",\n                object_key_prefix="objectKeyPrefix"\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['enable_magnetic_store_writes', 'magnetic_store_rejected_data_location']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnTable.MagneticStoreWritePropertiesProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnTable.PartitionKeyProperty
class CfnTable_PartitionKeyPropertyDef(BaseStruct):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of the partition key. Options are DIMENSION (dimension key) and MEASURE (measure key).\n')
    enforcement_in_record: typing.Optional[str] = pydantic.Field(None, description='The level of enforcement for the specification of a dimension key in ingested records. Options are REQUIRED (dimension key must be specified) and OPTIONAL (dimension key does not have to be specified).\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the attribute used for a dimension key.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-table-partitionkey.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    partition_key_property = timestream.CfnTable.PartitionKeyProperty(\n        type="type",\n\n        # the properties below are optional\n        enforcement_in_record="enforcementInRecord",\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type', 'enforcement_in_record', 'name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnTable.PartitionKeyProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnTable.RetentionPropertiesProperty
class CfnTable_RetentionPropertiesPropertyDef(BaseStruct):
    magnetic_store_retention_period_in_days: typing.Optional[str] = pydantic.Field(None, description='The duration for which data must be stored in the magnetic store.\n')
    memory_store_retention_period_in_hours: typing.Optional[str] = pydantic.Field(None, description='The duration for which data must be stored in the memory store.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-table-retentionproperties.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    retention_properties_property = timestream.CfnTable.RetentionPropertiesProperty(\n        magnetic_store_retention_period_in_days="magneticStoreRetentionPeriodInDays",\n        memory_store_retention_period_in_hours="memoryStoreRetentionPeriodInHours"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['magnetic_store_retention_period_in_days', 'memory_store_retention_period_in_hours']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnTable.RetentionPropertiesProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnTable.S3ConfigurationProperty
class CfnTable_S3ConfigurationPropertyDef(BaseStruct):
    bucket_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The bucket name of the customer S3 bucket.\n')
    encryption_option: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The encryption option for the customer S3 location. Options are S3 server-side encryption with an S3 managed key or AWS managed key.\n')
    kms_key_id: typing.Optional[str] = pydantic.Field(None, description='The AWS KMS key ID for the customer S3 location when encrypting with an AWS managed key.\n')
    object_key_prefix: typing.Optional[str] = pydantic.Field(None, description='The object key preview for the customer S3 location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-table-s3configuration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    s3_configuration_property = timestream.CfnTable.S3ConfigurationProperty(\n        bucket_name="bucketName",\n        encryption_option="encryptionOption",\n\n        # the properties below are optional\n        kms_key_id="kmsKeyId",\n        object_key_prefix="objectKeyPrefix"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket_name', 'encryption_option', 'kms_key_id', 'object_key_prefix']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnTable.S3ConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnTable.SchemaProperty
class CfnTable_SchemaPropertyDef(BaseStruct):
    composite_partition_key: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_timestream.CfnTable_PartitionKeyPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A non-empty list of partition keys defining the attributes used to partition the table data. The order of the list determines the partition hierarchy. The name and type of each partition key as well as the partition key order cannot be changed after the table is created. However, the enforcement level of each partition key can be changed.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-timestream-table-schema.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    schema_property = timestream.CfnTable.SchemaProperty(\n        composite_partition_key=[timestream.CfnTable.PartitionKeyProperty(\n            type="type",\n\n            # the properties below are optional\n            enforcement_in_record="enforcementInRecord",\n            name="name"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['composite_partition_key']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnTable.SchemaProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnDatabase
class CfnDatabaseDef(BaseCfnResource):
    database_name: typing.Optional[str] = pydantic.Field(None, description='The name of the Timestream database. *Length Constraints* : Minimum length of 3 bytes. Maximum length of 256 bytes.\n')
    kms_key_id: typing.Optional[str] = pydantic.Field(None, description='The identifier of the AWS KMS key used to encrypt the data stored in the database.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The tags to add to the database.')
    _init_params: typing.ClassVar[list[str]] = ['database_name', 'kms_key_id', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnDatabase'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_timestream.CfnDatabaseDefConfig] = pydantic.Field(None)


class CfnDatabaseDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_timestream.CfnDatabaseDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_timestream.CfnDatabaseDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_timestream.CfnDatabaseDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_timestream.CfnDatabaseDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_timestream.CfnDatabaseDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_timestream.CfnDatabaseDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_timestream.CfnDatabaseDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_timestream.CfnDatabaseDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_timestream.CfnDatabaseDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_timestream.CfnDatabaseDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_timestream.CfnDatabaseDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_timestream.CfnDatabaseDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_timestream.CfnDatabaseDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnDatabaseDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnDatabaseDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDatabaseDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnDatabaseDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDatabaseDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnDatabaseDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnDatabaseDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnDatabaseDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnDatabaseDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnDatabaseDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDatabaseDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnDatabaseDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnDatabaseDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDatabaseDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_timestream.CfnInfluxDBInstance
class CfnInfluxDBInstanceDef(BaseCfnResource):
    allocated_storage: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of storage to allocate for your DB storage type in GiB (gibibytes).\n')
    bucket: typing.Optional[str] = pydantic.Field(None, description='The name of the initial InfluxDB bucket. All InfluxDB data is stored in a bucket. A bucket combines the concept of a database and a retention period (the duration of time that each data point persists). A bucket belongs to an organization.\n')
    db_instance_type: typing.Optional[str] = pydantic.Field(None, description='The Timestream for InfluxDB DB instance type to run on.\n')
    db_parameter_group_identifier: typing.Optional[str] = pydantic.Field(None, description='The name or id of the DB parameter group to assign to your DB instance. DB parameter groups specify how the database is configured. For example, DB parameter groups can specify the limit for query concurrency.\n')
    db_storage_type: typing.Optional[str] = pydantic.Field(None, description='The Timestream for InfluxDB DB storage type to read and write InfluxDB data. You can choose between 3 different types of provisioned Influx IOPS included storage according to your workloads requirements: - Influx IO Included 3000 IOPS - Influx IO Included 12000 IOPS - Influx IO Included 16000 IOPS\n')
    deployment_type: typing.Optional[str] = pydantic.Field(None, description='Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.\n')
    log_delivery_configuration: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnInfluxDBInstance_LogDeliveryConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configuration for sending InfluxDB engine logs to a specified S3 bucket.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands. This name will also be a prefix included in the endpoint. DB instance names must be unique per customer and per region.\n')
    organization: typing.Optional[str] = pydantic.Field(None, description='The name of the initial organization for the initial admin user in InfluxDB. An InfluxDB organization is a workspace for a group of users.\n')
    password: typing.Optional[str] = pydantic.Field(None, description='The password of the initial admin user created in InfluxDB. This password will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a Secret created in Amazon SecretManager in your account.\n')
    publicly_accessible: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Configures the DB instance with a public IP to facilitate access. Default: - false\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='A list of key-value pairs to associate with the DB instance.\n')
    username: typing.Optional[str] = pydantic.Field(None, description="The username of the initial admin user created in InfluxDB. Must start with a letter and can't end with a hyphen or contain two consecutive hyphens. For example, my-user1. This username will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a Secret created in Amazon Secrets Manager in your account.\n")
    vpc_security_group_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of VPC security group IDs to associate with the DB instance.\n')
    vpc_subnet_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of VPC subnet IDs to associate with the DB instance. Provide at least two VPC subnet IDs in different availability zones when deploying with a Multi-AZ standby.')
    _init_params: typing.ClassVar[list[str]] = ['allocated_storage', 'bucket', 'db_instance_type', 'db_parameter_group_identifier', 'db_storage_type', 'deployment_type', 'log_delivery_configuration', 'name', 'organization', 'password', 'publicly_accessible', 'tags', 'username', 'vpc_security_group_ids', 'vpc_subnet_ids']
    _method_names: typing.ClassVar[list[str]] = ['LogDeliveryConfigurationProperty', 'S3ConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnInfluxDBInstance'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_timestream.CfnInfluxDBInstanceDefConfig] = pydantic.Field(None)


class CfnInfluxDBInstanceDefConfig(pydantic.BaseModel):
    LogDeliveryConfigurationProperty: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefLogdeliveryconfigurationpropertyParams]] = pydantic.Field(None, description='')
    S3ConfigurationProperty: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefS3ConfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_timestream.CfnInfluxDBInstanceDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    cdk_tag_manager_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnInfluxDBInstanceDefLogdeliveryconfigurationpropertyParams(pydantic.BaseModel):
    s3_configuration: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnInfluxDBInstance_S3ConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    ...

class CfnInfluxDBInstanceDefS3ConfigurationpropertyParams(pydantic.BaseModel):
    bucket_name: str = pydantic.Field(..., description='')
    enabled: typing.Union[bool, models.UnsupportedResource] = pydantic.Field(..., description='')
    ...

class CfnInfluxDBInstanceDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnInfluxDBInstanceDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnInfluxDBInstanceDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnInfluxDBInstanceDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnInfluxDBInstanceDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnInfluxDBInstanceDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnInfluxDBInstanceDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnInfluxDBInstanceDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnInfluxDBInstanceDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnInfluxDBInstanceDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnInfluxDBInstanceDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnInfluxDBInstanceDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnInfluxDBInstanceDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnInfluxDBInstanceDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQuery
class CfnScheduledQueryDef(BaseCfnResource):
    error_report_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_ErrorReportConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Configuration for error reporting. Error reports will be generated when a problem is encountered when writing the query results.\n')
    notification_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_NotificationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Notification configuration for the scheduled query. A notification is sent by Timestream when a query run finishes, when the state is updated or when you delete it.\n')
    query_string: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The query string to run. Parameter names can be specified in the query string ``@`` character followed by an identifier. The named Parameter ``@scheduled_runtime`` is reserved and can be used in the query to get the time at which the query is scheduled to run. The timestamp calculated according to the ScheduleConfiguration parameter, will be the value of ``@scheduled_runtime`` paramater for each query run. For example, consider an instance of a scheduled query executing on 2021-12-01 00:00:00. For this instance, the ``@scheduled_runtime`` parameter is initialized to the timestamp 2021-12-01 00:00:00 when invoking the query.\n')
    schedule_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_ScheduleConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Schedule configuration.\n')
    scheduled_query_execution_role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN for the IAM role that Timestream will assume when running the scheduled query.\n')
    client_token: typing.Optional[str] = pydantic.Field(None, description='Using a ClientToken makes the call to CreateScheduledQuery idempotent, in other words, making the same request repeatedly will produce the same result. Making multiple identical CreateScheduledQuery requests has the same effect as making a single request. - If CreateScheduledQuery is called without a ``ClientToken`` , the Query SDK generates a ``ClientToken`` on your behalf. - After 8 hours, any request with the same ``ClientToken`` is treated as a new request.\n')
    kms_key_id: typing.Optional[str] = pydantic.Field(None, description='The Amazon KMS key used to encrypt the scheduled query resource, at-rest. If the Amazon KMS key is not specified, the scheduled query resource will be encrypted with a Timestream owned Amazon KMS key. To specify a KMS key, use the key ID, key ARN, alias name, or alias ARN. When using an alias name, prefix the name with *alias/* If ErrorReportConfiguration uses ``SSE_KMS`` as encryption type, the same KmsKeyId is used to encrypt the error report at rest.\n')
    scheduled_query_name: typing.Optional[str] = pydantic.Field(None, description='A name for the query. Scheduled query names must be unique within each Region.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='A list of key-value pairs to label the scheduled query.\n')
    target_configuration: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_TargetConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Scheduled query target store configuration.')
    _init_params: typing.ClassVar[list[str]] = ['error_report_configuration', 'notification_configuration', 'query_string', 'schedule_configuration', 'scheduled_query_execution_role_arn', 'client_token', 'kms_key_id', 'scheduled_query_name', 'tags', 'target_configuration']
    _method_names: typing.ClassVar[list[str]] = ['DimensionMappingProperty', 'ErrorReportConfigurationProperty', 'MixedMeasureMappingProperty', 'MultiMeasureAttributeMappingProperty', 'MultiMeasureMappingsProperty', 'NotificationConfigurationProperty', 'S3ConfigurationProperty', 'ScheduleConfigurationProperty', 'SnsConfigurationProperty', 'TargetConfigurationProperty', 'TimestreamConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQuery'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_timestream.CfnScheduledQueryDefConfig] = pydantic.Field(None)


class CfnScheduledQueryDefConfig(pydantic.BaseModel):
    DimensionMappingProperty: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefDimensionmappingpropertyParams]] = pydantic.Field(None, description='')
    ErrorReportConfigurationProperty: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefErrorreportconfigurationpropertyParams]] = pydantic.Field(None, description='')
    MixedMeasureMappingProperty: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefMixedmeasuremappingpropertyParams]] = pydantic.Field(None, description='')
    MultiMeasureAttributeMappingProperty: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefMultimeasureattributemappingpropertyParams]] = pydantic.Field(None, description='')
    MultiMeasureMappingsProperty: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefMultimeasuremappingspropertyParams]] = pydantic.Field(None, description='')
    NotificationConfigurationProperty: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefNotificationconfigurationpropertyParams]] = pydantic.Field(None, description='')
    S3ConfigurationProperty: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefS3ConfigurationpropertyParams]] = pydantic.Field(None, description='')
    ScheduleConfigurationProperty: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefScheduleconfigurationpropertyParams]] = pydantic.Field(None, description='')
    SnsConfigurationProperty: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefSnsconfigurationpropertyParams]] = pydantic.Field(None, description='')
    TargetConfigurationProperty: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefTargetconfigurationpropertyParams]] = pydantic.Field(None, description='')
    TimestreamConfigurationProperty: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefTimestreamconfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_timestream.CfnScheduledQueryDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnScheduledQueryDefDimensionmappingpropertyParams(pydantic.BaseModel):
    dimension_value_type: str = pydantic.Field(..., description='')
    name: str = pydantic.Field(..., description='')
    ...

class CfnScheduledQueryDefErrorreportconfigurationpropertyParams(pydantic.BaseModel):
    s3_configuration: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_S3ConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    ...

class CfnScheduledQueryDefMixedmeasuremappingpropertyParams(pydantic.BaseModel):
    measure_value_type: str = pydantic.Field(..., description='')
    measure_name: typing.Optional[str] = pydantic.Field(None, description='')
    multi_measure_attribute_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_MultiMeasureAttributeMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    source_column: typing.Optional[str] = pydantic.Field(None, description='')
    target_measure_name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScheduledQueryDefMultimeasureattributemappingpropertyParams(pydantic.BaseModel):
    measure_value_type: str = pydantic.Field(..., description='')
    source_column: str = pydantic.Field(..., description='')
    target_multi_measure_attribute_name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScheduledQueryDefMultimeasuremappingspropertyParams(pydantic.BaseModel):
    multi_measure_attribute_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_MultiMeasureAttributeMappingPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    target_multi_measure_name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScheduledQueryDefNotificationconfigurationpropertyParams(pydantic.BaseModel):
    sns_configuration: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_SnsConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    ...

class CfnScheduledQueryDefS3ConfigurationpropertyParams(pydantic.BaseModel):
    bucket_name: str = pydantic.Field(..., description='')
    encryption_option: typing.Optional[str] = pydantic.Field(None, description='')
    object_key_prefix: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScheduledQueryDefScheduleconfigurationpropertyParams(pydantic.BaseModel):
    schedule_expression: str = pydantic.Field(..., description='')
    ...

class CfnScheduledQueryDefSnsconfigurationpropertyParams(pydantic.BaseModel):
    topic_arn: str = pydantic.Field(..., description='')
    ...

class CfnScheduledQueryDefTargetconfigurationpropertyParams(pydantic.BaseModel):
    timestream_configuration: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_TimestreamConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    ...

class CfnScheduledQueryDefTimestreamconfigurationpropertyParams(pydantic.BaseModel):
    database_name: str = pydantic.Field(..., description='')
    dimension_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_DimensionMappingPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    table_name: str = pydantic.Field(..., description='')
    time_column: str = pydantic.Field(..., description='')
    measure_name_column: typing.Optional[str] = pydantic.Field(None, description='')
    mixed_measure_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_MixedMeasureMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    multi_measure_mappings: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_MultiMeasureMappingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnScheduledQueryDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnScheduledQueryDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnScheduledQueryDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnScheduledQueryDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnScheduledQueryDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnScheduledQueryDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnScheduledQueryDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnScheduledQueryDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnScheduledQueryDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnScheduledQueryDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnScheduledQueryDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnScheduledQueryDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnScheduledQueryDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnScheduledQueryDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_timestream.CfnTable
class CfnTableDef(BaseCfnResource):
    database_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Timestream database that contains this table. *Length Constraints* : Minimum length of 3 bytes. Maximum length of 256 bytes.\n')
    magnetic_store_write_properties: typing.Any = pydantic.Field(None, description='Contains properties to set on the table when enabling magnetic store writes. This object has the following attributes: - *EnableMagneticStoreWrites* : A ``boolean`` flag to enable magnetic store writes. - *MagneticStoreRejectedDataLocation* : The location to write error reports for records rejected, asynchronously, during magnetic store writes. Only ``S3Configuration`` objects are allowed. The ``S3Configuration`` object has the following attributes: - *BucketName* : The name of the S3 bucket. - *EncryptionOption* : The encryption option for the S3 location. Valid values are S3 server-side encryption with an S3 managed key ( ``SSE_S3`` ) or AWS managed key ( ``SSE_KMS`` ). - *KmsKeyId* : The AWS KMS key ID to use when encrypting with an AWS managed key. - *ObjectKeyPrefix* : The prefix to use option for the objects stored in S3. Both ``BucketName`` and ``EncryptionOption`` are *required* when ``S3Configuration`` is specified. If you specify ``SSE_KMS`` as your ``EncryptionOption`` then ``KmsKeyId`` is *required* . ``EnableMagneticStoreWrites`` attribute is *required* when ``MagneticStoreWriteProperties`` is specified. ``MagneticStoreRejectedDataLocation`` attribute is *required* when ``EnableMagneticStoreWrites`` is set to ``true`` . See the following examples: *JSON:: { "Type" : AWS::Timestream::Table", "Properties":{ "DatabaseName":"TestDatabase", "TableName":"TestTable", "MagneticStoreWriteProperties":{ "EnableMagneticStoreWrites":true, "MagneticStoreRejectedDataLocation":{ "S3Configuration":{ "BucketName":"testbucket", "EncryptionOption":"SSE_KMS", "KmsKeyId":"1234abcd-12ab-34cd-56ef-1234567890ab", "ObjectKeyPrefix":"prefix" } } } } } *YAML:: Type: AWS::Timestream::Table DependsOn: TestDatabase Properties: TableName: "TestTable" DatabaseName: "TestDatabase" MagneticStoreWriteProperties: EnableMagneticStoreWrites: true MagneticStoreRejectedDataLocation: S3Configuration: BucketName: "testbucket" EncryptionOption: "SSE_KMS" KmsKeyId: "1234abcd-12ab-34cd-56ef-1234567890ab" ObjectKeyPrefix: "prefix"\n')
    retention_properties: typing.Any = pydantic.Field(None, description='The retention duration for the memory store and magnetic store. This object has the following attributes:. - *MemoryStoreRetentionPeriodInHours* : Retention duration for memory store, in hours. - *MagneticStoreRetentionPeriodInDays* : Retention duration for magnetic store, in days. Both attributes are of type ``string`` . Both attributes are *required* when ``RetentionProperties`` is specified. See the following examples: *JSON* ``{ "Type" : AWS::Timestream::Table", "Properties" : { "DatabaseName" : "TestDatabase", "TableName" : "TestTable", "RetentionProperties" : { "MemoryStoreRetentionPeriodInHours": "24", "MagneticStoreRetentionPeriodInDays": "7" } } }`` *YAML:: Type: AWS::Timestream::Table DependsOn: TestDatabase Properties: TableName: "TestTable" DatabaseName: "TestDatabase" RetentionProperties: MemoryStoreRetentionPeriodInHours: "24" MagneticStoreRetentionPeriodInDays: "7"\n')
    schema_: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnTable_SchemaPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The schema of the table.\n', alias='schema')
    table_name: typing.Optional[str] = pydantic.Field(None, description='The name of the Timestream table. *Length Constraints* : Minimum length of 3 bytes. Maximum length of 256 bytes.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The tags to add to the table.')
    _init_params: typing.ClassVar[list[str]] = ['database_name', 'magnetic_store_write_properties', 'retention_properties', 'schema', 'table_name', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['MagneticStoreRejectedDataLocationProperty', 'MagneticStoreWritePropertiesProperty', 'PartitionKeyProperty', 'RetentionPropertiesProperty', 'S3ConfigurationProperty', 'SchemaProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnTable'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_timestream.CfnTableDefConfig] = pydantic.Field(None)


class CfnTableDefConfig(pydantic.BaseModel):
    MagneticStoreRejectedDataLocationProperty: typing.Optional[list[models.aws_timestream.CfnTableDefMagneticstorerejecteddatalocationpropertyParams]] = pydantic.Field(None, description='')
    MagneticStoreWritePropertiesProperty: typing.Optional[list[models.aws_timestream.CfnTableDefMagneticstorewritepropertiespropertyParams]] = pydantic.Field(None, description='')
    PartitionKeyProperty: typing.Optional[list[models.aws_timestream.CfnTableDefPartitionkeypropertyParams]] = pydantic.Field(None, description='')
    RetentionPropertiesProperty: typing.Optional[list[models.aws_timestream.CfnTableDefRetentionpropertiespropertyParams]] = pydantic.Field(None, description='')
    S3ConfigurationProperty: typing.Optional[list[models.aws_timestream.CfnTableDefS3ConfigurationpropertyParams]] = pydantic.Field(None, description='')
    SchemaProperty: typing.Optional[list[models.aws_timestream.CfnTableDefSchemapropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_timestream.CfnTableDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_timestream.CfnTableDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_timestream.CfnTableDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_timestream.CfnTableDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_timestream.CfnTableDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_timestream.CfnTableDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_timestream.CfnTableDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_timestream.CfnTableDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_timestream.CfnTableDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_timestream.CfnTableDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_timestream.CfnTableDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_timestream.CfnTableDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_timestream.CfnTableDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnTableDefMagneticstorerejecteddatalocationpropertyParams(pydantic.BaseModel):
    s3_configuration: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnTable_S3ConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnTableDefMagneticstorewritepropertiespropertyParams(pydantic.BaseModel):
    enable_magnetic_store_writes: typing.Union[bool, models.UnsupportedResource] = pydantic.Field(..., description='')
    magnetic_store_rejected_data_location: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnTable_MagneticStoreRejectedDataLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnTableDefPartitionkeypropertyParams(pydantic.BaseModel):
    type: str = pydantic.Field(..., description='')
    enforcement_in_record: typing.Optional[str] = pydantic.Field(None, description='')
    name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTableDefRetentionpropertiespropertyParams(pydantic.BaseModel):
    magnetic_store_retention_period_in_days: typing.Optional[str] = pydantic.Field(None, description='')
    memory_store_retention_period_in_hours: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTableDefS3ConfigurationpropertyParams(pydantic.BaseModel):
    bucket_name: str = pydantic.Field(..., description='')
    encryption_option: str = pydantic.Field(..., description='')
    kms_key_id: typing.Optional[str] = pydantic.Field(None, description='')
    object_key_prefix: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTableDefSchemapropertyParams(pydantic.BaseModel):
    composite_partition_key: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_timestream.CfnTable_PartitionKeyPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnTableDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnTableDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnTableDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnTableDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnTableDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnTableDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnTableDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnTableDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnTableDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnTableDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnTableDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnTableDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnTableDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnTableDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_timestream.CfnDatabaseProps
class CfnDatabasePropsDef(BaseCfnProperty):
    database_name: typing.Optional[str] = pydantic.Field(None, description='The name of the Timestream database. *Length Constraints* : Minimum length of 3 bytes. Maximum length of 256 bytes.\n')
    kms_key_id: typing.Optional[str] = pydantic.Field(None, description='The identifier of the AWS KMS key used to encrypt the data stored in the database.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The tags to add to the database.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-timestream-database.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    cfn_database_props = timestream.CfnDatabaseProps(\n        database_name="databaseName",\n        kms_key_id="kmsKeyId",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['database_name', 'kms_key_id', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnDatabaseProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnInfluxDBInstanceProps
class CfnInfluxDBInstancePropsDef(BaseCfnProperty):
    allocated_storage: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of storage to allocate for your DB storage type in GiB (gibibytes).\n')
    bucket: typing.Optional[str] = pydantic.Field(None, description='The name of the initial InfluxDB bucket. All InfluxDB data is stored in a bucket. A bucket combines the concept of a database and a retention period (the duration of time that each data point persists). A bucket belongs to an organization.\n')
    db_instance_type: typing.Optional[str] = pydantic.Field(None, description='The Timestream for InfluxDB DB instance type to run on.\n')
    db_parameter_group_identifier: typing.Optional[str] = pydantic.Field(None, description='The name or id of the DB parameter group to assign to your DB instance. DB parameter groups specify how the database is configured. For example, DB parameter groups can specify the limit for query concurrency.\n')
    db_storage_type: typing.Optional[str] = pydantic.Field(None, description='The Timestream for InfluxDB DB storage type to read and write InfluxDB data. You can choose between 3 different types of provisioned Influx IOPS included storage according to your workloads requirements: - Influx IO Included 3000 IOPS - Influx IO Included 12000 IOPS - Influx IO Included 16000 IOPS\n')
    deployment_type: typing.Optional[str] = pydantic.Field(None, description='Specifies whether the Timestream for InfluxDB is deployed as Single-AZ or with a MultiAZ Standby for High availability.\n')
    log_delivery_configuration: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnInfluxDBInstance_LogDeliveryConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configuration for sending InfluxDB engine logs to a specified S3 bucket.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands. This name will also be a prefix included in the endpoint. DB instance names must be unique per customer and per region.\n')
    organization: typing.Optional[str] = pydantic.Field(None, description='The name of the initial organization for the initial admin user in InfluxDB. An InfluxDB organization is a workspace for a group of users.\n')
    password: typing.Optional[str] = pydantic.Field(None, description='The password of the initial admin user created in InfluxDB. This password will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a Secret created in Amazon SecretManager in your account.\n')
    publicly_accessible: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Configures the DB instance with a public IP to facilitate access. Default: - false\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='A list of key-value pairs to associate with the DB instance.\n')
    username: typing.Optional[str] = pydantic.Field(None, description="The username of the initial admin user created in InfluxDB. Must start with a letter and can't end with a hyphen or contain two consecutive hyphens. For example, my-user1. This username will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. These attributes will be stored in a Secret created in Amazon Secrets Manager in your account.\n")
    vpc_security_group_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of VPC security group IDs to associate with the DB instance.\n')
    vpc_subnet_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of VPC subnet IDs to associate with the DB instance. Provide at least two VPC subnet IDs in different availability zones when deploying with a Multi-AZ standby.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-timestream-influxdbinstance.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    cfn_influx_dBInstance_props = timestream.CfnInfluxDBInstanceProps(\n        allocated_storage=123,\n        bucket="bucket",\n        db_instance_type="dbInstanceType",\n        db_parameter_group_identifier="dbParameterGroupIdentifier",\n        db_storage_type="dbStorageType",\n        deployment_type="deploymentType",\n        log_delivery_configuration=timestream.CfnInfluxDBInstance.LogDeliveryConfigurationProperty(\n            s3_configuration=timestream.CfnInfluxDBInstance.S3ConfigurationProperty(\n                bucket_name="bucketName",\n                enabled=False\n            )\n        ),\n        name="name",\n        organization="organization",\n        password="password",\n        publicly_accessible=False,\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        username="username",\n        vpc_security_group_ids=["vpcSecurityGroupIds"],\n        vpc_subnet_ids=["vpcSubnetIds"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['allocated_storage', 'bucket', 'db_instance_type', 'db_parameter_group_identifier', 'db_storage_type', 'deployment_type', 'log_delivery_configuration', 'name', 'organization', 'password', 'publicly_accessible', 'tags', 'username', 'vpc_security_group_ids', 'vpc_subnet_ids']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnInfluxDBInstanceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnScheduledQueryProps
class CfnScheduledQueryPropsDef(BaseCfnProperty):
    error_report_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_ErrorReportConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Configuration for error reporting. Error reports will be generated when a problem is encountered when writing the query results.\n')
    notification_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_NotificationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Notification configuration for the scheduled query. A notification is sent by Timestream when a query run finishes, when the state is updated or when you delete it.\n')
    query_string: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The query string to run. Parameter names can be specified in the query string ``@`` character followed by an identifier. The named Parameter ``@scheduled_runtime`` is reserved and can be used in the query to get the time at which the query is scheduled to run. The timestamp calculated according to the ScheduleConfiguration parameter, will be the value of ``@scheduled_runtime`` paramater for each query run. For example, consider an instance of a scheduled query executing on 2021-12-01 00:00:00. For this instance, the ``@scheduled_runtime`` parameter is initialized to the timestamp 2021-12-01 00:00:00 when invoking the query.\n')
    schedule_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_ScheduleConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Schedule configuration.\n')
    scheduled_query_execution_role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN for the IAM role that Timestream will assume when running the scheduled query.\n')
    client_token: typing.Optional[str] = pydantic.Field(None, description='Using a ClientToken makes the call to CreateScheduledQuery idempotent, in other words, making the same request repeatedly will produce the same result. Making multiple identical CreateScheduledQuery requests has the same effect as making a single request. - If CreateScheduledQuery is called without a ``ClientToken`` , the Query SDK generates a ``ClientToken`` on your behalf. - After 8 hours, any request with the same ``ClientToken`` is treated as a new request.\n')
    kms_key_id: typing.Optional[str] = pydantic.Field(None, description='The Amazon KMS key used to encrypt the scheduled query resource, at-rest. If the Amazon KMS key is not specified, the scheduled query resource will be encrypted with a Timestream owned Amazon KMS key. To specify a KMS key, use the key ID, key ARN, alias name, or alias ARN. When using an alias name, prefix the name with *alias/* If ErrorReportConfiguration uses ``SSE_KMS`` as encryption type, the same KmsKeyId is used to encrypt the error report at rest.\n')
    scheduled_query_name: typing.Optional[str] = pydantic.Field(None, description='A name for the query. Scheduled query names must be unique within each Region.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='A list of key-value pairs to label the scheduled query.\n')
    target_configuration: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnScheduledQuery_TargetConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Scheduled query target store configuration.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-timestream-scheduledquery.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    cfn_scheduled_query_props = timestream.CfnScheduledQueryProps(\n        error_report_configuration=timestream.CfnScheduledQuery.ErrorReportConfigurationProperty(\n            s3_configuration=timestream.CfnScheduledQuery.S3ConfigurationProperty(\n                bucket_name="bucketName",\n\n                # the properties below are optional\n                encryption_option="encryptionOption",\n                object_key_prefix="objectKeyPrefix"\n            )\n        ),\n        notification_configuration=timestream.CfnScheduledQuery.NotificationConfigurationProperty(\n            sns_configuration=timestream.CfnScheduledQuery.SnsConfigurationProperty(\n                topic_arn="topicArn"\n            )\n        ),\n        query_string="queryString",\n        schedule_configuration=timestream.CfnScheduledQuery.ScheduleConfigurationProperty(\n            schedule_expression="scheduleExpression"\n        ),\n        scheduled_query_execution_role_arn="scheduledQueryExecutionRoleArn",\n\n        # the properties below are optional\n        client_token="clientToken",\n        kms_key_id="kmsKeyId",\n        scheduled_query_name="scheduledQueryName",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        target_configuration=timestream.CfnScheduledQuery.TargetConfigurationProperty(\n            timestream_configuration=timestream.CfnScheduledQuery.TimestreamConfigurationProperty(\n                database_name="databaseName",\n                dimension_mappings=[timestream.CfnScheduledQuery.DimensionMappingProperty(\n                    dimension_value_type="dimensionValueType",\n                    name="name"\n                )],\n                table_name="tableName",\n                time_column="timeColumn",\n\n                # the properties below are optional\n                measure_name_column="measureNameColumn",\n                mixed_measure_mappings=[timestream.CfnScheduledQuery.MixedMeasureMappingProperty(\n                    measure_value_type="measureValueType",\n\n                    # the properties below are optional\n                    measure_name="measureName",\n                    multi_measure_attribute_mappings=[timestream.CfnScheduledQuery.MultiMeasureAttributeMappingProperty(\n                        measure_value_type="measureValueType",\n                        source_column="sourceColumn",\n\n                        # the properties below are optional\n                        target_multi_measure_attribute_name="targetMultiMeasureAttributeName"\n                    )],\n                    source_column="sourceColumn",\n                    target_measure_name="targetMeasureName"\n                )],\n                multi_measure_mappings=timestream.CfnScheduledQuery.MultiMeasureMappingsProperty(\n                    multi_measure_attribute_mappings=[timestream.CfnScheduledQuery.MultiMeasureAttributeMappingProperty(\n                        measure_value_type="measureValueType",\n                        source_column="sourceColumn",\n\n                        # the properties below are optional\n                        target_multi_measure_attribute_name="targetMultiMeasureAttributeName"\n                    )],\n\n                    # the properties below are optional\n                    target_multi_measure_name="targetMultiMeasureName"\n                )\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['error_report_configuration', 'notification_configuration', 'query_string', 'schedule_configuration', 'scheduled_query_execution_role_arn', 'client_token', 'kms_key_id', 'scheduled_query_name', 'tags', 'target_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnScheduledQueryProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_timestream.CfnTableProps
class CfnTablePropsDef(BaseCfnProperty):
    database_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Timestream database that contains this table. *Length Constraints* : Minimum length of 3 bytes. Maximum length of 256 bytes.\n')
    magnetic_store_write_properties: typing.Any = pydantic.Field(None, description='Contains properties to set on the table when enabling magnetic store writes. This object has the following attributes: - *EnableMagneticStoreWrites* : A ``boolean`` flag to enable magnetic store writes. - *MagneticStoreRejectedDataLocation* : The location to write error reports for records rejected, asynchronously, during magnetic store writes. Only ``S3Configuration`` objects are allowed. The ``S3Configuration`` object has the following attributes: - *BucketName* : The name of the S3 bucket. - *EncryptionOption* : The encryption option for the S3 location. Valid values are S3 server-side encryption with an S3 managed key ( ``SSE_S3`` ) or AWS managed key ( ``SSE_KMS`` ). - *KmsKeyId* : The AWS KMS key ID to use when encrypting with an AWS managed key. - *ObjectKeyPrefix* : The prefix to use option for the objects stored in S3. Both ``BucketName`` and ``EncryptionOption`` are *required* when ``S3Configuration`` is specified. If you specify ``SSE_KMS`` as your ``EncryptionOption`` then ``KmsKeyId`` is *required* . ``EnableMagneticStoreWrites`` attribute is *required* when ``MagneticStoreWriteProperties`` is specified. ``MagneticStoreRejectedDataLocation`` attribute is *required* when ``EnableMagneticStoreWrites`` is set to ``true`` . See the following examples: *JSON:: { "Type" : AWS::Timestream::Table", "Properties":{ "DatabaseName":"TestDatabase", "TableName":"TestTable", "MagneticStoreWriteProperties":{ "EnableMagneticStoreWrites":true, "MagneticStoreRejectedDataLocation":{ "S3Configuration":{ "BucketName":"testbucket", "EncryptionOption":"SSE_KMS", "KmsKeyId":"1234abcd-12ab-34cd-56ef-1234567890ab", "ObjectKeyPrefix":"prefix" } } } } } *YAML:: Type: AWS::Timestream::Table DependsOn: TestDatabase Properties: TableName: "TestTable" DatabaseName: "TestDatabase" MagneticStoreWriteProperties: EnableMagneticStoreWrites: true MagneticStoreRejectedDataLocation: S3Configuration: BucketName: "testbucket" EncryptionOption: "SSE_KMS" KmsKeyId: "1234abcd-12ab-34cd-56ef-1234567890ab" ObjectKeyPrefix: "prefix"\n')
    retention_properties: typing.Any = pydantic.Field(None, description='The retention duration for the memory store and magnetic store. This object has the following attributes:. - *MemoryStoreRetentionPeriodInHours* : Retention duration for memory store, in hours. - *MagneticStoreRetentionPeriodInDays* : Retention duration for magnetic store, in days. Both attributes are of type ``string`` . Both attributes are *required* when ``RetentionProperties`` is specified. See the following examples: *JSON* ``{ "Type" : AWS::Timestream::Table", "Properties" : { "DatabaseName" : "TestDatabase", "TableName" : "TestTable", "RetentionProperties" : { "MemoryStoreRetentionPeriodInHours": "24", "MagneticStoreRetentionPeriodInDays": "7" } } }`` *YAML:: Type: AWS::Timestream::Table DependsOn: TestDatabase Properties: TableName: "TestTable" DatabaseName: "TestDatabase" RetentionProperties: MemoryStoreRetentionPeriodInHours: "24" MagneticStoreRetentionPeriodInDays: "7"\n')
    schema_: typing.Union[models.UnsupportedResource, models.aws_timestream.CfnTable_SchemaPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The schema of the table.\n', alias='schema')
    table_name: typing.Optional[str] = pydantic.Field(None, description='The name of the Timestream table. *Length Constraints* : Minimum length of 3 bytes. Maximum length of 256 bytes.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The tags to add to the table.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-timestream-table.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_timestream as timestream\n\n    # magnetic_store_write_properties: Any\n    # retention_properties: Any\n\n    cfn_table_props = timestream.CfnTableProps(\n        database_name="databaseName",\n\n        # the properties below are optional\n        magnetic_store_write_properties=magnetic_store_write_properties,\n        retention_properties=retention_properties,\n        schema=timestream.CfnTable.SchemaProperty(\n            composite_partition_key=[timestream.CfnTable.PartitionKeyProperty(\n                type="type",\n\n                # the properties below are optional\n                enforcement_in_record="enforcementInRecord",\n                name="name"\n            )]\n        ),\n        table_name="tableName",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['database_name', 'magnetic_store_write_properties', 'retention_properties', 'schema', 'table_name', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_timestream.CfnTableProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




class ModuleModel(pydantic.BaseModel):
    CfnInfluxDBInstance_LogDeliveryConfigurationProperty: typing.Optional[dict[str, models.aws_timestream.CfnInfluxDBInstance_LogDeliveryConfigurationPropertyDef]] = pydantic.Field(None)
    CfnInfluxDBInstance_S3ConfigurationProperty: typing.Optional[dict[str, models.aws_timestream.CfnInfluxDBInstance_S3ConfigurationPropertyDef]] = pydantic.Field(None)
    CfnScheduledQuery_DimensionMappingProperty: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQuery_DimensionMappingPropertyDef]] = pydantic.Field(None)
    CfnScheduledQuery_ErrorReportConfigurationProperty: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQuery_ErrorReportConfigurationPropertyDef]] = pydantic.Field(None)
    CfnScheduledQuery_MixedMeasureMappingProperty: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQuery_MixedMeasureMappingPropertyDef]] = pydantic.Field(None)
    CfnScheduledQuery_MultiMeasureAttributeMappingProperty: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQuery_MultiMeasureAttributeMappingPropertyDef]] = pydantic.Field(None)
    CfnScheduledQuery_MultiMeasureMappingsProperty: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQuery_MultiMeasureMappingsPropertyDef]] = pydantic.Field(None)
    CfnScheduledQuery_NotificationConfigurationProperty: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQuery_NotificationConfigurationPropertyDef]] = pydantic.Field(None)
    CfnScheduledQuery_S3ConfigurationProperty: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQuery_S3ConfigurationPropertyDef]] = pydantic.Field(None)
    CfnScheduledQuery_ScheduleConfigurationProperty: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQuery_ScheduleConfigurationPropertyDef]] = pydantic.Field(None)
    CfnScheduledQuery_SnsConfigurationProperty: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQuery_SnsConfigurationPropertyDef]] = pydantic.Field(None)
    CfnScheduledQuery_TargetConfigurationProperty: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQuery_TargetConfigurationPropertyDef]] = pydantic.Field(None)
    CfnScheduledQuery_TimestreamConfigurationProperty: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQuery_TimestreamConfigurationPropertyDef]] = pydantic.Field(None)
    CfnTable_MagneticStoreRejectedDataLocationProperty: typing.Optional[dict[str, models.aws_timestream.CfnTable_MagneticStoreRejectedDataLocationPropertyDef]] = pydantic.Field(None)
    CfnTable_MagneticStoreWritePropertiesProperty: typing.Optional[dict[str, models.aws_timestream.CfnTable_MagneticStoreWritePropertiesPropertyDef]] = pydantic.Field(None)
    CfnTable_PartitionKeyProperty: typing.Optional[dict[str, models.aws_timestream.CfnTable_PartitionKeyPropertyDef]] = pydantic.Field(None)
    CfnTable_RetentionPropertiesProperty: typing.Optional[dict[str, models.aws_timestream.CfnTable_RetentionPropertiesPropertyDef]] = pydantic.Field(None)
    CfnTable_S3ConfigurationProperty: typing.Optional[dict[str, models.aws_timestream.CfnTable_S3ConfigurationPropertyDef]] = pydantic.Field(None)
    CfnTable_SchemaProperty: typing.Optional[dict[str, models.aws_timestream.CfnTable_SchemaPropertyDef]] = pydantic.Field(None)
    CfnDatabase: typing.Optional[dict[str, models.aws_timestream.CfnDatabaseDef]] = pydantic.Field(None)
    CfnInfluxDBInstance: typing.Optional[dict[str, models.aws_timestream.CfnInfluxDBInstanceDef]] = pydantic.Field(None)
    CfnScheduledQuery: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQueryDef]] = pydantic.Field(None)
    CfnTable: typing.Optional[dict[str, models.aws_timestream.CfnTableDef]] = pydantic.Field(None)
    CfnDatabaseProps: typing.Optional[dict[str, models.aws_timestream.CfnDatabasePropsDef]] = pydantic.Field(None)
    CfnInfluxDBInstanceProps: typing.Optional[dict[str, models.aws_timestream.CfnInfluxDBInstancePropsDef]] = pydantic.Field(None)
    CfnScheduledQueryProps: typing.Optional[dict[str, models.aws_timestream.CfnScheduledQueryPropsDef]] = pydantic.Field(None)
    CfnTableProps: typing.Optional[dict[str, models.aws_timestream.CfnTablePropsDef]] = pydantic.Field(None)
    ...

import models
