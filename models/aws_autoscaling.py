from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_autoscaling.AutoScalingGroupRequireImdsv2Aspect
class AutoScalingGroupRequireImdsv2AspectDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['visit']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.AutoScalingGroupRequireImdsv2Aspect'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.AutoScalingGroupRequireImdsv2AspectDefConfig] = pydantic.Field(None)


class AutoScalingGroupRequireImdsv2AspectDefConfig(pydantic.BaseModel):
    visit: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupRequireImdsv2AspectDefVisitParams]] = pydantic.Field(None, description='All aspects can visit an IConstruct.')

class AutoScalingGroupRequireImdsv2AspectDefVisitParams(pydantic.BaseModel):
    node: models.AnyResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.BlockDeviceVolume
class BlockDeviceVolumeDef(BaseClass):
    ebs_device: typing.Union[models.aws_autoscaling.EbsDevicePropsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='EBS device info.')
    virtual_name: typing.Optional[str] = pydantic.Field(None, description='Virtual device name.')
    _init_params: typing.ClassVar[list[str]] = ['ebs_device', 'virtual_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['ebs', 'ebs_from_snapshot', 'ephemeral', 'no_device']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.BlockDeviceVolume'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.BlockDeviceVolumeDefConfig] = pydantic.Field(None)


class BlockDeviceVolumeDefConfig(pydantic.BaseModel):
    ebs: typing.Optional[list[models.aws_autoscaling.BlockDeviceVolumeDefEbsParams]] = pydantic.Field(None, description='Creates a new Elastic Block Storage device.')
    ebs_from_snapshot: typing.Optional[list[models.aws_autoscaling.BlockDeviceVolumeDefEbsFromSnapshotParams]] = pydantic.Field(None, description='Creates a new Elastic Block Storage device from an existing snapshot.')
    ephemeral: typing.Optional[list[models.aws_autoscaling.BlockDeviceVolumeDefEphemeralParams]] = pydantic.Field(None, description='Creates a virtual, ephemeral device.\nThe name will be in the form ephemeral{volumeIndex}.')
    no_device: typing.Optional[list[models.aws_autoscaling.BlockDeviceVolumeDefNoDeviceParams]] = pydantic.Field(None, description='Supresses a volume mapping.')

class BlockDeviceVolumeDefEbsParams(pydantic.BaseModel):
    volume_size: typing.Union[int, float] = pydantic.Field(..., description='The volume size, in Gibibytes (GiB).\n')
    encrypted: typing.Optional[bool] = pydantic.Field(None, description='Specifies whether the EBS volume is encrypted. Encrypted EBS volumes can only be attached to instances that support Amazon EBS encryption Default: false\n')
    delete_on_termination: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether to delete the volume when the instance is terminated. Default: - true for Amazon EC2 Auto Scaling, false otherwise (e.g. EBS)\n')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='The number of I/O operations per second (IOPS) to provision for the volume. Must only be set for ``volumeType``: ``EbsDeviceVolumeType.IO1`` The maximum ratio of IOPS to volume size (in GiB) is 50:1, so for 5,000 provisioned IOPS, you need at least 100 GiB storage on the volume. Default: - none, required for ``EbsDeviceVolumeType.IO1``\n')
    throughput: typing.Union[int, float, None] = pydantic.Field(None, description='The throughput that the volume supports, in MiB/s Takes a minimum of 125 and maximum of 1000. Default: - 125 MiB/s. Only valid on gp3 volumes.\n')
    volume_type: typing.Optional[aws_cdk.aws_autoscaling.EbsDeviceVolumeType] = pydantic.Field(None, description='The EBS volume type. Default: ``EbsDeviceVolumeType.GP2``')
    return_config: typing.Optional[list[models.aws_autoscaling.BlockDeviceVolumeDefConfig]] = pydantic.Field(None)
    ...

class BlockDeviceVolumeDefEbsFromSnapshotParams(pydantic.BaseModel):
    snapshot_id: str = pydantic.Field(..., description='The snapshot ID of the volume to use.\n')
    volume_size: typing.Union[int, float, None] = pydantic.Field(None, description='The volume size, in Gibibytes (GiB). If you specify volumeSize, it must be equal or greater than the size of the snapshot. Default: - The snapshot size\n')
    delete_on_termination: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether to delete the volume when the instance is terminated. Default: - true for Amazon EC2 Auto Scaling, false otherwise (e.g. EBS)\n')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='The number of I/O operations per second (IOPS) to provision for the volume. Must only be set for ``volumeType``: ``EbsDeviceVolumeType.IO1`` The maximum ratio of IOPS to volume size (in GiB) is 50:1, so for 5,000 provisioned IOPS, you need at least 100 GiB storage on the volume. Default: - none, required for ``EbsDeviceVolumeType.IO1``\n')
    throughput: typing.Union[int, float, None] = pydantic.Field(None, description='The throughput that the volume supports, in MiB/s Takes a minimum of 125 and maximum of 1000. Default: - 125 MiB/s. Only valid on gp3 volumes.\n')
    volume_type: typing.Optional[aws_cdk.aws_autoscaling.EbsDeviceVolumeType] = pydantic.Field(None, description='The EBS volume type. Default: ``EbsDeviceVolumeType.GP2``')
    return_config: typing.Optional[list[models.aws_autoscaling.BlockDeviceVolumeDefConfig]] = pydantic.Field(None)
    ...

class BlockDeviceVolumeDefEphemeralParams(pydantic.BaseModel):
    volume_index: typing.Union[int, float] = pydantic.Field(..., description='the volume index. Must be equal or greater than 0')
    return_config: typing.Optional[list[models.aws_autoscaling.BlockDeviceVolumeDefConfig]] = pydantic.Field(None)
    ...

class BlockDeviceVolumeDefNoDeviceParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_autoscaling.BlockDeviceVolumeDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_autoscaling.GroupMetric
class GroupMetricDef(BaseClass):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.GroupMetric'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.GroupMetrics
class GroupMetricsDef(BaseClass):
    metrics: list[models.aws_autoscaling.GroupMetricDef] = pydantic.Field(REQUIRED_INIT_PARAM)
    _init_params: typing.ClassVar[list[str]] = ['metrics']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['all']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.GroupMetrics'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.GroupMetricsDefConfig] = pydantic.Field(None)


class GroupMetricsDefConfig(pydantic.BaseModel):
    all: typing.Optional[list[models.aws_autoscaling.GroupMetricsDefAllParams]] = pydantic.Field(None, description='Report all group metrics.')

class GroupMetricsDefAllParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_autoscaling.GroupMetricsDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_autoscaling.HealthCheck
class HealthCheckDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['ec2', 'elb']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.HealthCheck'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.HealthCheckDefConfig] = pydantic.Field(None)


class HealthCheckDefConfig(pydantic.BaseModel):
    ec2: typing.Optional[list[models.aws_autoscaling.HealthCheckDefEc2Params]] = pydantic.Field(None, description='Use EC2 for health checks.')
    elb: typing.Optional[list[models.aws_autoscaling.HealthCheckDefElbParams]] = pydantic.Field(None, description='Use ELB for health checks.\nIt considers the instance unhealthy if it fails either the EC2 status checks or the load balancer health checks.')

class HealthCheckDefEc2Params(pydantic.BaseModel):
    grace: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Specified the time Auto Scaling waits before checking the health status of an EC2 instance that has come into service. Default: Duration.seconds(0)')
    return_config: typing.Optional[list[models.aws_autoscaling.HealthCheckDefConfig]] = pydantic.Field(None)
    ...

class HealthCheckDefElbParams(pydantic.BaseModel):
    grace: models.DurationDef = pydantic.Field(..., description='Specified the time Auto Scaling waits before checking the health status of an EC2 instance that has come into service. This option is required for ELB health checks.')
    return_config: typing.Optional[list[models.aws_autoscaling.HealthCheckDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_autoscaling.ScalingEvents
class ScalingEventsDef(BaseClass):
    types: list[aws_cdk.aws_autoscaling.ScalingEvent] = pydantic.Field(REQUIRED_INIT_PARAM)
    _init_params: typing.ClassVar[list[str]] = ['types']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.ScalingEvents'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.Schedule
class ScheduleDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['cron', 'expression']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.Schedule'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.ScheduleDefConfig] = pydantic.Field(None)


class ScheduleDefConfig(pydantic.BaseModel):
    cron: typing.Optional[list[models.aws_autoscaling.ScheduleDefCronParams]] = pydantic.Field(None, description='Create a schedule from a set of cron fields.')
    expression: typing.Optional[list[models.aws_autoscaling.ScheduleDefExpressionParams]] = pydantic.Field(None, description='Construct a schedule from a literal schedule expression.')

class ScheduleDefCronParams(pydantic.BaseModel):
    day: typing.Optional[str] = pydantic.Field(None, description='The day of the month to run this rule at. Default: - Every day of the month\n')
    hour: typing.Optional[str] = pydantic.Field(None, description='The hour to run this rule at. Default: - Every hour\n')
    minute: typing.Optional[str] = pydantic.Field(None, description='The minute to run this rule at. Default: - Every minute\n')
    month: typing.Optional[str] = pydantic.Field(None, description='The month to run this rule at. Default: - Every month\n')
    week_day: typing.Optional[str] = pydantic.Field(None, description='The day of the week to run this rule at. Default: - Any day of the week')
    return_config: typing.Optional[list[models.aws_autoscaling.ScheduleDefConfig]] = pydantic.Field(None)
    ...

class ScheduleDefExpressionParams(pydantic.BaseModel):
    expression: str = pydantic.Field(..., description='The expression to use. Must be in a format that AutoScaling will recognize\n\n:see: http://crontab.org/\n')
    return_config: typing.Optional[list[models.aws_autoscaling.ScheduleDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_autoscaling.Signals
class SignalsDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['render_creation_policy']
    _classmethod_names: typing.ClassVar[list[str]] = ['wait_for_all', 'wait_for_count', 'wait_for_min_capacity']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.Signals'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.SignalsDefConfig] = pydantic.Field(None)


class SignalsDefConfig(pydantic.BaseModel):
    render_creation_policy: typing.Optional[list[models.aws_autoscaling.SignalsDefRenderCreationPolicyParams]] = pydantic.Field(None, description="Render the ASG's CreationPolicy.")
    wait_for_all: typing.Optional[list[models.aws_autoscaling.SignalsDefWaitForAllParams]] = pydantic.Field(None, description='Wait for the desiredCapacity of the AutoScalingGroup amount of signals to have been received.\nIf no desiredCapacity has been configured, wait for minCapacity signals intead.\n\nThis number is used during initial creation and during replacing updates.\nDuring rolling updates, all updated instances must send a signal.')
    wait_for_count: typing.Optional[list[models.aws_autoscaling.SignalsDefWaitForCountParams]] = pydantic.Field(None, description='Wait for a specific amount of signals to have been received.\nYou should send one signal per instance, so this represents the number of\ninstances to wait for.\n\nThis number is used during initial creation and during replacing updates.\nDuring rolling updates, all updated instances must send a signal.')
    wait_for_min_capacity: typing.Optional[list[models.aws_autoscaling.SignalsDefWaitForMinCapacityParams]] = pydantic.Field(None, description='Wait for the minCapacity of the AutoScalingGroup amount of signals to have been received.\nThis number is used during initial creation and during replacing updates.\nDuring rolling updates, all updated instances must send a signal.')

class SignalsDefRenderCreationPolicyParams(pydantic.BaseModel):
    desired_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The desiredCapacity of the ASG. Default: - desired capacity not configured\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The minSize of the ASG. Default: - minCapacity not configured')
    ...

class SignalsDefWaitForAllParams(pydantic.BaseModel):
    min_success_percentage: typing.Union[int, float, None] = pydantic.Field(None, description='The percentage of signals that need to be successful. If this number is less than 100, a percentage of signals may be failure signals while still succeeding the creation or update in CloudFormation. Default: 100\n')
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='How long to wait for the signals to be sent. This should reflect how long it takes your instances to start up (including instance start time and instance initialization time). Default: Duration.minutes(5)')
    return_config: typing.Optional[list[models.aws_autoscaling.SignalsDefConfig]] = pydantic.Field(None)
    ...

class SignalsDefWaitForCountParams(pydantic.BaseModel):
    count: typing.Union[int, float] = pydantic.Field(..., description='-\n')
    min_success_percentage: typing.Union[int, float, None] = pydantic.Field(None, description='The percentage of signals that need to be successful. If this number is less than 100, a percentage of signals may be failure signals while still succeeding the creation or update in CloudFormation. Default: 100\n')
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='How long to wait for the signals to be sent. This should reflect how long it takes your instances to start up (including instance start time and instance initialization time). Default: Duration.minutes(5)')
    return_config: typing.Optional[list[models.aws_autoscaling.SignalsDefConfig]] = pydantic.Field(None)
    ...

class SignalsDefWaitForMinCapacityParams(pydantic.BaseModel):
    min_success_percentage: typing.Union[int, float, None] = pydantic.Field(None, description='The percentage of signals that need to be successful. If this number is less than 100, a percentage of signals may be failure signals while still succeeding the creation or update in CloudFormation. Default: 100\n')
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='How long to wait for the signals to be sent. This should reflect how long it takes your instances to start up (including instance start time and instance initialization time). Default: Duration.minutes(5)')
    return_config: typing.Optional[list[models.aws_autoscaling.SignalsDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_autoscaling.UpdatePolicy
class UpdatePolicyDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['replacing_update', 'rolling_update']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.UpdatePolicy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.UpdatePolicyDefConfig] = pydantic.Field(None)


class UpdatePolicyDefConfig(pydantic.BaseModel):
    replacing_update: typing.Optional[list[models.aws_autoscaling.UpdatePolicyDefReplacingUpdateParams]] = pydantic.Field(None, description='Create a new AutoScalingGroup and switch over to it.')
    rolling_update: typing.Optional[list[models.aws_autoscaling.UpdatePolicyDefRollingUpdateParams]] = pydantic.Field(None, description='Replace the instances in the AutoScalingGroup one by one, or in batches.')

class UpdatePolicyDefReplacingUpdateParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_autoscaling.UpdatePolicyDefConfig]] = pydantic.Field(None)
    ...

class UpdatePolicyDefRollingUpdateParams(pydantic.BaseModel):
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of instances that AWS CloudFormation updates at once. This number affects the speed of the replacement. Default: 1\n')
    min_instances_in_service: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum number of instances that must be in service before more instances are replaced. This number affects the speed of the replacement. Default: 0\n')
    min_success_percentage: typing.Union[int, float, None] = pydantic.Field(None, description='The percentage of instances that must signal success for the update to succeed. Default: - The ``minSuccessPercentage`` configured for ``signals`` on the AutoScalingGroup\n')
    pause_time: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The pause time after making a change to a batch of instances. Default: - The ``timeout`` configured for ``signals`` on the AutoScalingGroup\n')
    suspend_processes: typing.Optional[typing.Sequence[aws_cdk.aws_autoscaling.ScalingProcess]] = pydantic.Field(None, description='Specifies the Auto Scaling processes to suspend during a stack update. Suspending processes prevents Auto Scaling from interfering with a stack update. Default: HealthCheck, ReplaceUnhealthy, AZRebalance, AlarmNotification, ScheduledActions.\n')
    wait_on_resource_signals: typing.Optional[bool] = pydantic.Field(None, description='Specifies whether the Auto Scaling group waits on signals from new instances during an update. Default: true if you configured ``signals`` on the AutoScalingGroup, false otherwise')
    return_config: typing.Optional[list[models.aws_autoscaling.UpdatePolicyDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_autoscaling.AutoScalingGroup
class AutoScalingGroupDef(BaseConstruct, ConnectableMixin):
    vpc: typing.Union[_REQUIRED_INIT_PARAM, models.aws_ec2.VpcDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='VPC to launch these instances in.\n')
    init: typing.Optional[models.aws_ec2.CloudFormationInitDef] = pydantic.Field(None, description='Apply the given CloudFormation Init configuration to the instances in the AutoScalingGroup at startup. If you specify ``init``, you must also specify ``signals`` to configure the number of instances to wait for and the timeout for waiting for the init process. Default: - no CloudFormation init\n')
    init_options: typing.Union[models.aws_autoscaling.ApplyCloudFormationInitOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Use the given options for applying CloudFormation Init. Describes the configsets to use and the timeout to wait Default: - default options\n')
    instance_type: typing.Optional[models.aws_ec2.InstanceTypeDef] = pydantic.Field(None, description='Type of instance to launch. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Do not provide any instance type\n')
    launch_template: typing.Optional[typing.Union[models.aws_ec2.LaunchTemplateDef]] = pydantic.Field(None, description='Launch template to use. Launch configuration related settings and MixedInstancesPolicy must not be specified when a launch template is specified. Default: - Do not provide any launch template\n')
    machine_image: typing.Optional[typing.Union[models.aws_ec2.AmazonLinux2022ImageSsmParameterDef, models.aws_ec2.AmazonLinux2023ImageSsmParameterDef, models.aws_ec2.AmazonLinux2ImageSsmParameterDef, models.aws_ec2.AmazonLinuxImageDef, models.aws_ec2.AmazonLinuxImageSsmParameterBaseDef, models.aws_ec2.GenericLinuxImageDef, models.aws_ec2.GenericSSMParameterImageDef, models.aws_ec2.GenericWindowsImageDef, models.aws_ec2.LookupMachineImageDef, models.aws_ec2.NatInstanceImageDef, models.aws_ec2.ResolveSsmParameterAtLaunchImageDef, models.aws_ec2.WindowsImageDef, models.aws_ecs.BottleRocketImageDef, models.aws_ecs.EcsOptimizedImageDef, models.aws_eks.EksOptimizedImageDef]] = pydantic.Field(None, description='AMI to launch. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Do not provide any machine image\n')
    mixed_instances_policy: typing.Union[models.aws_autoscaling.MixedInstancesPolicyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Mixed Instances Policy to use. Launch configuration related settings and Launch Template must not be specified when a MixedInstancesPolicy is specified. Default: - Do not provide any MixedInstancesPolicy\n')
    require_imdsv2: typing.Optional[bool] = pydantic.Field(None, description='Whether IMDSv2 should be required on launched instances. Default: false\n')
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='An IAM role to associate with the instance profile assigned to this Auto Scaling Group. The role must be assumable by the service principal ``ec2.amazonaws.com``: ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: A role will automatically be created, it can be accessed via the ``role`` property\n')
    security_group: typing.Optional[typing.Union[models.aws_ec2.SecurityGroupDef]] = pydantic.Field(None, description='Security group to launch the instances in. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - A SecurityGroup will be created if none is specified.\n')
    user_data: typing.Optional[models.aws_ec2.UserDataDef] = pydantic.Field(None, description="Specific UserData to use. The UserData may still be mutated after creation. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - A UserData object appropriate for the MachineImage's Operating System is created.\n")
    allow_all_outbound: typing.Optional[bool] = pydantic.Field(None, description='Whether the instances can initiate connections to anywhere by default. Default: true\n')
    associate_public_ip_address: typing.Optional[bool] = pydantic.Field(None, description='Whether instances in the Auto Scaling Group should have public IP addresses associated with them. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Use subnet setting.\n')
    auto_scaling_group_name: typing.Optional[str] = pydantic.Field(None, description='The name of the Auto Scaling group. This name must be unique per Region per account. Default: - Auto generated by CloudFormation\n')
    block_devices: typing.Optional[typing.Sequence[typing.Union[models.aws_autoscaling.BlockDeviceDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies how block devices are exposed to the instance. You can specify virtual devices and EBS volumes. Each instance that is launched has an associated root device volume, either an Amazon EBS volume or an instance store volume. You can use block device mappings to specify additional EBS volumes or instance store volumes to attach to an instance when it is launched. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Uses the block device mapping of the AMI\n')
    capacity_rebalance: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether Capacity Rebalancing is enabled. When you turn on Capacity Rebalancing, Amazon EC2 Auto Scaling attempts to launch a Spot Instance whenever Amazon EC2 notifies that a Spot Instance is at an elevated risk of interruption. After launching a new instance, it then terminates an old instance. Default: false\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Default scaling cooldown for this AutoScalingGroup. Default: Duration.minutes(5)\n')
    default_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The amount of time, in seconds, until a newly launched instance can contribute to the Amazon CloudWatch metrics. This delay lets an instance finish initializing before Amazon EC2 Auto Scaling aggregates instance metrics, resulting in more reliable usage data. Set this value equal to the amount of time that it takes for resource consumption to become stable after an instance reaches the InService state. To optimize the performance of scaling policies that scale continuously, such as target tracking and step scaling policies, we strongly recommend that you enable the default instance warmup, even if its value is set to 0 seconds Default instance warmup will not be added if no value is specified Default: None\n')
    desired_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Initial amount of instances in the fleet. If this is set to a number, every deployment will reset the amount of instances to this number. It is recommended to leave this value blank. Default: minCapacity, and leave unchanged during deployment\n')
    group_metrics: typing.Optional[typing.Sequence[models.aws_autoscaling.GroupMetricsDef]] = pydantic.Field(None, description='Enable monitoring for group metrics, these metrics describe the group rather than any of its instances. To report all group metrics use ``GroupMetrics.all()`` Group metrics are reported in a granularity of 1 minute at no additional charge. Default: - no group metrics will be reported\n')
    health_check: typing.Optional[models.aws_autoscaling.HealthCheckDef] = pydantic.Field(None, description='Configuration for health checks. Default: - HealthCheck.ec2 with no grace period\n')
    ignore_unmodified_size_properties: typing.Optional[bool] = pydantic.Field(None, description="If the ASG has scheduled actions, don't reset unchanged group sizes. Only used if the ASG has scheduled actions (which may scale your ASG up or down regardless of cdk deployments). If true, the size of the group will only be reset if it has been changed in the CDK app. If false, the sizes will always be changed back to what they were in the CDK app on deployment. Default: true\n")
    instance_monitoring: typing.Optional[aws_cdk.aws_autoscaling.Monitoring] = pydantic.Field(None, description='Controls whether instances in this group are launched with detailed or basic monitoring. When detailed monitoring is enabled, Amazon CloudWatch generates metrics every minute and your account is charged a fee. When you disable detailed monitoring, CloudWatch generates metrics every 5 minutes. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Monitoring.DETAILED\n')
    key_name: typing.Optional[str] = pydantic.Field(None, description='Name of SSH keypair to grant access to instances. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - No SSH access will be possible.\n')
    max_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Maximum number of instances in the fleet. Default: desiredCapacity\n')
    max_instance_lifetime: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The maximum amount of time that an instance can be in service. The maximum duration applies to all current and future instances in the group. As an instance approaches its maximum duration, it is terminated and replaced, and cannot be used again. You must specify a value of at least 604,800 seconds (7 days). To clear a previously set value, leave this property undefined. Default: none\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum number of instances in the fleet. Default: 1\n')
    new_instances_protected_from_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Whether newly-launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. By default, Auto Scaling can terminate an instance at any time after launch when scaling in an Auto Scaling Group, subject to the group's termination policy. However, you may wish to protect newly-launched instances from being scaled in if they are going to run critical applications that should not be prematurely terminated. This flag must be enabled if the Auto Scaling Group will be associated with an ECS Capacity Provider with managed termination protection. Default: false\n")
    notifications: typing.Optional[typing.Sequence[typing.Union[models.aws_autoscaling.NotificationConfigurationDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Configure autoscaling group to send notifications about fleet changes to an SNS topic(s). Default: - No fleet change notifications will be sent.\n')
    signals: typing.Optional[models.aws_autoscaling.SignalsDef] = pydantic.Field(None, description='Configure waiting for signals during deployment. Use this to pause the CloudFormation deployment to wait for the instances in the AutoScalingGroup to report successful startup during creation and updates. The UserData script needs to invoke ``cfn-signal`` with a success or failure code after it is done setting up the instance. Without waiting for signals, the CloudFormation deployment will proceed as soon as the AutoScalingGroup has been created or updated but before the instances in the group have been started. For example, to have instances wait for an Elastic Load Balancing health check before they signal success, add a health-check verification by using the cfn-init helper script. For an example, see the verify_instance_health command in the Auto Scaling rolling updates sample template: https://github.com/awslabs/aws-cloudformation-templates/blob/master/aws/services/AutoScaling/AutoScalingRollingUpdates.yaml Default: - Do not wait for signals\n')
    spot_price: typing.Optional[str] = pydantic.Field(None, description='The maximum hourly price (in USD) to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot market price. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: none\n')
    ssm_session_permissions: typing.Optional[bool] = pydantic.Field(None, description='Add SSM session permissions to the instance role. Setting this to ``true`` adds the necessary permissions to connect to the instance using SSM Session Manager. You can do this from the AWS Console. NOTE: Setting this flag to ``true`` may not be enough by itself. You must also use an AMI that comes with the SSM Agent, or install the SSM Agent yourself. See `Working with SSM Agent <https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html>`_ in the SSM Developer Guide. Default: false\n')
    termination_policies: typing.Optional[typing.Sequence[aws_cdk.aws_autoscaling.TerminationPolicy]] = pydantic.Field(None, description='A policy or a list of policies that are used to select the instances to terminate. The policies are executed in the order that you list them. Default: - ``TerminationPolicy.DEFAULT``\n')
    update_policy: typing.Optional[models.aws_autoscaling.UpdatePolicyDef] = pydantic.Field(None, description="What to do when an AutoScalingGroup's instance configuration is changed. This is applied when any of the settings on the ASG are changed that affect how the instances should be created (VPC, instance type, startup scripts, etc.). It indicates how the existing instances should be replaced with new instances matching the new config. By default, nothing is done and only new instances are launched with the new config. Default: - ``UpdatePolicy.rollingUpdate()`` if using ``init``, ``UpdatePolicy.none()`` otherwise\n")
    vpc_subnets: typing.Union[models.aws_ec2.SubnetSelectionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Where to place instances within the VPC. Default: - All Private subnets.')
    _init_params: typing.ClassVar[list[str]] = ['vpc', 'init', 'init_options', 'instance_type', 'launch_template', 'machine_image', 'mixed_instances_policy', 'require_imdsv2', 'role', 'security_group', 'user_data', 'allow_all_outbound', 'associate_public_ip_address', 'auto_scaling_group_name', 'block_devices', 'capacity_rebalance', 'cooldown', 'default_instance_warmup', 'desired_capacity', 'group_metrics', 'health_check', 'ignore_unmodified_size_properties', 'instance_monitoring', 'key_name', 'max_capacity', 'max_instance_lifetime', 'min_capacity', 'new_instances_protected_from_scale_in', 'notifications', 'signals', 'spot_price', 'ssm_session_permissions', 'termination_policies', 'update_policy', 'vpc_subnets']
    _method_names: typing.ClassVar[list[str]] = ['add_lifecycle_hook', 'add_security_group', 'add_to_role_policy', 'add_user_data', 'add_warm_pool', 'apply_cloud_formation_init', 'apply_removal_policy', 'are_new_instances_protected_from_scale_in', 'attach_to_application_target_group', 'attach_to_classic_lb', 'attach_to_network_target_group', 'protect_new_instances_from_scale_in', 'scale_on_cpu_utilization', 'scale_on_incoming_bytes', 'scale_on_metric', 'scale_on_outgoing_bytes', 'scale_on_request_count', 'scale_on_schedule', 'scale_to_track_metric']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_auto_scaling_group_name']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.AutoScalingGroup'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_auto_scaling_group_name']
    ...


    from_auto_scaling_group_name: typing.Optional[models.aws_autoscaling.AutoScalingGroupDefFromAutoScalingGroupNameParams] = pydantic.Field(None, description='')
    resource_config: typing.Optional[models.aws_autoscaling.AutoScalingGroupDefConfig] = pydantic.Field(None)


class AutoScalingGroupDefConfig(pydantic.BaseModel):
    add_lifecycle_hook: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefAddLifecycleHookParams]] = pydantic.Field(None, description='Send a message to either an SQS queue or SNS topic when instances launch or terminate.')
    add_security_group: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefAddSecurityGroupParams]] = pydantic.Field(None, description='Add the security group to all instances via the launch template security groups array.')
    add_to_role_policy: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefAddToRolePolicyParams]] = pydantic.Field(None, description='Adds a statement to the IAM role assumed by instances of this fleet.')
    add_user_data: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefAddUserDataParams]] = pydantic.Field(None, description="Add command to the startup script of fleet instances.\nThe command must be in the scripting language supported by the fleet's OS (i.e. Linux/Windows).\nDoes nothing for imported ASGs.")
    add_warm_pool: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefAddWarmPoolParams]] = pydantic.Field(None, description='Add a pool of pre-initialized EC2 instances that sits alongside an Auto Scaling group.')
    apply_cloud_formation_init: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefApplyCloudFormationInitParams]] = pydantic.Field(None, description="Use a CloudFormation Init configuration at instance startup.\nThis does the following:\n\n- Attaches the CloudFormation Init metadata to the AutoScalingGroup resource.\n- Add commands to the UserData to run ``cfn-init`` and ``cfn-signal``.\n- Update the instance's CreationPolicy to wait for ``cfn-init`` to finish\n  before reporting success.")
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    are_new_instances_protected_from_scale_in: typing.Optional[bool] = pydantic.Field(None, description='Returns ``true`` if newly-launched instances are protected from scale-in.')
    attach_to_application_target_group: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefAttachToApplicationTargetGroupParams]] = pydantic.Field(None, description='Attach to ELBv2 Application Target Group.')
    attach_to_classic_lb: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefAttachToClassicLbParams]] = pydantic.Field(None, description='Attach to a classic load balancer.')
    attach_to_network_target_group: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefAttachToNetworkTargetGroupParams]] = pydantic.Field(None, description='Attach to ELBv2 Application Target Group.')
    protect_new_instances_from_scale_in: typing.Optional[bool] = pydantic.Field(None, description='Ensures newly-launched instances are protected from scale-in.')
    scale_on_cpu_utilization: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefScaleOnCpuUtilizationParams]] = pydantic.Field(None, description='Scale out or in to achieve a target CPU utilization.')
    scale_on_incoming_bytes: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefScaleOnIncomingBytesParams]] = pydantic.Field(None, description='Scale out or in to achieve a target network ingress rate.')
    scale_on_metric: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefScaleOnMetricParams]] = pydantic.Field(None, description='Scale out or in, in response to a metric.')
    scale_on_outgoing_bytes: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefScaleOnOutgoingBytesParams]] = pydantic.Field(None, description='Scale out or in to achieve a target network egress rate.')
    scale_on_request_count: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefScaleOnRequestCountParams]] = pydantic.Field(None, description='Scale out or in to achieve a target request handling rate.\nThe AutoScalingGroup must have been attached to an Application Load Balancer\nin order to be able to call this.')
    scale_on_schedule: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefScaleOnScheduleParams]] = pydantic.Field(None, description='Scale out or in based on time.')
    scale_to_track_metric: typing.Optional[list[models.aws_autoscaling.AutoScalingGroupDefScaleToTrackMetricParams]] = pydantic.Field(None, description='Scale out or in in order to keep a metric around a target value.')
    connections_config: typing.Optional[models.aws_ec2.ConnectionsDefConfig] = pydantic.Field(None)
    grant_principal_config: typing.Optional[models._interface_methods.AwsIamIPrincipalDefConfig] = pydantic.Field(None)
    role_config: typing.Optional[models._interface_methods.AwsIamIRoleDefConfig] = pydantic.Field(None)
    user_data_config: typing.Optional[models.aws_ec2.UserDataDefConfig] = pydantic.Field(None)

class AutoScalingGroupDefAddLifecycleHookParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    lifecycle_transition: aws_cdk.aws_autoscaling.LifecycleTransition = pydantic.Field(..., description='The state of the Amazon EC2 instance to which you want to attach the lifecycle hook.\n')
    default_result: typing.Optional[aws_cdk.aws_autoscaling.DefaultResult] = pydantic.Field(None, description='The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. Default: Continue\n')
    heartbeat_timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Maximum time between calls to RecordLifecycleActionHeartbeat for the hook. If the lifecycle hook times out, perform the action in DefaultResult. Default: - No heartbeat timeout.\n')
    lifecycle_hook_name: typing.Optional[str] = pydantic.Field(None, description='Name of the lifecycle hook. Default: - Automatically generated name.\n')
    notification_metadata: typing.Optional[str] = pydantic.Field(None, description='Additional data to pass to the lifecycle hook target. Default: - No metadata.\n')
    notification_target: typing.Optional[typing.Union[models.aws_autoscaling_hooktargets.FunctionHookDef, models.aws_autoscaling_hooktargets.QueueHookDef, models.aws_autoscaling_hooktargets.TopicHookDef]] = pydantic.Field(None, description='The target of the lifecycle hook. Default: - No target.\n')
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The role that allows publishing to the notification target. Default: - A role will be created if a target is provided. Otherwise, no role is created.')
    return_config: typing.Optional[list[models.aws_autoscaling.LifecycleHookDefConfig]] = pydantic.Field(None)
    ...

class AutoScalingGroupDefAddSecurityGroupParams(pydantic.BaseModel):
    security_group: typing.Union[models.aws_ec2.SecurityGroupDef] = pydantic.Field(..., description=': The security group to add.')
    ...

class AutoScalingGroupDefAddToRolePolicyParams(pydantic.BaseModel):
    statement: models.aws_iam.PolicyStatementDef = pydantic.Field(..., description='-')
    ...

class AutoScalingGroupDefAddUserDataParams(pydantic.BaseModel):
    commands: list[str] = pydantic.Field(...)
    ...

class AutoScalingGroupDefAddWarmPoolParams(pydantic.BaseModel):
    max_group_prepared_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="The maximum number of instances that are allowed to be in the warm pool or in any state except Terminated for the Auto Scaling group. If the value is not specified, Amazon EC2 Auto Scaling launches and maintains the difference between the group's maximum capacity and its desired capacity. Default: - max size of the Auto Scaling group\n")
    min_size: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum number of instances to maintain in the warm pool. Default: 0\n')
    pool_state: typing.Optional[aws_cdk.aws_autoscaling.PoolState] = pydantic.Field(None, description='The instance state to transition to after the lifecycle actions are complete. Default: PoolState.STOPPED\n')
    reuse_on_scale_in: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether instances in the Auto Scaling group can be returned to the warm pool on scale in. If the value is not specified, instances in the Auto Scaling group will be terminated when the group scales in. Default: false')
    return_config: typing.Optional[list[models.aws_autoscaling.WarmPoolDefConfig]] = pydantic.Field(None)
    ...

class AutoScalingGroupDefApplyCloudFormationInitParams(pydantic.BaseModel):
    init: models.aws_ec2.CloudFormationInitDef = pydantic.Field(..., description='-\n')
    config_sets: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="ConfigSet to activate. Default: ['default']\n")
    embed_fingerprint: typing.Optional[bool] = pydantic.Field(None, description='Force instance replacement by embedding a config fingerprint. If ``true`` (the default), a hash of the config will be embedded into the UserData, so that if the config changes, the UserData changes and instances will be replaced (given an UpdatePolicy has been configured on the AutoScalingGroup). If ``false``, no such hash will be embedded, and if the CloudFormation Init config changes nothing will happen to the running instances. If a config update introduces errors, you will not notice until after the CloudFormation deployment successfully finishes and the next instance fails to launch. Default: true\n')
    ignore_failures: typing.Optional[bool] = pydantic.Field(None, description="Don't fail the instance creation when cfn-init fails. You can use this to prevent CloudFormation from rolling back when instances fail to start up, to help in debugging. Default: false\n")
    include_role: typing.Optional[bool] = pydantic.Field(None, description='Include --role argument when running cfn-init and cfn-signal commands. This will be the IAM instance profile attached to the EC2 instance Default: false\n')
    include_url: typing.Optional[bool] = pydantic.Field(None, description='Include --url argument when running cfn-init and cfn-signal commands. This will be the cloudformation endpoint in the deployed region e.g. https://cloudformation.us-east-1.amazonaws.com Default: false\n')
    print_log: typing.Optional[bool] = pydantic.Field(None, description='Print the results of running cfn-init to the Instance System Log. By default, the output of running cfn-init is written to a log file on the instance. Set this to ``true`` to print it to the System Log (visible from the EC2 Console), ``false`` to not print it. (Be aware that the system log is refreshed at certain points in time of the instance life cycle, and successful execution may not always show up). Default: true')
    ...

class AutoScalingGroupDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class AutoScalingGroupDefAttachToApplicationTargetGroupParams(pydantic.BaseModel):
    target_group: typing.Union[models.aws_elasticloadbalancingv2.ApplicationTargetGroupDef] = pydantic.Field(..., description='-')
    ...

class AutoScalingGroupDefAttachToClassicLbParams(pydantic.BaseModel):
    load_balancer: models.aws_elasticloadbalancing.LoadBalancerDef = pydantic.Field(..., description='-')
    ...

class AutoScalingGroupDefAttachToNetworkTargetGroupParams(pydantic.BaseModel):
    target_group: typing.Union[models.aws_elasticloadbalancingv2.NetworkTargetGroupDef] = pydantic.Field(..., description='-')
    ...

class AutoScalingGroupDefFromAutoScalingGroupNameParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-')
    id: str = pydantic.Field(..., description='-\n')
    auto_scaling_group_name: str = pydantic.Field(..., description='-')
    ...

class AutoScalingGroupDefScaleOnCpuUtilizationParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    target_utilization_percent: typing.Union[int, float] = pydantic.Field(..., description='Target average CPU utilization across the task.\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.')
    ...

class AutoScalingGroupDefScaleOnIncomingBytesParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    target_bytes_per_second: typing.Union[int, float] = pydantic.Field(..., description='Target average bytes/seconds on each instance.\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.')
    ...

class AutoScalingGroupDefScaleOnMetricParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    metric: typing.Union[models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef] = pydantic.Field(..., description='Metric to scale on.\n')
    scaling_steps: typing.Sequence[typing.Union[models.aws_autoscaling.ScalingIntervalDef, dict[str, typing.Any]]] = pydantic.Field(..., description='The intervals for scaling. Maps a range of metric values to a particular scaling behavior. Must be between 2 and 40 steps.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_autoscaling.AdjustmentType] = pydantic.Field(None, description="How the adjustment numbers inside 'intervals' are interpreted. Default: ChangeInCapacity\n")
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Grace period after scaling activity. Default: Default cooldown period on your AutoScalingGroup\n')
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: Same as the cooldown\n')
    evaluation_periods: typing.Union[int, float, None] = pydantic.Field(None, description='How many evaluation periods of the metric to wait before triggering a scaling action. Raising this value can be used to smooth out the metric, at the expense of slower response times. Default: 1\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_autoscaling.MetricAggregationType] = pydantic.Field(None, description='Aggregation to apply to all data points over the evaluation periods. Only has meaning if ``evaluationPeriods != 1``. Default: - The statistic from the metric if applicable (MIN, MAX, AVERAGE), otherwise AVERAGE.\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect')
    ...

class AutoScalingGroupDefScaleOnOutgoingBytesParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    target_bytes_per_second: typing.Union[int, float] = pydantic.Field(..., description='Target average bytes/seconds on each instance.\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.')
    ...

class AutoScalingGroupDefScaleOnRequestCountParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    target_requests_per_minute: typing.Union[int, float, None] = pydantic.Field(None, description="Target average requests/minute on each instance. Default: - Specify exactly one of 'targetRequestsPerMinute' and 'targetRequestsPerSecond'\n")
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.')
    ...

class AutoScalingGroupDefScaleOnScheduleParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    schedule: models.aws_autoscaling.ScheduleDef = pydantic.Field(..., description='When to perform this action. Supports cron expressions. For more information about cron expressions, see https://en.wikipedia.org/wiki/Cron.\n')
    desired_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new desired capacity. At the scheduled time, set the desired capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new desired capacity.\n')
    end_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action expires. Default: - The rule never expires.\n')
    max_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new maximum capacity. At the scheduled time, set the maximum capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new maximum capacity.\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new minimum capacity. At the scheduled time, set the minimum capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new minimum capacity.\n')
    start_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action becomes active. Default: - The rule is activate immediately.\n')
    time_zone: typing.Optional[str] = pydantic.Field(None, description='Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as Etc/GMT+9 or Pacific/Tahiti). For more information, see https://en.wikipedia.org/wiki/List_of_tz_database_time_zones. Default: - UTC')
    return_config: typing.Optional[list[models.aws_autoscaling.ScheduledActionDefConfig]] = pydantic.Field(None)
    ...

class AutoScalingGroupDefScaleToTrackMetricParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    metric: typing.Union[models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef] = pydantic.Field(..., description="Metric to track. The metric must represent a utilization, so that if it's higher than the target value, your ASG should scale out, and if it's lower it should scale in.\n")
    target_value: typing.Union[int, float] = pydantic.Field(..., description='Value to keep the metric around.\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.LifecycleHook
class LifecycleHookDef(BaseConstruct):
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AutoScalingGroup to add the lifecycle hook to.\n')
    lifecycle_transition: typing.Union[aws_cdk.aws_autoscaling.LifecycleTransition, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The state of the Amazon EC2 instance to which you want to attach the lifecycle hook.\n')
    default_result: typing.Optional[aws_cdk.aws_autoscaling.DefaultResult] = pydantic.Field(None, description='The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. Default: Continue\n')
    heartbeat_timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Maximum time between calls to RecordLifecycleActionHeartbeat for the hook. If the lifecycle hook times out, perform the action in DefaultResult. Default: - No heartbeat timeout.\n')
    lifecycle_hook_name: typing.Optional[str] = pydantic.Field(None, description='Name of the lifecycle hook. Default: - Automatically generated name.\n')
    notification_metadata: typing.Optional[str] = pydantic.Field(None, description='Additional data to pass to the lifecycle hook target. Default: - No metadata.\n')
    notification_target: typing.Optional[typing.Union[models.aws_autoscaling_hooktargets.FunctionHookDef, models.aws_autoscaling_hooktargets.QueueHookDef, models.aws_autoscaling_hooktargets.TopicHookDef]] = pydantic.Field(None, description='The target of the lifecycle hook. Default: - No target.\n')
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The role that allows publishing to the notification target. Default: - A role will be created if a target is provided. Otherwise, no role is created.')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group', 'lifecycle_transition', 'default_result', 'heartbeat_timeout', 'lifecycle_hook_name', 'notification_metadata', 'notification_target', 'role']
    _method_names: typing.ClassVar[list[str]] = ['apply_removal_policy']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.LifecycleHook'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.LifecycleHookDefConfig] = pydantic.Field(None)


class LifecycleHookDefConfig(pydantic.BaseModel):
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    role_config: typing.Optional[models._interface_methods.AwsIamIRoleDefConfig] = pydantic.Field(None)

class LifecycleHookDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.ScheduledAction
class ScheduledActionDef(BaseConstruct):
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AutoScalingGroup to apply the scheduled actions to.\n')
    schedule: typing.Union[models.aws_autoscaling.ScheduleDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='When to perform this action. Supports cron expressions. For more information about cron expressions, see https://en.wikipedia.org/wiki/Cron.\n')
    desired_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new desired capacity. At the scheduled time, set the desired capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new desired capacity.\n')
    end_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action expires. Default: - The rule never expires.\n')
    max_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new maximum capacity. At the scheduled time, set the maximum capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new maximum capacity.\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new minimum capacity. At the scheduled time, set the minimum capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new minimum capacity.\n')
    start_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action becomes active. Default: - The rule is activate immediately.\n')
    time_zone: typing.Optional[str] = pydantic.Field(None, description='Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as Etc/GMT+9 or Pacific/Tahiti). For more information, see https://en.wikipedia.org/wiki/List_of_tz_database_time_zones. Default: - UTC')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group', 'schedule', 'desired_capacity', 'end_time', 'max_capacity', 'min_capacity', 'start_time', 'time_zone']
    _method_names: typing.ClassVar[list[str]] = ['apply_removal_policy']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.ScheduledAction'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.ScheduledActionDefConfig] = pydantic.Field(None)


class ScheduledActionDefConfig(pydantic.BaseModel):
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)

class ScheduledActionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.StepScalingAction
class StepScalingActionDef(BaseConstruct):
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The auto scaling group.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_autoscaling.AdjustmentType] = pydantic.Field(None, description='How the adjustment numbers are interpreted. Default: ChangeInCapacity\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: The default cooldown configured on the AutoScalingGroup\n')
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: Same as the cooldown\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_autoscaling.MetricAggregationType] = pydantic.Field(None, description='The aggregation type for the CloudWatch metrics. Default: Average\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group', 'adjustment_type', 'cooldown', 'estimated_instance_warmup', 'metric_aggregation_type', 'min_adjustment_magnitude']
    _method_names: typing.ClassVar[list[str]] = ['add_adjustment']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.StepScalingAction'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.StepScalingActionDefConfig] = pydantic.Field(None)


class StepScalingActionDefConfig(pydantic.BaseModel):
    add_adjustment: typing.Optional[list[models.aws_autoscaling.StepScalingActionDefAddAdjustmentParams]] = pydantic.Field(None, description='Add an adjusment interval to the ScalingAction.')

class StepScalingActionDefAddAdjustmentParams(pydantic.BaseModel):
    adjustment: typing.Union[int, float] = pydantic.Field(..., description='What number to adjust the capacity with. The number is interpeted as an added capacity, a new fixed capacity or an added percentage depending on the AdjustmentType value of the StepScalingPolicy. Can be positive or negative.\n')
    lower_bound: typing.Union[int, float, None] = pydantic.Field(None, description='Lower bound where this scaling tier applies. The scaling tier applies if the difference between the metric value and its alarm threshold is higher than this value. Default: -Infinity if this is the first tier, otherwise the upperBound of the previous tier\n')
    upper_bound: typing.Union[int, float, None] = pydantic.Field(None, description='Upper bound where this scaling tier applies. The scaling tier applies if the difference between the metric value and its alarm threshold is lower than this value. Default: +Infinity')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.StepScalingPolicy
class StepScalingPolicyDef(BaseConstruct):
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The auto scaling group.\n')
    metric: typing.Union[_REQUIRED_INIT_PARAM, models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='Metric to scale on.\n')
    scaling_steps: typing.Union[typing.Sequence[typing.Union[models.aws_autoscaling.ScalingIntervalDef, dict[str, typing.Any]]], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The intervals for scaling. Maps a range of metric values to a particular scaling behavior. Must be between 2 and 40 steps.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_autoscaling.AdjustmentType] = pydantic.Field(None, description="How the adjustment numbers inside 'intervals' are interpreted. Default: ChangeInCapacity\n")
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Grace period after scaling activity. Default: Default cooldown period on your AutoScalingGroup\n')
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: Same as the cooldown\n')
    evaluation_periods: typing.Union[int, float, None] = pydantic.Field(None, description='How many evaluation periods of the metric to wait before triggering a scaling action. Raising this value can be used to smooth out the metric, at the expense of slower response times. Default: 1\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_autoscaling.MetricAggregationType] = pydantic.Field(None, description='Aggregation to apply to all data points over the evaluation periods. Only has meaning if ``evaluationPeriods != 1``. Default: - The statistic from the metric if applicable (MIN, MAX, AVERAGE), otherwise AVERAGE.\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group', 'metric', 'scaling_steps', 'adjustment_type', 'cooldown', 'estimated_instance_warmup', 'evaluation_periods', 'metric_aggregation_type', 'min_adjustment_magnitude']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.StepScalingPolicy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.TargetTrackingScalingPolicy
class TargetTrackingScalingPolicyDef(BaseConstruct):
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='')
    target_value: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The target value for the metric.\n')
    custom_metric: typing.Optional[typing.Union[models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef]] = pydantic.Field(None, description='A custom metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No custom metric.\n')
    predefined_metric: typing.Optional[aws_cdk.aws_autoscaling.PredefinedMetric] = pydantic.Field(None, description='A predefined metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No predefined metric.\n')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='The resource label associated with the predefined metric. Should be supplied if the predefined metric is ALBRequestCountPerTarget, and the format should be: app///targetgroup// Default: - No resource label.\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group', 'target_value', 'custom_metric', 'predefined_metric', 'resource_label', 'cooldown', 'disable_scale_in', 'estimated_instance_warmup']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.TargetTrackingScalingPolicy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.WarmPool
class WarmPoolDef(BaseConstruct):
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Auto Scaling group to add the warm pool to.\n')
    max_group_prepared_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="The maximum number of instances that are allowed to be in the warm pool or in any state except Terminated for the Auto Scaling group. If the value is not specified, Amazon EC2 Auto Scaling launches and maintains the difference between the group's maximum capacity and its desired capacity. Default: - max size of the Auto Scaling group\n")
    min_size: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum number of instances to maintain in the warm pool. Default: 0\n')
    pool_state: typing.Optional[aws_cdk.aws_autoscaling.PoolState] = pydantic.Field(None, description='The instance state to transition to after the lifecycle actions are complete. Default: PoolState.STOPPED\n')
    reuse_on_scale_in: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether instances in the Auto Scaling group can be returned to the warm pool on scale in. If the value is not specified, instances in the Auto Scaling group will be terminated when the group scales in. Default: false')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group', 'max_group_prepared_capacity', 'min_size', 'pool_state', 'reuse_on_scale_in']
    _method_names: typing.ClassVar[list[str]] = ['apply_removal_policy']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.WarmPool'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.WarmPoolDefConfig] = pydantic.Field(None)


class WarmPoolDefConfig(pydantic.BaseModel):
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)

class WarmPoolDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.AdjustmentTier
class AdjustmentTierDef(BaseStruct):
    adjustment: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='What number to adjust the capacity with. The number is interpeted as an added capacity, a new fixed capacity or an added percentage depending on the AdjustmentType value of the StepScalingPolicy. Can be positive or negative.\n')
    lower_bound: typing.Union[int, float, None] = pydantic.Field(None, description='Lower bound where this scaling tier applies. The scaling tier applies if the difference between the metric value and its alarm threshold is higher than this value. Default: -Infinity if this is the first tier, otherwise the upperBound of the previous tier\n')
    upper_bound: typing.Union[int, float, None] = pydantic.Field(None, description='Upper bound where this scaling tier applies. The scaling tier applies if the difference between the metric value and its alarm threshold is lower than this value. Default: +Infinity\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    adjustment_tier = autoscaling.AdjustmentTier(\n        adjustment=123,\n\n        # the properties below are optional\n        lower_bound=123,\n        upper_bound=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['adjustment', 'lower_bound', 'upper_bound']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.AdjustmentTier'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.ApplyCloudFormationInitOptions
class ApplyCloudFormationInitOptionsDef(BaseStruct):
    config_sets: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="ConfigSet to activate. Default: ['default']\n")
    embed_fingerprint: typing.Optional[bool] = pydantic.Field(None, description='Force instance replacement by embedding a config fingerprint. If ``true`` (the default), a hash of the config will be embedded into the UserData, so that if the config changes, the UserData changes and instances will be replaced (given an UpdatePolicy has been configured on the AutoScalingGroup). If ``false``, no such hash will be embedded, and if the CloudFormation Init config changes nothing will happen to the running instances. If a config update introduces errors, you will not notice until after the CloudFormation deployment successfully finishes and the next instance fails to launch. Default: true\n')
    ignore_failures: typing.Optional[bool] = pydantic.Field(None, description="Don't fail the instance creation when cfn-init fails. You can use this to prevent CloudFormation from rolling back when instances fail to start up, to help in debugging. Default: false\n")
    include_role: typing.Optional[bool] = pydantic.Field(None, description='Include --role argument when running cfn-init and cfn-signal commands. This will be the IAM instance profile attached to the EC2 instance Default: false\n')
    include_url: typing.Optional[bool] = pydantic.Field(None, description='Include --url argument when running cfn-init and cfn-signal commands. This will be the cloudformation endpoint in the deployed region e.g. https://cloudformation.us-east-1.amazonaws.com Default: false\n')
    print_log: typing.Optional[bool] = pydantic.Field(None, description='Print the results of running cfn-init to the Instance System Log. By default, the output of running cfn-init is written to a log file on the instance. Set this to ``true`` to print it to the System Log (visible from the EC2 Console), ``false`` to not print it. (Be aware that the system log is refreshed at certain points in time of the instance life cycle, and successful execution may not always show up). Default: true\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    apply_cloud_formation_init_options = autoscaling.ApplyCloudFormationInitOptions(\n        config_sets=["configSets"],\n        embed_fingerprint=False,\n        ignore_failures=False,\n        include_role=False,\n        include_url=False,\n        print_log=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['config_sets', 'embed_fingerprint', 'ignore_failures', 'include_role', 'include_url', 'print_log']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.ApplyCloudFormationInitOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.AutoScalingGroupProps
class AutoScalingGroupPropsDef(BaseStruct):
    allow_all_outbound: typing.Optional[bool] = pydantic.Field(None, description='Whether the instances can initiate connections to anywhere by default. Default: true\n')
    associate_public_ip_address: typing.Optional[bool] = pydantic.Field(None, description='Whether instances in the Auto Scaling Group should have public IP addresses associated with them. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Use subnet setting.\n')
    auto_scaling_group_name: typing.Optional[str] = pydantic.Field(None, description='The name of the Auto Scaling group. This name must be unique per Region per account. Default: - Auto generated by CloudFormation\n')
    block_devices: typing.Optional[typing.Sequence[typing.Union[models.aws_autoscaling.BlockDeviceDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies how block devices are exposed to the instance. You can specify virtual devices and EBS volumes. Each instance that is launched has an associated root device volume, either an Amazon EBS volume or an instance store volume. You can use block device mappings to specify additional EBS volumes or instance store volumes to attach to an instance when it is launched. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Uses the block device mapping of the AMI\n')
    capacity_rebalance: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether Capacity Rebalancing is enabled. When you turn on Capacity Rebalancing, Amazon EC2 Auto Scaling attempts to launch a Spot Instance whenever Amazon EC2 notifies that a Spot Instance is at an elevated risk of interruption. After launching a new instance, it then terminates an old instance. Default: false\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Default scaling cooldown for this AutoScalingGroup. Default: Duration.minutes(5)\n')
    default_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The amount of time, in seconds, until a newly launched instance can contribute to the Amazon CloudWatch metrics. This delay lets an instance finish initializing before Amazon EC2 Auto Scaling aggregates instance metrics, resulting in more reliable usage data. Set this value equal to the amount of time that it takes for resource consumption to become stable after an instance reaches the InService state. To optimize the performance of scaling policies that scale continuously, such as target tracking and step scaling policies, we strongly recommend that you enable the default instance warmup, even if its value is set to 0 seconds Default instance warmup will not be added if no value is specified Default: None\n')
    desired_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Initial amount of instances in the fleet. If this is set to a number, every deployment will reset the amount of instances to this number. It is recommended to leave this value blank. Default: minCapacity, and leave unchanged during deployment\n')
    group_metrics: typing.Optional[typing.Sequence[models.aws_autoscaling.GroupMetricsDef]] = pydantic.Field(None, description='Enable monitoring for group metrics, these metrics describe the group rather than any of its instances. To report all group metrics use ``GroupMetrics.all()`` Group metrics are reported in a granularity of 1 minute at no additional charge. Default: - no group metrics will be reported\n')
    health_check: typing.Optional[models.aws_autoscaling.HealthCheckDef] = pydantic.Field(None, description='Configuration for health checks. Default: - HealthCheck.ec2 with no grace period\n')
    ignore_unmodified_size_properties: typing.Optional[bool] = pydantic.Field(None, description="If the ASG has scheduled actions, don't reset unchanged group sizes. Only used if the ASG has scheduled actions (which may scale your ASG up or down regardless of cdk deployments). If true, the size of the group will only be reset if it has been changed in the CDK app. If false, the sizes will always be changed back to what they were in the CDK app on deployment. Default: true\n")
    instance_monitoring: typing.Optional[aws_cdk.aws_autoscaling.Monitoring] = pydantic.Field(None, description='Controls whether instances in this group are launched with detailed or basic monitoring. When detailed monitoring is enabled, Amazon CloudWatch generates metrics every minute and your account is charged a fee. When you disable detailed monitoring, CloudWatch generates metrics every 5 minutes. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Monitoring.DETAILED\n')
    key_name: typing.Optional[str] = pydantic.Field(None, description='Name of SSH keypair to grant access to instances. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - No SSH access will be possible.\n')
    max_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Maximum number of instances in the fleet. Default: desiredCapacity\n')
    max_instance_lifetime: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The maximum amount of time that an instance can be in service. The maximum duration applies to all current and future instances in the group. As an instance approaches its maximum duration, it is terminated and replaced, and cannot be used again. You must specify a value of at least 604,800 seconds (7 days). To clear a previously set value, leave this property undefined. Default: none\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum number of instances in the fleet. Default: 1\n')
    new_instances_protected_from_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Whether newly-launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. By default, Auto Scaling can terminate an instance at any time after launch when scaling in an Auto Scaling Group, subject to the group's termination policy. However, you may wish to protect newly-launched instances from being scaled in if they are going to run critical applications that should not be prematurely terminated. This flag must be enabled if the Auto Scaling Group will be associated with an ECS Capacity Provider with managed termination protection. Default: false\n")
    notifications: typing.Optional[typing.Sequence[typing.Union[models.aws_autoscaling.NotificationConfigurationDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Configure autoscaling group to send notifications about fleet changes to an SNS topic(s). Default: - No fleet change notifications will be sent.\n')
    signals: typing.Optional[models.aws_autoscaling.SignalsDef] = pydantic.Field(None, description='Configure waiting for signals during deployment. Use this to pause the CloudFormation deployment to wait for the instances in the AutoScalingGroup to report successful startup during creation and updates. The UserData script needs to invoke ``cfn-signal`` with a success or failure code after it is done setting up the instance. Without waiting for signals, the CloudFormation deployment will proceed as soon as the AutoScalingGroup has been created or updated but before the instances in the group have been started. For example, to have instances wait for an Elastic Load Balancing health check before they signal success, add a health-check verification by using the cfn-init helper script. For an example, see the verify_instance_health command in the Auto Scaling rolling updates sample template: https://github.com/awslabs/aws-cloudformation-templates/blob/master/aws/services/AutoScaling/AutoScalingRollingUpdates.yaml Default: - Do not wait for signals\n')
    spot_price: typing.Optional[str] = pydantic.Field(None, description='The maximum hourly price (in USD) to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot market price. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: none\n')
    ssm_session_permissions: typing.Optional[bool] = pydantic.Field(None, description='Add SSM session permissions to the instance role. Setting this to ``true`` adds the necessary permissions to connect to the instance using SSM Session Manager. You can do this from the AWS Console. NOTE: Setting this flag to ``true`` may not be enough by itself. You must also use an AMI that comes with the SSM Agent, or install the SSM Agent yourself. See `Working with SSM Agent <https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html>`_ in the SSM Developer Guide. Default: false\n')
    termination_policies: typing.Optional[typing.Sequence[aws_cdk.aws_autoscaling.TerminationPolicy]] = pydantic.Field(None, description='A policy or a list of policies that are used to select the instances to terminate. The policies are executed in the order that you list them. Default: - ``TerminationPolicy.DEFAULT``\n')
    update_policy: typing.Optional[models.aws_autoscaling.UpdatePolicyDef] = pydantic.Field(None, description="What to do when an AutoScalingGroup's instance configuration is changed. This is applied when any of the settings on the ASG are changed that affect how the instances should be created (VPC, instance type, startup scripts, etc.). It indicates how the existing instances should be replaced with new instances matching the new config. By default, nothing is done and only new instances are launched with the new config. Default: - ``UpdatePolicy.rollingUpdate()`` if using ``init``, ``UpdatePolicy.none()`` otherwise\n")
    vpc_subnets: typing.Union[models.aws_ec2.SubnetSelectionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Where to place instances within the VPC. Default: - All Private subnets.\n')
    vpc: typing.Union[_REQUIRED_INIT_PARAM, models.aws_ec2.VpcDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='VPC to launch these instances in.\n')
    init: typing.Optional[models.aws_ec2.CloudFormationInitDef] = pydantic.Field(None, description='Apply the given CloudFormation Init configuration to the instances in the AutoScalingGroup at startup. If you specify ``init``, you must also specify ``signals`` to configure the number of instances to wait for and the timeout for waiting for the init process. Default: - no CloudFormation init\n')
    init_options: typing.Union[models.aws_autoscaling.ApplyCloudFormationInitOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Use the given options for applying CloudFormation Init. Describes the configsets to use and the timeout to wait Default: - default options\n')
    instance_type: typing.Optional[models.aws_ec2.InstanceTypeDef] = pydantic.Field(None, description='Type of instance to launch. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Do not provide any instance type\n')
    launch_template: typing.Optional[typing.Union[models.aws_ec2.LaunchTemplateDef]] = pydantic.Field(None, description='Launch template to use. Launch configuration related settings and MixedInstancesPolicy must not be specified when a launch template is specified. Default: - Do not provide any launch template\n')
    machine_image: typing.Optional[typing.Union[models.aws_ec2.AmazonLinux2022ImageSsmParameterDef, models.aws_ec2.AmazonLinux2023ImageSsmParameterDef, models.aws_ec2.AmazonLinux2ImageSsmParameterDef, models.aws_ec2.AmazonLinuxImageDef, models.aws_ec2.AmazonLinuxImageSsmParameterBaseDef, models.aws_ec2.GenericLinuxImageDef, models.aws_ec2.GenericSSMParameterImageDef, models.aws_ec2.GenericWindowsImageDef, models.aws_ec2.LookupMachineImageDef, models.aws_ec2.NatInstanceImageDef, models.aws_ec2.ResolveSsmParameterAtLaunchImageDef, models.aws_ec2.WindowsImageDef, models.aws_ecs.BottleRocketImageDef, models.aws_ecs.EcsOptimizedImageDef, models.aws_eks.EksOptimizedImageDef]] = pydantic.Field(None, description='AMI to launch. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Do not provide any machine image\n')
    mixed_instances_policy: typing.Union[models.aws_autoscaling.MixedInstancesPolicyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Mixed Instances Policy to use. Launch configuration related settings and Launch Template must not be specified when a MixedInstancesPolicy is specified. Default: - Do not provide any MixedInstancesPolicy\n')
    require_imdsv2: typing.Optional[bool] = pydantic.Field(None, description='Whether IMDSv2 should be required on launched instances. Default: false\n')
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='An IAM role to associate with the instance profile assigned to this Auto Scaling Group. The role must be assumable by the service principal ``ec2.amazonaws.com``: ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: A role will automatically be created, it can be accessed via the ``role`` property\n')
    security_group: typing.Optional[typing.Union[models.aws_ec2.SecurityGroupDef]] = pydantic.Field(None, description='Security group to launch the instances in. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - A SecurityGroup will be created if none is specified.\n')
    user_data: typing.Optional[models.aws_ec2.UserDataDef] = pydantic.Field(None, description='Specific UserData to use. The UserData may still be mutated after creation. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - A UserData object appropriate for the MachineImage\'s Operating System is created.\n\n:exampleMetadata: infused\n\nExample::\n\n    # vpc: ec2.Vpc\n    # instance_type: ec2.InstanceType\n    # machine_image: ec2.IMachineImage\n\n\n    autoscaling.AutoScalingGroup(self, "ASG",\n        vpc=vpc,\n        instance_type=instance_type,\n        machine_image=machine_image,\n\n        # ...\n\n        init=ec2.CloudFormationInit.from_elements(\n            ec2.InitFile.from_string("/etc/my_instance", "This got written during instance startup")),\n        signals=autoscaling.Signals.wait_for_all(\n            timeout=Duration.minutes(10)\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['allow_all_outbound', 'associate_public_ip_address', 'auto_scaling_group_name', 'block_devices', 'capacity_rebalance', 'cooldown', 'default_instance_warmup', 'desired_capacity', 'group_metrics', 'health_check', 'ignore_unmodified_size_properties', 'instance_monitoring', 'key_name', 'max_capacity', 'max_instance_lifetime', 'min_capacity', 'new_instances_protected_from_scale_in', 'notifications', 'signals', 'spot_price', 'ssm_session_permissions', 'termination_policies', 'update_policy', 'vpc_subnets', 'vpc', 'init', 'init_options', 'instance_type', 'launch_template', 'machine_image', 'mixed_instances_policy', 'require_imdsv2', 'role', 'security_group', 'user_data']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.AutoScalingGroupProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.AutoScalingGroupPropsDefConfig] = pydantic.Field(None)


class AutoScalingGroupPropsDefConfig(pydantic.BaseModel):
    vpc_config: typing.Optional[models._interface_methods.AwsEc2IVpcDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.BaseTargetTrackingProps
class BaseTargetTrackingPropsDef(BaseStruct):
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    base_target_tracking_props = autoscaling.BaseTargetTrackingProps(\n        cooldown=cdk.Duration.minutes(30),\n        disable_scale_in=False,\n        estimated_instance_warmup=cdk.Duration.minutes(30)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cooldown', 'disable_scale_in', 'estimated_instance_warmup']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.BaseTargetTrackingProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.BasicLifecycleHookProps
class BasicLifecycleHookPropsDef(BaseStruct):
    lifecycle_transition: typing.Union[aws_cdk.aws_autoscaling.LifecycleTransition, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The state of the Amazon EC2 instance to which you want to attach the lifecycle hook.\n')
    default_result: typing.Optional[aws_cdk.aws_autoscaling.DefaultResult] = pydantic.Field(None, description='The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. Default: Continue\n')
    heartbeat_timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Maximum time between calls to RecordLifecycleActionHeartbeat for the hook. If the lifecycle hook times out, perform the action in DefaultResult. Default: - No heartbeat timeout.\n')
    lifecycle_hook_name: typing.Optional[str] = pydantic.Field(None, description='Name of the lifecycle hook. Default: - Automatically generated name.\n')
    notification_metadata: typing.Optional[str] = pydantic.Field(None, description='Additional data to pass to the lifecycle hook target. Default: - No metadata.\n')
    notification_target: typing.Optional[typing.Union[models.aws_autoscaling_hooktargets.FunctionHookDef, models.aws_autoscaling_hooktargets.QueueHookDef, models.aws_autoscaling_hooktargets.TopicHookDef]] = pydantic.Field(None, description='The target of the lifecycle hook. Default: - No target.\n')
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The role that allows publishing to the notification target. Default: - A role will be created if a target is provided. Otherwise, no role is created.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_autoscaling as autoscaling\n    from aws_cdk import aws_iam as iam\n\n    # lifecycle_hook_target: autoscaling.ILifecycleHookTarget\n    # role: iam.Role\n\n    basic_lifecycle_hook_props = autoscaling.BasicLifecycleHookProps(\n        lifecycle_transition=autoscaling.LifecycleTransition.INSTANCE_LAUNCHING,\n\n        # the properties below are optional\n        default_result=autoscaling.DefaultResult.CONTINUE,\n        heartbeat_timeout=cdk.Duration.minutes(30),\n        lifecycle_hook_name="lifecycleHookName",\n        notification_metadata="notificationMetadata",\n        notification_target=lifecycle_hook_target,\n        role=role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['lifecycle_transition', 'default_result', 'heartbeat_timeout', 'lifecycle_hook_name', 'notification_metadata', 'notification_target', 'role']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.BasicLifecycleHookProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.BasicScheduledActionProps
class BasicScheduledActionPropsDef(BaseStruct):
    schedule: typing.Union[models.aws_autoscaling.ScheduleDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='When to perform this action. Supports cron expressions. For more information about cron expressions, see https://en.wikipedia.org/wiki/Cron.\n')
    desired_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new desired capacity. At the scheduled time, set the desired capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new desired capacity.\n')
    end_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action expires. Default: - The rule never expires.\n')
    max_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new maximum capacity. At the scheduled time, set the maximum capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new maximum capacity.\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new minimum capacity. At the scheduled time, set the minimum capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new minimum capacity.\n')
    start_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action becomes active. Default: - The rule is activate immediately.\n')
    time_zone: typing.Optional[str] = pydantic.Field(None, description='Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as Etc/GMT+9 or Pacific/Tahiti). For more information, see https://en.wikipedia.org/wiki/List_of_tz_database_time_zones. Default: - UTC\n\n:exampleMetadata: infused\n\nExample::\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n\n\n    auto_scaling_group.scale_on_schedule("PrescaleInTheMorning",\n        schedule=autoscaling.Schedule.cron(hour="8", minute="0"),\n        min_capacity=20\n    )\n\n    auto_scaling_group.scale_on_schedule("AllowDownscalingAtNight",\n        schedule=autoscaling.Schedule.cron(hour="20", minute="0"),\n        min_capacity=1\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['schedule', 'desired_capacity', 'end_time', 'max_capacity', 'min_capacity', 'start_time', 'time_zone']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.BasicScheduledActionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.BasicStepScalingPolicyProps
class BasicStepScalingPolicyPropsDef(BaseStruct):
    metric: typing.Union[_REQUIRED_INIT_PARAM, models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='Metric to scale on.')
    scaling_steps: typing.Union[typing.Sequence[typing.Union[models.aws_autoscaling.ScalingIntervalDef, dict[str, typing.Any]]], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The intervals for scaling. Maps a range of metric values to a particular scaling behavior. Must be between 2 and 40 steps.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_autoscaling.AdjustmentType] = pydantic.Field(None, description="How the adjustment numbers inside 'intervals' are interpreted. Default: ChangeInCapacity\n")
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Grace period after scaling activity. Default: Default cooldown period on your AutoScalingGroup\n')
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: Same as the cooldown\n')
    evaluation_periods: typing.Union[int, float, None] = pydantic.Field(None, description='How many evaluation periods of the metric to wait before triggering a scaling action. Raising this value can be used to smooth out the metric, at the expense of slower response times. Default: 1\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_autoscaling.MetricAggregationType] = pydantic.Field(None, description='Aggregation to apply to all data points over the evaluation periods. Only has meaning if ``evaluationPeriods != 1``. Default: - The statistic from the metric if applicable (MIN, MAX, AVERAGE), otherwise AVERAGE.\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect\n\n:exampleMetadata: infused\n\nExample::\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n\n\n    worker_utilization_metric = cloudwatch.Metric(\n        namespace="MyService",\n        metric_name="WorkerUtilization"\n    )\n\n    auto_scaling_group.scale_on_metric("ScaleToCPU",\n        metric=worker_utilization_metric,\n        scaling_steps=[autoscaling.ScalingInterval(upper=10, change=-1), autoscaling.ScalingInterval(lower=50, change=+1), autoscaling.ScalingInterval(lower=70, change=+3)\n        ],\n\n        # Change this to AdjustmentType.PERCENT_CHANGE_IN_CAPACITY to interpret the\n        # \'change\' numbers before as percentages instead of capacity counts.\n        adjustment_type=autoscaling.AdjustmentType.CHANGE_IN_CAPACITY\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric', 'scaling_steps', 'adjustment_type', 'cooldown', 'estimated_instance_warmup', 'evaluation_periods', 'metric_aggregation_type', 'min_adjustment_magnitude']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.BasicStepScalingPolicyProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.BasicTargetTrackingScalingPolicyProps
class BasicTargetTrackingScalingPolicyPropsDef(BaseStruct):
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.\n')
    target_value: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The target value for the metric.\n')
    custom_metric: typing.Optional[typing.Union[models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef]] = pydantic.Field(None, description='A custom metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No custom metric.\n')
    predefined_metric: typing.Optional[aws_cdk.aws_autoscaling.PredefinedMetric] = pydantic.Field(None, description='A predefined metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No predefined metric.\n')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='The resource label associated with the predefined metric. Should be supplied if the predefined metric is ALBRequestCountPerTarget, and the format should be: app///targetgroup// Default: - No resource label.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_autoscaling as autoscaling\n    from aws_cdk import aws_cloudwatch as cloudwatch\n\n    # metric: cloudwatch.Metric\n\n    basic_target_tracking_scaling_policy_props = autoscaling.BasicTargetTrackingScalingPolicyProps(\n        target_value=123,\n\n        # the properties below are optional\n        cooldown=cdk.Duration.minutes(30),\n        custom_metric=metric,\n        disable_scale_in=False,\n        estimated_instance_warmup=cdk.Duration.minutes(30),\n        predefined_metric=autoscaling.PredefinedMetric.ASG_AVERAGE_CPU_UTILIZATION,\n        resource_label="resourceLabel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cooldown', 'disable_scale_in', 'estimated_instance_warmup', 'target_value', 'custom_metric', 'predefined_metric', 'resource_label']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.BasicTargetTrackingScalingPolicyProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.BindHookTargetOptions
class BindHookTargetOptionsDef(BaseStruct):
    lifecycle_hook: typing.Union[models.aws_autoscaling.LifecycleHookDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The lifecycle hook to attach to. [disable-awslint:ref-via-interface]\n')
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The role to use when attaching to the lifecycle hook. [disable-awslint:ref-via-interface] Default: : a role is not created unless the target arn is specified\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n    from aws_cdk import aws_iam as iam\n\n    # lifecycle_hook: autoscaling.LifecycleHook\n    # role: iam.Role\n\n    bind_hook_target_options = autoscaling.BindHookTargetOptions(\n        lifecycle_hook=lifecycle_hook,\n\n        # the properties below are optional\n        role=role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['lifecycle_hook', 'role']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.BindHookTargetOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.BlockDevice
class BlockDeviceDef(BaseStruct):
    device_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The device name exposed to the EC2 instance. Supply a value like ``/dev/sdh``, ``xvdh``.\n')
    volume: typing.Union[models.aws_autoscaling.BlockDeviceVolumeDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Defines the block device volume, to be either an Amazon EBS volume or an ephemeral instance store volume. Supply a value like ``BlockDeviceVolume.ebs(15)``, ``BlockDeviceVolume.ephemeral(0)``.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    # block_device_volume: autoscaling.BlockDeviceVolume\n\n    block_device = autoscaling.BlockDevice(\n        device_name="deviceName",\n        volume=block_device_volume\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['device_name', 'volume']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.BlockDevice'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.AcceleratorCountRequestProperty
class CfnAutoScalingGroup_AcceleratorCountRequestPropertyDef(BaseStruct):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum value.\n')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum value.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-acceleratorcountrequest.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    accelerator_count_request_property = autoscaling.CfnAutoScalingGroup.AcceleratorCountRequestProperty(\n        max=123,\n        min=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max', 'min']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.AcceleratorCountRequestProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.AcceleratorTotalMemoryMiBRequestProperty
class CfnAutoScalingGroup_AcceleratorTotalMemoryMiBRequestPropertyDef(BaseStruct):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='The memory maximum in MiB.\n')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='The memory minimum in MiB.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-acceleratortotalmemorymibrequest.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    accelerator_total_memory_mi_bRequest_property = autoscaling.CfnAutoScalingGroup.AcceleratorTotalMemoryMiBRequestProperty(\n        max=123,\n        min=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max', 'min']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.AcceleratorTotalMemoryMiBRequestProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.BaselineEbsBandwidthMbpsRequestProperty
class CfnAutoScalingGroup_BaselineEbsBandwidthMbpsRequestPropertyDef(BaseStruct):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum value in Mbps.\n')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum value in Mbps.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-baselineebsbandwidthmbpsrequest.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    baseline_ebs_bandwidth_mbps_request_property = autoscaling.CfnAutoScalingGroup.BaselineEbsBandwidthMbpsRequestProperty(\n        max=123,\n        min=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max', 'min']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.BaselineEbsBandwidthMbpsRequestProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.InstanceRequirementsProperty
class CfnAutoScalingGroup_InstanceRequirementsPropertyDef(BaseStruct):
    accelerator_count: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_AcceleratorCountRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The minimum and maximum number of accelerators (GPUs, FPGAs, or AWS Inferentia chips) for an instance type. To exclude accelerator-enabled instance types, set ``Max`` to ``0`` . Default: No minimum or maximum limits\n')
    accelerator_manufacturers: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Indicates whether instance types must have accelerators by specific manufacturers. - For instance types with NVIDIA devices, specify ``nvidia`` . - For instance types with AMD devices, specify ``amd`` . - For instance types with AWS devices, specify ``amazon-web-services`` . - For instance types with Xilinx devices, specify ``xilinx`` . Default: Any manufacturer\n')
    accelerator_names: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Lists the accelerators that must be on an instance type. - For instance types with NVIDIA A100 GPUs, specify ``a100`` . - For instance types with NVIDIA V100 GPUs, specify ``v100`` . - For instance types with NVIDIA K80 GPUs, specify ``k80`` . - For instance types with NVIDIA T4 GPUs, specify ``t4`` . - For instance types with NVIDIA M60 GPUs, specify ``m60`` . - For instance types with AMD Radeon Pro V520 GPUs, specify ``radeon-pro-v520`` . - For instance types with Xilinx VU9P FPGAs, specify ``vu9p`` . Default: Any accelerator\n')
    accelerator_total_memory_mib: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_AcceleratorTotalMemoryMiBRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The minimum and maximum total memory size for the accelerators on an instance type, in MiB. Default: No minimum or maximum limits\n')
    accelerator_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Lists the accelerator types that must be on an instance type. - For instance types with GPU accelerators, specify ``gpu`` . - For instance types with FPGA accelerators, specify ``fpga`` . - For instance types with inference accelerators, specify ``inference`` . Default: Any accelerator type\n')
    allowed_instance_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="The instance types to apply your specified attributes against. All other instance types are ignored, even if they match your specified attributes. You can use strings with one or more wild cards, represented by an asterisk ( ``*`` ), to allow an instance type, size, or generation. The following are examples: ``m5.8xlarge`` , ``c5*.*`` , ``m5a.*`` , ``r*`` , ``*3*`` . For example, if you specify ``c5*`` , Amazon EC2 Auto Scaling will allow the entire C5 instance family, which includes all C5a and C5n instance types. If you specify ``m5a.*`` , Amazon EC2 Auto Scaling will allow all the M5a instance types, but not the M5n instance types. .. epigraph:: If you specify ``AllowedInstanceTypes`` , you can't specify ``ExcludedInstanceTypes`` . Default: All instance types\n")
    bare_metal: typing.Optional[str] = pydantic.Field(None, description='Indicates whether bare metal instance types are included, excluded, or required. Default: ``excluded``\n')
    baseline_ebs_bandwidth_mbps: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_BaselineEbsBandwidthMbpsRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The minimum and maximum baseline bandwidth performance for an instance type, in Mbps. For more information, see `Amazon EBS–optimized instances <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . Default: No minimum or maximum limits\n')
    burstable_performance: typing.Optional[str] = pydantic.Field(None, description='Indicates whether burstable performance instance types are included, excluded, or required. For more information, see `Burstable performance instances <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/burstable-performance-instances.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . Default: ``excluded``\n')
    cpu_manufacturers: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="Lists which specific CPU manufacturers to include. - For instance types with Intel CPUs, specify ``intel`` . - For instance types with AMD CPUs, specify ``amd`` . - For instance types with AWS CPUs, specify ``amazon-web-services`` . .. epigraph:: Don't confuse the CPU hardware manufacturer with the CPU hardware architecture. Instances will be launched with a compatible CPU architecture based on the Amazon Machine Image (AMI) that you specify in your launch template. Default: Any manufacturer\n")
    excluded_instance_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="The instance types to exclude. You can use strings with one or more wild cards, represented by an asterisk ( ``*`` ), to exclude an instance family, type, size, or generation. The following are examples: ``m5.8xlarge`` , ``c5*.*`` , ``m5a.*`` , ``r*`` , ``*3*`` . For example, if you specify ``c5*`` , you are excluding the entire C5 instance family, which includes all C5a and C5n instance types. If you specify ``m5a.*`` , Amazon EC2 Auto Scaling will exclude all the M5a instance types, but not the M5n instance types. .. epigraph:: If you specify ``ExcludedInstanceTypes`` , you can't specify ``AllowedInstanceTypes`` . Default: No excluded instance types\n")
    instance_generations: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Indicates whether current or previous generation instance types are included. - For current generation instance types, specify ``current`` . The current generation includes EC2 instance types currently recommended for use. This typically includes the latest two to three generations in each instance family. For more information, see `Instance types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . - For previous generation instance types, specify ``previous`` . Default: Any current or previous generation\n')
    local_storage: typing.Optional[str] = pydantic.Field(None, description='Indicates whether instance types with instance store volumes are included, excluded, or required. For more information, see `Amazon EC2 instance store <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . Default: ``included``\n')
    local_storage_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Indicates the type of local storage that is required. - For instance types with hard disk drive (HDD) storage, specify ``hdd`` . - For instance types with solid state drive (SSD) storage, specify ``ssd`` . Default: Any local storage type\n')
    memory_gib_per_v_cpu: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_MemoryGiBPerVCpuRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The minimum and maximum amount of memory per vCPU for an instance type, in GiB. Default: No minimum or maximum limits\n')
    memory_mib: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_MemoryMiBRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The minimum and maximum instance memory size for an instance type, in MiB.\n')
    network_bandwidth_gbps: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_NetworkBandwidthGbpsRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The minimum and maximum amount of network bandwidth, in gigabits per second (Gbps). Default: No minimum or maximum limits\n')
    network_interface_count: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_NetworkInterfaceCountRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The minimum and maximum number of network interfaces for an instance type. Default: No minimum or maximum limits\n')
    on_demand_max_price_percentage_over_lowest_price: typing.Union[int, float, None] = pydantic.Field(None, description='The price protection threshold for On-Demand Instances. This is the maximum you’ll pay for an On-Demand Instance, expressed as a percentage higher than the least expensive current generation M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as ``999999`` . If you set ``DesiredCapacityType`` to ``vcpu`` or ``memory-mib`` , the price protection threshold is applied based on the per vCPU or per memory price instead of the per instance price. Default: ``20``\n')
    require_hibernate_support: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether instance types must provide On-Demand Instance hibernation support. Default: ``false``\n')
    spot_max_price_percentage_over_lowest_price: typing.Union[int, float, None] = pydantic.Field(None, description='The price protection threshold for Spot Instances. This is the maximum you’ll pay for a Spot Instance, expressed as a percentage higher than the least expensive current generation M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as ``999999`` . If you set ``DesiredCapacityType`` to ``vcpu`` or ``memory-mib`` , the price protection threshold is applied based on the per vCPU or per memory price instead of the per instance price. Default: ``100``\n')
    total_local_storage_gb: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_TotalLocalStorageGBRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The minimum and maximum total local storage size for an instance type, in GB. Default: No minimum or maximum limits\n')
    v_cpu_count: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_VCpuCountRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The minimum and maximum number of vCPUs for an instance type.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-instancerequirements.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    instance_requirements_property = autoscaling.CfnAutoScalingGroup.InstanceRequirementsProperty(\n        accelerator_count=autoscaling.CfnAutoScalingGroup.AcceleratorCountRequestProperty(\n            max=123,\n            min=123\n        ),\n        accelerator_manufacturers=["acceleratorManufacturers"],\n        accelerator_names=["acceleratorNames"],\n        accelerator_total_memory_mi_b=autoscaling.CfnAutoScalingGroup.AcceleratorTotalMemoryMiBRequestProperty(\n            max=123,\n            min=123\n        ),\n        accelerator_types=["acceleratorTypes"],\n        allowed_instance_types=["allowedInstanceTypes"],\n        bare_metal="bareMetal",\n        baseline_ebs_bandwidth_mbps=autoscaling.CfnAutoScalingGroup.BaselineEbsBandwidthMbpsRequestProperty(\n            max=123,\n            min=123\n        ),\n        burstable_performance="burstablePerformance",\n        cpu_manufacturers=["cpuManufacturers"],\n        excluded_instance_types=["excludedInstanceTypes"],\n        instance_generations=["instanceGenerations"],\n        local_storage="localStorage",\n        local_storage_types=["localStorageTypes"],\n        memory_gi_bPer_vCpu=autoscaling.CfnAutoScalingGroup.MemoryGiBPerVCpuRequestProperty(\n            max=123,\n            min=123\n        ),\n        memory_mi_b=autoscaling.CfnAutoScalingGroup.MemoryMiBRequestProperty(\n            max=123,\n            min=123\n        ),\n        network_bandwidth_gbps=autoscaling.CfnAutoScalingGroup.NetworkBandwidthGbpsRequestProperty(\n            max=123,\n            min=123\n        ),\n        network_interface_count=autoscaling.CfnAutoScalingGroup.NetworkInterfaceCountRequestProperty(\n            max=123,\n            min=123\n        ),\n        on_demand_max_price_percentage_over_lowest_price=123,\n        require_hibernate_support=False,\n        spot_max_price_percentage_over_lowest_price=123,\n        total_local_storage_gb=autoscaling.CfnAutoScalingGroup.TotalLocalStorageGBRequestProperty(\n            max=123,\n            min=123\n        ),\n        v_cpu_count=autoscaling.CfnAutoScalingGroup.VCpuCountRequestProperty(\n            max=123,\n            min=123\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['accelerator_count', 'accelerator_manufacturers', 'accelerator_names', 'accelerator_total_memory_mib', 'accelerator_types', 'allowed_instance_types', 'bare_metal', 'baseline_ebs_bandwidth_mbps', 'burstable_performance', 'cpu_manufacturers', 'excluded_instance_types', 'instance_generations', 'local_storage', 'local_storage_types', 'memory_gib_per_v_cpu', 'memory_mib', 'network_bandwidth_gbps', 'network_interface_count', 'on_demand_max_price_percentage_over_lowest_price', 'require_hibernate_support', 'spot_max_price_percentage_over_lowest_price', 'total_local_storage_gb', 'v_cpu_count']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.InstanceRequirementsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.InstancesDistributionProperty
class CfnAutoScalingGroup_InstancesDistributionPropertyDef(BaseStruct):
    on_demand_allocation_strategy: typing.Optional[str] = pydantic.Field(None, description="The allocation strategy to apply to your On-Demand Instances when they are launched. Possible instance types are determined by the launch template overrides that you specify. The following lists the valid values: - **lowest-price** - Uses price to determine which instance types are the highest priority, launching the lowest priced instance types within an Availability Zone first. This is the default value for Auto Scaling groups that specify ``InstanceRequirements`` . - **prioritized** - You set the order of instance types for the launch template overrides from highest to lowest priority (from first to last in the list). Amazon EC2 Auto Scaling launches your highest priority instance types first. If all your On-Demand capacity cannot be fulfilled using your highest priority instance type, then Amazon EC2 Auto Scaling launches the remaining capacity using the second priority instance type, and so on. This is the default value for Auto Scaling groups that don't specify ``InstanceRequirements`` and cannot be used for groups that do.\n")
    on_demand_base_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="The minimum amount of the Auto Scaling group's capacity that must be fulfilled by On-Demand Instances. This base portion is launched first as your group scales. This number has the same unit of measurement as the group's desired capacity. If you change the default unit of measurement (number of instances) by specifying weighted capacity values in your launch template overrides list, or by changing the default desired capacity type setting of the group, you must specify this number using the same unit of measurement. Default: 0 .. epigraph:: An update to this setting means a gradual replacement of instances to adjust the current On-Demand Instance levels. When replacing instances, Amazon EC2 Auto Scaling launches new instances before terminating the previous ones.\n")
    on_demand_percentage_above_base_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Controls the percentages of On-Demand Instances and Spot Instances for your additional capacity beyond ``OnDemandBaseCapacity`` . Expressed as a number (for example, 20 specifies 20% On-Demand Instances, 80% Spot Instances). If set to 100, only On-Demand Instances are used. Default: 100 .. epigraph:: An update to this setting means a gradual replacement of instances to adjust the current On-Demand and Spot Instance levels for your additional capacity higher than the base capacity. When replacing instances, Amazon EC2 Auto Scaling launches new instances before terminating the previous ones.\n')
    spot_allocation_strategy: typing.Optional[str] = pydantic.Field(None, description='The allocation strategy to apply to your Spot Instances when they are launched. Possible instance types are determined by the launch template overrides that you specify. The following lists the valid values: - **capacity-optimized** - Requests Spot Instances using pools that are optimally chosen based on the available Spot capacity. This strategy has the lowest risk of interruption. To give certain instance types a higher chance of launching first, use ``capacity-optimized-prioritized`` . - **capacity-optimized-prioritized** - You set the order of instance types for the launch template overrides from highest to lowest priority (from first to last in the list). Amazon EC2 Auto Scaling honors the instance type priorities on a best effort basis but optimizes for capacity first. Note that if the On-Demand allocation strategy is set to ``prioritized`` , the same priority is applied when fulfilling On-Demand capacity. This is not a valid value for Auto Scaling groups that specify ``InstanceRequirements`` . - **lowest-price** - Requests Spot Instances using the lowest priced pools within an Availability Zone, across the number of Spot pools that you specify for the ``SpotInstancePools`` property. To ensure that your desired capacity is met, you might receive Spot Instances from several pools. This is the default value, but it might lead to high interruption rates because this strategy only considers instance price and not available capacity. - **price-capacity-optimized (recommended)** - The price and capacity optimized allocation strategy looks at both price and capacity to select the Spot Instance pools that are the least likely to be interrupted and have the lowest possible price.\n')
    spot_instance_pools: typing.Union[int, float, None] = pydantic.Field(None, description='The number of Spot Instance pools across which to allocate your Spot Instances. The Spot pools are determined from the different instance types in the overrides. Valid only when the ``SpotAllocationStrategy`` is ``lowest-price`` . Value must be in the range of 1–20. Default: 2\n')
    spot_max_price: typing.Optional[str] = pydantic.Field(None, description='The maximum price per unit hour that you are willing to pay for a Spot Instance. If your maximum price is lower than the Spot price for the instance types that you selected, your Spot Instances are not launched. We do not recommend specifying a maximum price because it can lead to increased interruptions. When Spot Instances launch, you pay the current Spot price. To remove a maximum price that you previously set, include the property but specify an empty string ("") for the value. .. epigraph:: If you specify a maximum price, your instances will be interrupted more frequently than if you do not specify one. Valid Range: Minimum value of 0.001\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-instancesdistribution.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    instances_distribution_property = autoscaling.CfnAutoScalingGroup.InstancesDistributionProperty(\n        on_demand_allocation_strategy="onDemandAllocationStrategy",\n        on_demand_base_capacity=123,\n        on_demand_percentage_above_base_capacity=123,\n        spot_allocation_strategy="spotAllocationStrategy",\n        spot_instance_pools=123,\n        spot_max_price="spotMaxPrice"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['on_demand_allocation_strategy', 'on_demand_base_capacity', 'on_demand_percentage_above_base_capacity', 'spot_allocation_strategy', 'spot_instance_pools', 'spot_max_price']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.InstancesDistributionProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.LaunchTemplateOverridesProperty
class CfnAutoScalingGroup_LaunchTemplateOverridesPropertyDef(BaseStruct):
    instance_requirements: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_InstanceRequirementsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="The instance requirements. Amazon EC2 Auto Scaling uses your specified requirements to identify instance types. Then, it uses your On-Demand and Spot allocation strategies to launch instances from these instance types. You can specify up to four separate sets of instance requirements per Auto Scaling group. This is useful for provisioning instances from different Amazon Machine Images (AMIs) in the same Auto Scaling group. To do this, create the AMIs and create a new launch template for each AMI. Then, create a compatible set of instance requirements for each launch template. .. epigraph:: If you specify ``InstanceRequirements`` , you can't specify ``InstanceType`` .\n")
    instance_type: typing.Optional[str] = pydantic.Field(None, description='The instance type, such as ``m3.xlarge`` . You must specify an instance type that is supported in your requested Region and Availability Zones. For more information, see `Instance types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html>`_ in the *Amazon Elastic Compute Cloud User Guide* . You can specify up to 40 instance types per Auto Scaling group.\n')
    launch_template_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplateSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Provides a launch template for the specified instance type or set of instance requirements. For example, some instance types might require a launch template with a different AMI. If not provided, Amazon EC2 Auto Scaling uses the launch template that's specified in the ``LaunchTemplate`` definition. For more information, see `Specifying a different launch template for an instance type <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups-launch-template-overrides.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . You can specify up to 20 launch templates per Auto Scaling group. The launch templates specified in the overrides and in the ``LaunchTemplate`` definition count towards this limit.\n")
    weighted_capacity: typing.Optional[str] = pydantic.Field(None, description='If you provide a list of instance types to use, you can specify the number of capacity units provided by each instance type in terms of virtual CPUs, memory, storage, throughput, or other relative performance characteristic. When a Spot or On-Demand Instance is launched, the capacity units count toward the desired capacity. Amazon EC2 Auto Scaling launches instances until the desired capacity is totally fulfilled, even if this results in an overage. For example, if there are two units remaining to fulfill capacity, and Amazon EC2 Auto Scaling can only launch an instance with a ``WeightedCapacity`` of five units, the instance is launched, and the desired capacity is exceeded by three units. For more information, see `Configure instance weighting for Amazon EC2 Auto Scaling <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups-instance-weighting.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Value must be in the range of 1-999. If you specify a value for ``WeightedCapacity`` for one instance type, you must specify a value for ``WeightedCapacity`` for all of them. .. epigraph:: Every Auto Scaling group has three size parameters ( ``DesiredCapacity`` , ``MaxSize`` , and ``MinSize`` ). Usually, you set these sizes based on a specific number of instances. However, if you configure a mixed instances policy that defines weights for the instance types, you must specify these sizes with the same units that you use for weighting instances.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-launchtemplateoverrides.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    launch_template_overrides_property = autoscaling.CfnAutoScalingGroup.LaunchTemplateOverridesProperty(\n        instance_requirements=autoscaling.CfnAutoScalingGroup.InstanceRequirementsProperty(\n            accelerator_count=autoscaling.CfnAutoScalingGroup.AcceleratorCountRequestProperty(\n                max=123,\n                min=123\n            ),\n            accelerator_manufacturers=["acceleratorManufacturers"],\n            accelerator_names=["acceleratorNames"],\n            accelerator_total_memory_mi_b=autoscaling.CfnAutoScalingGroup.AcceleratorTotalMemoryMiBRequestProperty(\n                max=123,\n                min=123\n            ),\n            accelerator_types=["acceleratorTypes"],\n            allowed_instance_types=["allowedInstanceTypes"],\n            bare_metal="bareMetal",\n            baseline_ebs_bandwidth_mbps=autoscaling.CfnAutoScalingGroup.BaselineEbsBandwidthMbpsRequestProperty(\n                max=123,\n                min=123\n            ),\n            burstable_performance="burstablePerformance",\n            cpu_manufacturers=["cpuManufacturers"],\n            excluded_instance_types=["excludedInstanceTypes"],\n            instance_generations=["instanceGenerations"],\n            local_storage="localStorage",\n            local_storage_types=["localStorageTypes"],\n            memory_gi_bPer_vCpu=autoscaling.CfnAutoScalingGroup.MemoryGiBPerVCpuRequestProperty(\n                max=123,\n                min=123\n            ),\n            memory_mi_b=autoscaling.CfnAutoScalingGroup.MemoryMiBRequestProperty(\n                max=123,\n                min=123\n            ),\n            network_bandwidth_gbps=autoscaling.CfnAutoScalingGroup.NetworkBandwidthGbpsRequestProperty(\n                max=123,\n                min=123\n            ),\n            network_interface_count=autoscaling.CfnAutoScalingGroup.NetworkInterfaceCountRequestProperty(\n                max=123,\n                min=123\n            ),\n            on_demand_max_price_percentage_over_lowest_price=123,\n            require_hibernate_support=False,\n            spot_max_price_percentage_over_lowest_price=123,\n            total_local_storage_gb=autoscaling.CfnAutoScalingGroup.TotalLocalStorageGBRequestProperty(\n                max=123,\n                min=123\n            ),\n            v_cpu_count=autoscaling.CfnAutoScalingGroup.VCpuCountRequestProperty(\n                max=123,\n                min=123\n            )\n        ),\n        instance_type="instanceType",\n        launch_template_specification=autoscaling.CfnAutoScalingGroup.LaunchTemplateSpecificationProperty(\n            version="version",\n\n            # the properties below are optional\n            launch_template_id="launchTemplateId",\n            launch_template_name="launchTemplateName"\n        ),\n        weighted_capacity="weightedCapacity"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['instance_requirements', 'instance_type', 'launch_template_specification', 'weighted_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.LaunchTemplateOverridesProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.LaunchTemplateProperty
class CfnAutoScalingGroup_LaunchTemplatePropertyDef(BaseStruct):
    launch_template_specification: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplateSpecificationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The launch template.\n')
    overrides: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplateOverridesPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Any properties that you specify override the same properties in the launch template.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-launchtemplate.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    launch_template_property = autoscaling.CfnAutoScalingGroup.LaunchTemplateProperty(\n        launch_template_specification=autoscaling.CfnAutoScalingGroup.LaunchTemplateSpecificationProperty(\n            version="version",\n\n            # the properties below are optional\n            launch_template_id="launchTemplateId",\n            launch_template_name="launchTemplateName"\n        ),\n\n        # the properties below are optional\n        overrides=[autoscaling.CfnAutoScalingGroup.LaunchTemplateOverridesProperty(\n            instance_requirements=autoscaling.CfnAutoScalingGroup.InstanceRequirementsProperty(\n                accelerator_count=autoscaling.CfnAutoScalingGroup.AcceleratorCountRequestProperty(\n                    max=123,\n                    min=123\n                ),\n                accelerator_manufacturers=["acceleratorManufacturers"],\n                accelerator_names=["acceleratorNames"],\n                accelerator_total_memory_mi_b=autoscaling.CfnAutoScalingGroup.AcceleratorTotalMemoryMiBRequestProperty(\n                    max=123,\n                    min=123\n                ),\n                accelerator_types=["acceleratorTypes"],\n                allowed_instance_types=["allowedInstanceTypes"],\n                bare_metal="bareMetal",\n                baseline_ebs_bandwidth_mbps=autoscaling.CfnAutoScalingGroup.BaselineEbsBandwidthMbpsRequestProperty(\n                    max=123,\n                    min=123\n                ),\n                burstable_performance="burstablePerformance",\n                cpu_manufacturers=["cpuManufacturers"],\n                excluded_instance_types=["excludedInstanceTypes"],\n                instance_generations=["instanceGenerations"],\n                local_storage="localStorage",\n                local_storage_types=["localStorageTypes"],\n                memory_gi_bPer_vCpu=autoscaling.CfnAutoScalingGroup.MemoryGiBPerVCpuRequestProperty(\n                    max=123,\n                    min=123\n                ),\n                memory_mi_b=autoscaling.CfnAutoScalingGroup.MemoryMiBRequestProperty(\n                    max=123,\n                    min=123\n                ),\n                network_bandwidth_gbps=autoscaling.CfnAutoScalingGroup.NetworkBandwidthGbpsRequestProperty(\n                    max=123,\n                    min=123\n                ),\n                network_interface_count=autoscaling.CfnAutoScalingGroup.NetworkInterfaceCountRequestProperty(\n                    max=123,\n                    min=123\n                ),\n                on_demand_max_price_percentage_over_lowest_price=123,\n                require_hibernate_support=False,\n                spot_max_price_percentage_over_lowest_price=123,\n                total_local_storage_gb=autoscaling.CfnAutoScalingGroup.TotalLocalStorageGBRequestProperty(\n                    max=123,\n                    min=123\n                ),\n                v_cpu_count=autoscaling.CfnAutoScalingGroup.VCpuCountRequestProperty(\n                    max=123,\n                    min=123\n                )\n            ),\n            instance_type="instanceType",\n            launch_template_specification=autoscaling.CfnAutoScalingGroup.LaunchTemplateSpecificationProperty(\n                version="version",\n\n                # the properties below are optional\n                launch_template_id="launchTemplateId",\n                launch_template_name="launchTemplateName"\n            ),\n            weighted_capacity="weightedCapacity"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['launch_template_specification', 'overrides']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.LaunchTemplateProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.LaunchTemplateSpecificationProperty
class CfnAutoScalingGroup_LaunchTemplateSpecificationPropertyDef(BaseStruct):
    version: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The version number of the launch template. Specifying ``$Latest`` or ``$Default`` for the template version number is not supported. However, you can specify ``LatestVersionNumber`` or ``DefaultVersionNumber`` using the ``Fn::GetAtt`` intrinsic function. For more information, see `Fn::GetAtt <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-getatt.html>`_ . .. epigraph:: For an example of using the ``Fn::GetAtt`` function, see the `Examples <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-autoscaling-autoscalinggroup.html#aws-resource-autoscaling-autoscalinggroup--examples>`_ section of the ``AWS::AutoScaling::AutoScalingGroup`` resource.\n')
    launch_template_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the launch template. You must specify the ``LaunchTemplateID`` or the ``LaunchTemplateName`` , but not both.\n')
    launch_template_name: typing.Optional[str] = pydantic.Field(None, description='The name of the launch template. You must specify the ``LaunchTemplateName`` or the ``LaunchTemplateID`` , but not both.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-launchtemplatespecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    launch_template_specification_property = autoscaling.CfnAutoScalingGroup.LaunchTemplateSpecificationProperty(\n        version="version",\n\n        # the properties below are optional\n        launch_template_id="launchTemplateId",\n        launch_template_name="launchTemplateName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['version', 'launch_template_id', 'launch_template_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.LaunchTemplateSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.LifecycleHookSpecificationProperty
class CfnAutoScalingGroup_LifecycleHookSpecificationPropertyDef(BaseStruct):
    lifecycle_hook_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the lifecycle hook.\n')
    lifecycle_transition: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The lifecycle transition. For Auto Scaling groups, there are two major lifecycle transitions. - To create a lifecycle hook for scale-out events, specify ``autoscaling:EC2_INSTANCE_LAUNCHING`` . - To create a lifecycle hook for scale-in events, specify ``autoscaling:EC2_INSTANCE_TERMINATING`` .\n')
    default_result: typing.Optional[str] = pydantic.Field(None, description='The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. The default value is ``ABANDON`` . Valid values: ``CONTINUE`` | ``ABANDON``\n')
    heartbeat_timeout: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum time, in seconds, that can elapse before the lifecycle hook times out. The range is from ``30`` to ``7200`` seconds. The default value is ``3600`` seconds (1 hour).\n')
    notification_metadata: typing.Optional[str] = pydantic.Field(None, description='Additional information that you want to include any time Amazon EC2 Auto Scaling sends a message to the notification target.\n')
    notification_target_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the notification target that Amazon EC2 Auto Scaling sends notifications to when an instance is in a wait state for the lifecycle hook. You can specify an Amazon SNS topic or an Amazon SQS queue.\n')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target. For information about creating this role, see `Configure a notification target for a lifecycle hook <https://docs.aws.amazon.com/autoscaling/ec2/userguide/prepare-for-lifecycle-notifications.html#lifecycle-hook-notification-target>`_ in the *Amazon EC2 Auto Scaling User Guide* . Valid only if the notification target is an Amazon SNS topic or an Amazon SQS queue.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-lifecyclehookspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    lifecycle_hook_specification_property = autoscaling.CfnAutoScalingGroup.LifecycleHookSpecificationProperty(\n        lifecycle_hook_name="lifecycleHookName",\n        lifecycle_transition="lifecycleTransition",\n\n        # the properties below are optional\n        default_result="defaultResult",\n        heartbeat_timeout=123,\n        notification_metadata="notificationMetadata",\n        notification_target_arn="notificationTargetArn",\n        role_arn="roleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['lifecycle_hook_name', 'lifecycle_transition', 'default_result', 'heartbeat_timeout', 'notification_metadata', 'notification_target_arn', 'role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.LifecycleHookSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.MemoryGiBPerVCpuRequestProperty
class CfnAutoScalingGroup_MemoryGiBPerVCpuRequestPropertyDef(BaseStruct):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='The memory maximum in GiB.\n')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='The memory minimum in GiB.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-memorygibpervcpurequest.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    memory_gi_bPer_vCpu_request_property = autoscaling.CfnAutoScalingGroup.MemoryGiBPerVCpuRequestProperty(\n        max=123,\n        min=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max', 'min']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.MemoryGiBPerVCpuRequestProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.MemoryMiBRequestProperty
class CfnAutoScalingGroup_MemoryMiBRequestPropertyDef(BaseStruct):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='The memory maximum in MiB.\n')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='The memory minimum in MiB.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-memorymibrequest.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    memory_mi_bRequest_property = autoscaling.CfnAutoScalingGroup.MemoryMiBRequestProperty(\n        max=123,\n        min=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max', 'min']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.MemoryMiBRequestProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.MetricsCollectionProperty
class CfnAutoScalingGroup_MetricsCollectionPropertyDef(BaseStruct):
    granularity: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The frequency at which Amazon EC2 Auto Scaling sends aggregated data to CloudWatch. The only valid value is ``1Minute`` .\n')
    metrics: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Identifies the metrics to enable. You can specify one or more of the following metrics: - ``GroupMinSize`` - ``GroupMaxSize`` - ``GroupDesiredCapacity`` - ``GroupInServiceInstances`` - ``GroupPendingInstances`` - ``GroupStandbyInstances`` - ``GroupTerminatingInstances`` - ``GroupTotalInstances`` - ``GroupInServiceCapacity`` - ``GroupPendingCapacity`` - ``GroupStandbyCapacity`` - ``GroupTerminatingCapacity`` - ``GroupTotalCapacity`` - ``WarmPoolDesiredCapacity`` - ``WarmPoolWarmedCapacity`` - ``WarmPoolPendingCapacity`` - ``WarmPoolTerminatingCapacity`` - ``WarmPoolTotalCapacity`` - ``GroupAndWarmPoolDesiredCapacity`` - ``GroupAndWarmPoolTotalCapacity`` If you specify ``Granularity`` and don\'t specify any metrics, all metrics are enabled. For more information, see `Auto Scaling group metrics <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-cloudwatch-monitoring.html#as-group-metrics>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-metricscollection.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    metrics_collection_property = autoscaling.CfnAutoScalingGroup.MetricsCollectionProperty(\n        granularity="granularity",\n\n        # the properties below are optional\n        metrics=["metrics"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['granularity', 'metrics']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.MetricsCollectionProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.MixedInstancesPolicyProperty
class CfnAutoScalingGroup_MixedInstancesPolicyPropertyDef(BaseStruct):
    launch_template: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplatePropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='One or more launch templates and the instance types (overrides) that are used to launch EC2 instances to fulfill On-Demand and Spot capacities.\n')
    instances_distribution: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_InstancesDistributionPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The instances distribution.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-mixedinstancespolicy.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    mixed_instances_policy_property = autoscaling.CfnAutoScalingGroup.MixedInstancesPolicyProperty(\n        launch_template=autoscaling.CfnAutoScalingGroup.LaunchTemplateProperty(\n            launch_template_specification=autoscaling.CfnAutoScalingGroup.LaunchTemplateSpecificationProperty(\n                version="version",\n\n                # the properties below are optional\n                launch_template_id="launchTemplateId",\n                launch_template_name="launchTemplateName"\n            ),\n\n            # the properties below are optional\n            overrides=[autoscaling.CfnAutoScalingGroup.LaunchTemplateOverridesProperty(\n                instance_requirements=autoscaling.CfnAutoScalingGroup.InstanceRequirementsProperty(\n                    accelerator_count=autoscaling.CfnAutoScalingGroup.AcceleratorCountRequestProperty(\n                        max=123,\n                        min=123\n                    ),\n                    accelerator_manufacturers=["acceleratorManufacturers"],\n                    accelerator_names=["acceleratorNames"],\n                    accelerator_total_memory_mi_b=autoscaling.CfnAutoScalingGroup.AcceleratorTotalMemoryMiBRequestProperty(\n                        max=123,\n                        min=123\n                    ),\n                    accelerator_types=["acceleratorTypes"],\n                    allowed_instance_types=["allowedInstanceTypes"],\n                    bare_metal="bareMetal",\n                    baseline_ebs_bandwidth_mbps=autoscaling.CfnAutoScalingGroup.BaselineEbsBandwidthMbpsRequestProperty(\n                        max=123,\n                        min=123\n                    ),\n                    burstable_performance="burstablePerformance",\n                    cpu_manufacturers=["cpuManufacturers"],\n                    excluded_instance_types=["excludedInstanceTypes"],\n                    instance_generations=["instanceGenerations"],\n                    local_storage="localStorage",\n                    local_storage_types=["localStorageTypes"],\n                    memory_gi_bPer_vCpu=autoscaling.CfnAutoScalingGroup.MemoryGiBPerVCpuRequestProperty(\n                        max=123,\n                        min=123\n                    ),\n                    memory_mi_b=autoscaling.CfnAutoScalingGroup.MemoryMiBRequestProperty(\n                        max=123,\n                        min=123\n                    ),\n                    network_bandwidth_gbps=autoscaling.CfnAutoScalingGroup.NetworkBandwidthGbpsRequestProperty(\n                        max=123,\n                        min=123\n                    ),\n                    network_interface_count=autoscaling.CfnAutoScalingGroup.NetworkInterfaceCountRequestProperty(\n                        max=123,\n                        min=123\n                    ),\n                    on_demand_max_price_percentage_over_lowest_price=123,\n                    require_hibernate_support=False,\n                    spot_max_price_percentage_over_lowest_price=123,\n                    total_local_storage_gb=autoscaling.CfnAutoScalingGroup.TotalLocalStorageGBRequestProperty(\n                        max=123,\n                        min=123\n                    ),\n                    v_cpu_count=autoscaling.CfnAutoScalingGroup.VCpuCountRequestProperty(\n                        max=123,\n                        min=123\n                    )\n                ),\n                instance_type="instanceType",\n                launch_template_specification=autoscaling.CfnAutoScalingGroup.LaunchTemplateSpecificationProperty(\n                    version="version",\n\n                    # the properties below are optional\n                    launch_template_id="launchTemplateId",\n                    launch_template_name="launchTemplateName"\n                ),\n                weighted_capacity="weightedCapacity"\n            )]\n        ),\n\n        # the properties below are optional\n        instances_distribution=autoscaling.CfnAutoScalingGroup.InstancesDistributionProperty(\n            on_demand_allocation_strategy="onDemandAllocationStrategy",\n            on_demand_base_capacity=123,\n            on_demand_percentage_above_base_capacity=123,\n            spot_allocation_strategy="spotAllocationStrategy",\n            spot_instance_pools=123,\n            spot_max_price="spotMaxPrice"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['launch_template', 'instances_distribution']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.MixedInstancesPolicyProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.NetworkBandwidthGbpsRequestProperty
class CfnAutoScalingGroup_NetworkBandwidthGbpsRequestPropertyDef(BaseStruct):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum amount of network bandwidth, in gigabits per second (Gbps).\n')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum amount of network bandwidth, in gigabits per second (Gbps).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-networkbandwidthgbpsrequest.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    network_bandwidth_gbps_request_property = autoscaling.CfnAutoScalingGroup.NetworkBandwidthGbpsRequestProperty(\n        max=123,\n        min=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max', 'min']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.NetworkBandwidthGbpsRequestProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.NetworkInterfaceCountRequestProperty
class CfnAutoScalingGroup_NetworkInterfaceCountRequestPropertyDef(BaseStruct):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of network interfaces.\n')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum number of network interfaces.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-networkinterfacecountrequest.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    network_interface_count_request_property = autoscaling.CfnAutoScalingGroup.NetworkInterfaceCountRequestProperty(\n        max=123,\n        min=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max', 'min']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.NetworkInterfaceCountRequestProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.NotificationConfigurationProperty
class CfnAutoScalingGroup_NotificationConfigurationPropertyDef(BaseStruct):
    topic_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the Amazon SNS topic.\n')
    notification_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of event types that send a notification. Event types can include any of the following types. *Allowed values* : - ``autoscaling:EC2_INSTANCE_LAUNCH`` - ``autoscaling:EC2_INSTANCE_LAUNCH_ERROR`` - ``autoscaling:EC2_INSTANCE_TERMINATE`` - ``autoscaling:EC2_INSTANCE_TERMINATE_ERROR`` - ``autoscaling:TEST_NOTIFICATION``\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-notificationconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    notification_configuration_property = autoscaling.CfnAutoScalingGroup.NotificationConfigurationProperty(\n        topic_arn="topicArn",\n\n        # the properties below are optional\n        notification_types=["notificationTypes"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['topic_arn', 'notification_types']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.NotificationConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.TagPropertyProperty
class CfnAutoScalingGroup_TagPropertyPropertyDef(BaseStruct):
    key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The tag key.\n')
    propagate_at_launch: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Set to ``true`` if you want CloudFormation to copy the tag to EC2 instances that are launched as part of the Auto Scaling group. Set to ``false`` if you want the tag attached only to the Auto Scaling group and not copied to any instances launched as part of the Auto Scaling group.\n')
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The tag value.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-tagproperty.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    tag_property_property = autoscaling.CfnAutoScalingGroup.TagPropertyProperty(\n        key="key",\n        propagate_at_launch=False,\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['key', 'propagate_at_launch', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.TagPropertyProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.TotalLocalStorageGBRequestProperty
class CfnAutoScalingGroup_TotalLocalStorageGBRequestPropertyDef(BaseStruct):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='The storage maximum in GB.\n')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='The storage minimum in GB.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-totallocalstoragegbrequest.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    total_local_storage_gBRequest_property = autoscaling.CfnAutoScalingGroup.TotalLocalStorageGBRequestProperty(\n        max=123,\n        min=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max', 'min']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.TotalLocalStorageGBRequestProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup.VCpuCountRequestProperty
class CfnAutoScalingGroup_VCpuCountRequestPropertyDef(BaseStruct):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of vCPUs.\n')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum number of vCPUs.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-autoscalinggroup-vcpucountrequest.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    v_cpu_count_request_property = autoscaling.CfnAutoScalingGroup.VCpuCountRequestProperty(\n        max=123,\n        min=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max', 'min']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup.VCpuCountRequestProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnLaunchConfiguration.BlockDeviceMappingProperty
class CfnLaunchConfiguration_BlockDeviceMappingPropertyDef(BaseStruct):
    device_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The device name assigned to the volume (for example, ``/dev/sdh`` or ``xvdh`` ). For more information, see `Device naming on Linux instances <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/device_naming.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . .. epigraph:: To define a block device mapping, set the device name and exactly one of the following properties: ``Ebs`` , ``NoDevice`` , or ``VirtualName`` .\n')
    ebs: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnLaunchConfiguration_BlockDevicePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Information to attach an EBS volume to an instance at launch.\n')
    no_device: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Setting this value to ``true`` prevents a volume that is included in the block device mapping of the AMI from being mapped to the specified device name at launch. If ``NoDevice`` is ``true`` for the root device, instances might fail the EC2 health check. In that case, Amazon EC2 Auto Scaling launches replacement instances.\n')
    virtual_name: typing.Optional[str] = pydantic.Field(None, description='The name of the instance store volume (virtual device) to attach to an instance at launch. The name must be in the form ephemeral *X* where *X* is a number starting from zero (0), for example, ``ephemeral0`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-launchconfiguration-blockdevicemapping.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    block_device_mapping_property = autoscaling.CfnLaunchConfiguration.BlockDeviceMappingProperty(\n        device_name="deviceName",\n\n        # the properties below are optional\n        ebs=autoscaling.CfnLaunchConfiguration.BlockDeviceProperty(\n            delete_on_termination=False,\n            encrypted=False,\n            iops=123,\n            snapshot_id="snapshotId",\n            throughput=123,\n            volume_size=123,\n            volume_type="volumeType"\n        ),\n        no_device=False,\n        virtual_name="virtualName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['device_name', 'ebs', 'no_device', 'virtual_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnLaunchConfiguration.BlockDeviceMappingProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnLaunchConfiguration.BlockDeviceProperty
class CfnLaunchConfiguration_BlockDevicePropertyDef(BaseStruct):
    delete_on_termination: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether the volume is deleted on instance termination. For Amazon EC2 Auto Scaling, the default value is ``true`` .\n')
    encrypted: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Specifies whether the volume should be encrypted. Encrypted EBS volumes can only be attached to instances that support Amazon EBS encryption. For more information, see `Supported instance types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#EBSEncryption_supported_instances>`_ . If your AMI uses encrypted volumes, you can also only launch it on supported instance types. .. epigraph:: If you are creating a volume from a snapshot, you cannot create an unencrypted volume from an encrypted snapshot. Also, you cannot specify a KMS key ID when using a launch configuration. If you enable encryption by default, the EBS volumes that you create are always encrypted, either using the AWS managed KMS key or a customer-managed KMS key, regardless of whether the snapshot was encrypted. For more information, see `Use AWS KMS keys to encrypt Amazon EBS volumes <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-data-protection.html#encryption>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='The number of input/output (I/O) operations per second (IOPS) to provision for the volume. For ``gp3`` and ``io1`` volumes, this represents the number of IOPS that are provisioned for the volume. For ``gp2`` volumes, this represents the baseline performance of the volume and the rate at which the volume accumulates I/O credits for bursting. The following are the supported values for each volume type: - ``gp3`` : 3,000-16,000 IOPS - ``io1`` : 100-64,000 IOPS For ``io1`` volumes, we guarantee 64,000 IOPS only for `Instances built on the Nitro System <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#ec2-nitro-instances>`_ . Other instance families guarantee performance up to 32,000 IOPS. ``Iops`` is supported when the volume type is ``gp3`` or ``io1`` and required only when the volume type is ``io1`` . (Not used with ``standard`` , ``gp2`` , ``st1`` , or ``sc1`` volumes.)\n')
    snapshot_id: typing.Optional[str] = pydantic.Field(None, description='The snapshot ID of the volume to use. You must specify either a ``VolumeSize`` or a ``SnapshotId`` .\n')
    throughput: typing.Union[int, float, None] = pydantic.Field(None, description='The throughput (MiBps) to provision for a ``gp3`` volume.\n')
    volume_size: typing.Union[int, float, None] = pydantic.Field(None, description='The volume size, in GiBs. The following are the supported volumes sizes for each volume type:. - ``gp2`` and ``gp3`` : 1-16,384 - ``io1`` : 4-16,384 - ``st1`` and ``sc1`` : 125-16,384 - ``standard`` : 1-1,024 You must specify either a ``SnapshotId`` or a ``VolumeSize`` . If you specify both ``SnapshotId`` and ``VolumeSize`` , the volume size must be equal or greater than the size of the snapshot.\n')
    volume_type: typing.Optional[str] = pydantic.Field(None, description='The volume type. For more information, see `Amazon EBS volume types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . Valid values: ``standard`` | ``io1`` | ``gp2`` | ``st1`` | ``sc1`` | ``gp3``\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-launchconfiguration-blockdevice.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    block_device_property = autoscaling.CfnLaunchConfiguration.BlockDeviceProperty(\n        delete_on_termination=False,\n        encrypted=False,\n        iops=123,\n        snapshot_id="snapshotId",\n        throughput=123,\n        volume_size=123,\n        volume_type="volumeType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['delete_on_termination', 'encrypted', 'iops', 'snapshot_id', 'throughput', 'volume_size', 'volume_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnLaunchConfiguration.BlockDeviceProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnLaunchConfiguration.MetadataOptionsProperty
class CfnLaunchConfiguration_MetadataOptionsPropertyDef(BaseStruct):
    http_endpoint: typing.Optional[str] = pydantic.Field(None, description='This parameter enables or disables the HTTP metadata endpoint on your instances. If the parameter is not specified, the default state is ``enabled`` . .. epigraph:: If you specify a value of ``disabled`` , you will not be able to access your instance metadata.\n')
    http_put_response_hop_limit: typing.Union[int, float, None] = pydantic.Field(None, description='The desired HTTP PUT response hop limit for instance metadata requests. The larger the number, the further instance metadata requests can travel. Default: 1\n')
    http_tokens: typing.Optional[str] = pydantic.Field(None, description='The state of token usage for your instance metadata requests. If the parameter is not specified in the request, the default state is ``optional`` . If the state is ``optional`` , you can choose to retrieve instance metadata with or without a signed token header on your request. If you retrieve the IAM role credentials without a token, the version 1.0 role credentials are returned. If you retrieve the IAM role credentials using a valid signed token, the version 2.0 role credentials are returned. If the state is ``required`` , you must send a signed token header with any instance metadata retrieval requests. In this state, retrieving the IAM role credentials always returns the version 2.0 credentials; the version 1.0 credentials are not available.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-launchconfiguration-metadataoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    metadata_options_property = autoscaling.CfnLaunchConfiguration.MetadataOptionsProperty(\n        http_endpoint="httpEndpoint",\n        http_put_response_hop_limit=123,\n        http_tokens="httpTokens"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['http_endpoint', 'http_put_response_hop_limit', 'http_tokens']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnLaunchConfiguration.MetadataOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.CustomizedMetricSpecificationProperty
class CfnScalingPolicy_CustomizedMetricSpecificationPropertyDef(BaseStruct):
    metric_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the metric. To get the exact metric name, namespace, and dimensions, inspect the `Metric <https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Metric.html>`_ object that is returned by a call to `ListMetrics <https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html>`_ .\n')
    namespace: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The namespace of the metric.\n')
    statistic: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The statistic of the metric.\n')
    dimensions: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricDimensionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The dimensions of the metric. Conditional: If you published your metric with dimensions, you must specify the same dimensions in your scaling policy.\n')
    unit: typing.Optional[str] = pydantic.Field(None, description='The unit of the metric. For a complete list of the units that CloudWatch supports, see the `MetricDatum <https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html>`_ data type in the *Amazon CloudWatch API Reference* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-customizedmetricspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    customized_metric_specification_property = autoscaling.CfnScalingPolicy.CustomizedMetricSpecificationProperty(\n        metric_name="metricName",\n        namespace="namespace",\n        statistic="statistic",\n\n        # the properties below are optional\n        dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n            name="name",\n            value="value"\n        )],\n        unit="unit"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric_name', 'namespace', 'statistic', 'dimensions', 'unit']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.CustomizedMetricSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.MetricDataQueryProperty
class CfnScalingPolicy_MetricDataQueryPropertyDef(BaseStruct):
    expression: typing.Optional[str] = pydantic.Field(None, description='The math expression to perform on the returned data, if this object is performing a math expression. This expression can use the ``Id`` of the other metrics to refer to those metrics, and can also use the ``Id`` of other expressions to use the result of those expressions. Conditional: Within each ``MetricDataQuery`` object, you must specify either ``Expression`` or ``MetricStat`` , but not both.\n')
    label: typing.Optional[str] = pydantic.Field(None, description='A human-readable label for this metric or expression. This is especially useful if this is a math expression, so that you know what the value represents.\n')
    metric_stat: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricStatPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Information about the metric data to return. Conditional: Within each ``MetricDataQuery`` object, you must specify either ``Expression`` or ``MetricStat`` , but not both.\n')
    return_data: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether to return the timestamps and raw data values of this metric. If you use any math expressions, specify ``true`` for this value for only the final math expression that the metric specification is based on. You must specify ``false`` for ``ReturnData`` for all the other metrics and expressions used in the metric specification. If you are only retrieving metrics and not performing any math expressions, do not specify anything for ``ReturnData`` . This sets it to its default ( ``true`` ).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-metricdataquery.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    metric_data_query_property = autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n        id="id",\n\n        # the properties below are optional\n        expression="expression",\n        label="label",\n        metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n            metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                metric_name="metricName",\n                namespace="namespace",\n\n                # the properties below are optional\n                dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                    name="name",\n                    value="value"\n                )]\n            ),\n            stat="stat",\n\n            # the properties below are optional\n            unit="unit"\n        ),\n        return_data=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['expression', 'label', 'metric_stat', 'return_data']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.MetricDataQueryProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.MetricDimensionProperty
class CfnScalingPolicy_MetricDimensionPropertyDef(BaseStruct):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the dimension.\n')
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The value of the dimension.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-metricdimension.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    metric_dimension_property = autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n        name="name",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.MetricDimensionProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.MetricProperty
class CfnScalingPolicy_MetricPropertyDef(BaseStruct):
    metric_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the metric.\n')
    namespace: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The namespace of the metric. For more information, see the table in `AWS services that publish CloudWatch metrics <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html>`_ in the *Amazon CloudWatch User Guide* .\n')
    dimensions: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricDimensionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The dimensions for the metric. For the list of available dimensions, see the AWS documentation available from the table in `AWS services that publish CloudWatch metrics <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html>`_ in the *Amazon CloudWatch User Guide* . Conditional: If you published your metric with dimensions, you must specify the same dimensions in your scaling policy.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-metric.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    metric_property = autoscaling.CfnScalingPolicy.MetricProperty(\n        metric_name="metricName",\n        namespace="namespace",\n\n        # the properties below are optional\n        dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n            name="name",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric_name', 'namespace', 'dimensions']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.MetricProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.MetricStatProperty
class CfnScalingPolicy_MetricStatPropertyDef(BaseStruct):
    metric: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The CloudWatch metric to return, including the metric name, namespace, and dimensions. To get the exact metric name, namespace, and dimensions, inspect the `Metric <https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Metric.html>`_ object that is returned by a call to `ListMetrics <https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html>`_ .\n')
    stat: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The statistic to return. It can include any CloudWatch statistic or extended statistic. For a list of valid values, see the table in `Statistics <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Statistic>`_ in the *Amazon CloudWatch User Guide* . The most commonly used metrics for predictive scaling are ``Average`` and ``Sum`` .\n')
    unit: typing.Optional[str] = pydantic.Field(None, description='The unit to use for the returned data points. For a complete list of the units that CloudWatch supports, see the `MetricDatum <https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html>`_ data type in the *Amazon CloudWatch API Reference* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-metricstat.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    metric_stat_property = autoscaling.CfnScalingPolicy.MetricStatProperty(\n        metric=autoscaling.CfnScalingPolicy.MetricProperty(\n            metric_name="metricName",\n            namespace="namespace",\n\n            # the properties below are optional\n            dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                name="name",\n                value="value"\n            )]\n        ),\n        stat="stat",\n\n        # the properties below are optional\n        unit="unit"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric', 'stat', 'unit']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.MetricStatProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.PredefinedMetricSpecificationProperty
class CfnScalingPolicy_PredefinedMetricSpecificationPropertyDef(BaseStruct):
    predefined_metric_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The metric type. The following predefined metrics are available:. - ``ASGAverageCPUUtilization`` - Average CPU utilization of the Auto Scaling group. - ``ASGAverageNetworkIn`` - Average number of bytes received on all network interfaces by the Auto Scaling group. - ``ASGAverageNetworkOut`` - Average number of bytes sent out on all network interfaces by the Auto Scaling group. - ``ALBRequestCountPerTarget`` - Average Application Load Balancer request count per target for your Auto Scaling group.\n')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='A label that uniquely identifies a specific Application Load Balancer target group from which to determine the average request count served by your Auto Scaling group. You can\'t specify a resource label unless the target group is attached to the Auto Scaling group. You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is: ``app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff`` . Where: - app// is the final portion of the load balancer ARN - targetgroup// is the final portion of the target group ARN. To find the ARN for an Application Load Balancer, use the `DescribeLoadBalancers <https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html>`_ API operation. To find the ARN for the target group, use the `DescribeTargetGroups <https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html>`_ API operation.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-predefinedmetricspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    predefined_metric_specification_property = autoscaling.CfnScalingPolicy.PredefinedMetricSpecificationProperty(\n        predefined_metric_type="predefinedMetricType",\n\n        # the properties below are optional\n        resource_label="resourceLabel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['predefined_metric_type', 'resource_label']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.PredefinedMetricSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingConfigurationProperty
class CfnScalingPolicy_PredictiveScalingConfigurationPropertyDef(BaseStruct):
    metric_specifications: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingMetricSpecificationPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='This structure includes the metrics and target utilization to use for predictive scaling. This is an array, but we currently only support a single metric specification. That is, you can specify a target value and a single metric pair, or a target value and one scaling metric and one load metric.\n')
    max_capacity_breach_behavior: typing.Optional[str] = pydantic.Field(None, description='Defines the behavior that should be applied if the forecast capacity approaches or exceeds the maximum capacity of the Auto Scaling group. Defaults to ``HonorMaxCapacity`` if not specified. The following are possible values: - ``HonorMaxCapacity`` - Amazon EC2 Auto Scaling cannot scale out capacity higher than the maximum capacity. The maximum capacity is enforced as a hard limit. - ``IncreaseMaxCapacity`` - Amazon EC2 Auto Scaling can scale out capacity higher than the maximum capacity when the forecast capacity is close to or exceeds the maximum capacity. The upper limit is determined by the forecasted capacity and the value for ``MaxCapacityBuffer`` .\n')
    max_capacity_buffer: typing.Union[int, float, None] = pydantic.Field(None, description='The size of the capacity buffer to use when the forecast capacity is close to or exceeds the maximum capacity. The value is specified as a percentage relative to the forecast capacity. For example, if the buffer is 10, this means a 10 percent buffer, such that if the forecast capacity is 50, and the maximum capacity is 40, then the effective maximum capacity is 55. If set to 0, Amazon EC2 Auto Scaling may scale capacity higher than the maximum capacity to equal but not exceed forecast capacity. Required if the ``MaxCapacityBreachBehavior`` property is set to ``IncreaseMaxCapacity`` , and cannot be used otherwise.\n')
    mode: typing.Optional[str] = pydantic.Field(None, description='The predictive scaling mode. Defaults to ``ForecastOnly`` if not specified.\n')
    scheduling_buffer_time: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time, in seconds, by which the instance launch time can be advanced. For example, the forecast says to add capacity at 10:00 AM, and you choose to pre-launch instances by 5 minutes. In that case, the instances will be launched at 9:55 AM. The intention is to give resources time to be provisioned. It can take a few minutes to launch an EC2 instance. The actual amount of time required depends on several factors, such as the size of the instance and whether there are startup scripts to complete. The value must be less than the forecast interval duration of 3600 seconds (60 minutes). Defaults to 300 seconds if not specified.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-predictivescalingconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    predictive_scaling_configuration_property = autoscaling.CfnScalingPolicy.PredictiveScalingConfigurationProperty(\n        metric_specifications=[autoscaling.CfnScalingPolicy.PredictiveScalingMetricSpecificationProperty(\n            target_value=123,\n\n            # the properties below are optional\n            customized_capacity_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedCapacityMetricProperty(\n                metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n                    id="id",\n\n                    # the properties below are optional\n                    expression="expression",\n                    label="label",\n                    metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                        metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                            metric_name="metricName",\n                            namespace="namespace",\n\n                            # the properties below are optional\n                            dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                                name="name",\n                                value="value"\n                            )]\n                        ),\n                        stat="stat",\n\n                        # the properties below are optional\n                        unit="unit"\n                    ),\n                    return_data=False\n                )]\n            ),\n            customized_load_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedLoadMetricProperty(\n                metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n                    id="id",\n\n                    # the properties below are optional\n                    expression="expression",\n                    label="label",\n                    metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                        metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                            metric_name="metricName",\n                            namespace="namespace",\n\n                            # the properties below are optional\n                            dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                                name="name",\n                                value="value"\n                            )]\n                        ),\n                        stat="stat",\n\n                        # the properties below are optional\n                        unit="unit"\n                    ),\n                    return_data=False\n                )]\n            ),\n            customized_scaling_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedScalingMetricProperty(\n                metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n                    id="id",\n\n                    # the properties below are optional\n                    expression="expression",\n                    label="label",\n                    metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                        metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                            metric_name="metricName",\n                            namespace="namespace",\n\n                            # the properties below are optional\n                            dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                                name="name",\n                                value="value"\n                            )]\n                        ),\n                        stat="stat",\n\n                        # the properties below are optional\n                        unit="unit"\n                    ),\n                    return_data=False\n                )]\n            ),\n            predefined_load_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedLoadMetricProperty(\n                predefined_metric_type="predefinedMetricType",\n\n                # the properties below are optional\n                resource_label="resourceLabel"\n            ),\n            predefined_metric_pair_specification=autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedMetricPairProperty(\n                predefined_metric_type="predefinedMetricType",\n\n                # the properties below are optional\n                resource_label="resourceLabel"\n            ),\n            predefined_scaling_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedScalingMetricProperty(\n                predefined_metric_type="predefinedMetricType",\n\n                # the properties below are optional\n                resource_label="resourceLabel"\n            )\n        )],\n\n        # the properties below are optional\n        max_capacity_breach_behavior="maxCapacityBreachBehavior",\n        max_capacity_buffer=123,\n        mode="mode",\n        scheduling_buffer_time=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric_specifications', 'max_capacity_breach_behavior', 'max_capacity_buffer', 'mode', 'scheduling_buffer_time']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedCapacityMetricProperty
class CfnScalingPolicy_PredictiveScalingCustomizedCapacityMetricPropertyDef(BaseStruct):
    metric_data_queries: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricDataQueryPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='One or more metric data queries to provide the data points for a capacity metric. Use multiple metric data queries only if you are performing a math expression on returned data.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-predictivescalingcustomizedcapacitymetric.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    predictive_scaling_customized_capacity_metric_property = autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedCapacityMetricProperty(\n        metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n            id="id",\n\n            # the properties below are optional\n            expression="expression",\n            label="label",\n            metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                    metric_name="metricName",\n                    namespace="namespace",\n\n                    # the properties below are optional\n                    dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                        name="name",\n                        value="value"\n                    )]\n                ),\n                stat="stat",\n\n                # the properties below are optional\n                unit="unit"\n            ),\n            return_data=False\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric_data_queries']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedCapacityMetricProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedLoadMetricProperty
class CfnScalingPolicy_PredictiveScalingCustomizedLoadMetricPropertyDef(BaseStruct):
    metric_data_queries: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricDataQueryPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='One or more metric data queries to provide the data points for a load metric. Use multiple metric data queries only if you are performing a math expression on returned data.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-predictivescalingcustomizedloadmetric.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    predictive_scaling_customized_load_metric_property = autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedLoadMetricProperty(\n        metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n            id="id",\n\n            # the properties below are optional\n            expression="expression",\n            label="label",\n            metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                    metric_name="metricName",\n                    namespace="namespace",\n\n                    # the properties below are optional\n                    dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                        name="name",\n                        value="value"\n                    )]\n                ),\n                stat="stat",\n\n                # the properties below are optional\n                unit="unit"\n            ),\n            return_data=False\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric_data_queries']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedLoadMetricProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedScalingMetricProperty
class CfnScalingPolicy_PredictiveScalingCustomizedScalingMetricPropertyDef(BaseStruct):
    metric_data_queries: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricDataQueryPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='One or more metric data queries to provide the data points for a scaling metric. Use multiple metric data queries only if you are performing a math expression on returned data.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-predictivescalingcustomizedscalingmetric.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    predictive_scaling_customized_scaling_metric_property = autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedScalingMetricProperty(\n        metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n            id="id",\n\n            # the properties below are optional\n            expression="expression",\n            label="label",\n            metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                    metric_name="metricName",\n                    namespace="namespace",\n\n                    # the properties below are optional\n                    dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                        name="name",\n                        value="value"\n                    )]\n                ),\n                stat="stat",\n\n                # the properties below are optional\n                unit="unit"\n            ),\n            return_data=False\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric_data_queries']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedScalingMetricProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingMetricSpecificationProperty
class CfnScalingPolicy_PredictiveScalingMetricSpecificationPropertyDef(BaseStruct):
    target_value: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the target utilization. .. epigraph:: Some metrics are based on a count instead of a percentage, such as the request count for an Application Load Balancer or the number of messages in an SQS queue. If the scaling policy specifies one of these metrics, specify the target utilization as the optimal average request or message count per instance during any one-minute interval.\n')
    customized_capacity_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingCustomizedCapacityMetricPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The customized capacity metric specification.\n')
    customized_load_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingCustomizedLoadMetricPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The customized load metric specification.\n')
    customized_scaling_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingCustomizedScalingMetricPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The customized scaling metric specification.\n')
    predefined_load_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingPredefinedLoadMetricPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The predefined load metric specification.\n')
    predefined_metric_pair_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingPredefinedMetricPairPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The predefined metric pair specification from which Amazon EC2 Auto Scaling determines the appropriate scaling metric and load metric to use.\n')
    predefined_scaling_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingPredefinedScalingMetricPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The predefined scaling metric specification.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-predictivescalingmetricspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    predictive_scaling_metric_specification_property = autoscaling.CfnScalingPolicy.PredictiveScalingMetricSpecificationProperty(\n        target_value=123,\n\n        # the properties below are optional\n        customized_capacity_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedCapacityMetricProperty(\n            metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n                id="id",\n\n                # the properties below are optional\n                expression="expression",\n                label="label",\n                metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                    metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                        metric_name="metricName",\n                        namespace="namespace",\n\n                        # the properties below are optional\n                        dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                            name="name",\n                            value="value"\n                        )]\n                    ),\n                    stat="stat",\n\n                    # the properties below are optional\n                    unit="unit"\n                ),\n                return_data=False\n            )]\n        ),\n        customized_load_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedLoadMetricProperty(\n            metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n                id="id",\n\n                # the properties below are optional\n                expression="expression",\n                label="label",\n                metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                    metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                        metric_name="metricName",\n                        namespace="namespace",\n\n                        # the properties below are optional\n                        dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                            name="name",\n                            value="value"\n                        )]\n                    ),\n                    stat="stat",\n\n                    # the properties below are optional\n                    unit="unit"\n                ),\n                return_data=False\n            )]\n        ),\n        customized_scaling_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedScalingMetricProperty(\n            metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n                id="id",\n\n                # the properties below are optional\n                expression="expression",\n                label="label",\n                metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                    metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                        metric_name="metricName",\n                        namespace="namespace",\n\n                        # the properties below are optional\n                        dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                            name="name",\n                            value="value"\n                        )]\n                    ),\n                    stat="stat",\n\n                    # the properties below are optional\n                    unit="unit"\n                ),\n                return_data=False\n            )]\n        ),\n        predefined_load_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedLoadMetricProperty(\n            predefined_metric_type="predefinedMetricType",\n\n            # the properties below are optional\n            resource_label="resourceLabel"\n        ),\n        predefined_metric_pair_specification=autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedMetricPairProperty(\n            predefined_metric_type="predefinedMetricType",\n\n            # the properties below are optional\n            resource_label="resourceLabel"\n        ),\n        predefined_scaling_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedScalingMetricProperty(\n            predefined_metric_type="predefinedMetricType",\n\n            # the properties below are optional\n            resource_label="resourceLabel"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['target_value', 'customized_capacity_metric_specification', 'customized_load_metric_specification', 'customized_scaling_metric_specification', 'predefined_load_metric_specification', 'predefined_metric_pair_specification', 'predefined_scaling_metric_specification']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingMetricSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedLoadMetricProperty
class CfnScalingPolicy_PredictiveScalingPredefinedLoadMetricPropertyDef(BaseStruct):
    predefined_metric_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The metric type.\n')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='A label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group. You can\'t specify a resource label unless the target group is attached to the Auto Scaling group. You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is: ``app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff`` . Where: - app// is the final portion of the load balancer ARN - targetgroup// is the final portion of the target group ARN. To find the ARN for an Application Load Balancer, use the `DescribeLoadBalancers <https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html>`_ API operation. To find the ARN for the target group, use the `DescribeTargetGroups <https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html>`_ API operation.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-predictivescalingpredefinedloadmetric.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    predictive_scaling_predefined_load_metric_property = autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedLoadMetricProperty(\n        predefined_metric_type="predefinedMetricType",\n\n        # the properties below are optional\n        resource_label="resourceLabel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['predefined_metric_type', 'resource_label']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedLoadMetricProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedMetricPairProperty
class CfnScalingPolicy_PredictiveScalingPredefinedMetricPairPropertyDef(BaseStruct):
    predefined_metric_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Indicates which metrics to use. There are two different types of metrics for each metric type: one is a load metric and one is a scaling metric. For example, if the metric type is ``ASGCPUUtilization`` , the Auto Scaling group's total CPU metric is used as the load metric, and the average CPU metric is used for the scaling metric.\n")
    resource_label: typing.Optional[str] = pydantic.Field(None, description='A label that uniquely identifies a specific Application Load Balancer target group from which to determine the total and average request count served by your Auto Scaling group. You can\'t specify a resource label unless the target group is attached to the Auto Scaling group. You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is: ``app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff`` . Where: - app// is the final portion of the load balancer ARN - targetgroup// is the final portion of the target group ARN. To find the ARN for an Application Load Balancer, use the `DescribeLoadBalancers <https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html>`_ API operation. To find the ARN for the target group, use the `DescribeTargetGroups <https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html>`_ API operation.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-predictivescalingpredefinedmetricpair.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    predictive_scaling_predefined_metric_pair_property = autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedMetricPairProperty(\n        predefined_metric_type="predefinedMetricType",\n\n        # the properties below are optional\n        resource_label="resourceLabel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['predefined_metric_type', 'resource_label']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedMetricPairProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedScalingMetricProperty
class CfnScalingPolicy_PredictiveScalingPredefinedScalingMetricPropertyDef(BaseStruct):
    predefined_metric_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The metric type.\n')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='A label that uniquely identifies a specific Application Load Balancer target group from which to determine the average request count served by your Auto Scaling group. You can\'t specify a resource label unless the target group is attached to the Auto Scaling group. You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is: ``app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff`` . Where: - app// is the final portion of the load balancer ARN - targetgroup// is the final portion of the target group ARN. To find the ARN for an Application Load Balancer, use the `DescribeLoadBalancers <https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html>`_ API operation. To find the ARN for the target group, use the `DescribeTargetGroups <https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html>`_ API operation.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-predictivescalingpredefinedscalingmetric.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    predictive_scaling_predefined_scaling_metric_property = autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedScalingMetricProperty(\n        predefined_metric_type="predefinedMetricType",\n\n        # the properties below are optional\n        resource_label="resourceLabel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['predefined_metric_type', 'resource_label']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedScalingMetricProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.StepAdjustmentProperty
class CfnScalingPolicy_StepAdjustmentPropertyDef(BaseStruct):
    scaling_adjustment: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity. For exact capacity, you must specify a non-negative value.\n')
    metric_interval_lower_bound: typing.Union[int, float, None] = pydantic.Field(None, description='The lower bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the lower bound is inclusive (the metric must be greater than or equal to the threshold plus the lower bound). Otherwise, it is exclusive (the metric must be greater than the threshold plus the lower bound). A null value indicates negative infinity.\n')
    metric_interval_upper_bound: typing.Union[int, float, None] = pydantic.Field(None, description='The upper bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the upper bound is exclusive (the metric must be less than the threshold plus the upper bound). Otherwise, it is inclusive (the metric must be less than or equal to the threshold plus the upper bound). A null value indicates positive infinity. The upper bound must be greater than the lower bound.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-stepadjustment.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    step_adjustment_property = autoscaling.CfnScalingPolicy.StepAdjustmentProperty(\n        scaling_adjustment=123,\n\n        # the properties below are optional\n        metric_interval_lower_bound=123,\n        metric_interval_upper_bound=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['scaling_adjustment', 'metric_interval_lower_bound', 'metric_interval_upper_bound']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.StepAdjustmentProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy.TargetTrackingConfigurationProperty
class CfnScalingPolicy_TargetTrackingConfigurationPropertyDef(BaseStruct):
    target_value: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The target value for the metric. .. epigraph:: Some metrics are based on a count instead of a percentage, such as the request count for an Application Load Balancer or the number of messages in an SQS queue. If the scaling policy specifies one of these metrics, specify the target utilization as the optimal average request or message count per instance during any one-minute interval.\n')
    customized_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_CustomizedMetricSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A customized metric. You must specify either a predefined metric or a customized metric.\n')
    disable_scale_in: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="Indicates whether scaling in by the target tracking scaling policy is disabled. If scaling in is disabled, the target tracking scaling policy doesn't remove instances from the Auto Scaling group. Otherwise, the target tracking scaling policy can remove instances from the Auto Scaling group. The default is ``false`` .\n")
    predefined_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredefinedMetricSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A predefined metric. You must specify either a predefined metric or a customized metric.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-scalingpolicy-targettrackingconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    target_tracking_configuration_property = autoscaling.CfnScalingPolicy.TargetTrackingConfigurationProperty(\n        target_value=123,\n\n        # the properties below are optional\n        customized_metric_specification=autoscaling.CfnScalingPolicy.CustomizedMetricSpecificationProperty(\n            metric_name="metricName",\n            namespace="namespace",\n            statistic="statistic",\n\n            # the properties below are optional\n            dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                name="name",\n                value="value"\n            )],\n            unit="unit"\n        ),\n        disable_scale_in=False,\n        predefined_metric_specification=autoscaling.CfnScalingPolicy.PredefinedMetricSpecificationProperty(\n            predefined_metric_type="predefinedMetricType",\n\n            # the properties below are optional\n            resource_label="resourceLabel"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['target_value', 'customized_metric_specification', 'disable_scale_in', 'predefined_metric_specification']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy.TargetTrackingConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnWarmPool.InstanceReusePolicyProperty
class CfnWarmPool_InstanceReusePolicyPropertyDef(BaseStruct):
    reuse_on_scale_in: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Specifies whether instances in the Auto Scaling group can be returned to the warm pool on scale in.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-autoscaling-warmpool-instancereusepolicy.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    instance_reuse_policy_property = autoscaling.CfnWarmPool.InstanceReusePolicyProperty(\n        reuse_on_scale_in=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['reuse_on_scale_in']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnWarmPool.InstanceReusePolicyProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CommonAutoScalingGroupProps
class CommonAutoScalingGroupPropsDef(BaseStruct):
    allow_all_outbound: typing.Optional[bool] = pydantic.Field(None, description='Whether the instances can initiate connections to anywhere by default. Default: true\n')
    associate_public_ip_address: typing.Optional[bool] = pydantic.Field(None, description='Whether instances in the Auto Scaling Group should have public IP addresses associated with them. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Use subnet setting.\n')
    auto_scaling_group_name: typing.Optional[str] = pydantic.Field(None, description='The name of the Auto Scaling group. This name must be unique per Region per account. Default: - Auto generated by CloudFormation\n')
    block_devices: typing.Optional[typing.Sequence[typing.Union[models.aws_autoscaling.BlockDeviceDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies how block devices are exposed to the instance. You can specify virtual devices and EBS volumes. Each instance that is launched has an associated root device volume, either an Amazon EBS volume or an instance store volume. You can use block device mappings to specify additional EBS volumes or instance store volumes to attach to an instance when it is launched. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Uses the block device mapping of the AMI\n')
    capacity_rebalance: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether Capacity Rebalancing is enabled. When you turn on Capacity Rebalancing, Amazon EC2 Auto Scaling attempts to launch a Spot Instance whenever Amazon EC2 notifies that a Spot Instance is at an elevated risk of interruption. After launching a new instance, it then terminates an old instance. Default: false\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Default scaling cooldown for this AutoScalingGroup. Default: Duration.minutes(5)\n')
    default_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The amount of time, in seconds, until a newly launched instance can contribute to the Amazon CloudWatch metrics. This delay lets an instance finish initializing before Amazon EC2 Auto Scaling aggregates instance metrics, resulting in more reliable usage data. Set this value equal to the amount of time that it takes for resource consumption to become stable after an instance reaches the InService state. To optimize the performance of scaling policies that scale continuously, such as target tracking and step scaling policies, we strongly recommend that you enable the default instance warmup, even if its value is set to 0 seconds Default instance warmup will not be added if no value is specified Default: None\n')
    desired_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Initial amount of instances in the fleet. If this is set to a number, every deployment will reset the amount of instances to this number. It is recommended to leave this value blank. Default: minCapacity, and leave unchanged during deployment\n')
    group_metrics: typing.Optional[typing.Sequence[models.aws_autoscaling.GroupMetricsDef]] = pydantic.Field(None, description='Enable monitoring for group metrics, these metrics describe the group rather than any of its instances. To report all group metrics use ``GroupMetrics.all()`` Group metrics are reported in a granularity of 1 minute at no additional charge. Default: - no group metrics will be reported\n')
    health_check: typing.Optional[models.aws_autoscaling.HealthCheckDef] = pydantic.Field(None, description='Configuration for health checks. Default: - HealthCheck.ec2 with no grace period\n')
    ignore_unmodified_size_properties: typing.Optional[bool] = pydantic.Field(None, description="If the ASG has scheduled actions, don't reset unchanged group sizes. Only used if the ASG has scheduled actions (which may scale your ASG up or down regardless of cdk deployments). If true, the size of the group will only be reset if it has been changed in the CDK app. If false, the sizes will always be changed back to what they were in the CDK app on deployment. Default: true\n")
    instance_monitoring: typing.Optional[aws_cdk.aws_autoscaling.Monitoring] = pydantic.Field(None, description='Controls whether instances in this group are launched with detailed or basic monitoring. When detailed monitoring is enabled, Amazon CloudWatch generates metrics every minute and your account is charged a fee. When you disable detailed monitoring, CloudWatch generates metrics every 5 minutes. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - Monitoring.DETAILED\n')
    key_name: typing.Optional[str] = pydantic.Field(None, description='Name of SSH keypair to grant access to instances. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: - No SSH access will be possible.\n')
    max_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Maximum number of instances in the fleet. Default: desiredCapacity\n')
    max_instance_lifetime: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The maximum amount of time that an instance can be in service. The maximum duration applies to all current and future instances in the group. As an instance approaches its maximum duration, it is terminated and replaced, and cannot be used again. You must specify a value of at least 604,800 seconds (7 days). To clear a previously set value, leave this property undefined. Default: none\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum number of instances in the fleet. Default: 1\n')
    new_instances_protected_from_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Whether newly-launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. By default, Auto Scaling can terminate an instance at any time after launch when scaling in an Auto Scaling Group, subject to the group's termination policy. However, you may wish to protect newly-launched instances from being scaled in if they are going to run critical applications that should not be prematurely terminated. This flag must be enabled if the Auto Scaling Group will be associated with an ECS Capacity Provider with managed termination protection. Default: false\n")
    notifications: typing.Optional[typing.Sequence[typing.Union[models.aws_autoscaling.NotificationConfigurationDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Configure autoscaling group to send notifications about fleet changes to an SNS topic(s). Default: - No fleet change notifications will be sent.\n')
    signals: typing.Optional[models.aws_autoscaling.SignalsDef] = pydantic.Field(None, description='Configure waiting for signals during deployment. Use this to pause the CloudFormation deployment to wait for the instances in the AutoScalingGroup to report successful startup during creation and updates. The UserData script needs to invoke ``cfn-signal`` with a success or failure code after it is done setting up the instance. Without waiting for signals, the CloudFormation deployment will proceed as soon as the AutoScalingGroup has been created or updated but before the instances in the group have been started. For example, to have instances wait for an Elastic Load Balancing health check before they signal success, add a health-check verification by using the cfn-init helper script. For an example, see the verify_instance_health command in the Auto Scaling rolling updates sample template: https://github.com/awslabs/aws-cloudformation-templates/blob/master/aws/services/AutoScaling/AutoScalingRollingUpdates.yaml Default: - Do not wait for signals\n')
    spot_price: typing.Optional[str] = pydantic.Field(None, description='The maximum hourly price (in USD) to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot market price. ``launchTemplate`` and ``mixedInstancesPolicy`` must not be specified when this property is specified Default: none\n')
    ssm_session_permissions: typing.Optional[bool] = pydantic.Field(None, description='Add SSM session permissions to the instance role. Setting this to ``true`` adds the necessary permissions to connect to the instance using SSM Session Manager. You can do this from the AWS Console. NOTE: Setting this flag to ``true`` may not be enough by itself. You must also use an AMI that comes with the SSM Agent, or install the SSM Agent yourself. See `Working with SSM Agent <https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html>`_ in the SSM Developer Guide. Default: false\n')
    termination_policies: typing.Optional[typing.Sequence[aws_cdk.aws_autoscaling.TerminationPolicy]] = pydantic.Field(None, description='A policy or a list of policies that are used to select the instances to terminate. The policies are executed in the order that you list them. Default: - ``TerminationPolicy.DEFAULT``\n')
    update_policy: typing.Optional[models.aws_autoscaling.UpdatePolicyDef] = pydantic.Field(None, description="What to do when an AutoScalingGroup's instance configuration is changed. This is applied when any of the settings on the ASG are changed that affect how the instances should be created (VPC, instance type, startup scripts, etc.). It indicates how the existing instances should be replaced with new instances matching the new config. By default, nothing is done and only new instances are launched with the new config. Default: - ``UpdatePolicy.rollingUpdate()`` if using ``init``, ``UpdatePolicy.none()`` otherwise\n")
    vpc_subnets: typing.Union[models.aws_ec2.SubnetSelectionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Where to place instances within the VPC. Default: - All Private subnets.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_autoscaling as autoscaling\n    from aws_cdk import aws_ec2 as ec2\n    from aws_cdk import aws_sns as sns\n\n    # block_device_volume: autoscaling.BlockDeviceVolume\n    # group_metrics: autoscaling.GroupMetrics\n    # health_check: autoscaling.HealthCheck\n    # scaling_events: autoscaling.ScalingEvents\n    # signals: autoscaling.Signals\n    # subnet: ec2.Subnet\n    # subnet_filter: ec2.SubnetFilter\n    # topic: sns.Topic\n    # update_policy: autoscaling.UpdatePolicy\n\n    common_auto_scaling_group_props = autoscaling.CommonAutoScalingGroupProps(\n        allow_all_outbound=False,\n        associate_public_ip_address=False,\n        auto_scaling_group_name="autoScalingGroupName",\n        block_devices=[autoscaling.BlockDevice(\n            device_name="deviceName",\n            volume=block_device_volume\n        )],\n        capacity_rebalance=False,\n        cooldown=cdk.Duration.minutes(30),\n        default_instance_warmup=cdk.Duration.minutes(30),\n        desired_capacity=123,\n        group_metrics=[group_metrics],\n        health_check=health_check,\n        ignore_unmodified_size_properties=False,\n        instance_monitoring=autoscaling.Monitoring.BASIC,\n        key_name="keyName",\n        max_capacity=123,\n        max_instance_lifetime=cdk.Duration.minutes(30),\n        min_capacity=123,\n        new_instances_protected_from_scale_in=False,\n        notifications=[autoscaling.NotificationConfiguration(\n            topic=topic,\n\n            # the properties below are optional\n            scaling_events=scaling_events\n        )],\n        signals=signals,\n        spot_price="spotPrice",\n        ssm_session_permissions=False,\n        termination_policies=[autoscaling.TerminationPolicy.ALLOCATION_STRATEGY],\n        update_policy=update_policy,\n        vpc_subnets=ec2.SubnetSelection(\n            availability_zones=["availabilityZones"],\n            one_per_az=False,\n            subnet_filters=[subnet_filter],\n            subnet_group_name="subnetGroupName",\n            subnets=[subnet],\n            subnet_type=ec2.SubnetType.PRIVATE_ISOLATED\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['allow_all_outbound', 'associate_public_ip_address', 'auto_scaling_group_name', 'block_devices', 'capacity_rebalance', 'cooldown', 'default_instance_warmup', 'desired_capacity', 'group_metrics', 'health_check', 'ignore_unmodified_size_properties', 'instance_monitoring', 'key_name', 'max_capacity', 'max_instance_lifetime', 'min_capacity', 'new_instances_protected_from_scale_in', 'notifications', 'signals', 'spot_price', 'ssm_session_permissions', 'termination_policies', 'update_policy', 'vpc_subnets']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CommonAutoScalingGroupProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CpuUtilizationScalingProps
class CpuUtilizationScalingPropsDef(BaseStruct):
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.\n')
    target_utilization_percent: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='Target average CPU utilization across the task.\n\n:exampleMetadata: infused\n\nExample::\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n\n\n    auto_scaling_group.scale_on_cpu_utilization("KeepSpareCPU",\n        target_utilization_percent=50\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cooldown', 'disable_scale_in', 'estimated_instance_warmup', 'target_utilization_percent']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CpuUtilizationScalingProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CronOptions
class CronOptionsDef(BaseStruct):
    day: typing.Optional[str] = pydantic.Field(None, description='The day of the month to run this rule at. Default: - Every day of the month\n')
    hour: typing.Optional[str] = pydantic.Field(None, description='The hour to run this rule at. Default: - Every hour\n')
    minute: typing.Optional[str] = pydantic.Field(None, description='The minute to run this rule at. Default: - Every minute\n')
    month: typing.Optional[str] = pydantic.Field(None, description='The month to run this rule at. Default: - Every month\n')
    week_day: typing.Optional[str] = pydantic.Field(None, description='The day of the week to run this rule at. Default: - Any day of the week\n\n:see: http://crontab.org/\n:exampleMetadata: infused\n\nExample::\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n\n\n    auto_scaling_group.scale_on_schedule("PrescaleInTheMorning",\n        schedule=autoscaling.Schedule.cron(hour="8", minute="0"),\n        min_capacity=20\n    )\n\n    auto_scaling_group.scale_on_schedule("AllowDownscalingAtNight",\n        schedule=autoscaling.Schedule.cron(hour="20", minute="0"),\n        min_capacity=1\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['day', 'hour', 'minute', 'month', 'week_day']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CronOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.EbsDeviceOptions
class EbsDeviceOptionsDef(BaseStruct):
    delete_on_termination: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether to delete the volume when the instance is terminated. Default: - true for Amazon EC2 Auto Scaling, false otherwise (e.g. EBS)\n')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='The number of I/O operations per second (IOPS) to provision for the volume. Must only be set for ``volumeType``: ``EbsDeviceVolumeType.IO1`` The maximum ratio of IOPS to volume size (in GiB) is 50:1, so for 5,000 provisioned IOPS, you need at least 100 GiB storage on the volume. Default: - none, required for ``EbsDeviceVolumeType.IO1``\n')
    throughput: typing.Union[int, float, None] = pydantic.Field(None, description='The throughput that the volume supports, in MiB/s Takes a minimum of 125 and maximum of 1000. Default: - 125 MiB/s. Only valid on gp3 volumes.\n')
    volume_type: typing.Optional[aws_cdk.aws_autoscaling.EbsDeviceVolumeType] = pydantic.Field(None, description='The EBS volume type. Default: ``EbsDeviceVolumeType.GP2``\n')
    encrypted: typing.Optional[bool] = pydantic.Field(None, description='Specifies whether the EBS volume is encrypted. Encrypted EBS volumes can only be attached to instances that support Amazon EBS encryption Default: false\n\n:exampleMetadata: infused\n\nExample::\n\n    # vpc: ec2.Vpc\n    # instance_type: ec2.InstanceType\n    # machine_image: ec2.IMachineImage\n\n\n    auto_scaling_group = autoscaling.AutoScalingGroup(self, "ASG",\n        vpc=vpc,\n        instance_type=instance_type,\n        machine_image=machine_image,\n        block_devices=[autoscaling.BlockDevice(\n            device_name="gp3-volume",\n            volume=autoscaling.BlockDeviceVolume.ebs(15,\n                volume_type=autoscaling.EbsDeviceVolumeType.GP3,\n                throughput=125\n            )\n        )\n        ]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['delete_on_termination', 'iops', 'throughput', 'volume_type', 'encrypted']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.EbsDeviceOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.EbsDeviceOptionsBase
class EbsDeviceOptionsBaseDef(BaseStruct):
    delete_on_termination: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether to delete the volume when the instance is terminated. Default: - true for Amazon EC2 Auto Scaling, false otherwise (e.g. EBS)\n')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='The number of I/O operations per second (IOPS) to provision for the volume. Must only be set for ``volumeType``: ``EbsDeviceVolumeType.IO1`` The maximum ratio of IOPS to volume size (in GiB) is 50:1, so for 5,000 provisioned IOPS, you need at least 100 GiB storage on the volume. Default: - none, required for ``EbsDeviceVolumeType.IO1``\n')
    throughput: typing.Union[int, float, None] = pydantic.Field(None, description='The throughput that the volume supports, in MiB/s Takes a minimum of 125 and maximum of 1000. Default: - 125 MiB/s. Only valid on gp3 volumes.\n')
    volume_type: typing.Optional[aws_cdk.aws_autoscaling.EbsDeviceVolumeType] = pydantic.Field(None, description='The EBS volume type. Default: ``EbsDeviceVolumeType.GP2``\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    ebs_device_options_base = autoscaling.EbsDeviceOptionsBase(\n        delete_on_termination=False,\n        iops=123,\n        throughput=123,\n        volume_type=autoscaling.EbsDeviceVolumeType.STANDARD\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['delete_on_termination', 'iops', 'throughput', 'volume_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.EbsDeviceOptionsBase'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.EbsDeviceProps
class EbsDevicePropsDef(BaseStruct):
    delete_on_termination: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether to delete the volume when the instance is terminated. Default: - true for Amazon EC2 Auto Scaling, false otherwise (e.g. EBS)\n')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='The number of I/O operations per second (IOPS) to provision for the volume. Must only be set for ``volumeType``: ``EbsDeviceVolumeType.IO1`` The maximum ratio of IOPS to volume size (in GiB) is 50:1, so for 5,000 provisioned IOPS, you need at least 100 GiB storage on the volume. Default: - none, required for ``EbsDeviceVolumeType.IO1``\n')
    throughput: typing.Union[int, float, None] = pydantic.Field(None, description='The throughput that the volume supports, in MiB/s Takes a minimum of 125 and maximum of 1000. Default: - 125 MiB/s. Only valid on gp3 volumes.\n')
    volume_type: typing.Optional[aws_cdk.aws_autoscaling.EbsDeviceVolumeType] = pydantic.Field(None, description='The EBS volume type. Default: ``EbsDeviceVolumeType.GP2``\n')
    volume_size: typing.Union[int, float, None] = pydantic.Field(None, description='The volume size, in Gibibytes (GiB). If you specify volumeSize, it must be equal or greater than the size of the snapshot. Default: - The snapshot size\n')
    snapshot_id: typing.Optional[str] = pydantic.Field(None, description='The snapshot ID of the volume to use. Default: - No snapshot will be used\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    ebs_device_props = autoscaling.EbsDeviceProps(\n        delete_on_termination=False,\n        iops=123,\n        snapshot_id="snapshotId",\n        throughput=123,\n        volume_size=123,\n        volume_type=autoscaling.EbsDeviceVolumeType.STANDARD\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['delete_on_termination', 'iops', 'throughput', 'volume_type', 'volume_size', 'snapshot_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.EbsDeviceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.EbsDeviceSnapshotOptions
class EbsDeviceSnapshotOptionsDef(BaseStruct):
    delete_on_termination: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether to delete the volume when the instance is terminated. Default: - true for Amazon EC2 Auto Scaling, false otherwise (e.g. EBS)\n')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='The number of I/O operations per second (IOPS) to provision for the volume. Must only be set for ``volumeType``: ``EbsDeviceVolumeType.IO1`` The maximum ratio of IOPS to volume size (in GiB) is 50:1, so for 5,000 provisioned IOPS, you need at least 100 GiB storage on the volume. Default: - none, required for ``EbsDeviceVolumeType.IO1``\n')
    throughput: typing.Union[int, float, None] = pydantic.Field(None, description='The throughput that the volume supports, in MiB/s Takes a minimum of 125 and maximum of 1000. Default: - 125 MiB/s. Only valid on gp3 volumes.\n')
    volume_type: typing.Optional[aws_cdk.aws_autoscaling.EbsDeviceVolumeType] = pydantic.Field(None, description='The EBS volume type. Default: ``EbsDeviceVolumeType.GP2``\n')
    volume_size: typing.Union[int, float, None] = pydantic.Field(None, description='The volume size, in Gibibytes (GiB). If you specify volumeSize, it must be equal or greater than the size of the snapshot. Default: - The snapshot size\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    ebs_device_snapshot_options = autoscaling.EbsDeviceSnapshotOptions(\n        delete_on_termination=False,\n        iops=123,\n        throughput=123,\n        volume_size=123,\n        volume_type=autoscaling.EbsDeviceVolumeType.STANDARD\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['delete_on_termination', 'iops', 'throughput', 'volume_type', 'volume_size']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.EbsDeviceSnapshotOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.Ec2HealthCheckOptions
class Ec2HealthCheckOptionsDef(BaseStruct):
    grace: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Specified the time Auto Scaling waits before checking the health status of an EC2 instance that has come into service. Default: Duration.seconds(0)\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    ec2_health_check_options = autoscaling.Ec2HealthCheckOptions(\n        grace=cdk.Duration.minutes(30)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['grace']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.Ec2HealthCheckOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.ElbHealthCheckOptions
class ElbHealthCheckOptionsDef(BaseStruct):
    grace: typing.Union[models.DurationDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specified the time Auto Scaling waits before checking the health status of an EC2 instance that has come into service. This option is required for ELB health checks.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    elb_health_check_options = autoscaling.ElbHealthCheckOptions(\n        grace=cdk.Duration.minutes(30)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['grace']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.ElbHealthCheckOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.ElbHealthCheckOptionsDefConfig] = pydantic.Field(None)


class ElbHealthCheckOptionsDefConfig(pydantic.BaseModel):
    grace_config: typing.Optional[models.core.DurationDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.InstancesDistribution
class InstancesDistributionDef(BaseStruct):
    on_demand_allocation_strategy: typing.Optional[aws_cdk.aws_autoscaling.OnDemandAllocationStrategy] = pydantic.Field(None, description='Indicates how to allocate instance types to fulfill On-Demand capacity. The only valid value is prioritized, which is also the default value. Default: OnDemandAllocationStrategy.PRIORITIZED\n')
    on_demand_base_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="The minimum amount of the Auto Scaling group's capacity that must be fulfilled by On-Demand Instances. This base portion is provisioned first as your group scales. Defaults to 0 if not specified. If you specify weights for the instance types in the overrides, set the value of OnDemandBaseCapacity in terms of the number of capacity units, and not the number of instances. Default: 0\n")
    on_demand_percentage_above_base_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Controls the percentages of On-Demand Instances and Spot Instances for your additional capacity beyond OnDemandBaseCapacity. Expressed as a number (for example, 20 specifies 20% On-Demand Instances, 80% Spot Instances). Defaults to 100 if not specified. If set to 100, only On-Demand Instances are provisioned. Default: 100\n')
    spot_allocation_strategy: typing.Optional[aws_cdk.aws_autoscaling.SpotAllocationStrategy] = pydantic.Field(None, description='If the allocation strategy is lowest-price, the Auto Scaling group launches instances using the Spot pools with the lowest price, and evenly allocates your instances across the number of Spot pools that you specify. Defaults to lowest-price if not specified. If the allocation strategy is capacity-optimized (recommended), the Auto Scaling group launches instances using Spot pools that are optimally chosen based on the available Spot capacity. Alternatively, you can use capacity-optimized-prioritized and set the order of instance types in the list of launch template overrides from highest to lowest priority (from first to last in the list). Amazon EC2 Auto Scaling honors the instance type priorities on a best-effort basis but optimizes for capacity first. Default: SpotAllocationStrategy.LOWEST_PRICE\n')
    spot_instance_pools: typing.Union[int, float, None] = pydantic.Field(None, description='The number of Spot Instance pools to use to allocate your Spot capacity. The Spot pools are determined from the different instance types in the overrides. Valid only when the Spot allocation strategy is lowest-price. Value must be in the range of 1 to 20. Defaults to 2 if not specified. Default: 2\n')
    spot_max_price: typing.Optional[str] = pydantic.Field(None, description='The maximum price per unit hour that you are willing to pay for a Spot Instance. If you leave the value at its default (empty), Amazon EC2 Auto Scaling uses the On-Demand price as the maximum Spot price. To remove a value that you previously set, include the property but specify an empty string ("") for the value. Default: "" - On-Demand price\n\n:exampleMetadata: infused\n\nExample::\n\n    # vpc: ec2.Vpc\n    # launch_template1: ec2.LaunchTemplate\n    # launch_template2: ec2.LaunchTemplate\n\n\n    autoscaling.AutoScalingGroup(self, "ASG",\n        vpc=vpc,\n        mixed_instances_policy=autoscaling.MixedInstancesPolicy(\n            instances_distribution=autoscaling.InstancesDistribution(\n                on_demand_percentage_above_base_capacity=50\n            ),\n            launch_template=launch_template1,\n            launch_template_overrides=[autoscaling.LaunchTemplateOverrides(instance_type=ec2.InstanceType("t3.micro")), autoscaling.LaunchTemplateOverrides(instance_type=ec2.InstanceType("t3a.micro")), autoscaling.LaunchTemplateOverrides(instance_type=ec2.InstanceType("t4g.micro"), launch_template=launch_template2)]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['on_demand_allocation_strategy', 'on_demand_base_capacity', 'on_demand_percentage_above_base_capacity', 'spot_allocation_strategy', 'spot_instance_pools', 'spot_max_price']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.InstancesDistribution'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.LaunchTemplateOverrides
class LaunchTemplateOverridesDef(BaseStruct):
    instance_type: typing.Union[models.aws_ec2.InstanceTypeDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The instance type, such as m3.xlarge. You must use an instance type that is supported in your requested Region and Availability Zones. Default: - Do not override instance type\n')
    launch_template: typing.Optional[typing.Union[models.aws_ec2.LaunchTemplateDef]] = pydantic.Field(None, description="Provides the launch template to be used when launching the instance type. For example, some instance types might require a launch template with a different AMI. If not provided, Amazon EC2 Auto Scaling uses the launch template that's defined for your mixed instances policy. Default: - Do not override launch template\n")
    weighted_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The number of capacity units provided by the specified instance type in terms of virtual CPUs, memory, storage, throughput, or other relative performance characteristic. When a Spot or On-Demand Instance is provisioned, the capacity units count toward the desired capacity. Amazon EC2 Auto Scaling provisions instances until the desired capacity is totally fulfilled, even if this results in an overage. Value must be in the range of 1 to 999. For example, If there are 2 units remaining to fulfill capacity, and Amazon EC2 Auto Scaling can only provision an instance with a WeightedCapacity of 5 units, the instance is provisioned, and the desired capacity is exceeded by 3 units. Default: - Do not provide weight\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n    from aws_cdk import aws_ec2 as ec2\n\n    # instance_type: ec2.InstanceType\n    # launch_template: ec2.LaunchTemplate\n\n    launch_template_overrides = autoscaling.LaunchTemplateOverrides(\n        instance_type=instance_type,\n\n        # the properties below are optional\n        launch_template=launch_template,\n        weighted_capacity=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['instance_type', 'launch_template', 'weighted_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.LaunchTemplateOverrides'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.LaunchTemplateOverridesDefConfig] = pydantic.Field(None)


class LaunchTemplateOverridesDefConfig(pydantic.BaseModel):
    instance_type_config: typing.Optional[models.aws_ec2.InstanceTypeDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.LifecycleHookProps
class LifecycleHookPropsDef(BaseStruct):
    lifecycle_transition: typing.Union[aws_cdk.aws_autoscaling.LifecycleTransition, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The state of the Amazon EC2 instance to which you want to attach the lifecycle hook.\n')
    default_result: typing.Optional[aws_cdk.aws_autoscaling.DefaultResult] = pydantic.Field(None, description='The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. Default: Continue\n')
    heartbeat_timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Maximum time between calls to RecordLifecycleActionHeartbeat for the hook. If the lifecycle hook times out, perform the action in DefaultResult. Default: - No heartbeat timeout.\n')
    lifecycle_hook_name: typing.Optional[str] = pydantic.Field(None, description='Name of the lifecycle hook. Default: - Automatically generated name.\n')
    notification_metadata: typing.Optional[str] = pydantic.Field(None, description='Additional data to pass to the lifecycle hook target. Default: - No metadata.\n')
    notification_target: typing.Optional[typing.Union[models.aws_autoscaling_hooktargets.FunctionHookDef, models.aws_autoscaling_hooktargets.QueueHookDef, models.aws_autoscaling_hooktargets.TopicHookDef]] = pydantic.Field(None, description='The target of the lifecycle hook. Default: - No target.\n')
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The role that allows publishing to the notification target. Default: - A role will be created if a target is provided. Otherwise, no role is created.\n')
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AutoScalingGroup to add the lifecycle hook to.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_autoscaling as autoscaling\n    from aws_cdk import aws_iam as iam\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n    # lifecycle_hook_target: autoscaling.ILifecycleHookTarget\n    # role: iam.Role\n\n    lifecycle_hook_props = autoscaling.LifecycleHookProps(\n        auto_scaling_group=auto_scaling_group,\n        lifecycle_transition=autoscaling.LifecycleTransition.INSTANCE_LAUNCHING,\n\n        # the properties below are optional\n        default_result=autoscaling.DefaultResult.CONTINUE,\n        heartbeat_timeout=cdk.Duration.minutes(30),\n        lifecycle_hook_name="lifecycleHookName",\n        notification_metadata="notificationMetadata",\n        notification_target=lifecycle_hook_target,\n        role=role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['lifecycle_transition', 'default_result', 'heartbeat_timeout', 'lifecycle_hook_name', 'notification_metadata', 'notification_target', 'role', 'auto_scaling_group']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.LifecycleHookProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.LifecycleHookPropsDefConfig] = pydantic.Field(None)


class LifecycleHookPropsDefConfig(pydantic.BaseModel):
    auto_scaling_group_config: typing.Optional[models._interface_methods.AwsAutoscalingIAutoScalingGroupDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.LifecycleHookTargetConfig
class LifecycleHookTargetConfigDef(BaseStruct):
    created_role: typing.Union[_REQUIRED_INIT_PARAM, models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The IRole that was used to bind the lifecycle hook to the target.\n')
    notification_target_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The targetArn that the lifecycle hook was bound to.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n    from aws_cdk import aws_iam as iam\n\n    # role: iam.Role\n\n    lifecycle_hook_target_config = autoscaling.LifecycleHookTargetConfig(\n        created_role=role,\n        notification_target_arn="notificationTargetArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['created_role', 'notification_target_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.LifecycleHookTargetConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.LifecycleHookTargetConfigDefConfig] = pydantic.Field(None)


class LifecycleHookTargetConfigDefConfig(pydantic.BaseModel):
    created_role_config: typing.Optional[models._interface_methods.AwsIamIRoleDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.MetricTargetTrackingProps
class MetricTargetTrackingPropsDef(BaseStruct):
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.\n')
    metric: typing.Union[_REQUIRED_INIT_PARAM, models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef] = pydantic.Field(REQUIRED_INIT_PARAM, description="Metric to track. The metric must represent a utilization, so that if it's higher than the target value, your ASG should scale out, and if it's lower it should scale in.\n")
    target_value: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='Value to keep the metric around.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_autoscaling as autoscaling\n    from aws_cdk import aws_cloudwatch as cloudwatch\n\n    # metric: cloudwatch.Metric\n\n    metric_target_tracking_props = autoscaling.MetricTargetTrackingProps(\n        metric=metric,\n        target_value=123,\n\n        # the properties below are optional\n        cooldown=cdk.Duration.minutes(30),\n        disable_scale_in=False,\n        estimated_instance_warmup=cdk.Duration.minutes(30)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cooldown', 'disable_scale_in', 'estimated_instance_warmup', 'metric', 'target_value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.MetricTargetTrackingProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.MixedInstancesPolicy
class MixedInstancesPolicyDef(BaseStruct):
    launch_template: typing.Union[_REQUIRED_INIT_PARAM, models.aws_ec2.LaunchTemplateDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='Launch template to use.\n')
    instances_distribution: typing.Union[models.aws_autoscaling.InstancesDistributionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='InstancesDistribution to use. Default: - The value for each property in it uses a default value.\n')
    launch_template_overrides: typing.Optional[typing.Sequence[typing.Union[models.aws_autoscaling.LaunchTemplateOverridesDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Launch template overrides. The maximum number of instance types that can be associated with an Auto Scaling group is 40. The maximum number of distinct launch templates you can define for an Auto Scaling group is 20. Default: - Do not provide any overrides\n\n:exampleMetadata: infused\n\nExample::\n\n    # vpc: ec2.Vpc\n    # launch_template1: ec2.LaunchTemplate\n    # launch_template2: ec2.LaunchTemplate\n\n\n    autoscaling.AutoScalingGroup(self, "ASG",\n        vpc=vpc,\n        mixed_instances_policy=autoscaling.MixedInstancesPolicy(\n            instances_distribution=autoscaling.InstancesDistribution(\n                on_demand_percentage_above_base_capacity=50\n            ),\n            launch_template=launch_template1,\n            launch_template_overrides=[autoscaling.LaunchTemplateOverrides(instance_type=ec2.InstanceType("t3.micro")), autoscaling.LaunchTemplateOverrides(instance_type=ec2.InstanceType("t3a.micro")), autoscaling.LaunchTemplateOverrides(instance_type=ec2.InstanceType("t4g.micro"), launch_template=launch_template2)]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['launch_template', 'instances_distribution', 'launch_template_overrides']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.MixedInstancesPolicy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.MixedInstancesPolicyDefConfig] = pydantic.Field(None)


class MixedInstancesPolicyDefConfig(pydantic.BaseModel):
    launch_template_config: typing.Optional[models._interface_methods.AwsEc2ILaunchTemplateDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.NetworkUtilizationScalingProps
class NetworkUtilizationScalingPropsDef(BaseStruct):
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.\n')
    target_bytes_per_second: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='Target average bytes/seconds on each instance.\n\n:exampleMetadata: infused\n\nExample::\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n\n\n    auto_scaling_group.scale_on_incoming_bytes("LimitIngressPerInstance",\n        target_bytes_per_second=10 * 1024 * 1024\n    )\n    auto_scaling_group.scale_on_outgoing_bytes("LimitEgressPerInstance",\n        target_bytes_per_second=10 * 1024 * 1024\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cooldown', 'disable_scale_in', 'estimated_instance_warmup', 'target_bytes_per_second']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.NetworkUtilizationScalingProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.NotificationConfiguration
class NotificationConfigurationDef(BaseStruct):
    topic: typing.Union[_REQUIRED_INIT_PARAM, models.aws_sns.TopicBaseDef, models.aws_sns.TopicDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='SNS topic to send notifications about fleet scaling events.\n')
    scaling_events: typing.Optional[models.aws_autoscaling.ScalingEventsDef] = pydantic.Field(None, description='Which fleet scaling events triggers a notification. Default: ScalingEvents.ALL\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n    from aws_cdk import aws_sns as sns\n\n    # scaling_events: autoscaling.ScalingEvents\n    # topic: sns.Topic\n\n    notification_configuration = autoscaling.NotificationConfiguration(\n        topic=topic,\n\n        # the properties below are optional\n        scaling_events=scaling_events\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['topic', 'scaling_events']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.NotificationConfiguration'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.NotificationConfigurationDefConfig] = pydantic.Field(None)


class NotificationConfigurationDefConfig(pydantic.BaseModel):
    topic_config: typing.Optional[models._interface_methods.AwsSnsITopicDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.RenderSignalsOptions
class RenderSignalsOptionsDef(BaseStruct):
    desired_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The desiredCapacity of the ASG. Default: - desired capacity not configured\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The minSize of the ASG. Default: - minCapacity not configured\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    render_signals_options = autoscaling.RenderSignalsOptions(\n        desired_capacity=123,\n        min_capacity=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['desired_capacity', 'min_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.RenderSignalsOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.RequestCountScalingProps
class RequestCountScalingPropsDef(BaseStruct):
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.\n')
    target_requests_per_minute: typing.Union[int, float, None] = pydantic.Field(None, description='Target average requests/minute on each instance. Default: - Specify exactly one of \'targetRequestsPerMinute\' and \'targetRequestsPerSecond\'\n\n:exampleMetadata: infused\n\nExample::\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n\n\n    auto_scaling_group.scale_on_request_count("LimitRPS",\n        target_requests_per_second=1000\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cooldown', 'disable_scale_in', 'estimated_instance_warmup', 'target_requests_per_minute']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.RequestCountScalingProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.RollingUpdateOptions
class RollingUpdateOptionsDef(BaseStruct):
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of instances that AWS CloudFormation updates at once. This number affects the speed of the replacement. Default: 1\n')
    min_instances_in_service: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum number of instances that must be in service before more instances are replaced. This number affects the speed of the replacement. Default: 0\n')
    min_success_percentage: typing.Union[int, float, None] = pydantic.Field(None, description='The percentage of instances that must signal success for the update to succeed. Default: - The ``minSuccessPercentage`` configured for ``signals`` on the AutoScalingGroup\n')
    pause_time: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The pause time after making a change to a batch of instances. Default: - The ``timeout`` configured for ``signals`` on the AutoScalingGroup\n')
    suspend_processes: typing.Optional[typing.Sequence[aws_cdk.aws_autoscaling.ScalingProcess]] = pydantic.Field(None, description='Specifies the Auto Scaling processes to suspend during a stack update. Suspending processes prevents Auto Scaling from interfering with a stack update. Default: HealthCheck, ReplaceUnhealthy, AZRebalance, AlarmNotification, ScheduledActions.\n')
    wait_on_resource_signals: typing.Optional[bool] = pydantic.Field(None, description='Specifies whether the Auto Scaling group waits on signals from new instances during an update. Default: true if you configured ``signals`` on the AutoScalingGroup, false otherwise\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    rolling_update_options = autoscaling.RollingUpdateOptions(\n        max_batch_size=123,\n        min_instances_in_service=123,\n        min_success_percentage=123,\n        pause_time=cdk.Duration.minutes(30),\n        suspend_processes=[autoscaling.ScalingProcess.LAUNCH],\n        wait_on_resource_signals=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_batch_size', 'min_instances_in_service', 'min_success_percentage', 'pause_time', 'suspend_processes', 'wait_on_resource_signals']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.RollingUpdateOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.ScalingInterval
class ScalingIntervalDef(BaseStruct):
    change: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The capacity adjustment to apply in this interval. The number is interpreted differently based on AdjustmentType: - ChangeInCapacity: add the adjustment to the current capacity. The number can be positive or negative. - PercentChangeInCapacity: add or remove the given percentage of the current capacity to itself. The number can be in the range [-100..100]. - ExactCapacity: set the capacity to this number. The number must be positive.\n')
    lower: typing.Union[int, float, None] = pydantic.Field(None, description='The lower bound of the interval. The scaling adjustment will be applied if the metric is higher than this value. Default: Threshold automatically derived from neighbouring intervals\n')
    upper: typing.Union[int, float, None] = pydantic.Field(None, description='The upper bound of the interval. The scaling adjustment will be applied if the metric is lower than this value. Default: Threshold automatically derived from neighbouring intervals\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    scaling_interval = autoscaling.ScalingInterval(\n        change=123,\n\n        # the properties below are optional\n        lower=123,\n        upper=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['change', 'lower', 'upper']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.ScalingInterval'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.ScheduledActionProps
class ScheduledActionPropsDef(BaseStruct):
    schedule: typing.Union[models.aws_autoscaling.ScheduleDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='When to perform this action. Supports cron expressions. For more information about cron expressions, see https://en.wikipedia.org/wiki/Cron.\n')
    desired_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new desired capacity. At the scheduled time, set the desired capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new desired capacity.\n')
    end_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action expires. Default: - The rule never expires.\n')
    max_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new maximum capacity. At the scheduled time, set the maximum capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new maximum capacity.\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new minimum capacity. At the scheduled time, set the minimum capacity to the given capacity. At least one of maxCapacity, minCapacity, or desiredCapacity must be supplied. Default: - No new minimum capacity.\n')
    start_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action becomes active. Default: - The rule is activate immediately.\n')
    time_zone: typing.Optional[str] = pydantic.Field(None, description='Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as Etc/GMT+9 or Pacific/Tahiti). For more information, see https://en.wikipedia.org/wiki/List_of_tz_database_time_zones. Default: - UTC\n')
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AutoScalingGroup to apply the scheduled actions to.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n    # schedule: autoscaling.Schedule\n\n    scheduled_action_props = autoscaling.ScheduledActionProps(\n        auto_scaling_group=auto_scaling_group,\n        schedule=schedule,\n\n        # the properties below are optional\n        desired_capacity=123,\n        end_time=Date(),\n        max_capacity=123,\n        min_capacity=123,\n        start_time=Date(),\n        time_zone="timeZone"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['schedule', 'desired_capacity', 'end_time', 'max_capacity', 'min_capacity', 'start_time', 'time_zone', 'auto_scaling_group']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.ScheduledActionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.ScheduledActionPropsDefConfig] = pydantic.Field(None)


class ScheduledActionPropsDefConfig(pydantic.BaseModel):
    auto_scaling_group_config: typing.Optional[models._interface_methods.AwsAutoscalingIAutoScalingGroupDefConfig] = pydantic.Field(None)
    schedule_config: typing.Optional[models.aws_autoscaling.ScheduleDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.SignalsOptions
class SignalsOptionsDef(BaseStruct):
    min_success_percentage: typing.Union[int, float, None] = pydantic.Field(None, description='The percentage of signals that need to be successful. If this number is less than 100, a percentage of signals may be failure signals while still succeeding the creation or update in CloudFormation. Default: 100\n')
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='How long to wait for the signals to be sent. This should reflect how long it takes your instances to start up (including instance start time and instance initialization time). Default: Duration.minutes(5)\n\n:exampleMetadata: infused\n\nExample::\n\n    # vpc: ec2.Vpc\n    # instance_type: ec2.InstanceType\n    # machine_image: ec2.IMachineImage\n\n\n    autoscaling.AutoScalingGroup(self, "ASG",\n        vpc=vpc,\n        instance_type=instance_type,\n        machine_image=machine_image,\n\n        # ...\n\n        init=ec2.CloudFormationInit.from_elements(\n            ec2.InitFile.from_string("/etc/my_instance", "This got written during instance startup")),\n        signals=autoscaling.Signals.wait_for_all(\n            timeout=Duration.minutes(10)\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['min_success_percentage', 'timeout']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.SignalsOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.StepScalingActionProps
class StepScalingActionPropsDef(BaseStruct):
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The auto scaling group.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_autoscaling.AdjustmentType] = pydantic.Field(None, description='How the adjustment numbers are interpreted. Default: ChangeInCapacity\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: The default cooldown configured on the AutoScalingGroup\n')
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: Same as the cooldown\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_autoscaling.MetricAggregationType] = pydantic.Field(None, description='The aggregation type for the CloudWatch metrics. Default: Average\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n\n    step_scaling_action_props = autoscaling.StepScalingActionProps(\n        auto_scaling_group=auto_scaling_group,\n\n        # the properties below are optional\n        adjustment_type=autoscaling.AdjustmentType.CHANGE_IN_CAPACITY,\n        cooldown=cdk.Duration.minutes(30),\n        estimated_instance_warmup=cdk.Duration.minutes(30),\n        metric_aggregation_type=autoscaling.MetricAggregationType.AVERAGE,\n        min_adjustment_magnitude=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group', 'adjustment_type', 'cooldown', 'estimated_instance_warmup', 'metric_aggregation_type', 'min_adjustment_magnitude']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.StepScalingActionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.StepScalingActionPropsDefConfig] = pydantic.Field(None)


class StepScalingActionPropsDefConfig(pydantic.BaseModel):
    auto_scaling_group_config: typing.Optional[models._interface_methods.AwsAutoscalingIAutoScalingGroupDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.StepScalingPolicyProps
class StepScalingPolicyPropsDef(BaseStruct):
    metric: typing.Union[_REQUIRED_INIT_PARAM, models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='Metric to scale on.')
    scaling_steps: typing.Union[typing.Sequence[typing.Union[models.aws_autoscaling.ScalingIntervalDef, dict[str, typing.Any]]], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The intervals for scaling. Maps a range of metric values to a particular scaling behavior. Must be between 2 and 40 steps.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_autoscaling.AdjustmentType] = pydantic.Field(None, description="How the adjustment numbers inside 'intervals' are interpreted. Default: ChangeInCapacity\n")
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Grace period after scaling activity. Default: Default cooldown period on your AutoScalingGroup\n')
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: Same as the cooldown\n')
    evaluation_periods: typing.Union[int, float, None] = pydantic.Field(None, description='How many evaluation periods of the metric to wait before triggering a scaling action. Raising this value can be used to smooth out the metric, at the expense of slower response times. Default: 1\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_autoscaling.MetricAggregationType] = pydantic.Field(None, description='Aggregation to apply to all data points over the evaluation periods. Only has meaning if ``evaluationPeriods != 1``. Default: - The statistic from the metric if applicable (MIN, MAX, AVERAGE), otherwise AVERAGE.\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect\n')
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The auto scaling group.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_autoscaling as autoscaling\n    from aws_cdk import aws_cloudwatch as cloudwatch\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n    # metric: cloudwatch.Metric\n\n    step_scaling_policy_props = autoscaling.StepScalingPolicyProps(\n        auto_scaling_group=auto_scaling_group,\n        metric=metric,\n        scaling_steps=[autoscaling.ScalingInterval(\n            change=123,\n\n            # the properties below are optional\n            lower=123,\n            upper=123\n        )],\n\n        # the properties below are optional\n        adjustment_type=autoscaling.AdjustmentType.CHANGE_IN_CAPACITY,\n        cooldown=cdk.Duration.minutes(30),\n        estimated_instance_warmup=cdk.Duration.minutes(30),\n        evaluation_periods=123,\n        metric_aggregation_type=autoscaling.MetricAggregationType.AVERAGE,\n        min_adjustment_magnitude=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric', 'scaling_steps', 'adjustment_type', 'cooldown', 'estimated_instance_warmup', 'evaluation_periods', 'metric_aggregation_type', 'min_adjustment_magnitude', 'auto_scaling_group']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.StepScalingPolicyProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.StepScalingPolicyPropsDefConfig] = pydantic.Field(None)


class StepScalingPolicyPropsDefConfig(pydantic.BaseModel):
    auto_scaling_group_config: typing.Optional[models._interface_methods.AwsAutoscalingIAutoScalingGroupDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.TargetTrackingScalingPolicyProps
class TargetTrackingScalingPolicyPropsDef(BaseStruct):
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scaling completes before another scaling activity can start. Default: - The default cooldown configured on the AutoScalingGroup.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the autoscaling group. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the group. Default: false\n")
    estimated_instance_warmup: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Estimated time until a newly launched instance can send metrics to CloudWatch. Default: - Same as the cooldown.\n')
    target_value: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The target value for the metric.\n')
    custom_metric: typing.Optional[typing.Union[models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef]] = pydantic.Field(None, description='A custom metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No custom metric.\n')
    predefined_metric: typing.Optional[aws_cdk.aws_autoscaling.PredefinedMetric] = pydantic.Field(None, description='A predefined metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No predefined metric.\n')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='The resource label associated with the predefined metric. Should be supplied if the predefined metric is ALBRequestCountPerTarget, and the format should be: app///targetgroup// Default: - No resource label.\n')
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='')
    _init_params: typing.ClassVar[list[str]] = ['cooldown', 'disable_scale_in', 'estimated_instance_warmup', 'target_value', 'custom_metric', 'predefined_metric', 'resource_label', 'auto_scaling_group']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.TargetTrackingScalingPolicyProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.TargetTrackingScalingPolicyPropsDefConfig] = pydantic.Field(None)


class TargetTrackingScalingPolicyPropsDefConfig(pydantic.BaseModel):
    auto_scaling_group_config: typing.Optional[models._interface_methods.AwsAutoscalingIAutoScalingGroupDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.WarmPoolOptions
class WarmPoolOptionsDef(BaseStruct):
    max_group_prepared_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="The maximum number of instances that are allowed to be in the warm pool or in any state except Terminated for the Auto Scaling group. If the value is not specified, Amazon EC2 Auto Scaling launches and maintains the difference between the group's maximum capacity and its desired capacity. Default: - max size of the Auto Scaling group\n")
    min_size: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum number of instances to maintain in the warm pool. Default: 0\n')
    pool_state: typing.Optional[aws_cdk.aws_autoscaling.PoolState] = pydantic.Field(None, description='The instance state to transition to after the lifecycle actions are complete. Default: PoolState.STOPPED\n')
    reuse_on_scale_in: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether instances in the Auto Scaling group can be returned to the warm pool on scale in. If the value is not specified, instances in the Auto Scaling group will be terminated when the group scales in. Default: false\n\n:exampleMetadata: infused\n\nExample::\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n\n\n    auto_scaling_group.add_warm_pool(\n        min_size=1,\n        reuse_on_scale_in=True\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_group_prepared_capacity', 'min_size', 'pool_state', 'reuse_on_scale_in']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.WarmPoolOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.WarmPoolProps
class WarmPoolPropsDef(BaseStruct):
    max_group_prepared_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="The maximum number of instances that are allowed to be in the warm pool or in any state except Terminated for the Auto Scaling group. If the value is not specified, Amazon EC2 Auto Scaling launches and maintains the difference between the group's maximum capacity and its desired capacity. Default: - max size of the Auto Scaling group\n")
    min_size: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum number of instances to maintain in the warm pool. Default: 0\n')
    pool_state: typing.Optional[aws_cdk.aws_autoscaling.PoolState] = pydantic.Field(None, description='The instance state to transition to after the lifecycle actions are complete. Default: PoolState.STOPPED\n')
    reuse_on_scale_in: typing.Optional[bool] = pydantic.Field(None, description='Indicates whether instances in the Auto Scaling group can be returned to the warm pool on scale in. If the value is not specified, instances in the Auto Scaling group will be terminated when the group scales in. Default: false\n')
    auto_scaling_group: typing.Union[_REQUIRED_INIT_PARAM, models.aws_autoscaling.AutoScalingGroupDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Auto Scaling group to add the warm pool to.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    # auto_scaling_group: autoscaling.AutoScalingGroup\n\n    warm_pool_props = autoscaling.WarmPoolProps(\n        auto_scaling_group=auto_scaling_group,\n\n        # the properties below are optional\n        max_group_prepared_capacity=123,\n        min_size=123,\n        pool_state=autoscaling.PoolState.HIBERNATED,\n        reuse_on_scale_in=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_group_prepared_capacity', 'min_size', 'pool_state', 'reuse_on_scale_in', 'auto_scaling_group']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.WarmPoolProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.WarmPoolPropsDefConfig] = pydantic.Field(None)


class WarmPoolPropsDefConfig(pydantic.BaseModel):
    auto_scaling_group_config: typing.Optional[models._interface_methods.AwsAutoscalingIAutoScalingGroupDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_autoscaling.AdjustmentType
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.DefaultResult
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.EbsDeviceVolumeType
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.LifecycleTransition
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.MetricAggregationType
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.Monitoring
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.OnDemandAllocationStrategy
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.PoolState
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.PredefinedMetric
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.ScalingEvent
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.ScalingProcess
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.SpotAllocationStrategy
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.TerminationPolicy
# skipping emum

#  autogenerated from aws_cdk.aws_autoscaling.IAutoScalingGroup
#  skipping Interface

#  autogenerated from aws_cdk.aws_autoscaling.ILifecycleHook
#  skipping Interface

#  autogenerated from aws_cdk.aws_autoscaling.ILifecycleHookTarget
#  skipping Interface

#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroup
class CfnAutoScalingGroupDef(BaseCfnResource):
    max_size: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The maximum size of the group. .. epigraph:: With a mixed instances policy that uses instance weighting, Amazon EC2 Auto Scaling may need to go above ``MaxSize`` to meet your capacity requirements. In this event, Amazon EC2 Auto Scaling will never go above ``MaxSize`` by more than your largest instance weight (weights that define how many units each instance contributes to the desired capacity of the group).\n')
    min_size: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The minimum size of the group.\n')
    auto_scaling_group_name: typing.Optional[str] = pydantic.Field(None, description='The name of the Auto Scaling group. This name must be unique per Region per account. The name can contain any ASCII character 33 to 126 including most punctuation characters, digits, and upper and lowercased letters. .. epigraph:: You cannot use a colon (:) in the name.\n')
    availability_zones: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of Availability Zones where instances in the Auto Scaling group can be created. Used for launching into the default VPC subnet in each Availability Zone when not using the ``VPCZoneIdentifier`` property, or for attaching a network interface when an existing network interface ID is specified in a launch template.\n')
    capacity_rebalance: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether Capacity Rebalancing is enabled. Otherwise, Capacity Rebalancing is disabled. When you turn on Capacity Rebalancing, Amazon EC2 Auto Scaling attempts to launch a Spot Instance whenever Amazon EC2 notifies that a Spot Instance is at an elevated risk of interruption. After launching a new instance, it then terminates an old instance. For more information, see `Use Capacity Rebalancing to handle Amazon EC2 Spot Interruptions <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html>`_ in the in the *Amazon EC2 Auto Scaling User Guide* .\n')
    context: typing.Optional[str] = pydantic.Field(None, description='Reserved.\n')
    cooldown: typing.Optional[str] = pydantic.Field(None, description='*Only needed if you use simple scaling policies.*. The amount of time, in seconds, between one scaling activity ending and another one starting due to simple scaling policies. For more information, see `Scaling cooldowns for Amazon EC2 Auto Scaling <https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Default: ``300`` seconds\n')
    default_instance_warmup: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time, in seconds, until a new instance is considered to have finished initializing and resource consumption to become stable after it enters the ``InService`` state. During an instance refresh, Amazon EC2 Auto Scaling waits for the warm-up period after it replaces an instance before it moves on to replacing the next instance. Amazon EC2 Auto Scaling also waits for the warm-up period before aggregating the metrics for new instances with existing instances in the Amazon CloudWatch metrics that are used for scaling, resulting in more reliable usage data. For more information, see `Set the default instance warmup for an Auto Scaling group <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-default-instance-warmup.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . .. epigraph:: To manage various warm-up settings at the group level, we recommend that you set the default instance warmup, *even if it is set to 0 seconds* . To remove a value that you previously set, include the property but specify ``-1`` for the value. However, we strongly recommend keeping the default instance warmup enabled by specifying a value of ``0`` or other nominal value. Default: None\n')
    desired_capacity: typing.Optional[str] = pydantic.Field(None, description='The desired capacity is the initial capacity of the Auto Scaling group at the time of its creation and the capacity it attempts to maintain. It can scale beyond this capacity if you configure automatic scaling. The number must be greater than or equal to the minimum size of the group and less than or equal to the maximum size of the group. If you do not specify a desired capacity when creating the stack, the default is the minimum size of the group. CloudFormation marks the Auto Scaling group as successful (by setting its status to CREATE_COMPLETE) when the desired capacity is reached. However, if a maximum Spot price is set in the launch template or launch configuration that you specified, then desired capacity is not used as a criteria for success. Whether your request is fulfilled depends on Spot Instance capacity and your maximum price.\n')
    desired_capacity_type: typing.Optional[str] = pydantic.Field(None, description='The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports ``DesiredCapacityType`` for attribute-based instance type selection only. For more information, see `Creating an Auto Scaling group using attribute-based instance type selection <https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-instance-type-requirements.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . By default, Amazon EC2 Auto Scaling specifies ``units`` , which translates into number of instances. Valid values: ``units`` | ``vcpu`` | ``memory-mib``\n')
    health_check_grace_period: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time, in seconds, that Amazon EC2 Auto Scaling waits before checking the health status of an EC2 instance that has come into service and marking it unhealthy due to a failed health check. This is useful if your instances do not immediately pass their health checks after they enter the ``InService`` state. For more information, see `Set the health check grace period for an Auto Scaling group <https://docs.aws.amazon.com/autoscaling/ec2/userguide/health-check-grace-period.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Default: ``0`` seconds\n')
    health_check_type: typing.Optional[str] = pydantic.Field(None, description='A comma-separated value string of one or more health check types. The valid values are ``EC2`` , ``ELB`` , and ``VPC_LATTICE`` . ``EC2`` is the default health check and cannot be disabled. For more information, see `Health checks for Auto Scaling instances <https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Only specify ``EC2`` if you must clear a value that was previously set.\n')
    instance_id: typing.Optional[str] = pydantic.Field(None, description="The ID of the instance used to base the launch configuration on. For more information, see `Create an Auto Scaling group using an EC2 instance <https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-from-instance.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . If you specify ``LaunchTemplate`` , ``MixedInstancesPolicy`` , or ``LaunchConfigurationName`` , don't specify ``InstanceId`` .\n")
    launch_configuration_name: typing.Optional[str] = pydantic.Field(None, description="The name of the launch configuration to use to launch instances. Required only if you don't specify ``LaunchTemplate`` , ``MixedInstancesPolicy`` , or ``InstanceId`` .\n")
    launch_template: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplateSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Information used to specify the launch template and version to use to launch instances. You can alternatively associate a launch template to the Auto Scaling group by specifying a ``MixedInstancesPolicy`` . For more information about creating launch templates, see `Create a launch template for an Auto Scaling group <https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-template.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . If you omit this property, you must specify ``MixedInstancesPolicy`` , ``LaunchConfigurationName`` , or ``InstanceId`` .\n')
    lifecycle_hook_specification_list: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LifecycleHookSpecificationPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='One or more lifecycle hooks to add to the Auto Scaling group before instances are launched.\n')
    load_balancer_names: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of Classic Load Balancers associated with this Auto Scaling group. For Application Load Balancers, Network Load Balancers, and Gateway Load Balancers, specify the ``TargetGroupARNs`` property instead.\n')
    max_instance_lifetime: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum amount of time, in seconds, that an instance can be in service. The default is null. If specified, the value must be either 0 or a number equal to or greater than 86,400 seconds (1 day). For more information, see `Replacing Auto Scaling instances based on maximum instance lifetime <https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-max-instance-lifetime.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    metrics_collection: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_MetricsCollectionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Enables the monitoring of group metrics of an Auto Scaling group. By default, these metrics are disabled.\n')
    mixed_instances_policy: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_MixedInstancesPolicyPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An embedded object that specifies a mixed instances policy. The policy includes properties that not only define the distribution of On-Demand Instances and Spot Instances, the maximum price to pay for Spot Instances (optional), and how the Auto Scaling group allocates instance types to fulfill On-Demand and Spot capacities, but also the properties that specify the instance configuration information—the launch template and instance types. The policy can also include a weight for each instance type and different launch templates for individual instance types. For more information, see `Auto Scaling groups with multiple instance types and purchase options <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    new_instances_protected_from_scale_in: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. For more information about preventing instances from terminating on scale in, see `Using instance scale-in protection <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-instance-protection.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    notification_configuration: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_NotificationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    notification_configurations: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_NotificationConfigurationPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Configures an Auto Scaling group to send notifications when specified events take place.\n')
    placement_group: typing.Optional[str] = pydantic.Field(None, description='The name of the placement group into which to launch your instances. For more information, see `Placement groups <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . .. epigraph:: A *cluster* placement group is a logical grouping of instances within a single Availability Zone. You cannot specify multiple Availability Zones and a cluster placement group.\n')
    service_linked_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other AWS service on your behalf. By default, Amazon EC2 Auto Scaling uses a service-linked role named ``AWSServiceRoleForAutoScaling`` , which it creates if it does not exist. For more information, see `Service-linked roles <https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-service-linked-role.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.aws_autoscaling.CfnAutoScalingGroup_TagPropertyPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='One or more tags. You can tag your Auto Scaling group and propagate the tags to the Amazon EC2 instances it launches. Tags are not propagated to Amazon EBS volumes. To add tags to Amazon EBS volumes, specify the tags in a launch template but use caution. If the launch template specifies an instance tag with a key that is also specified for the Auto Scaling group, Amazon EC2 Auto Scaling overrides the value of that instance tag with the value specified by the Auto Scaling group. For more information, see `Tag Auto Scaling groups and instances <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-tagging.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    target_group_arns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The Amazon Resource Names (ARN) of the Elastic Load Balancing target groups to associate with the Auto Scaling group. Instances are registered as targets with the target groups. The target groups receive incoming traffic and route requests to one or more registered targets. For more information, see `Use Elastic Load Balancing to distribute traffic across the instances in your Auto Scaling group <https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    termination_policies: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A policy or a list of policies that are used to select the instance to terminate. These policies are executed in the order that you list them. For more information, see `Work with Amazon EC2 Auto Scaling termination policies <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-termination-policies.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Valid values: ``Default`` | ``AllocationStrategy`` | ``ClosestToNextInstanceHour`` | ``NewestInstance`` | ``OldestInstance`` | ``OldestLaunchConfiguration`` | ``OldestLaunchTemplate`` | ``arn:aws:lambda:region:account-id:function:my-function:my-alias``\n')
    vpc_zone_identifier: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of subnet IDs for a virtual private cloud (VPC) where instances in the Auto Scaling group can be created. If this resource specifies public subnets and is also in a VPC that is defined in the same stack template, you must use the `DependsOn attribute <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-dependson.html>`_ to declare a dependency on the `VPC-gateway attachment <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-vpc-gateway-attachment.html>`_ . .. epigraph:: When you update ``VPCZoneIdentifier`` , this retains the same Auto Scaling group and replaces old instances with new ones, according to the specified subnets. You can optionally specify how CloudFormation handles these updates by using an `UpdatePolicy attribute <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-updatepolicy.html>`_ . Required to launch instances into a nondefault VPC. If you specify ``VPCZoneIdentifier`` with ``AvailabilityZones`` , the subnets that you specify for this property must reside in those Availability Zones.')
    _init_params: typing.ClassVar[list[str]] = ['max_size', 'min_size', 'auto_scaling_group_name', 'availability_zones', 'capacity_rebalance', 'context', 'cooldown', 'default_instance_warmup', 'desired_capacity', 'desired_capacity_type', 'health_check_grace_period', 'health_check_type', 'instance_id', 'launch_configuration_name', 'launch_template', 'lifecycle_hook_specification_list', 'load_balancer_names', 'max_instance_lifetime', 'metrics_collection', 'mixed_instances_policy', 'new_instances_protected_from_scale_in', 'notification_configuration', 'notification_configurations', 'placement_group', 'service_linked_role_arn', 'tags', 'target_group_arns', 'termination_policies', 'vpc_zone_identifier']
    _method_names: typing.ClassVar[list[str]] = ['AcceleratorCountRequestProperty', 'AcceleratorTotalMemoryMiBRequestProperty', 'BaselineEbsBandwidthMbpsRequestProperty', 'InstanceRequirementsProperty', 'InstancesDistributionProperty', 'LaunchTemplateOverridesProperty', 'LaunchTemplateProperty', 'LaunchTemplateSpecificationProperty', 'LifecycleHookSpecificationProperty', 'MemoryGiBPerVCpuRequestProperty', 'MemoryMiBRequestProperty', 'MetricsCollectionProperty', 'MixedInstancesPolicyProperty', 'NetworkBandwidthGbpsRequestProperty', 'NetworkInterfaceCountRequestProperty', 'NotificationConfigurationProperty', 'TagPropertyProperty', 'TotalLocalStorageGBRequestProperty', 'VCpuCountRequestProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroup'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.CfnAutoScalingGroupDefConfig] = pydantic.Field(None)


class CfnAutoScalingGroupDefConfig(pydantic.BaseModel):
    AcceleratorCountRequestProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefAcceleratorcountrequestpropertyParams]] = pydantic.Field(None, description='')
    AcceleratorTotalMemoryMiBRequestProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefAcceleratortotalmemorymibrequestpropertyParams]] = pydantic.Field(None, description='')
    BaselineEbsBandwidthMbpsRequestProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefBaselineebsbandwidthmbpsrequestpropertyParams]] = pydantic.Field(None, description='')
    InstanceRequirementsProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefInstancerequirementspropertyParams]] = pydantic.Field(None, description='')
    InstancesDistributionProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefInstancesdistributionpropertyParams]] = pydantic.Field(None, description='')
    LaunchTemplateOverridesProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefLaunchtemplateoverridespropertyParams]] = pydantic.Field(None, description='')
    LaunchTemplateProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefLaunchtemplatepropertyParams]] = pydantic.Field(None, description='')
    LaunchTemplateSpecificationProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefLaunchtemplatespecificationpropertyParams]] = pydantic.Field(None, description='')
    LifecycleHookSpecificationProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefLifecyclehookspecificationpropertyParams]] = pydantic.Field(None, description='')
    MemoryGiBPerVCpuRequestProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefMemorygibpervcpurequestpropertyParams]] = pydantic.Field(None, description='')
    MemoryMiBRequestProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefMemorymibrequestpropertyParams]] = pydantic.Field(None, description='')
    MetricsCollectionProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefMetricscollectionpropertyParams]] = pydantic.Field(None, description='')
    MixedInstancesPolicyProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefMixedinstancespolicypropertyParams]] = pydantic.Field(None, description='')
    NetworkBandwidthGbpsRequestProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefNetworkbandwidthgbpsrequestpropertyParams]] = pydantic.Field(None, description='')
    NetworkInterfaceCountRequestProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefNetworkinterfacecountrequestpropertyParams]] = pydantic.Field(None, description='')
    NotificationConfigurationProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefNotificationconfigurationpropertyParams]] = pydantic.Field(None, description='')
    TagPropertyProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefTagpropertypropertyParams]] = pydantic.Field(None, description='')
    TotalLocalStorageGBRequestProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefTotallocalstoragegbrequestpropertyParams]] = pydantic.Field(None, description='')
    VCpuCountRequestProperty: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefVcpucountrequestpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_autoscaling.CfnAutoScalingGroupDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnAutoScalingGroupDefAcceleratorcountrequestpropertyParams(pydantic.BaseModel):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefAcceleratortotalmemorymibrequestpropertyParams(pydantic.BaseModel):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefBaselineebsbandwidthmbpsrequestpropertyParams(pydantic.BaseModel):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefInstancerequirementspropertyParams(pydantic.BaseModel):
    accelerator_count: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_AcceleratorCountRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    accelerator_manufacturers: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    accelerator_names: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    accelerator_total_memory_mib: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_AcceleratorTotalMemoryMiBRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    accelerator_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    allowed_instance_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    bare_metal: typing.Optional[str] = pydantic.Field(None, description='')
    baseline_ebs_bandwidth_mbps: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_BaselineEbsBandwidthMbpsRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    burstable_performance: typing.Optional[str] = pydantic.Field(None, description='')
    cpu_manufacturers: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    excluded_instance_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    instance_generations: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    local_storage: typing.Optional[str] = pydantic.Field(None, description='')
    local_storage_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    memory_gib_per_v_cpu: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_MemoryGiBPerVCpuRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    memory_mib: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_MemoryMiBRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    network_bandwidth_gbps: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_NetworkBandwidthGbpsRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    network_interface_count: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_NetworkInterfaceCountRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    on_demand_max_price_percentage_over_lowest_price: typing.Union[int, float, None] = pydantic.Field(None, description='')
    require_hibernate_support: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    spot_max_price_percentage_over_lowest_price: typing.Union[int, float, None] = pydantic.Field(None, description='')
    total_local_storage_gb: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_TotalLocalStorageGBRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    v_cpu_count: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_VCpuCountRequestPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefInstancesdistributionpropertyParams(pydantic.BaseModel):
    on_demand_allocation_strategy: typing.Optional[str] = pydantic.Field(None, description='')
    on_demand_base_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='')
    on_demand_percentage_above_base_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='')
    spot_allocation_strategy: typing.Optional[str] = pydantic.Field(None, description='')
    spot_instance_pools: typing.Union[int, float, None] = pydantic.Field(None, description='')
    spot_max_price: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefLaunchtemplateoverridespropertyParams(pydantic.BaseModel):
    instance_requirements: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_InstanceRequirementsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    instance_type: typing.Optional[str] = pydantic.Field(None, description='')
    launch_template_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplateSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    weighted_capacity: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefLaunchtemplatepropertyParams(pydantic.BaseModel):
    launch_template_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplateSpecificationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    overrides: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplateOverridesPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefLaunchtemplatespecificationpropertyParams(pydantic.BaseModel):
    version: str = pydantic.Field(..., description='')
    launch_template_id: typing.Optional[str] = pydantic.Field(None, description='')
    launch_template_name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefLifecyclehookspecificationpropertyParams(pydantic.BaseModel):
    lifecycle_hook_name: str = pydantic.Field(..., description='')
    lifecycle_transition: str = pydantic.Field(..., description='')
    default_result: typing.Optional[str] = pydantic.Field(None, description='')
    heartbeat_timeout: typing.Union[int, float, None] = pydantic.Field(None, description='')
    notification_metadata: typing.Optional[str] = pydantic.Field(None, description='')
    notification_target_arn: typing.Optional[str] = pydantic.Field(None, description='')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefMemorygibpervcpurequestpropertyParams(pydantic.BaseModel):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefMemorymibrequestpropertyParams(pydantic.BaseModel):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefMetricscollectionpropertyParams(pydantic.BaseModel):
    granularity: str = pydantic.Field(..., description='')
    metrics: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefMixedinstancespolicypropertyParams(pydantic.BaseModel):
    launch_template: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplatePropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    instances_distribution: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_InstancesDistributionPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefNetworkbandwidthgbpsrequestpropertyParams(pydantic.BaseModel):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefNetworkinterfacecountrequestpropertyParams(pydantic.BaseModel):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefNotificationconfigurationpropertyParams(pydantic.BaseModel):
    topic_arn: str = pydantic.Field(..., description='')
    notification_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefTagpropertypropertyParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='')
    propagate_at_launch: typing.Union[bool, models.UnsupportedResource] = pydantic.Field(..., description='')
    value: str = pydantic.Field(..., description='')
    ...

class CfnAutoScalingGroupDefTotallocalstoragegbrequestpropertyParams(pydantic.BaseModel):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefVcpucountrequestpropertyParams(pydantic.BaseModel):
    max: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnAutoScalingGroupDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnAutoScalingGroupDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnAutoScalingGroupDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnAutoScalingGroupDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnAutoScalingGroupDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnAutoScalingGroupDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnAutoScalingGroupDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnAutoScalingGroupDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnAutoScalingGroupDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnAutoScalingGroupDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnAutoScalingGroupDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnAutoScalingGroupDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnAutoScalingGroupDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnAutoScalingGroupDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.CfnLaunchConfiguration
class CfnLaunchConfigurationDef(BaseCfnResource):
    image_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ID of the Amazon Machine Image (AMI) that was assigned during registration. For more information, see `Finding a Linux AMI <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . If you specify ``InstanceId`` , an ``ImageId`` is not required.\n')
    instance_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the instance type of the EC2 instance. For information about available instance types, see `Available instance types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#AvailableInstanceTypes>`_ in the *Amazon EC2 User Guide for Linux Instances* . If you specify ``InstanceId`` , an ``InstanceType`` is not required.\n')
    associate_public_ip_address: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="Specifies whether to assign a public IPv4 address to the group's instances. If the instance is launched into a default subnet, the default is to assign a public IPv4 address, unless you disabled the option to assign a public IPv4 address on the subnet. If the instance is launched into a nondefault subnet, the default is not to assign a public IPv4 address, unless you enabled the option to assign a public IPv4 address on the subnet. If you specify ``true`` , each instance in the Auto Scaling group receives a unique public IPv4 address. For more information, see `Launching Auto Scaling instances in a VPC <https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-in-vpc.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . If you specify this property, you must specify at least one subnet for ``VPCZoneIdentifier`` when you create your group.\n")
    block_device_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnLaunchConfiguration_BlockDeviceMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The block device mapping entries that define the block devices to attach to the instances at launch. By default, the block devices specified in the block device mapping for the AMI are used. For more information, see `Block device mappings <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html>`_ in the *Amazon EC2 User Guide for Linux Instances* .\n')
    classic_link_vpc_id: typing.Optional[str] = pydantic.Field(None, description='Available for backward compatibility.\n')
    classic_link_vpc_security_groups: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Available for backward compatibility.\n')
    ebs_optimized: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Specifies whether the launch configuration is optimized for EBS I/O ( ``true`` ) or not ( ``false`` ). The optimization provides dedicated throughput to Amazon EBS and an optimized configuration stack to provide optimal I/O performance. This optimization is not available with all instance types. Additional fees are incurred when you enable EBS optimization for an instance type that is not EBS-optimized by default. For more information, see `Amazon EBS-optimized instances <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . The default value is ``false`` .\n')
    iam_instance_profile: typing.Optional[str] = pydantic.Field(None, description='The name or the Amazon Resource Name (ARN) of the instance profile associated with the IAM role for the instance. The instance profile contains the IAM role. For more information, see `IAM role for applications that run on Amazon EC2 instances <https://docs.aws.amazon.com/autoscaling/ec2/userguide/us-iam-role.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    instance_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the Amazon EC2 instance to use to create the launch configuration. When you use an instance to create a launch configuration, all properties are derived from the instance with the exception of ``BlockDeviceMapping`` and ``AssociatePublicIpAddress`` . You can override any properties from the instance by specifying them in the launch configuration.\n')
    instance_monitoring: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Controls whether instances in this group are launched with detailed ( ``true`` ) or basic ( ``false`` ) monitoring. The default value is ``true`` (enabled). .. epigraph:: When detailed monitoring is enabled, Amazon CloudWatch generates metrics every minute and your account is charged a fee. When you disable detailed monitoring, CloudWatch generates metrics every 5 minutes. For more information, see `Configure Monitoring for Auto Scaling Instances <https://docs.aws.amazon.com/autoscaling/latest/userguide/enable-as-instance-metrics.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    kernel_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the kernel associated with the AMI. .. epigraph:: We recommend that you use PV-GRUB instead of kernels and RAM disks. For more information, see `User provided kernels <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/UserProvidedKernels.html>`_ in the *Amazon EC2 User Guide for Linux Instances* .\n')
    key_name: typing.Optional[str] = pydantic.Field(None, description='The name of the key pair. For more information, see `Amazon EC2 key pairs and Linux instances <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html>`_ in the *Amazon EC2 User Guide for Linux Instances* .\n')
    launch_configuration_name: typing.Optional[str] = pydantic.Field(None, description='The name of the launch configuration. This name must be unique per Region per account.\n')
    metadata_options: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnLaunchConfiguration_MetadataOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The metadata options for the instances. For more information, see `Configuring the Instance Metadata Options <https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-config.html#launch-configurations-imds>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    placement_tenancy: typing.Optional[str] = pydantic.Field(None, description='The tenancy of the instance, either ``default`` or ``dedicated`` . An instance with ``dedicated`` tenancy runs on isolated, single-tenant hardware and can only be launched into a VPC. To launch dedicated instances into a shared tenancy VPC (a VPC with the instance placement tenancy attribute set to ``default`` ), you must set the value of this property to ``dedicated`` . For more information, see `Configuring instance tenancy with Amazon EC2 Auto Scaling <https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-dedicated-instances.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . If you specify ``PlacementTenancy`` , you must specify at least one subnet for ``VPCZoneIdentifier`` when you create your group. Valid values: ``default`` | ``dedicated``\n')
    ram_disk_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the RAM disk to select. .. epigraph:: We recommend that you use PV-GRUB instead of kernels and RAM disks. For more information, see `User provided kernels <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/UserProvidedKernels.html>`_ in the *Amazon EC2 User Guide for Linux Instances* .\n')
    security_groups: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list that contains the security groups to assign to the instances in the Auto Scaling group. The list can contain both the IDs of existing security groups and references to `SecurityGroup <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-security-group.html>`_ resources created in the template. For more information, see `Control traffic to resources using security groups <https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html>`_ in the *Amazon Virtual Private Cloud User Guide* .\n')
    spot_price: typing.Optional[str] = pydantic.Field(None, description='The maximum hourly price to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot price. For more information, see `Request Spot Instances for fault-tolerant and flexible applications <https://docs.aws.amazon.com/autoscaling/ec2/userguide/launch-template-spot-instances.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Valid Range: Minimum value of 0.001 .. epigraph:: When you change your maximum price by creating a new launch configuration, running instances will continue to run as long as the maximum price for those running instances is higher than the current Spot price.\n')
    user_data: typing.Optional[str] = pydantic.Field(None, description='The Base64-encoded user data to make available to the launched EC2 instances. For more information, see `Instance metadata and user data <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html>`_ in the *Amazon EC2 User Guide for Linux Instances* .')
    _init_params: typing.ClassVar[list[str]] = ['image_id', 'instance_type', 'associate_public_ip_address', 'block_device_mappings', 'classic_link_vpc_id', 'classic_link_vpc_security_groups', 'ebs_optimized', 'iam_instance_profile', 'instance_id', 'instance_monitoring', 'kernel_id', 'key_name', 'launch_configuration_name', 'metadata_options', 'placement_tenancy', 'ram_disk_id', 'security_groups', 'spot_price', 'user_data']
    _method_names: typing.ClassVar[list[str]] = ['BlockDeviceMappingProperty', 'BlockDeviceProperty', 'MetadataOptionsProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnLaunchConfiguration'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.CfnLaunchConfigurationDefConfig] = pydantic.Field(None)


class CfnLaunchConfigurationDefConfig(pydantic.BaseModel):
    BlockDeviceMappingProperty: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefBlockdevicemappingpropertyParams]] = pydantic.Field(None, description='')
    BlockDeviceProperty: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefBlockdevicepropertyParams]] = pydantic.Field(None, description='')
    MetadataOptionsProperty: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefMetadataoptionspropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_autoscaling.CfnLaunchConfigurationDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnLaunchConfigurationDefBlockdevicemappingpropertyParams(pydantic.BaseModel):
    device_name: str = pydantic.Field(..., description='')
    ebs: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnLaunchConfiguration_BlockDevicePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    no_device: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    virtual_name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnLaunchConfigurationDefBlockdevicepropertyParams(pydantic.BaseModel):
    delete_on_termination: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    encrypted: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='')
    snapshot_id: typing.Optional[str] = pydantic.Field(None, description='')
    throughput: typing.Union[int, float, None] = pydantic.Field(None, description='')
    volume_size: typing.Union[int, float, None] = pydantic.Field(None, description='')
    volume_type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnLaunchConfigurationDefMetadataoptionspropertyParams(pydantic.BaseModel):
    http_endpoint: typing.Optional[str] = pydantic.Field(None, description='')
    http_put_response_hop_limit: typing.Union[int, float, None] = pydantic.Field(None, description='')
    http_tokens: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnLaunchConfigurationDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLaunchConfigurationDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLaunchConfigurationDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLaunchConfigurationDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLaunchConfigurationDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLaunchConfigurationDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLaunchConfigurationDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLaunchConfigurationDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLaunchConfigurationDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLaunchConfigurationDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLaunchConfigurationDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLaunchConfigurationDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLaunchConfigurationDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLaunchConfigurationDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.CfnLifecycleHook
class CfnLifecycleHookDef(BaseCfnResource):
    auto_scaling_group_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Auto Scaling group.\n')
    lifecycle_transition: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The lifecycle transition. For Auto Scaling groups, there are two major lifecycle transitions. - To create a lifecycle hook for scale-out events, specify ``autoscaling:EC2_INSTANCE_LAUNCHING`` . - To create a lifecycle hook for scale-in events, specify ``autoscaling:EC2_INSTANCE_TERMINATING`` .\n')
    default_result: typing.Optional[str] = pydantic.Field(None, description='The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. The default value is ``ABANDON`` . Valid values: ``CONTINUE`` | ``ABANDON``\n')
    heartbeat_timeout: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum time, in seconds, that can elapse before the lifecycle hook times out. The range is from ``30`` to ``7200`` seconds. The default value is ``3600`` seconds (1 hour).\n')
    lifecycle_hook_name: typing.Optional[str] = pydantic.Field(None, description='The name of the lifecycle hook.\n')
    notification_metadata: typing.Optional[str] = pydantic.Field(None, description='Additional information that you want to include any time Amazon EC2 Auto Scaling sends a message to the notification target.\n')
    notification_target_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the notification target that Amazon EC2 Auto Scaling sends notifications to when an instance is in a wait state for the lifecycle hook. You can specify an Amazon SNS topic or an Amazon SQS queue.\n')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target. For information about creating this role, see `Configure a notification target for a lifecycle hook <https://docs.aws.amazon.com/autoscaling/ec2/userguide/prepare-for-lifecycle-notifications.html#lifecycle-hook-notification-target>`_ in the *Amazon EC2 Auto Scaling User Guide* . Valid only if the notification target is an Amazon SNS topic or an Amazon SQS queue.')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group_name', 'lifecycle_transition', 'default_result', 'heartbeat_timeout', 'lifecycle_hook_name', 'notification_metadata', 'notification_target_arn', 'role_arn']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnLifecycleHook'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.CfnLifecycleHookDefConfig] = pydantic.Field(None)


class CfnLifecycleHookDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_autoscaling.CfnLifecycleHookDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnLifecycleHookDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLifecycleHookDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLifecycleHookDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLifecycleHookDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLifecycleHookDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLifecycleHookDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLifecycleHookDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLifecycleHookDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLifecycleHookDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLifecycleHookDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLifecycleHookDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLifecycleHookDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLifecycleHookDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLifecycleHookDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicy
class CfnScalingPolicyDef(BaseCfnResource):
    auto_scaling_group_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Auto Scaling group.\n')
    adjustment_type: typing.Optional[str] = pydantic.Field(None, description='Specifies how the scaling adjustment is interpreted (for example, an absolute number or a percentage). The valid values are ``ChangeInCapacity`` , ``ExactCapacity`` , and ``PercentChangeInCapacity`` . Required if the policy type is ``StepScaling`` or ``SimpleScaling`` . For more information, see `Scaling adjustment types <https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-adjustment>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    cooldown: typing.Optional[str] = pydantic.Field(None, description='A cooldown period, in seconds, that applies to a specific simple scaling policy. When a cooldown period is specified here, it overrides the default cooldown. Valid only if the policy type is ``SimpleScaling`` . For more information, see `Scaling cooldowns for Amazon EC2 Auto Scaling <https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Default: None\n')
    estimated_instance_warmup: typing.Union[int, float, None] = pydantic.Field(None, description='*Not needed if the default instance warmup is defined for the group.*. The estimated time, in seconds, until a newly launched instance can contribute to the CloudWatch metrics. This warm-up period applies to instances launched due to a specific target tracking or step scaling policy. When a warm-up period is specified here, it overrides the default instance warmup. Valid only if the policy type is ``TargetTrackingScaling`` or ``StepScaling`` . .. epigraph:: The default is to use the value for the default instance warmup defined for the group. If default instance warmup is null, then ``EstimatedInstanceWarmup`` falls back to the value of default cooldown.\n')
    metric_aggregation_type: typing.Optional[str] = pydantic.Field(None, description='The aggregation type for the CloudWatch metrics. The valid values are ``Minimum`` , ``Maximum`` , and ``Average`` . If the aggregation type is null, the value is treated as ``Average`` . Valid only if the policy type is ``StepScaling`` .\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum value to scale by when the adjustment type is ``PercentChangeInCapacity`` . For example, suppose that you create a step scaling policy to scale out an Auto Scaling group by 25 percent and you specify a ``MinAdjustmentMagnitude`` of 2. If the group has 4 instances and the scaling policy is performed, 25 percent of 4 is 1. However, because you specified a ``MinAdjustmentMagnitude`` of 2, Amazon EC2 Auto Scaling scales out the group by 2 instances. Valid only if the policy type is ``StepScaling`` or ``SimpleScaling`` . For more information, see `Scaling adjustment types <https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-adjustment>`_ in the *Amazon EC2 Auto Scaling User Guide* . .. epigraph:: Some Auto Scaling groups use instance weights. In this case, set the ``MinAdjustmentMagnitude`` to a value that is at least as large as your largest instance weight.\n')
    policy_type: typing.Optional[str] = pydantic.Field(None, description='One of the following policy types:. - ``TargetTrackingScaling`` - ``StepScaling`` - ``SimpleScaling`` (default) - ``PredictiveScaling``\n')
    predictive_scaling_configuration: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A predictive scaling policy. Provides support for predefined and custom metrics. Predefined metrics include CPU utilization, network in/out, and the Application Load Balancer request count. Required if the policy type is ``PredictiveScaling`` .\n')
    scaling_adjustment: typing.Union[int, float, None] = pydantic.Field(None, description='The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity. For exact capacity, you must specify a non-negative value. Required if the policy type is ``SimpleScaling`` . (Not used with any other policy type.)\n')
    step_adjustments: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_StepAdjustmentPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A set of adjustments that enable you to scale based on the size of the alarm breach. Required if the policy type is ``StepScaling`` . (Not used with any other policy type.)\n')
    target_tracking_configuration: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_TargetTrackingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A target tracking scaling policy. Provides support for predefined or custom metrics. The following predefined metrics are available: - ``ASGAverageCPUUtilization`` - ``ASGAverageNetworkIn`` - ``ASGAverageNetworkOut`` - ``ALBRequestCountPerTarget`` If you specify ``ALBRequestCountPerTarget`` for the metric, you must specify the ``ResourceLabel`` property with the ``PredefinedMetricSpecification`` . Required if the policy type is ``TargetTrackingScaling`` .')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group_name', 'adjustment_type', 'cooldown', 'estimated_instance_warmup', 'metric_aggregation_type', 'min_adjustment_magnitude', 'policy_type', 'predictive_scaling_configuration', 'scaling_adjustment', 'step_adjustments', 'target_tracking_configuration']
    _method_names: typing.ClassVar[list[str]] = ['CustomizedMetricSpecificationProperty', 'MetricDataQueryProperty', 'MetricDimensionProperty', 'MetricProperty', 'MetricStatProperty', 'PredefinedMetricSpecificationProperty', 'PredictiveScalingConfigurationProperty', 'PredictiveScalingCustomizedCapacityMetricProperty', 'PredictiveScalingCustomizedLoadMetricProperty', 'PredictiveScalingCustomizedScalingMetricProperty', 'PredictiveScalingMetricSpecificationProperty', 'PredictiveScalingPredefinedLoadMetricProperty', 'PredictiveScalingPredefinedMetricPairProperty', 'PredictiveScalingPredefinedScalingMetricProperty', 'StepAdjustmentProperty', 'TargetTrackingConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.CfnScalingPolicyDefConfig] = pydantic.Field(None)


class CfnScalingPolicyDefConfig(pydantic.BaseModel):
    CustomizedMetricSpecificationProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefCustomizedmetricspecificationpropertyParams]] = pydantic.Field(None, description='')
    MetricDataQueryProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefMetricdataquerypropertyParams]] = pydantic.Field(None, description='')
    MetricDimensionProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefMetricdimensionpropertyParams]] = pydantic.Field(None, description='')
    MetricProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefMetricpropertyParams]] = pydantic.Field(None, description='')
    MetricStatProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefMetricstatpropertyParams]] = pydantic.Field(None, description='')
    PredefinedMetricSpecificationProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefPredefinedmetricspecificationpropertyParams]] = pydantic.Field(None, description='')
    PredictiveScalingConfigurationProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefPredictivescalingconfigurationpropertyParams]] = pydantic.Field(None, description='')
    PredictiveScalingCustomizedCapacityMetricProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefPredictivescalingcustomizedcapacitymetricpropertyParams]] = pydantic.Field(None, description='')
    PredictiveScalingCustomizedLoadMetricProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefPredictivescalingcustomizedloadmetricpropertyParams]] = pydantic.Field(None, description='')
    PredictiveScalingCustomizedScalingMetricProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefPredictivescalingcustomizedscalingmetricpropertyParams]] = pydantic.Field(None, description='')
    PredictiveScalingMetricSpecificationProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefPredictivescalingmetricspecificationpropertyParams]] = pydantic.Field(None, description='')
    PredictiveScalingPredefinedLoadMetricProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefPredictivescalingpredefinedloadmetricpropertyParams]] = pydantic.Field(None, description='')
    PredictiveScalingPredefinedMetricPairProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefPredictivescalingpredefinedmetricpairpropertyParams]] = pydantic.Field(None, description='')
    PredictiveScalingPredefinedScalingMetricProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefPredictivescalingpredefinedscalingmetricpropertyParams]] = pydantic.Field(None, description='')
    StepAdjustmentProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefStepadjustmentpropertyParams]] = pydantic.Field(None, description='')
    TargetTrackingConfigurationProperty: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefTargettrackingconfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_autoscaling.CfnScalingPolicyDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnScalingPolicyDefCustomizedmetricspecificationpropertyParams(pydantic.BaseModel):
    metric_name: str = pydantic.Field(..., description='')
    namespace: str = pydantic.Field(..., description='')
    statistic: str = pydantic.Field(..., description='')
    dimensions: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricDimensionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    unit: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefMetricdataquerypropertyParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='')
    expression: typing.Optional[str] = pydantic.Field(None, description='')
    label: typing.Optional[str] = pydantic.Field(None, description='')
    metric_stat: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricStatPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    return_data: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefMetricdimensionpropertyParams(pydantic.BaseModel):
    name: str = pydantic.Field(..., description='')
    value: str = pydantic.Field(..., description='')
    ...

class CfnScalingPolicyDefMetricpropertyParams(pydantic.BaseModel):
    metric_name: str = pydantic.Field(..., description='')
    namespace: str = pydantic.Field(..., description='')
    dimensions: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricDimensionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefMetricstatpropertyParams(pydantic.BaseModel):
    metric: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    stat: str = pydantic.Field(..., description='')
    unit: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefPredefinedmetricspecificationpropertyParams(pydantic.BaseModel):
    predefined_metric_type: str = pydantic.Field(..., description='')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefPredictivescalingconfigurationpropertyParams(pydantic.BaseModel):
    metric_specifications: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingMetricSpecificationPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    max_capacity_breach_behavior: typing.Optional[str] = pydantic.Field(None, description='')
    max_capacity_buffer: typing.Union[int, float, None] = pydantic.Field(None, description='')
    mode: typing.Optional[str] = pydantic.Field(None, description='')
    scheduling_buffer_time: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefPredictivescalingcustomizedcapacitymetricpropertyParams(pydantic.BaseModel):
    metric_data_queries: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricDataQueryPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    ...

class CfnScalingPolicyDefPredictivescalingcustomizedloadmetricpropertyParams(pydantic.BaseModel):
    metric_data_queries: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricDataQueryPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    ...

class CfnScalingPolicyDefPredictivescalingcustomizedscalingmetricpropertyParams(pydantic.BaseModel):
    metric_data_queries: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_MetricDataQueryPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    ...

class CfnScalingPolicyDefPredictivescalingmetricspecificationpropertyParams(pydantic.BaseModel):
    target_value: typing.Union[int, float] = pydantic.Field(..., description='')
    customized_capacity_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingCustomizedCapacityMetricPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    customized_load_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingCustomizedLoadMetricPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    customized_scaling_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingCustomizedScalingMetricPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    predefined_load_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingPredefinedLoadMetricPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    predefined_metric_pair_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingPredefinedMetricPairPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    predefined_scaling_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingPredefinedScalingMetricPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefPredictivescalingpredefinedloadmetricpropertyParams(pydantic.BaseModel):
    predefined_metric_type: str = pydantic.Field(..., description='')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefPredictivescalingpredefinedmetricpairpropertyParams(pydantic.BaseModel):
    predefined_metric_type: str = pydantic.Field(..., description='')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefPredictivescalingpredefinedscalingmetricpropertyParams(pydantic.BaseModel):
    predefined_metric_type: str = pydantic.Field(..., description='')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefStepadjustmentpropertyParams(pydantic.BaseModel):
    scaling_adjustment: typing.Union[int, float] = pydantic.Field(..., description='')
    metric_interval_lower_bound: typing.Union[int, float, None] = pydantic.Field(None, description='')
    metric_interval_upper_bound: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefTargettrackingconfigurationpropertyParams(pydantic.BaseModel):
    target_value: typing.Union[int, float] = pydantic.Field(..., description='')
    customized_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_CustomizedMetricSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    disable_scale_in: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    predefined_metric_specification: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredefinedMetricSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnScalingPolicyDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnScalingPolicyDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnScalingPolicyDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnScalingPolicyDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnScalingPolicyDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnScalingPolicyDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnScalingPolicyDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnScalingPolicyDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnScalingPolicyDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnScalingPolicyDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnScalingPolicyDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnScalingPolicyDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnScalingPolicyDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.CfnScheduledAction
class CfnScheduledActionDef(BaseCfnResource):
    auto_scaling_group_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Auto Scaling group.\n')
    desired_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain. It can scale beyond this capacity if you add more scaling conditions. .. epigraph:: You must specify at least one of the following properties: ``MaxSize`` , ``MinSize`` , or ``DesiredCapacity`` .\n')
    end_time: typing.Optional[str] = pydantic.Field(None, description='The date and time for the recurring schedule to end, in UTC. For example, ``"2021-06-01T00:00:00Z"`` .\n')
    max_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum size of the Auto Scaling group.\n')
    min_size: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum size of the Auto Scaling group.\n')
    recurrence: typing.Optional[str] = pydantic.Field(None, description='The recurring schedule for this action. This format consists of five fields separated by white spaces: [Minute] [Hour] [Day_of_Month] [Month_of_Year] [Day_of_Week]. The value must be in quotes (for example, ``"30 0 1 1,6,12 *"`` ). For more information about this format, see `Crontab <https://docs.aws.amazon.com/http://crontab.org>`_ . When ``StartTime`` and ``EndTime`` are specified with ``Recurrence`` , they form the boundaries of when the recurring action starts and stops. Cron expressions use Universal Coordinated Time (UTC) by default.\n')
    start_time: typing.Optional[str] = pydantic.Field(None, description='The date and time for this action to start, in YYYY-MM-DDThh:mm:ssZ format in UTC/GMT only and in quotes (for example, ``"2021-06-01T00:00:00Z"`` ). If you specify ``Recurrence`` and ``StartTime`` , Amazon EC2 Auto Scaling performs the action at this time, and then performs the action based on the specified recurrence.\n')
    time_zone: typing.Optional[str] = pydantic.Field(None, description='Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as ``Etc/GMT+9`` or ``Pacific/Tahiti`` ). For more information, see `https://en.wikipedia.org/wiki/List_of_tz_database_time_zones <https://docs.aws.amazon.com/https://en.wikipedia.org/wiki/List_of_tz_database_time_zones>`_ .')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group_name', 'desired_capacity', 'end_time', 'max_size', 'min_size', 'recurrence', 'start_time', 'time_zone']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScheduledAction'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.CfnScheduledActionDefConfig] = pydantic.Field(None)


class CfnScheduledActionDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_autoscaling.CfnScheduledActionDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnScheduledActionDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnScheduledActionDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnScheduledActionDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnScheduledActionDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnScheduledActionDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnScheduledActionDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnScheduledActionDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnScheduledActionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnScheduledActionDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnScheduledActionDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnScheduledActionDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnScheduledActionDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnScheduledActionDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnScheduledActionDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.CfnWarmPool
class CfnWarmPoolDef(BaseCfnResource):
    auto_scaling_group_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Auto Scaling group.\n')
    instance_reuse_policy: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnWarmPool_InstanceReusePolicyPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Indicates whether instances in the Auto Scaling group can be returned to the warm pool on scale in. The default is to terminate instances in the Auto Scaling group when the group scales in.\n')
    max_group_prepared_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="Specifies the maximum number of instances that are allowed to be in the warm pool or in any state except ``Terminated`` for the Auto Scaling group. This is an optional property. Specify it only if you do not want the warm pool size to be determined by the difference between the group's maximum capacity and its desired capacity. .. epigraph:: If a value for ``MaxGroupPreparedCapacity`` is not specified, Amazon EC2 Auto Scaling launches and maintains the difference between the group's maximum capacity and its desired capacity. If you specify a value for ``MaxGroupPreparedCapacity`` , Amazon EC2 Auto Scaling uses the difference between the ``MaxGroupPreparedCapacity`` and the desired capacity instead. The size of the warm pool is dynamic. Only when ``MaxGroupPreparedCapacity`` and ``MinSize`` are set to the same value does the warm pool have an absolute size. If the desired capacity of the Auto Scaling group is higher than the ``MaxGroupPreparedCapacity`` , the capacity of the warm pool is 0, unless you specify a value for ``MinSize`` . To remove a value that you previously set, include the property but specify -1 for the value.\n")
    min_size: typing.Union[int, float, None] = pydantic.Field(None, description='Specifies the minimum number of instances to maintain in the warm pool. This helps you to ensure that there is always a certain number of warmed instances available to handle traffic spikes. Defaults to 0 if not specified.\n')
    pool_state: typing.Optional[str] = pydantic.Field(None, description='Sets the instance state to transition to after the lifecycle actions are complete. Default is ``Stopped`` .')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group_name', 'instance_reuse_policy', 'max_group_prepared_capacity', 'min_size', 'pool_state']
    _method_names: typing.ClassVar[list[str]] = ['InstanceReusePolicyProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnWarmPool'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_autoscaling.CfnWarmPoolDefConfig] = pydantic.Field(None)


class CfnWarmPoolDefConfig(pydantic.BaseModel):
    InstanceReusePolicyProperty: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefInstancereusepolicypropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_autoscaling.CfnWarmPoolDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnWarmPoolDefInstancereusepolicypropertyParams(pydantic.BaseModel):
    reuse_on_scale_in: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnWarmPoolDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnWarmPoolDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnWarmPoolDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnWarmPoolDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnWarmPoolDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnWarmPoolDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnWarmPoolDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnWarmPoolDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnWarmPoolDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnWarmPoolDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnWarmPoolDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnWarmPoolDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnWarmPoolDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnWarmPoolDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_autoscaling.CfnAutoScalingGroupProps
class CfnAutoScalingGroupPropsDef(BaseCfnProperty):
    max_size: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The maximum size of the group. .. epigraph:: With a mixed instances policy that uses instance weighting, Amazon EC2 Auto Scaling may need to go above ``MaxSize`` to meet your capacity requirements. In this event, Amazon EC2 Auto Scaling will never go above ``MaxSize`` by more than your largest instance weight (weights that define how many units each instance contributes to the desired capacity of the group).\n')
    min_size: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The minimum size of the group.\n')
    auto_scaling_group_name: typing.Optional[str] = pydantic.Field(None, description='The name of the Auto Scaling group. This name must be unique per Region per account. The name can contain any ASCII character 33 to 126 including most punctuation characters, digits, and upper and lowercased letters. .. epigraph:: You cannot use a colon (:) in the name.\n')
    availability_zones: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of Availability Zones where instances in the Auto Scaling group can be created. Used for launching into the default VPC subnet in each Availability Zone when not using the ``VPCZoneIdentifier`` property, or for attaching a network interface when an existing network interface ID is specified in a launch template.\n')
    capacity_rebalance: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether Capacity Rebalancing is enabled. Otherwise, Capacity Rebalancing is disabled. When you turn on Capacity Rebalancing, Amazon EC2 Auto Scaling attempts to launch a Spot Instance whenever Amazon EC2 notifies that a Spot Instance is at an elevated risk of interruption. After launching a new instance, it then terminates an old instance. For more information, see `Use Capacity Rebalancing to handle Amazon EC2 Spot Interruptions <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html>`_ in the in the *Amazon EC2 Auto Scaling User Guide* .\n')
    context: typing.Optional[str] = pydantic.Field(None, description='Reserved.\n')
    cooldown: typing.Optional[str] = pydantic.Field(None, description='*Only needed if you use simple scaling policies.*. The amount of time, in seconds, between one scaling activity ending and another one starting due to simple scaling policies. For more information, see `Scaling cooldowns for Amazon EC2 Auto Scaling <https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Default: ``300`` seconds\n')
    default_instance_warmup: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time, in seconds, until a new instance is considered to have finished initializing and resource consumption to become stable after it enters the ``InService`` state. During an instance refresh, Amazon EC2 Auto Scaling waits for the warm-up period after it replaces an instance before it moves on to replacing the next instance. Amazon EC2 Auto Scaling also waits for the warm-up period before aggregating the metrics for new instances with existing instances in the Amazon CloudWatch metrics that are used for scaling, resulting in more reliable usage data. For more information, see `Set the default instance warmup for an Auto Scaling group <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-default-instance-warmup.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . .. epigraph:: To manage various warm-up settings at the group level, we recommend that you set the default instance warmup, *even if it is set to 0 seconds* . To remove a value that you previously set, include the property but specify ``-1`` for the value. However, we strongly recommend keeping the default instance warmup enabled by specifying a value of ``0`` or other nominal value. Default: None\n')
    desired_capacity: typing.Optional[str] = pydantic.Field(None, description='The desired capacity is the initial capacity of the Auto Scaling group at the time of its creation and the capacity it attempts to maintain. It can scale beyond this capacity if you configure automatic scaling. The number must be greater than or equal to the minimum size of the group and less than or equal to the maximum size of the group. If you do not specify a desired capacity when creating the stack, the default is the minimum size of the group. CloudFormation marks the Auto Scaling group as successful (by setting its status to CREATE_COMPLETE) when the desired capacity is reached. However, if a maximum Spot price is set in the launch template or launch configuration that you specified, then desired capacity is not used as a criteria for success. Whether your request is fulfilled depends on Spot Instance capacity and your maximum price.\n')
    desired_capacity_type: typing.Optional[str] = pydantic.Field(None, description='The unit of measurement for the value specified for desired capacity. Amazon EC2 Auto Scaling supports ``DesiredCapacityType`` for attribute-based instance type selection only. For more information, see `Creating an Auto Scaling group using attribute-based instance type selection <https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-instance-type-requirements.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . By default, Amazon EC2 Auto Scaling specifies ``units`` , which translates into number of instances. Valid values: ``units`` | ``vcpu`` | ``memory-mib``\n')
    health_check_grace_period: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time, in seconds, that Amazon EC2 Auto Scaling waits before checking the health status of an EC2 instance that has come into service and marking it unhealthy due to a failed health check. This is useful if your instances do not immediately pass their health checks after they enter the ``InService`` state. For more information, see `Set the health check grace period for an Auto Scaling group <https://docs.aws.amazon.com/autoscaling/ec2/userguide/health-check-grace-period.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Default: ``0`` seconds\n')
    health_check_type: typing.Optional[str] = pydantic.Field(None, description='A comma-separated value string of one or more health check types. The valid values are ``EC2`` , ``ELB`` , and ``VPC_LATTICE`` . ``EC2`` is the default health check and cannot be disabled. For more information, see `Health checks for Auto Scaling instances <https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Only specify ``EC2`` if you must clear a value that was previously set.\n')
    instance_id: typing.Optional[str] = pydantic.Field(None, description="The ID of the instance used to base the launch configuration on. For more information, see `Create an Auto Scaling group using an EC2 instance <https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-from-instance.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . If you specify ``LaunchTemplate`` , ``MixedInstancesPolicy`` , or ``LaunchConfigurationName`` , don't specify ``InstanceId`` .\n")
    launch_configuration_name: typing.Optional[str] = pydantic.Field(None, description="The name of the launch configuration to use to launch instances. Required only if you don't specify ``LaunchTemplate`` , ``MixedInstancesPolicy`` , or ``InstanceId`` .\n")
    launch_template: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplateSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Information used to specify the launch template and version to use to launch instances. You can alternatively associate a launch template to the Auto Scaling group by specifying a ``MixedInstancesPolicy`` . For more information about creating launch templates, see `Create a launch template for an Auto Scaling group <https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-template.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . If you omit this property, you must specify ``MixedInstancesPolicy`` , ``LaunchConfigurationName`` , or ``InstanceId`` .\n')
    lifecycle_hook_specification_list: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_LifecycleHookSpecificationPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='One or more lifecycle hooks to add to the Auto Scaling group before instances are launched.\n')
    load_balancer_names: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of Classic Load Balancers associated with this Auto Scaling group. For Application Load Balancers, Network Load Balancers, and Gateway Load Balancers, specify the ``TargetGroupARNs`` property instead.\n')
    max_instance_lifetime: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum amount of time, in seconds, that an instance can be in service. The default is null. If specified, the value must be either 0 or a number equal to or greater than 86,400 seconds (1 day). For more information, see `Replacing Auto Scaling instances based on maximum instance lifetime <https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-max-instance-lifetime.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    metrics_collection: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_MetricsCollectionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Enables the monitoring of group metrics of an Auto Scaling group. By default, these metrics are disabled.\n')
    mixed_instances_policy: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_MixedInstancesPolicyPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An embedded object that specifies a mixed instances policy. The policy includes properties that not only define the distribution of On-Demand Instances and Spot Instances, the maximum price to pay for Spot Instances (optional), and how the Auto Scaling group allocates instance types to fulfill On-Demand and Spot capacities, but also the properties that specify the instance configuration information—the launch template and instance types. The policy can also include a weight for each instance type and different launch templates for individual instance types. For more information, see `Auto Scaling groups with multiple instance types and purchase options <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    new_instances_protected_from_scale_in: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether newly launched instances are protected from termination by Amazon EC2 Auto Scaling when scaling in. For more information about preventing instances from terminating on scale in, see `Using instance scale-in protection <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-instance-protection.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    notification_configuration: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_NotificationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    notification_configurations: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnAutoScalingGroup_NotificationConfigurationPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Configures an Auto Scaling group to send notifications when specified events take place.\n')
    placement_group: typing.Optional[str] = pydantic.Field(None, description='The name of the placement group into which to launch your instances. For more information, see `Placement groups <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . .. epigraph:: A *cluster* placement group is a logical grouping of instances within a single Availability Zone. You cannot specify multiple Availability Zones and a cluster placement group.\n')
    service_linked_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the service-linked role that the Auto Scaling group uses to call other AWS service on your behalf. By default, Amazon EC2 Auto Scaling uses a service-linked role named ``AWSServiceRoleForAutoScaling`` , which it creates if it does not exist. For more information, see `Service-linked roles <https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-service-linked-role.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.aws_autoscaling.CfnAutoScalingGroup_TagPropertyPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='One or more tags. You can tag your Auto Scaling group and propagate the tags to the Amazon EC2 instances it launches. Tags are not propagated to Amazon EBS volumes. To add tags to Amazon EBS volumes, specify the tags in a launch template but use caution. If the launch template specifies an instance tag with a key that is also specified for the Auto Scaling group, Amazon EC2 Auto Scaling overrides the value of that instance tag with the value specified by the Auto Scaling group. For more information, see `Tag Auto Scaling groups and instances <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-tagging.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    target_group_arns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The Amazon Resource Names (ARN) of the Elastic Load Balancing target groups to associate with the Auto Scaling group. Instances are registered as targets with the target groups. The target groups receive incoming traffic and route requests to one or more registered targets. For more information, see `Use Elastic Load Balancing to distribute traffic across the instances in your Auto Scaling group <https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    termination_policies: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A policy or a list of policies that are used to select the instance to terminate. These policies are executed in the order that you list them. For more information, see `Work with Amazon EC2 Auto Scaling termination policies <https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-termination-policies.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Valid values: ``Default`` | ``AllocationStrategy`` | ``ClosestToNextInstanceHour`` | ``NewestInstance`` | ``OldestInstance`` | ``OldestLaunchConfiguration`` | ``OldestLaunchTemplate`` | ``arn:aws:lambda:region:account-id:function:my-function:my-alias``\n')
    vpc_zone_identifier: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of subnet IDs for a virtual private cloud (VPC) where instances in the Auto Scaling group can be created. If this resource specifies public subnets and is also in a VPC that is defined in the same stack template, you must use the `DependsOn attribute <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-dependson.html>`_ to declare a dependency on the `VPC-gateway attachment <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-vpc-gateway-attachment.html>`_ . .. epigraph:: When you update ``VPCZoneIdentifier`` , this retains the same Auto Scaling group and replaces old instances with new ones, according to the specified subnets. You can optionally specify how CloudFormation handles these updates by using an `UpdatePolicy attribute <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-updatepolicy.html>`_ . Required to launch instances into a nondefault VPC. If you specify ``VPCZoneIdentifier`` with ``AvailabilityZones`` , the subnets that you specify for this property must reside in those Availability Zones.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-autoscaling-autoscalinggroup.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    cfn_auto_scaling_group_props = autoscaling.CfnAutoScalingGroupProps(\n        max_size="maxSize",\n        min_size="minSize",\n\n        # the properties below are optional\n        auto_scaling_group_name="autoScalingGroupName",\n        availability_zones=["availabilityZones"],\n        capacity_rebalance=False,\n        context="context",\n        cooldown="cooldown",\n        default_instance_warmup=123,\n        desired_capacity="desiredCapacity",\n        desired_capacity_type="desiredCapacityType",\n        health_check_grace_period=123,\n        health_check_type="healthCheckType",\n        instance_id="instanceId",\n        launch_configuration_name="launchConfigurationName",\n        launch_template=autoscaling.CfnAutoScalingGroup.LaunchTemplateSpecificationProperty(\n            version="version",\n\n            # the properties below are optional\n            launch_template_id="launchTemplateId",\n            launch_template_name="launchTemplateName"\n        ),\n        lifecycle_hook_specification_list=[autoscaling.CfnAutoScalingGroup.LifecycleHookSpecificationProperty(\n            lifecycle_hook_name="lifecycleHookName",\n            lifecycle_transition="lifecycleTransition",\n\n            # the properties below are optional\n            default_result="defaultResult",\n            heartbeat_timeout=123,\n            notification_metadata="notificationMetadata",\n            notification_target_arn="notificationTargetArn",\n            role_arn="roleArn"\n        )],\n        load_balancer_names=["loadBalancerNames"],\n        max_instance_lifetime=123,\n        metrics_collection=[autoscaling.CfnAutoScalingGroup.MetricsCollectionProperty(\n            granularity="granularity",\n\n            # the properties below are optional\n            metrics=["metrics"]\n        )],\n        mixed_instances_policy=autoscaling.CfnAutoScalingGroup.MixedInstancesPolicyProperty(\n            launch_template=autoscaling.CfnAutoScalingGroup.LaunchTemplateProperty(\n                launch_template_specification=autoscaling.CfnAutoScalingGroup.LaunchTemplateSpecificationProperty(\n                    version="version",\n\n                    # the properties below are optional\n                    launch_template_id="launchTemplateId",\n                    launch_template_name="launchTemplateName"\n                ),\n\n                # the properties below are optional\n                overrides=[autoscaling.CfnAutoScalingGroup.LaunchTemplateOverridesProperty(\n                    instance_requirements=autoscaling.CfnAutoScalingGroup.InstanceRequirementsProperty(\n                        accelerator_count=autoscaling.CfnAutoScalingGroup.AcceleratorCountRequestProperty(\n                            max=123,\n                            min=123\n                        ),\n                        accelerator_manufacturers=["acceleratorManufacturers"],\n                        accelerator_names=["acceleratorNames"],\n                        accelerator_total_memory_mi_b=autoscaling.CfnAutoScalingGroup.AcceleratorTotalMemoryMiBRequestProperty(\n                            max=123,\n                            min=123\n                        ),\n                        accelerator_types=["acceleratorTypes"],\n                        allowed_instance_types=["allowedInstanceTypes"],\n                        bare_metal="bareMetal",\n                        baseline_ebs_bandwidth_mbps=autoscaling.CfnAutoScalingGroup.BaselineEbsBandwidthMbpsRequestProperty(\n                            max=123,\n                            min=123\n                        ),\n                        burstable_performance="burstablePerformance",\n                        cpu_manufacturers=["cpuManufacturers"],\n                        excluded_instance_types=["excludedInstanceTypes"],\n                        instance_generations=["instanceGenerations"],\n                        local_storage="localStorage",\n                        local_storage_types=["localStorageTypes"],\n                        memory_gi_bPer_vCpu=autoscaling.CfnAutoScalingGroup.MemoryGiBPerVCpuRequestProperty(\n                            max=123,\n                            min=123\n                        ),\n                        memory_mi_b=autoscaling.CfnAutoScalingGroup.MemoryMiBRequestProperty(\n                            max=123,\n                            min=123\n                        ),\n                        network_bandwidth_gbps=autoscaling.CfnAutoScalingGroup.NetworkBandwidthGbpsRequestProperty(\n                            max=123,\n                            min=123\n                        ),\n                        network_interface_count=autoscaling.CfnAutoScalingGroup.NetworkInterfaceCountRequestProperty(\n                            max=123,\n                            min=123\n                        ),\n                        on_demand_max_price_percentage_over_lowest_price=123,\n                        require_hibernate_support=False,\n                        spot_max_price_percentage_over_lowest_price=123,\n                        total_local_storage_gb=autoscaling.CfnAutoScalingGroup.TotalLocalStorageGBRequestProperty(\n                            max=123,\n                            min=123\n                        ),\n                        v_cpu_count=autoscaling.CfnAutoScalingGroup.VCpuCountRequestProperty(\n                            max=123,\n                            min=123\n                        )\n                    ),\n                    instance_type="instanceType",\n                    launch_template_specification=autoscaling.CfnAutoScalingGroup.LaunchTemplateSpecificationProperty(\n                        version="version",\n\n                        # the properties below are optional\n                        launch_template_id="launchTemplateId",\n                        launch_template_name="launchTemplateName"\n                    ),\n                    weighted_capacity="weightedCapacity"\n                )]\n            ),\n\n            # the properties below are optional\n            instances_distribution=autoscaling.CfnAutoScalingGroup.InstancesDistributionProperty(\n                on_demand_allocation_strategy="onDemandAllocationStrategy",\n                on_demand_base_capacity=123,\n                on_demand_percentage_above_base_capacity=123,\n                spot_allocation_strategy="spotAllocationStrategy",\n                spot_instance_pools=123,\n                spot_max_price="spotMaxPrice"\n            )\n        ),\n        new_instances_protected_from_scale_in=False,\n        notification_configuration=autoscaling.CfnAutoScalingGroup.NotificationConfigurationProperty(\n            topic_arn="topicArn",\n\n            # the properties below are optional\n            notification_types=["notificationTypes"]\n        ),\n        notification_configurations=[autoscaling.CfnAutoScalingGroup.NotificationConfigurationProperty(\n            topic_arn="topicArn",\n\n            # the properties below are optional\n            notification_types=["notificationTypes"]\n        )],\n        placement_group="placementGroup",\n        service_linked_role_arn="serviceLinkedRoleArn",\n        tags=[autoscaling.CfnAutoScalingGroup.TagPropertyProperty(\n            key="key",\n            propagate_at_launch=False,\n            value="value"\n        )],\n        target_group_arns=["targetGroupArns"],\n        termination_policies=["terminationPolicies"],\n        vpc_zone_identifier=["vpcZoneIdentifier"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_size', 'min_size', 'auto_scaling_group_name', 'availability_zones', 'capacity_rebalance', 'context', 'cooldown', 'default_instance_warmup', 'desired_capacity', 'desired_capacity_type', 'health_check_grace_period', 'health_check_type', 'instance_id', 'launch_configuration_name', 'launch_template', 'lifecycle_hook_specification_list', 'load_balancer_names', 'max_instance_lifetime', 'metrics_collection', 'mixed_instances_policy', 'new_instances_protected_from_scale_in', 'notification_configuration', 'notification_configurations', 'placement_group', 'service_linked_role_arn', 'tags', 'target_group_arns', 'termination_policies', 'vpc_zone_identifier']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnAutoScalingGroupProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnLaunchConfigurationProps
class CfnLaunchConfigurationPropsDef(BaseCfnProperty):
    image_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ID of the Amazon Machine Image (AMI) that was assigned during registration. For more information, see `Finding a Linux AMI <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . If you specify ``InstanceId`` , an ``ImageId`` is not required.\n')
    instance_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the instance type of the EC2 instance. For information about available instance types, see `Available instance types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#AvailableInstanceTypes>`_ in the *Amazon EC2 User Guide for Linux Instances* . If you specify ``InstanceId`` , an ``InstanceType`` is not required.\n')
    associate_public_ip_address: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="Specifies whether to assign a public IPv4 address to the group's instances. If the instance is launched into a default subnet, the default is to assign a public IPv4 address, unless you disabled the option to assign a public IPv4 address on the subnet. If the instance is launched into a nondefault subnet, the default is not to assign a public IPv4 address, unless you enabled the option to assign a public IPv4 address on the subnet. If you specify ``true`` , each instance in the Auto Scaling group receives a unique public IPv4 address. For more information, see `Launching Auto Scaling instances in a VPC <https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-in-vpc.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . If you specify this property, you must specify at least one subnet for ``VPCZoneIdentifier`` when you create your group.\n")
    block_device_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnLaunchConfiguration_BlockDeviceMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The block device mapping entries that define the block devices to attach to the instances at launch. By default, the block devices specified in the block device mapping for the AMI are used. For more information, see `Block device mappings <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html>`_ in the *Amazon EC2 User Guide for Linux Instances* .\n')
    classic_link_vpc_id: typing.Optional[str] = pydantic.Field(None, description='Available for backward compatibility.\n')
    classic_link_vpc_security_groups: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Available for backward compatibility.\n')
    ebs_optimized: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Specifies whether the launch configuration is optimized for EBS I/O ( ``true`` ) or not ( ``false`` ). The optimization provides dedicated throughput to Amazon EBS and an optimized configuration stack to provide optimal I/O performance. This optimization is not available with all instance types. Additional fees are incurred when you enable EBS optimization for an instance type that is not EBS-optimized by default. For more information, see `Amazon EBS-optimized instances <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html>`_ in the *Amazon EC2 User Guide for Linux Instances* . The default value is ``false`` .\n')
    iam_instance_profile: typing.Optional[str] = pydantic.Field(None, description='The name or the Amazon Resource Name (ARN) of the instance profile associated with the IAM role for the instance. The instance profile contains the IAM role. For more information, see `IAM role for applications that run on Amazon EC2 instances <https://docs.aws.amazon.com/autoscaling/ec2/userguide/us-iam-role.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    instance_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the Amazon EC2 instance to use to create the launch configuration. When you use an instance to create a launch configuration, all properties are derived from the instance with the exception of ``BlockDeviceMapping`` and ``AssociatePublicIpAddress`` . You can override any properties from the instance by specifying them in the launch configuration.\n')
    instance_monitoring: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Controls whether instances in this group are launched with detailed ( ``true`` ) or basic ( ``false`` ) monitoring. The default value is ``true`` (enabled). .. epigraph:: When detailed monitoring is enabled, Amazon CloudWatch generates metrics every minute and your account is charged a fee. When you disable detailed monitoring, CloudWatch generates metrics every 5 minutes. For more information, see `Configure Monitoring for Auto Scaling Instances <https://docs.aws.amazon.com/autoscaling/latest/userguide/enable-as-instance-metrics.html>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    kernel_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the kernel associated with the AMI. .. epigraph:: We recommend that you use PV-GRUB instead of kernels and RAM disks. For more information, see `User provided kernels <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/UserProvidedKernels.html>`_ in the *Amazon EC2 User Guide for Linux Instances* .\n')
    key_name: typing.Optional[str] = pydantic.Field(None, description='The name of the key pair. For more information, see `Amazon EC2 key pairs and Linux instances <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html>`_ in the *Amazon EC2 User Guide for Linux Instances* .\n')
    launch_configuration_name: typing.Optional[str] = pydantic.Field(None, description='The name of the launch configuration. This name must be unique per Region per account.\n')
    metadata_options: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnLaunchConfiguration_MetadataOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The metadata options for the instances. For more information, see `Configuring the Instance Metadata Options <https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-launch-config.html#launch-configurations-imds>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    placement_tenancy: typing.Optional[str] = pydantic.Field(None, description='The tenancy of the instance, either ``default`` or ``dedicated`` . An instance with ``dedicated`` tenancy runs on isolated, single-tenant hardware and can only be launched into a VPC. To launch dedicated instances into a shared tenancy VPC (a VPC with the instance placement tenancy attribute set to ``default`` ), you must set the value of this property to ``dedicated`` . For more information, see `Configuring instance tenancy with Amazon EC2 Auto Scaling <https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-dedicated-instances.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . If you specify ``PlacementTenancy`` , you must specify at least one subnet for ``VPCZoneIdentifier`` when you create your group. Valid values: ``default`` | ``dedicated``\n')
    ram_disk_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the RAM disk to select. .. epigraph:: We recommend that you use PV-GRUB instead of kernels and RAM disks. For more information, see `User provided kernels <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/UserProvidedKernels.html>`_ in the *Amazon EC2 User Guide for Linux Instances* .\n')
    security_groups: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list that contains the security groups to assign to the instances in the Auto Scaling group. The list can contain both the IDs of existing security groups and references to `SecurityGroup <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-security-group.html>`_ resources created in the template. For more information, see `Control traffic to resources using security groups <https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html>`_ in the *Amazon Virtual Private Cloud User Guide* .\n')
    spot_price: typing.Optional[str] = pydantic.Field(None, description='The maximum hourly price to be paid for any Spot Instance launched to fulfill the request. Spot Instances are launched when the price you specify exceeds the current Spot price. For more information, see `Request Spot Instances for fault-tolerant and flexible applications <https://docs.aws.amazon.com/autoscaling/ec2/userguide/launch-template-spot-instances.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Valid Range: Minimum value of 0.001 .. epigraph:: When you change your maximum price by creating a new launch configuration, running instances will continue to run as long as the maximum price for those running instances is higher than the current Spot price.\n')
    user_data: typing.Optional[str] = pydantic.Field(None, description='The Base64-encoded user data to make available to the launched EC2 instances. For more information, see `Instance metadata and user data <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html>`_ in the *Amazon EC2 User Guide for Linux Instances* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-autoscaling-launchconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    cfn_launch_configuration_props = autoscaling.CfnLaunchConfigurationProps(\n        image_id="imageId",\n        instance_type="instanceType",\n\n        # the properties below are optional\n        associate_public_ip_address=False,\n        block_device_mappings=[autoscaling.CfnLaunchConfiguration.BlockDeviceMappingProperty(\n            device_name="deviceName",\n\n            # the properties below are optional\n            ebs=autoscaling.CfnLaunchConfiguration.BlockDeviceProperty(\n                delete_on_termination=False,\n                encrypted=False,\n                iops=123,\n                snapshot_id="snapshotId",\n                throughput=123,\n                volume_size=123,\n                volume_type="volumeType"\n            ),\n            no_device=False,\n            virtual_name="virtualName"\n        )],\n        classic_link_vpc_id="classicLinkVpcId",\n        classic_link_vpc_security_groups=["classicLinkVpcSecurityGroups"],\n        ebs_optimized=False,\n        iam_instance_profile="iamInstanceProfile",\n        instance_id="instanceId",\n        instance_monitoring=False,\n        kernel_id="kernelId",\n        key_name="keyName",\n        launch_configuration_name="launchConfigurationName",\n        metadata_options=autoscaling.CfnLaunchConfiguration.MetadataOptionsProperty(\n            http_endpoint="httpEndpoint",\n            http_put_response_hop_limit=123,\n            http_tokens="httpTokens"\n        ),\n        placement_tenancy="placementTenancy",\n        ram_disk_id="ramDiskId",\n        security_groups=["securityGroups"],\n        spot_price="spotPrice",\n        user_data="userData"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['image_id', 'instance_type', 'associate_public_ip_address', 'block_device_mappings', 'classic_link_vpc_id', 'classic_link_vpc_security_groups', 'ebs_optimized', 'iam_instance_profile', 'instance_id', 'instance_monitoring', 'kernel_id', 'key_name', 'launch_configuration_name', 'metadata_options', 'placement_tenancy', 'ram_disk_id', 'security_groups', 'spot_price', 'user_data']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnLaunchConfigurationProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnLifecycleHookProps
class CfnLifecycleHookPropsDef(BaseCfnProperty):
    auto_scaling_group_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Auto Scaling group.\n')
    lifecycle_transition: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The lifecycle transition. For Auto Scaling groups, there are two major lifecycle transitions. - To create a lifecycle hook for scale-out events, specify ``autoscaling:EC2_INSTANCE_LAUNCHING`` . - To create a lifecycle hook for scale-in events, specify ``autoscaling:EC2_INSTANCE_TERMINATING`` .\n')
    default_result: typing.Optional[str] = pydantic.Field(None, description='The action the Auto Scaling group takes when the lifecycle hook timeout elapses or if an unexpected failure occurs. The default value is ``ABANDON`` . Valid values: ``CONTINUE`` | ``ABANDON``\n')
    heartbeat_timeout: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum time, in seconds, that can elapse before the lifecycle hook times out. The range is from ``30`` to ``7200`` seconds. The default value is ``3600`` seconds (1 hour).\n')
    lifecycle_hook_name: typing.Optional[str] = pydantic.Field(None, description='The name of the lifecycle hook.\n')
    notification_metadata: typing.Optional[str] = pydantic.Field(None, description='Additional information that you want to include any time Amazon EC2 Auto Scaling sends a message to the notification target.\n')
    notification_target_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the notification target that Amazon EC2 Auto Scaling sends notifications to when an instance is in a wait state for the lifecycle hook. You can specify an Amazon SNS topic or an Amazon SQS queue.\n')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the IAM role that allows the Auto Scaling group to publish to the specified notification target. For information about creating this role, see `Configure a notification target for a lifecycle hook <https://docs.aws.amazon.com/autoscaling/ec2/userguide/prepare-for-lifecycle-notifications.html#lifecycle-hook-notification-target>`_ in the *Amazon EC2 Auto Scaling User Guide* . Valid only if the notification target is an Amazon SNS topic or an Amazon SQS queue.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-autoscaling-lifecyclehook.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    cfn_lifecycle_hook_props = autoscaling.CfnLifecycleHookProps(\n        auto_scaling_group_name="autoScalingGroupName",\n        lifecycle_transition="lifecycleTransition",\n\n        # the properties below are optional\n        default_result="defaultResult",\n        heartbeat_timeout=123,\n        lifecycle_hook_name="lifecycleHookName",\n        notification_metadata="notificationMetadata",\n        notification_target_arn="notificationTargetArn",\n        role_arn="roleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group_name', 'lifecycle_transition', 'default_result', 'heartbeat_timeout', 'lifecycle_hook_name', 'notification_metadata', 'notification_target_arn', 'role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnLifecycleHookProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScalingPolicyProps
class CfnScalingPolicyPropsDef(BaseCfnProperty):
    auto_scaling_group_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Auto Scaling group.\n')
    adjustment_type: typing.Optional[str] = pydantic.Field(None, description='Specifies how the scaling adjustment is interpreted (for example, an absolute number or a percentage). The valid values are ``ChangeInCapacity`` , ``ExactCapacity`` , and ``PercentChangeInCapacity`` . Required if the policy type is ``StepScaling`` or ``SimpleScaling`` . For more information, see `Scaling adjustment types <https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-adjustment>`_ in the *Amazon EC2 Auto Scaling User Guide* .\n')
    cooldown: typing.Optional[str] = pydantic.Field(None, description='A cooldown period, in seconds, that applies to a specific simple scaling policy. When a cooldown period is specified here, it overrides the default cooldown. Valid only if the policy type is ``SimpleScaling`` . For more information, see `Scaling cooldowns for Amazon EC2 Auto Scaling <https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html>`_ in the *Amazon EC2 Auto Scaling User Guide* . Default: None\n')
    estimated_instance_warmup: typing.Union[int, float, None] = pydantic.Field(None, description='*Not needed if the default instance warmup is defined for the group.*. The estimated time, in seconds, until a newly launched instance can contribute to the CloudWatch metrics. This warm-up period applies to instances launched due to a specific target tracking or step scaling policy. When a warm-up period is specified here, it overrides the default instance warmup. Valid only if the policy type is ``TargetTrackingScaling`` or ``StepScaling`` . .. epigraph:: The default is to use the value for the default instance warmup defined for the group. If default instance warmup is null, then ``EstimatedInstanceWarmup`` falls back to the value of default cooldown.\n')
    metric_aggregation_type: typing.Optional[str] = pydantic.Field(None, description='The aggregation type for the CloudWatch metrics. The valid values are ``Minimum`` , ``Maximum`` , and ``Average`` . If the aggregation type is null, the value is treated as ``Average`` . Valid only if the policy type is ``StepScaling`` .\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum value to scale by when the adjustment type is ``PercentChangeInCapacity`` . For example, suppose that you create a step scaling policy to scale out an Auto Scaling group by 25 percent and you specify a ``MinAdjustmentMagnitude`` of 2. If the group has 4 instances and the scaling policy is performed, 25 percent of 4 is 1. However, because you specified a ``MinAdjustmentMagnitude`` of 2, Amazon EC2 Auto Scaling scales out the group by 2 instances. Valid only if the policy type is ``StepScaling`` or ``SimpleScaling`` . For more information, see `Scaling adjustment types <https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html#as-scaling-adjustment>`_ in the *Amazon EC2 Auto Scaling User Guide* . .. epigraph:: Some Auto Scaling groups use instance weights. In this case, set the ``MinAdjustmentMagnitude`` to a value that is at least as large as your largest instance weight.\n')
    policy_type: typing.Optional[str] = pydantic.Field(None, description='One of the following policy types:. - ``TargetTrackingScaling`` - ``StepScaling`` - ``SimpleScaling`` (default) - ``PredictiveScaling``\n')
    predictive_scaling_configuration: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A predictive scaling policy. Provides support for predefined and custom metrics. Predefined metrics include CPU utilization, network in/out, and the Application Load Balancer request count. Required if the policy type is ``PredictiveScaling`` .\n')
    scaling_adjustment: typing.Union[int, float, None] = pydantic.Field(None, description='The amount by which to scale, based on the specified adjustment type. A positive value adds to the current capacity while a negative number removes from the current capacity. For exact capacity, you must specify a non-negative value. Required if the policy type is ``SimpleScaling`` . (Not used with any other policy type.)\n')
    step_adjustments: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_StepAdjustmentPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A set of adjustments that enable you to scale based on the size of the alarm breach. Required if the policy type is ``StepScaling`` . (Not used with any other policy type.)\n')
    target_tracking_configuration: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnScalingPolicy_TargetTrackingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A target tracking scaling policy. Provides support for predefined or custom metrics. The following predefined metrics are available: - ``ASGAverageCPUUtilization`` - ``ASGAverageNetworkIn`` - ``ASGAverageNetworkOut`` - ``ALBRequestCountPerTarget`` If you specify ``ALBRequestCountPerTarget`` for the metric, you must specify the ``ResourceLabel`` property with the ``PredefinedMetricSpecification`` . Required if the policy type is ``TargetTrackingScaling`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-autoscaling-scalingpolicy.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    cfn_scaling_policy_props = autoscaling.CfnScalingPolicyProps(\n        auto_scaling_group_name="autoScalingGroupName",\n\n        # the properties below are optional\n        adjustment_type="adjustmentType",\n        cooldown="cooldown",\n        estimated_instance_warmup=123,\n        metric_aggregation_type="metricAggregationType",\n        min_adjustment_magnitude=123,\n        policy_type="policyType",\n        predictive_scaling_configuration=autoscaling.CfnScalingPolicy.PredictiveScalingConfigurationProperty(\n            metric_specifications=[autoscaling.CfnScalingPolicy.PredictiveScalingMetricSpecificationProperty(\n                target_value=123,\n\n                # the properties below are optional\n                customized_capacity_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedCapacityMetricProperty(\n                    metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n                        id="id",\n\n                        # the properties below are optional\n                        expression="expression",\n                        label="label",\n                        metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                            metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                                metric_name="metricName",\n                                namespace="namespace",\n\n                                # the properties below are optional\n                                dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                                    name="name",\n                                    value="value"\n                                )]\n                            ),\n                            stat="stat",\n\n                            # the properties below are optional\n                            unit="unit"\n                        ),\n                        return_data=False\n                    )]\n                ),\n                customized_load_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedLoadMetricProperty(\n                    metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n                        id="id",\n\n                        # the properties below are optional\n                        expression="expression",\n                        label="label",\n                        metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                            metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                                metric_name="metricName",\n                                namespace="namespace",\n\n                                # the properties below are optional\n                                dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                                    name="name",\n                                    value="value"\n                                )]\n                            ),\n                            stat="stat",\n\n                            # the properties below are optional\n                            unit="unit"\n                        ),\n                        return_data=False\n                    )]\n                ),\n                customized_scaling_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingCustomizedScalingMetricProperty(\n                    metric_data_queries=[autoscaling.CfnScalingPolicy.MetricDataQueryProperty(\n                        id="id",\n\n                        # the properties below are optional\n                        expression="expression",\n                        label="label",\n                        metric_stat=autoscaling.CfnScalingPolicy.MetricStatProperty(\n                            metric=autoscaling.CfnScalingPolicy.MetricProperty(\n                                metric_name="metricName",\n                                namespace="namespace",\n\n                                # the properties below are optional\n                                dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                                    name="name",\n                                    value="value"\n                                )]\n                            ),\n                            stat="stat",\n\n                            # the properties below are optional\n                            unit="unit"\n                        ),\n                        return_data=False\n                    )]\n                ),\n                predefined_load_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedLoadMetricProperty(\n                    predefined_metric_type="predefinedMetricType",\n\n                    # the properties below are optional\n                    resource_label="resourceLabel"\n                ),\n                predefined_metric_pair_specification=autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedMetricPairProperty(\n                    predefined_metric_type="predefinedMetricType",\n\n                    # the properties below are optional\n                    resource_label="resourceLabel"\n                ),\n                predefined_scaling_metric_specification=autoscaling.CfnScalingPolicy.PredictiveScalingPredefinedScalingMetricProperty(\n                    predefined_metric_type="predefinedMetricType",\n\n                    # the properties below are optional\n                    resource_label="resourceLabel"\n                )\n            )],\n\n            # the properties below are optional\n            max_capacity_breach_behavior="maxCapacityBreachBehavior",\n            max_capacity_buffer=123,\n            mode="mode",\n            scheduling_buffer_time=123\n        ),\n        scaling_adjustment=123,\n        step_adjustments=[autoscaling.CfnScalingPolicy.StepAdjustmentProperty(\n            scaling_adjustment=123,\n\n            # the properties below are optional\n            metric_interval_lower_bound=123,\n            metric_interval_upper_bound=123\n        )],\n        target_tracking_configuration=autoscaling.CfnScalingPolicy.TargetTrackingConfigurationProperty(\n            target_value=123,\n\n            # the properties below are optional\n            customized_metric_specification=autoscaling.CfnScalingPolicy.CustomizedMetricSpecificationProperty(\n                metric_name="metricName",\n                namespace="namespace",\n                statistic="statistic",\n\n                # the properties below are optional\n                dimensions=[autoscaling.CfnScalingPolicy.MetricDimensionProperty(\n                    name="name",\n                    value="value"\n                )],\n                unit="unit"\n            ),\n            disable_scale_in=False,\n            predefined_metric_specification=autoscaling.CfnScalingPolicy.PredefinedMetricSpecificationProperty(\n                predefined_metric_type="predefinedMetricType",\n\n                # the properties below are optional\n                resource_label="resourceLabel"\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group_name', 'adjustment_type', 'cooldown', 'estimated_instance_warmup', 'metric_aggregation_type', 'min_adjustment_magnitude', 'policy_type', 'predictive_scaling_configuration', 'scaling_adjustment', 'step_adjustments', 'target_tracking_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScalingPolicyProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnScheduledActionProps
class CfnScheduledActionPropsDef(BaseCfnProperty):
    auto_scaling_group_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Auto Scaling group.\n')
    desired_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The desired capacity is the initial capacity of the Auto Scaling group after the scheduled action runs and the capacity it attempts to maintain. It can scale beyond this capacity if you add more scaling conditions. .. epigraph:: You must specify at least one of the following properties: ``MaxSize`` , ``MinSize`` , or ``DesiredCapacity`` .\n')
    end_time: typing.Optional[str] = pydantic.Field(None, description='The date and time for the recurring schedule to end, in UTC. For example, ``"2021-06-01T00:00:00Z"`` .\n')
    max_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum size of the Auto Scaling group.\n')
    min_size: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum size of the Auto Scaling group.\n')
    recurrence: typing.Optional[str] = pydantic.Field(None, description='The recurring schedule for this action. This format consists of five fields separated by white spaces: [Minute] [Hour] [Day_of_Month] [Month_of_Year] [Day_of_Week]. The value must be in quotes (for example, ``"30 0 1 1,6,12 *"`` ). For more information about this format, see `Crontab <https://docs.aws.amazon.com/http://crontab.org>`_ . When ``StartTime`` and ``EndTime`` are specified with ``Recurrence`` , they form the boundaries of when the recurring action starts and stops. Cron expressions use Universal Coordinated Time (UTC) by default.\n')
    start_time: typing.Optional[str] = pydantic.Field(None, description='The date and time for this action to start, in YYYY-MM-DDThh:mm:ssZ format in UTC/GMT only and in quotes (for example, ``"2021-06-01T00:00:00Z"`` ). If you specify ``Recurrence`` and ``StartTime`` , Amazon EC2 Auto Scaling performs the action at this time, and then performs the action based on the specified recurrence.\n')
    time_zone: typing.Optional[str] = pydantic.Field(None, description='Specifies the time zone for a cron expression. If a time zone is not provided, UTC is used by default. Valid values are the canonical names of the IANA time zones, derived from the IANA Time Zone Database (such as ``Etc/GMT+9`` or ``Pacific/Tahiti`` ). For more information, see `https://en.wikipedia.org/wiki/List_of_tz_database_time_zones <https://docs.aws.amazon.com/https://en.wikipedia.org/wiki/List_of_tz_database_time_zones>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-autoscaling-scheduledaction.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    cfn_scheduled_action_props = autoscaling.CfnScheduledActionProps(\n        auto_scaling_group_name="autoScalingGroupName",\n\n        # the properties below are optional\n        desired_capacity=123,\n        end_time="endTime",\n        max_size=123,\n        min_size=123,\n        recurrence="recurrence",\n        start_time="startTime",\n        time_zone="timeZone"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group_name', 'desired_capacity', 'end_time', 'max_size', 'min_size', 'recurrence', 'start_time', 'time_zone']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnScheduledActionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_autoscaling.CfnWarmPoolProps
class CfnWarmPoolPropsDef(BaseCfnProperty):
    auto_scaling_group_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Auto Scaling group.\n')
    instance_reuse_policy: typing.Union[models.UnsupportedResource, models.aws_autoscaling.CfnWarmPool_InstanceReusePolicyPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Indicates whether instances in the Auto Scaling group can be returned to the warm pool on scale in. The default is to terminate instances in the Auto Scaling group when the group scales in.\n')
    max_group_prepared_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="Specifies the maximum number of instances that are allowed to be in the warm pool or in any state except ``Terminated`` for the Auto Scaling group. This is an optional property. Specify it only if you do not want the warm pool size to be determined by the difference between the group's maximum capacity and its desired capacity. .. epigraph:: If a value for ``MaxGroupPreparedCapacity`` is not specified, Amazon EC2 Auto Scaling launches and maintains the difference between the group's maximum capacity and its desired capacity. If you specify a value for ``MaxGroupPreparedCapacity`` , Amazon EC2 Auto Scaling uses the difference between the ``MaxGroupPreparedCapacity`` and the desired capacity instead. The size of the warm pool is dynamic. Only when ``MaxGroupPreparedCapacity`` and ``MinSize`` are set to the same value does the warm pool have an absolute size. If the desired capacity of the Auto Scaling group is higher than the ``MaxGroupPreparedCapacity`` , the capacity of the warm pool is 0, unless you specify a value for ``MinSize`` . To remove a value that you previously set, include the property but specify -1 for the value.\n")
    min_size: typing.Union[int, float, None] = pydantic.Field(None, description='Specifies the minimum number of instances to maintain in the warm pool. This helps you to ensure that there is always a certain number of warmed instances available to handle traffic spikes. Defaults to 0 if not specified.\n')
    pool_state: typing.Optional[str] = pydantic.Field(None, description='Sets the instance state to transition to after the lifecycle actions are complete. Default is ``Stopped`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-autoscaling-warmpool.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_autoscaling as autoscaling\n\n    cfn_warm_pool_props = autoscaling.CfnWarmPoolProps(\n        auto_scaling_group_name="autoScalingGroupName",\n\n        # the properties below are optional\n        instance_reuse_policy=autoscaling.CfnWarmPool.InstanceReusePolicyProperty(\n            reuse_on_scale_in=False\n        ),\n        max_group_prepared_capacity=123,\n        min_size=123,\n        pool_state="poolState"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_group_name', 'instance_reuse_policy', 'max_group_prepared_capacity', 'min_size', 'pool_state']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_autoscaling.CfnWarmPoolProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




class ModuleModel(pydantic.BaseModel):
    AutoScalingGroupRequireImdsv2Aspect: typing.Optional[dict[str, models.aws_autoscaling.AutoScalingGroupRequireImdsv2AspectDef]] = pydantic.Field(None)
    BlockDeviceVolume: typing.Optional[dict[str, models.aws_autoscaling.BlockDeviceVolumeDef]] = pydantic.Field(None)
    GroupMetric: typing.Optional[dict[str, models.aws_autoscaling.GroupMetricDef]] = pydantic.Field(None)
    GroupMetrics: typing.Optional[dict[str, models.aws_autoscaling.GroupMetricsDef]] = pydantic.Field(None)
    HealthCheck: typing.Optional[dict[str, models.aws_autoscaling.HealthCheckDef]] = pydantic.Field(None)
    ScalingEvents: typing.Optional[dict[str, models.aws_autoscaling.ScalingEventsDef]] = pydantic.Field(None)
    Schedule: typing.Optional[dict[str, models.aws_autoscaling.ScheduleDef]] = pydantic.Field(None)
    Signals: typing.Optional[dict[str, models.aws_autoscaling.SignalsDef]] = pydantic.Field(None)
    UpdatePolicy: typing.Optional[dict[str, models.aws_autoscaling.UpdatePolicyDef]] = pydantic.Field(None)
    AutoScalingGroup: typing.Optional[dict[str, models.aws_autoscaling.AutoScalingGroupDef]] = pydantic.Field(None)
    LifecycleHook: typing.Optional[dict[str, models.aws_autoscaling.LifecycleHookDef]] = pydantic.Field(None)
    ScheduledAction: typing.Optional[dict[str, models.aws_autoscaling.ScheduledActionDef]] = pydantic.Field(None)
    StepScalingAction: typing.Optional[dict[str, models.aws_autoscaling.StepScalingActionDef]] = pydantic.Field(None)
    StepScalingPolicy: typing.Optional[dict[str, models.aws_autoscaling.StepScalingPolicyDef]] = pydantic.Field(None)
    TargetTrackingScalingPolicy: typing.Optional[dict[str, models.aws_autoscaling.TargetTrackingScalingPolicyDef]] = pydantic.Field(None)
    WarmPool: typing.Optional[dict[str, models.aws_autoscaling.WarmPoolDef]] = pydantic.Field(None)
    AdjustmentTier: typing.Optional[dict[str, models.aws_autoscaling.AdjustmentTierDef]] = pydantic.Field(None)
    ApplyCloudFormationInitOptions: typing.Optional[dict[str, models.aws_autoscaling.ApplyCloudFormationInitOptionsDef]] = pydantic.Field(None)
    AutoScalingGroupProps: typing.Optional[dict[str, models.aws_autoscaling.AutoScalingGroupPropsDef]] = pydantic.Field(None)
    BaseTargetTrackingProps: typing.Optional[dict[str, models.aws_autoscaling.BaseTargetTrackingPropsDef]] = pydantic.Field(None)
    BasicLifecycleHookProps: typing.Optional[dict[str, models.aws_autoscaling.BasicLifecycleHookPropsDef]] = pydantic.Field(None)
    BasicScheduledActionProps: typing.Optional[dict[str, models.aws_autoscaling.BasicScheduledActionPropsDef]] = pydantic.Field(None)
    BasicStepScalingPolicyProps: typing.Optional[dict[str, models.aws_autoscaling.BasicStepScalingPolicyPropsDef]] = pydantic.Field(None)
    BasicTargetTrackingScalingPolicyProps: typing.Optional[dict[str, models.aws_autoscaling.BasicTargetTrackingScalingPolicyPropsDef]] = pydantic.Field(None)
    BindHookTargetOptions: typing.Optional[dict[str, models.aws_autoscaling.BindHookTargetOptionsDef]] = pydantic.Field(None)
    BlockDevice: typing.Optional[dict[str, models.aws_autoscaling.BlockDeviceDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_AcceleratorCountRequestProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_AcceleratorCountRequestPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_AcceleratorTotalMemoryMiBRequestProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_AcceleratorTotalMemoryMiBRequestPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_BaselineEbsBandwidthMbpsRequestProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_BaselineEbsBandwidthMbpsRequestPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_InstanceRequirementsProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_InstanceRequirementsPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_InstancesDistributionProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_InstancesDistributionPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_LaunchTemplateOverridesProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplateOverridesPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_LaunchTemplateProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplatePropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_LaunchTemplateSpecificationProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_LaunchTemplateSpecificationPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_LifecycleHookSpecificationProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_LifecycleHookSpecificationPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_MemoryGiBPerVCpuRequestProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_MemoryGiBPerVCpuRequestPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_MemoryMiBRequestProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_MemoryMiBRequestPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_MetricsCollectionProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_MetricsCollectionPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_MixedInstancesPolicyProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_MixedInstancesPolicyPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_NetworkBandwidthGbpsRequestProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_NetworkBandwidthGbpsRequestPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_NetworkInterfaceCountRequestProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_NetworkInterfaceCountRequestPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_NotificationConfigurationProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_NotificationConfigurationPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_TagPropertyProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_TagPropertyPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_TotalLocalStorageGBRequestProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_TotalLocalStorageGBRequestPropertyDef]] = pydantic.Field(None)
    CfnAutoScalingGroup_VCpuCountRequestProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroup_VCpuCountRequestPropertyDef]] = pydantic.Field(None)
    CfnLaunchConfiguration_BlockDeviceMappingProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnLaunchConfiguration_BlockDeviceMappingPropertyDef]] = pydantic.Field(None)
    CfnLaunchConfiguration_BlockDeviceProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnLaunchConfiguration_BlockDevicePropertyDef]] = pydantic.Field(None)
    CfnLaunchConfiguration_MetadataOptionsProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnLaunchConfiguration_MetadataOptionsPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_CustomizedMetricSpecificationProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_CustomizedMetricSpecificationPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_MetricDataQueryProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_MetricDataQueryPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_MetricDimensionProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_MetricDimensionPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_MetricProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_MetricPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_MetricStatProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_MetricStatPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_PredefinedMetricSpecificationProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_PredefinedMetricSpecificationPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_PredictiveScalingConfigurationProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingConfigurationPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_PredictiveScalingCustomizedCapacityMetricProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingCustomizedCapacityMetricPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_PredictiveScalingCustomizedLoadMetricProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingCustomizedLoadMetricPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_PredictiveScalingCustomizedScalingMetricProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingCustomizedScalingMetricPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_PredictiveScalingMetricSpecificationProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingMetricSpecificationPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_PredictiveScalingPredefinedLoadMetricProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingPredefinedLoadMetricPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_PredictiveScalingPredefinedMetricPairProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingPredefinedMetricPairPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_PredictiveScalingPredefinedScalingMetricProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_PredictiveScalingPredefinedScalingMetricPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_StepAdjustmentProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_StepAdjustmentPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_TargetTrackingConfigurationProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicy_TargetTrackingConfigurationPropertyDef]] = pydantic.Field(None)
    CfnWarmPool_InstanceReusePolicyProperty: typing.Optional[dict[str, models.aws_autoscaling.CfnWarmPool_InstanceReusePolicyPropertyDef]] = pydantic.Field(None)
    CommonAutoScalingGroupProps: typing.Optional[dict[str, models.aws_autoscaling.CommonAutoScalingGroupPropsDef]] = pydantic.Field(None)
    CpuUtilizationScalingProps: typing.Optional[dict[str, models.aws_autoscaling.CpuUtilizationScalingPropsDef]] = pydantic.Field(None)
    CronOptions: typing.Optional[dict[str, models.aws_autoscaling.CronOptionsDef]] = pydantic.Field(None)
    EbsDeviceOptions: typing.Optional[dict[str, models.aws_autoscaling.EbsDeviceOptionsDef]] = pydantic.Field(None)
    EbsDeviceOptionsBase: typing.Optional[dict[str, models.aws_autoscaling.EbsDeviceOptionsBaseDef]] = pydantic.Field(None)
    EbsDeviceProps: typing.Optional[dict[str, models.aws_autoscaling.EbsDevicePropsDef]] = pydantic.Field(None)
    EbsDeviceSnapshotOptions: typing.Optional[dict[str, models.aws_autoscaling.EbsDeviceSnapshotOptionsDef]] = pydantic.Field(None)
    Ec2HealthCheckOptions: typing.Optional[dict[str, models.aws_autoscaling.Ec2HealthCheckOptionsDef]] = pydantic.Field(None)
    ElbHealthCheckOptions: typing.Optional[dict[str, models.aws_autoscaling.ElbHealthCheckOptionsDef]] = pydantic.Field(None)
    InstancesDistribution: typing.Optional[dict[str, models.aws_autoscaling.InstancesDistributionDef]] = pydantic.Field(None)
    LaunchTemplateOverrides: typing.Optional[dict[str, models.aws_autoscaling.LaunchTemplateOverridesDef]] = pydantic.Field(None)
    LifecycleHookProps: typing.Optional[dict[str, models.aws_autoscaling.LifecycleHookPropsDef]] = pydantic.Field(None)
    LifecycleHookTargetConfig: typing.Optional[dict[str, models.aws_autoscaling.LifecycleHookTargetConfigDef]] = pydantic.Field(None)
    MetricTargetTrackingProps: typing.Optional[dict[str, models.aws_autoscaling.MetricTargetTrackingPropsDef]] = pydantic.Field(None)
    MixedInstancesPolicy: typing.Optional[dict[str, models.aws_autoscaling.MixedInstancesPolicyDef]] = pydantic.Field(None)
    NetworkUtilizationScalingProps: typing.Optional[dict[str, models.aws_autoscaling.NetworkUtilizationScalingPropsDef]] = pydantic.Field(None)
    NotificationConfiguration: typing.Optional[dict[str, models.aws_autoscaling.NotificationConfigurationDef]] = pydantic.Field(None)
    RenderSignalsOptions: typing.Optional[dict[str, models.aws_autoscaling.RenderSignalsOptionsDef]] = pydantic.Field(None)
    RequestCountScalingProps: typing.Optional[dict[str, models.aws_autoscaling.RequestCountScalingPropsDef]] = pydantic.Field(None)
    RollingUpdateOptions: typing.Optional[dict[str, models.aws_autoscaling.RollingUpdateOptionsDef]] = pydantic.Field(None)
    ScalingInterval: typing.Optional[dict[str, models.aws_autoscaling.ScalingIntervalDef]] = pydantic.Field(None)
    ScheduledActionProps: typing.Optional[dict[str, models.aws_autoscaling.ScheduledActionPropsDef]] = pydantic.Field(None)
    SignalsOptions: typing.Optional[dict[str, models.aws_autoscaling.SignalsOptionsDef]] = pydantic.Field(None)
    StepScalingActionProps: typing.Optional[dict[str, models.aws_autoscaling.StepScalingActionPropsDef]] = pydantic.Field(None)
    StepScalingPolicyProps: typing.Optional[dict[str, models.aws_autoscaling.StepScalingPolicyPropsDef]] = pydantic.Field(None)
    TargetTrackingScalingPolicyProps: typing.Optional[dict[str, models.aws_autoscaling.TargetTrackingScalingPolicyPropsDef]] = pydantic.Field(None)
    WarmPoolOptions: typing.Optional[dict[str, models.aws_autoscaling.WarmPoolOptionsDef]] = pydantic.Field(None)
    WarmPoolProps: typing.Optional[dict[str, models.aws_autoscaling.WarmPoolPropsDef]] = pydantic.Field(None)
    CfnAutoScalingGroup: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroupDef]] = pydantic.Field(None)
    CfnLaunchConfiguration: typing.Optional[dict[str, models.aws_autoscaling.CfnLaunchConfigurationDef]] = pydantic.Field(None)
    CfnLifecycleHook: typing.Optional[dict[str, models.aws_autoscaling.CfnLifecycleHookDef]] = pydantic.Field(None)
    CfnScalingPolicy: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicyDef]] = pydantic.Field(None)
    CfnScheduledAction: typing.Optional[dict[str, models.aws_autoscaling.CfnScheduledActionDef]] = pydantic.Field(None)
    CfnWarmPool: typing.Optional[dict[str, models.aws_autoscaling.CfnWarmPoolDef]] = pydantic.Field(None)
    CfnAutoScalingGroupProps: typing.Optional[dict[str, models.aws_autoscaling.CfnAutoScalingGroupPropsDef]] = pydantic.Field(None)
    CfnLaunchConfigurationProps: typing.Optional[dict[str, models.aws_autoscaling.CfnLaunchConfigurationPropsDef]] = pydantic.Field(None)
    CfnLifecycleHookProps: typing.Optional[dict[str, models.aws_autoscaling.CfnLifecycleHookPropsDef]] = pydantic.Field(None)
    CfnScalingPolicyProps: typing.Optional[dict[str, models.aws_autoscaling.CfnScalingPolicyPropsDef]] = pydantic.Field(None)
    CfnScheduledActionProps: typing.Optional[dict[str, models.aws_autoscaling.CfnScheduledActionPropsDef]] = pydantic.Field(None)
    CfnWarmPoolProps: typing.Optional[dict[str, models.aws_autoscaling.CfnWarmPoolPropsDef]] = pydantic.Field(None)
    ...

import models
