from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams

#  autogenerated from aws_cdk.aws_stepfunctions.Chain
class ChainDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['next']
    _classmethod_names: typing.ClassVar[list[str]] = ['custom', 'sequence', 'start']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Chain'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[ChainDefConfig] = pydantic.Field(None)


class ChainDefConfig(pydantic.BaseModel):
    custom: typing.Optional[list[ChainDefCustomParams]] = pydantic.Field(None, description='Make a Chain with specific start and end states, and a last-added Chainable.')
    next: typing.Optional[list[ChainDefNextParams]] = pydantic.Field(None, description='Continue normal execution with the given state.')
    sequence: typing.Optional[list[ChainDefSequenceParams]] = pydantic.Field(None, description='Make a Chain with the start from one chain and the ends from another.')
    start: typing.Optional[list[ChainDefStartParams]] = pydantic.Field(None, description='Begin a new Chain from one chainable.')
    start_state_config: typing.Optional[models.aws_stepfunctions.StateDefConfig] = pydantic.Field(None)

class ChainDefCustomParams(pydantic.BaseModel):
    start_state: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    end_states: typing.Sequence[typing.Union[models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef]] = pydantic.Field(..., description='-\n')
    last_added: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...

class ChainDefNextParams(pydantic.BaseModel):
    next: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...

class ChainDefSequenceParams(pydantic.BaseModel):
    start: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-\n')
    next: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...

class ChainDefStartParams(pydantic.BaseModel):
    state: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Condition
class ConditionDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['render_condition']
    _classmethod_names: typing.ClassVar[list[str]] = ['and_', 'boolean_equals', 'boolean_equals_json_path', 'not_', 'number_equals', 'number_equals_json_path', 'number_greater_than', 'number_greater_than_equals', 'number_greater_than_equals_json_path', 'number_greater_than_json_path', 'number_less_than', 'number_less_than_equals', 'number_less_than_equals_json_path', 'number_less_than_json_path', 'or_', 'string_equals', 'string_equals_json_path', 'string_greater_than', 'string_greater_than_equals', 'string_greater_than_equals_json_path', 'string_greater_than_json_path', 'string_less_than', 'string_less_than_equals', 'string_less_than_equals_json_path', 'string_less_than_json_path', 'string_matches', 'timestamp_equals', 'timestamp_equals_json_path', 'timestamp_greater_than', 'timestamp_greater_than_equals', 'timestamp_greater_than_equals_json_path', 'timestamp_greater_than_json_path', 'timestamp_less_than', 'timestamp_less_than_equals', 'timestamp_less_than_equals_json_path', 'timestamp_less_than_json_path']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Condition'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[ConditionDefConfig] = pydantic.Field(None)


class ConditionDefConfig(pydantic.BaseModel):
    and_: typing.Optional[list[ConditionDefAndParams]] = pydantic.Field(None, description='Combine two or more conditions with a logical AND.')
    boolean_equals: typing.Optional[list[ConditionDefBooleanEqualsParams]] = pydantic.Field(None, description='Matches if a boolean field has the given value.')
    boolean_equals_json_path: typing.Optional[list[ConditionDefBooleanEqualsJsonPathParams]] = pydantic.Field(None, description='Matches if a boolean field equals to a value at a given mapping path.')
    not_: typing.Optional[list[ConditionDefNotParams]] = pydantic.Field(None, description='Negate a condition.')
    number_equals: typing.Optional[list[ConditionDefNumberEqualsParams]] = pydantic.Field(None, description='Matches if a numeric field has the given value.')
    number_equals_json_path: typing.Optional[list[ConditionDefNumberEqualsJsonPathParams]] = pydantic.Field(None, description='Matches if a numeric field has the value in a given mapping path.')
    number_greater_than: typing.Optional[list[ConditionDefNumberGreaterThanParams]] = pydantic.Field(None, description='Matches if a numeric field is greater than the given value.')
    number_greater_than_equals: typing.Optional[list[ConditionDefNumberGreaterThanEqualsParams]] = pydantic.Field(None, description='Matches if a numeric field is greater than or equal to the given value.')
    number_greater_than_equals_json_path: typing.Optional[list[ConditionDefNumberGreaterThanEqualsJsonPathParams]] = pydantic.Field(None, description='Matches if a numeric field is greater than or equal to the value at a given mapping path.')
    number_greater_than_json_path: typing.Optional[list[ConditionDefNumberGreaterThanJsonPathParams]] = pydantic.Field(None, description='Matches if a numeric field is greater than the value at a given mapping path.')
    number_less_than: typing.Optional[list[ConditionDefNumberLessThanParams]] = pydantic.Field(None, description='Matches if a numeric field is less than the given value.')
    number_less_than_equals: typing.Optional[list[ConditionDefNumberLessThanEqualsParams]] = pydantic.Field(None, description='Matches if a numeric field is less than or equal to the given value.')
    number_less_than_equals_json_path: typing.Optional[list[ConditionDefNumberLessThanEqualsJsonPathParams]] = pydantic.Field(None, description='Matches if a numeric field is less than or equal to the numeric value at given mapping path.')
    number_less_than_json_path: typing.Optional[list[ConditionDefNumberLessThanJsonPathParams]] = pydantic.Field(None, description='Matches if a numeric field is less than the value at the given mapping path.')
    or_: typing.Optional[list[ConditionDefOrParams]] = pydantic.Field(None, description='Combine two or more conditions with a logical OR.')
    render_condition: typing.Optional[bool] = pydantic.Field(None, description='Render Amazon States Language JSON for the condition.')
    string_equals: typing.Optional[list[ConditionDefStringEqualsParams]] = pydantic.Field(None, description='Matches if a string field has the given value.')
    string_equals_json_path: typing.Optional[list[ConditionDefStringEqualsJsonPathParams]] = pydantic.Field(None, description='Matches if a string field equals to a value at a given mapping path.')
    string_greater_than: typing.Optional[list[ConditionDefStringGreaterThanParams]] = pydantic.Field(None, description='Matches if a string field sorts after a given value.')
    string_greater_than_equals: typing.Optional[list[ConditionDefStringGreaterThanEqualsParams]] = pydantic.Field(None, description='Matches if a string field sorts after or equal to a given value.')
    string_greater_than_equals_json_path: typing.Optional[list[ConditionDefStringGreaterThanEqualsJsonPathParams]] = pydantic.Field(None, description='Matches if a string field sorts after or equal to value at a given mapping path.')
    string_greater_than_json_path: typing.Optional[list[ConditionDefStringGreaterThanJsonPathParams]] = pydantic.Field(None, description='Matches if a string field sorts after a value at a given mapping path.')
    string_less_than: typing.Optional[list[ConditionDefStringLessThanParams]] = pydantic.Field(None, description='Matches if a string field sorts before a given value.')
    string_less_than_equals: typing.Optional[list[ConditionDefStringLessThanEqualsParams]] = pydantic.Field(None, description='Matches if a string field sorts equal to or before a given value.')
    string_less_than_equals_json_path: typing.Optional[list[ConditionDefStringLessThanEqualsJsonPathParams]] = pydantic.Field(None, description='Matches if a string field sorts equal to or before a given mapping.')
    string_less_than_json_path: typing.Optional[list[ConditionDefStringLessThanJsonPathParams]] = pydantic.Field(None, description='Matches if a string field sorts before a given value at a particular mapping.')
    string_matches: typing.Optional[list[ConditionDefStringMatchesParams]] = pydantic.Field(None, description='Matches if a field matches a string pattern that can contain a wild card (*) e.g: log-*.txt or *LATEST*. No other characters other than "*" have any special meaning - * can be escaped: \\*.')
    timestamp_equals: typing.Optional[list[ConditionDefTimestampEqualsParams]] = pydantic.Field(None, description='Matches if a timestamp field is the same time as the given timestamp.')
    timestamp_equals_json_path: typing.Optional[list[ConditionDefTimestampEqualsJsonPathParams]] = pydantic.Field(None, description='Matches if a timestamp field is the same time as the timestamp at a given mapping path.')
    timestamp_greater_than: typing.Optional[list[ConditionDefTimestampGreaterThanParams]] = pydantic.Field(None, description='Matches if a timestamp field is after the given timestamp.')
    timestamp_greater_than_equals: typing.Optional[list[ConditionDefTimestampGreaterThanEqualsParams]] = pydantic.Field(None, description='Matches if a timestamp field is after or equal to the given timestamp.')
    timestamp_greater_than_equals_json_path: typing.Optional[list[ConditionDefTimestampGreaterThanEqualsJsonPathParams]] = pydantic.Field(None, description='Matches if a timestamp field is after or equal to the timestamp at a given mapping path.')
    timestamp_greater_than_json_path: typing.Optional[list[ConditionDefTimestampGreaterThanJsonPathParams]] = pydantic.Field(None, description='Matches if a timestamp field is after the timestamp at a given mapping path.')
    timestamp_less_than: typing.Optional[list[ConditionDefTimestampLessThanParams]] = pydantic.Field(None, description='Matches if a timestamp field is before the given timestamp.')
    timestamp_less_than_equals: typing.Optional[list[ConditionDefTimestampLessThanEqualsParams]] = pydantic.Field(None, description='Matches if a timestamp field is before or equal to the given timestamp.')
    timestamp_less_than_equals_json_path: typing.Optional[list[ConditionDefTimestampLessThanEqualsJsonPathParams]] = pydantic.Field(None, description='Matches if a timestamp field is before or equal to the timestamp at a given mapping path.')
    timestamp_less_than_json_path: typing.Optional[list[ConditionDefTimestampLessThanJsonPathParams]] = pydantic.Field(None, description='Matches if a timestamp field is before the timestamp at a given mapping path.')

class ConditionDefAndParams(pydantic.BaseModel):
    conditions: list[models.aws_stepfunctions.ConditionDef] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefBooleanEqualsParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: bool = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefBooleanEqualsJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefNotParams(pydantic.BaseModel):
    condition: models.aws_stepfunctions.ConditionDef = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefNumberEqualsParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: typing.Union[int, float] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefNumberEqualsJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefNumberGreaterThanParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: typing.Union[int, float] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefNumberGreaterThanEqualsParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: typing.Union[int, float] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefNumberGreaterThanEqualsJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefNumberGreaterThanJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefNumberLessThanParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: typing.Union[int, float] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefNumberLessThanEqualsParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: typing.Union[int, float] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefNumberLessThanEqualsJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefNumberLessThanJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefOrParams(pydantic.BaseModel):
    conditions: list[models.aws_stepfunctions.ConditionDef] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefStringEqualsParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefStringEqualsJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefStringGreaterThanParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefStringGreaterThanEqualsParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefStringGreaterThanEqualsJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefStringGreaterThanJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefStringLessThanParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefStringLessThanEqualsParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefStringLessThanEqualsJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefStringLessThanJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefStringMatchesParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefTimestampEqualsParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefTimestampEqualsJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefTimestampGreaterThanParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefTimestampGreaterThanEqualsParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefTimestampGreaterThanEqualsJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefTimestampGreaterThanJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefTimestampLessThanParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefTimestampLessThanEqualsParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefTimestampLessThanEqualsJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...

class ConditionDefTimestampLessThanJsonPathParams(pydantic.BaseModel):
    variable: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ConditionDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Errors
class ErrorsDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Errors'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.FieldUtils
class FieldUtilsDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['contains_task_token', 'find_referenced_paths', 'render_object']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.FieldUtils'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[FieldUtilsDefConfig] = pydantic.Field(None)


class FieldUtilsDefConfig(pydantic.BaseModel):
    contains_task_token: typing.Optional[list[FieldUtilsDefContainsTaskTokenParams]] = pydantic.Field(None, description='Returns whether the given task structure contains the TaskToken field anywhere.\nThe field is considered included if the field itself or one of its containing\nfields occurs anywhere in the payload.')
    find_referenced_paths: typing.Optional[list[FieldUtilsDefFindReferencedPathsParams]] = pydantic.Field(None, description='Return all JSON paths used in the given structure.')
    render_object: typing.Optional[list[FieldUtilsDefRenderObjectParams]] = pydantic.Field(None, description='Render a JSON structure containing fields to the right StepFunctions structure.')

class FieldUtilsDefContainsTaskTokenParams(pydantic.BaseModel):
    obj: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='-')
    ...

class FieldUtilsDefFindReferencedPathsParams(pydantic.BaseModel):
    obj: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='-')
    ...

class FieldUtilsDefRenderObjectParams(pydantic.BaseModel):
    obj: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.JsonPath
class JsonPathDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['array', 'array_contains', 'array_get_item', 'array_length', 'array_partition', 'array_range', 'array_unique', 'base64_decode', 'base64_encode', 'format', 'hash', 'json_merge', 'json_to_string', 'list_at', 'math_add', 'math_random', 'number_at', 'object_at', 'string_at', 'string_split', 'string_to_json', 'uuid']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.JsonPath'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['object_at', 'string_to_json']
    ...


    object_at: typing.Optional[JsonPathDefObjectAtParams] = pydantic.Field(None, description='Reference a complete (complex) object in a JSON path location.')
    string_to_json: typing.Optional[JsonPathDefStringToJsonParams] = pydantic.Field(None, description='Make an intrinsic States.StringToJson expression.\nDuring the execution of the Step Functions state machine, parse the given\nargument as JSON into its object form.\n\nFor example::\n\n   sfn.JsonPath.string_to_json(sfn.JsonPath.string_at("$.someJsonBody"))')
    resource_config: typing.Optional[JsonPathDefConfig] = pydantic.Field(None)


class JsonPathDefConfig(pydantic.BaseModel):
    array: typing.Optional[list[JsonPathDefArrayParams]] = pydantic.Field(None, description='Make an intrinsic States.Array expression.\nCombine any number of string literals or JsonPath expressions into an array.\n\nUse this function if the value of an array element directly has to come\nfrom a JSON Path expression (either the State object or the Context object).\n\nIf the array contains object literals whose values come from a JSON path\nexpression, you do not need to use this function.')
    array_contains: typing.Optional[list[JsonPathDefArrayContainsParams]] = pydantic.Field(None, description='Make an intrinsic States.ArrayContains expression.\nUse this function to determine if a specific value is present in an array. For example, you can use this function to detect if there was an error in a Map state iteration.')
    array_get_item: typing.Optional[list[JsonPathDefArrayGetItemParams]] = pydantic.Field(None, description="Make an intrinsic States.ArrayGetItem expression.\nUse this function to get a specified index's value in an array.")
    array_length: typing.Optional[list[JsonPathDefArrayLengthParams]] = pydantic.Field(None, description='Make an intrinsic States.ArrayLength expression.\nUse this function to get the length of an array.')
    array_partition: typing.Optional[list[JsonPathDefArrayPartitionParams]] = pydantic.Field(None, description='Make an intrinsic States.ArrayPartition expression.\nUse this function to partition a large array. You can also use this intrinsic to slice the data and then send the payload in smaller chunks.')
    array_range: typing.Optional[list[JsonPathDefArrayRangeParams]] = pydantic.Field(None, description='Make an intrinsic States.ArrayRange expression.\nUse this function to create a new array containing a specific range of elements. The new array can contain up to 1000 elements.')
    array_unique: typing.Optional[list[JsonPathDefArrayUniqueParams]] = pydantic.Field(None, description='Make an intrinsic States.ArrayUnique expression.\nUse this function to get the length of an array.\nUse this function to remove duplicate values from an array and returns an array containing only unique elements. This function takes an array, which can be unsorted, as its sole argument.')
    base64_decode: typing.Optional[list[JsonPathDefBase64DecodeParams]] = pydantic.Field(None, description='Make an intrinsic States.Base64Decode expression.\nUse this function to decode data based on MIME Base64 decoding scheme. You can use this function to pass data to other AWS services without using a Lambda function.')
    base64_encode: typing.Optional[list[JsonPathDefBase64EncodeParams]] = pydantic.Field(None, description='Make an intrinsic States.Base64Encode expression.\nUse this function to encode data based on MIME Base64 encoding scheme. You can use this function to pass data to other AWS services without using an AWS Lambda function.')
    format: typing.Optional[list[JsonPathDefFormatParams]] = pydantic.Field(None, description='Make an intrinsic States.Format expression.\nThis can be used to embed JSON Path variables inside a format string.\n\nFor example::\n\n   sfn.JsonPath.format("Hello, my name is {}.", sfn.JsonPath.string_at("$.name"))')
    hash: typing.Optional[list[JsonPathDefHashParams]] = pydantic.Field(None, description='Make an intrinsic States.Hash expression.\nUse this function to calculate the hash value of a given input. You can use this function to pass data to other AWS services without using a Lambda function.')
    json_merge: typing.Optional[list[JsonPathDefJsonMergeParams]] = pydantic.Field(None, description='Make an intrinsic States.JsonMerge expression.\nUse this function to merge two JSON objects into a single object.')
    json_to_string: typing.Optional[list[JsonPathDefJsonToStringParams]] = pydantic.Field(None, description='Make an intrinsic States.JsonToString expression.\nDuring the execution of the Step Functions state machine, encode the\ngiven object into a JSON string.\n\nFor example::\n\n   sfn.JsonPath.json_to_string(sfn.JsonPath.object_at("$.someObject"))')
    list_at: typing.Optional[list[JsonPathDefListAtParams]] = pydantic.Field(None, description='Instead of using a literal string list, get the value from a JSON path.')
    math_add: typing.Optional[list[JsonPathDefMathAddParams]] = pydantic.Field(None, description='Make an intrinsic States.MathAdd expression.\nUse this function to return the sum of two numbers. For example, you can use this function to increment values inside a loop without invoking a Lambda function.')
    math_random: typing.Optional[list[JsonPathDefMathRandomParams]] = pydantic.Field(None, description='Make an intrinsic States.MathRandom expression.\nUse this function to return a random number between the specified start and end number. For example, you can use this function to distribute a specific task between two or more resources.')
    number_at: typing.Optional[list[JsonPathDefNumberAtParams]] = pydantic.Field(None, description='Instead of using a literal number, get the value from a JSON path.')
    string_at: typing.Optional[list[JsonPathDefStringAtParams]] = pydantic.Field(None, description='Instead of using a literal string, get the value from a JSON path.')
    string_split: typing.Optional[list[JsonPathDefStringSplitParams]] = pydantic.Field(None, description='Make an intrinsic States.StringSplit expression.\nUse this function to split a string into an array of values. This function takes two arguments.The first argument is a string and the second argument is the delimiting character that the function will use to divide the string.')
    uuid: typing.Optional[bool] = pydantic.Field(None, description='Make an intrinsic States.UUID expression.\nUse this function to return a version 4 universally unique identifier (v4 UUID) generated using random numbers. For example, you can use this function to call other AWS services or resources that need a UUID parameter or insert items in a DynamoDB table.\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html')

class JsonPathDefArrayParams(pydantic.BaseModel):
    values: list[str] = pydantic.Field(...)
    ...

class JsonPathDefArrayContainsParams(pydantic.BaseModel):
    array: typing.Any = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefArrayGetItemParams(pydantic.BaseModel):
    array: typing.Any = pydantic.Field(..., description='-\n')
    index: typing.Union[int, float] = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefArrayLengthParams(pydantic.BaseModel):
    array: typing.Any = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefArrayPartitionParams(pydantic.BaseModel):
    array: typing.Any = pydantic.Field(..., description='-\n')
    chunk_size: typing.Union[int, float] = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefArrayRangeParams(pydantic.BaseModel):
    start: typing.Union[int, float] = pydantic.Field(..., description='-\n')
    end: typing.Union[int, float] = pydantic.Field(..., description='-\n')
    step: typing.Union[int, float] = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefArrayUniqueParams(pydantic.BaseModel):
    array: typing.Any = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefBase64DecodeParams(pydantic.BaseModel):
    base64: str = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefBase64EncodeParams(pydantic.BaseModel):
    input: str = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefFormatParams(pydantic.BaseModel):
    format_string: str = pydantic.Field(..., description='-\n')
    values: list[str] = pydantic.Field(...)
    ...

class JsonPathDefHashParams(pydantic.BaseModel):
    data: typing.Any = pydantic.Field(..., description='-\n')
    algorithm: str = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefJsonMergeParams(pydantic.BaseModel):
    value1: typing.Any = pydantic.Field(..., description='-\n')
    value2: typing.Any = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefJsonToStringParams(pydantic.BaseModel):
    value: typing.Any = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefListAtParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='-')
    ...

class JsonPathDefMathAddParams(pydantic.BaseModel):
    num1: typing.Union[int, float] = pydantic.Field(..., description='-\n')
    num2: typing.Union[int, float] = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefMathRandomParams(pydantic.BaseModel):
    start: typing.Union[int, float] = pydantic.Field(..., description='-\n')
    end: typing.Union[int, float] = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefNumberAtParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='-')
    ...

class JsonPathDefObjectAtParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='-')
    ...

class JsonPathDefStringAtParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='-')
    ...

class JsonPathDefStringSplitParams(pydantic.BaseModel):
    input_string: str = pydantic.Field(..., description='-\n')
    splitter: str = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...

class JsonPathDefStringToJsonParams(pydantic.BaseModel):
    json_string: str = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-intrinsic-functions.html\n')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Result
class ResultDef(BaseClass):
    value: typing.Any = pydantic.Field(..., description='result of the Pass operation.')
    _init_params: typing.ClassVar[list[str]] = ['value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['from_array', 'from_boolean', 'from_number', 'from_object', 'from_string']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Result'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_array', 'from_boolean', 'from_number', 'from_object', 'from_string']
    ...


    from_array: typing.Optional[ResultDefFromArrayParams] = pydantic.Field(None, description='The result of the operation is an array.')
    from_boolean: typing.Optional[ResultDefFromBooleanParams] = pydantic.Field(None, description='The result of the operation is a boolean.')
    from_number: typing.Optional[ResultDefFromNumberParams] = pydantic.Field(None, description='The result of the operation is a number.')
    from_object: typing.Optional[ResultDefFromObjectParams] = pydantic.Field(None, description='The result of the operation is an object.')
    from_string: typing.Optional[ResultDefFromStringParams] = pydantic.Field(None, description='The result of the operation is a string.')

class ResultDefFromArrayParams(pydantic.BaseModel):
    value: typing.Sequence[typing.Any] = pydantic.Field(..., description='-')
    ...

class ResultDefFromBooleanParams(pydantic.BaseModel):
    value: bool = pydantic.Field(..., description='-')
    ...

class ResultDefFromNumberParams(pydantic.BaseModel):
    value: typing.Union[int, float] = pydantic.Field(..., description='-')
    ...

class ResultDefFromObjectParams(pydantic.BaseModel):
    value: typing.Mapping[str, typing.Any] = pydantic.Field(..., description='-')
    ...

class ResultDefFromStringParams(pydantic.BaseModel):
    value: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.State
class StateDef(BaseClass):
    comment: typing.Optional[str] = pydantic.Field(None, description='A comment describing this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $\n')
    parameters: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Parameters pass a collection of key-value pairs, either static values or JSONPath expressions that select from the input. Default: No parameters\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to indicate where to inject the state's output. May also be the special value JsonPath.DISCARD, which will cause the state's input to become its output. Default: $\n")
    result_selector: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description="The JSON that will replace the state's raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state's raw result. Default: - None")
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'output_path', 'parameters', 'result_path', 'result_selector']
    _method_names: typing.ClassVar[list[str]] = ['add_prefix', 'bind_to_graph']
    _classmethod_names: typing.ClassVar[list[str]] = ['filter_nextables', 'find_reachable_end_states', 'find_reachable_states', 'prefix_states']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.State'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[StateDefConfig] = pydantic.Field(None)


class StateDefConfig(pydantic.BaseModel):
    add_prefix: typing.Optional[list[StateDefAddPrefixParams]] = pydantic.Field(None, description='Add a prefix to the stateId of this state.')
    bind_to_graph: typing.Optional[list[StateDefBindToGraphParams]] = pydantic.Field(None, description="Register this state as part of the given graph.\nDon't call this. It will be called automatically when you work\nwith states normally.")
    filter_nextables: typing.Optional[list[StateDefFilterNextablesParams]] = pydantic.Field(None, description='Return only the states that allow chaining from an array of states.')
    find_reachable_end_states: typing.Optional[list[StateDefFindReachableEndStatesParams]] = pydantic.Field(None, description='Find the set of end states states reachable through transitions from the given start state.')
    find_reachable_states: typing.Optional[list[StateDefFindReachableStatesParams]] = pydantic.Field(None, description="Find the set of states reachable through transitions from the given start state.\nThis does not retrieve states from within sub-graphs, such as states within a Parallel state's branch.")
    prefix_states: typing.Optional[list[StateDefPrefixStatesParams]] = pydantic.Field(None, description='Add a prefix to the stateId of all States found in a construct tree.')

class StateDefAddPrefixParams(pydantic.BaseModel):
    x: str = pydantic.Field(..., description='-')
    ...

class StateDefBindToGraphParams(pydantic.BaseModel):
    graph: models.aws_stepfunctions.StateGraphDef = pydantic.Field(..., description='-')
    ...

class StateDefFilterNextablesParams(pydantic.BaseModel):
    states: typing.Sequence[models.aws_stepfunctions.StateDef] = pydantic.Field(..., description='-')
    ...

class StateDefFindReachableEndStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class StateDefFindReachableStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class StateDefPrefixStatesParams(pydantic.BaseModel):
    root: models.AnyResource = pydantic.Field(..., description='-\n')
    prefix: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.StateGraph
class StateGraphDef(BaseClass):
    start_state: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='state that gets executed when the state machine is launched.')
    graph_description: str = pydantic.Field(..., description='description of the state machine.')
    _init_params: typing.ClassVar[list[str]] = ['start_state', 'graph_description']
    _method_names: typing.ClassVar[list[str]] = ['register_policy_statement', 'register_state', 'register_super_graph']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.StateGraph'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[StateGraphDefConfig] = pydantic.Field(None)


class StateGraphDefConfig(pydantic.BaseModel):
    register_policy_statement: typing.Optional[list[StateGraphDefRegisterPolicyStatementParams]] = pydantic.Field(None, description='Register a Policy Statement used by states in this graph.')
    register_state: typing.Optional[list[StateGraphDefRegisterStateParams]] = pydantic.Field(None, description='Register a state as part of this graph.\nCalled by State.bindToGraph().')
    register_super_graph: typing.Optional[list[StateGraphDefRegisterSuperGraphParams]] = pydantic.Field(None, description='Register this graph as a child of the given graph.\nResource changes will be bubbled up to the given graph.')
    start_state_config: typing.Optional[models.aws_stepfunctions.StateDefConfig] = pydantic.Field(None)

class StateGraphDefRegisterPolicyStatementParams(pydantic.BaseModel):
    statement: models.aws_iam.PolicyStatementDef = pydantic.Field(..., description='-')
    ...

class StateGraphDefRegisterStateParams(pydantic.BaseModel):
    state: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-')
    ...

class StateGraphDefRegisterSuperGraphParams(pydantic.BaseModel):
    graph: models.aws_stepfunctions.StateGraphDef = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.StateMachineFragment
class StateMachineFragmentDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['next', 'prefix_states']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.StateMachineFragment'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[StateMachineFragmentDefConfig] = pydantic.Field(None)


class StateMachineFragmentDefConfig(pydantic.BaseModel):
    next: typing.Optional[list[StateMachineFragmentDefNextParams]] = pydantic.Field(None, description='Continue normal execution with the given state.')
    prefix_states: typing.Optional[list[StateMachineFragmentDefPrefixStatesParams]] = pydantic.Field(None, description='Prefix the IDs of all states in this state machine fragment.\nUse this to avoid multiple copies of the state machine all having the\nsame state IDs.')
    start_state_config: typing.Optional[models.aws_stepfunctions.StateDefConfig] = pydantic.Field(None)

class StateMachineFragmentDefNextParams(pydantic.BaseModel):
    next: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...

class StateMachineFragmentDefPrefixStatesParams(pydantic.BaseModel):
    prefix: typing.Optional[str] = pydantic.Field(None, description='The prefix to add. Will use construct ID by default.')
    return_config: typing.Optional[list[models.aws_stepfunctions.StateMachineFragmentDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.StateTransitionMetric
class StateTransitionMetricDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['metric', 'metric_consumed_capacity', 'metric_provisioned_bucket_size', 'metric_provisioned_refill_rate', 'metric_throttled_events']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.StateTransitionMetric'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['metric', 'metric_consumed_capacity', 'metric_provisioned_bucket_size', 'metric_provisioned_refill_rate', 'metric_throttled_events']
    ...


    metric: typing.Optional[StateTransitionMetricDefMetricParams] = pydantic.Field(None, description="Return the given named metric for the service's state transition metrics.")
    metric_consumed_capacity: typing.Optional[StateTransitionMetricDefMetricConsumedCapacityParams] = pydantic.Field(None, description='Metric for the number of available state transitions per second.')
    metric_provisioned_bucket_size: typing.Optional[StateTransitionMetricDefMetricProvisionedBucketSizeParams] = pydantic.Field(None, description='Metric for the number of available state transitions.')
    metric_provisioned_refill_rate: typing.Optional[StateTransitionMetricDefMetricProvisionedRefillRateParams] = pydantic.Field(None, description='Metric for the provisioned steady-state execution rate.')
    metric_throttled_events: typing.Optional[StateTransitionMetricDefMetricThrottledEventsParams] = pydantic.Field(None, description='Metric for the number of throttled state transitions.')

class StateTransitionMetricDefMetricParams(pydantic.BaseModel):
    metric_name: str = pydantic.Field(..., description='-\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: average over 5 minutes\n')
    ...

class StateTransitionMetricDefMetricConsumedCapacityParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: average over 5 minutes\n')
    ...

class StateTransitionMetricDefMetricProvisionedBucketSizeParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: average over 5 minutes\n')
    ...

class StateTransitionMetricDefMetricProvisionedRefillRateParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: average over 5 minutes\n')
    ...

class StateTransitionMetricDefMetricThrottledEventsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: sum over 5 minutes\n')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.TaskInput
class TaskInputDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['from_json_path_at', 'from_object', 'from_text']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.TaskInput'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_json_path_at', 'from_object', 'from_text']
    ...


    from_json_path_at: typing.Optional[TaskInputDefFromJsonPathAtParams] = pydantic.Field(None, description='Use a part of the execution data or task context as task input.\nUse this when you want to use a subobject or string from\nthe current state machine execution or the current task context\nas complete payload to a task.')
    from_object: typing.Optional[TaskInputDefFromObjectParams] = pydantic.Field(None, description='Use an object as task input.\nThis object may contain JSON path fields as object values, if desired.')
    from_text: typing.Optional[TaskInputDefFromTextParams] = pydantic.Field(None, description='Use a literal string as task input.\nThis might be a JSON-encoded object, or just a text.')

class TaskInputDefFromJsonPathAtParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='-')
    ...

class TaskInputDefFromObjectParams(pydantic.BaseModel):
    obj: typing.Mapping[str, typing.Any] = pydantic.Field(..., description='-')
    ...

class TaskInputDefFromTextParams(pydantic.BaseModel):
    text: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.TaskRole
class TaskRoleDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['from_role', 'from_role_arn_json_path']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.TaskRole'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_role', 'from_role_arn_json_path']
    ...


    from_role: typing.Optional[TaskRoleDefFromRoleParams] = pydantic.Field(None, description='Construct a task role based on the provided IAM Role.')
    from_role_arn_json_path: typing.Optional[TaskRoleDefFromRoleArnJsonPathParams] = pydantic.Field(None, description='Construct a task role retrieved from task inputs using a json expression.')

class TaskRoleDefFromRoleParams(pydantic.BaseModel):
    role: typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef] = pydantic.Field(..., description='IAM Role.')
    ...

class TaskRoleDefFromRoleArnJsonPathParams(pydantic.BaseModel):
    expression: str = pydantic.Field(..., description='json expression to roleArn.\n\nExample::\n\n    sfn.TaskRole.from_role_arn_json_path("$.RoleArn")\n')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.TaskStateBase
class TaskStateBaseDef(BaseClass):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: - No comment\n')
    credentials: typing.Union[models.aws_stepfunctions.CredentialsDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Credentials for an IAM Role that the State Machine assumes for executing the task. This enables cross-account resource invocations. Default: - None (Task is executed using the State Machine's execution role)\n")
    heartbeat: typing.Optional[models.DurationDef] = pydantic.Field(None, description='(deprecated) Timeout for the heartbeat. Default: - None\n')
    heartbeat_timeout: typing.Optional[models.aws_stepfunctions.TimeoutDef] = pydantic.Field(None, description='Timeout for the heartbeat. [disable-awslint:duration-prop-type] is needed because all props interface in aws-stepfunctions-tasks extend this interface Default: - None\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: - The entire task input (JSON path '$')\n")
    integration_pattern: typing.Optional[aws_cdk.aws_stepfunctions.IntegrationPattern] = pydantic.Field(None, description='AWS Step Functions integrates with services directly in the Amazon States Language. You can control these AWS services using service integration patterns Default: - ``IntegrationPattern.REQUEST_RESPONSE`` for most tasks. ``IntegrationPattern.RUN_JOB`` for the following exceptions: ``BatchSubmitJob``, ``EmrAddStep``, ``EmrCreateCluster``, ``EmrTerminationCluster``, and ``EmrContainersStartJobRun``.\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to select select a portion of the state output to pass to the next state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: - The entire JSON node determined by the state input, the task result, and resultPath is passed to the next state (JSON path '$')\n")
    result_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to indicate where to inject the state's output. May also be the special value JsonPath.DISCARD, which will cause the state's input to become its output. Default: - Replaces the entire input with the result (JSON path '$')\n")
    result_selector: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description="The JSON that will replace the state's raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state's raw result. Default: - None\n")
    task_timeout: typing.Optional[models.aws_stepfunctions.TimeoutDef] = pydantic.Field(None, description='Timeout for the task. [disable-awslint:duration-prop-type] is needed because all props interface in aws-stepfunctions-tasks extend this interface Default: - None\n')
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='(deprecated) Timeout for the task. Default: - None')
    _init_params: typing.ClassVar[list[str]] = ['comment', 'credentials', 'heartbeat', 'heartbeat_timeout', 'input_path', 'integration_pattern', 'output_path', 'result_path', 'result_selector', 'task_timeout', 'timeout']
    _method_names: typing.ClassVar[list[str]] = ['add_catch', 'add_prefix', 'add_retry', 'bind_to_graph', 'metric', 'metric_failed', 'metric_heartbeat_timed_out', 'metric_run_time', 'metric_schedule_time', 'metric_scheduled', 'metric_started', 'metric_succeeded', 'metric_time', 'metric_timed_out', 'next']
    _classmethod_names: typing.ClassVar[list[str]] = ['filter_nextables', 'find_reachable_end_states', 'find_reachable_states', 'prefix_states']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.TaskStateBase'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[TaskStateBaseDefConfig] = pydantic.Field(None)


class TaskStateBaseDefConfig(pydantic.BaseModel):
    add_catch: typing.Optional[list[TaskStateBaseDefAddCatchParams]] = pydantic.Field(None, description='Add a recovery handler for this state.\nWhen a particular error occurs, execution will continue at the error\nhandler instead of failing the state machine execution.')
    add_prefix: typing.Optional[list[TaskStateBaseDefAddPrefixParams]] = pydantic.Field(None, description='Add a prefix to the stateId of this state.')
    add_retry: typing.Optional[list[TaskStateBaseDefAddRetryParams]] = pydantic.Field(None, description='Add retry configuration for this state.\nThis controls if and how the execution will be retried if a particular\nerror occurs.')
    bind_to_graph: typing.Optional[list[TaskStateBaseDefBindToGraphParams]] = pydantic.Field(None, description="Register this state as part of the given graph.\nDon't call this. It will be called automatically when you work\nwith states normally.")
    filter_nextables: typing.Optional[list[TaskStateBaseDefFilterNextablesParams]] = pydantic.Field(None, description='Return only the states that allow chaining from an array of states.')
    find_reachable_end_states: typing.Optional[list[TaskStateBaseDefFindReachableEndStatesParams]] = pydantic.Field(None, description='Find the set of end states states reachable through transitions from the given start state.')
    find_reachable_states: typing.Optional[list[TaskStateBaseDefFindReachableStatesParams]] = pydantic.Field(None, description="Find the set of states reachable through transitions from the given start state.\nThis does not retrieve states from within sub-graphs, such as states within a Parallel state's branch.")
    metric: typing.Optional[list[TaskStateBaseDefMetricParams]] = pydantic.Field(None, description='Return the given named metric for this Task.')
    metric_failed: typing.Optional[list[TaskStateBaseDefMetricFailedParams]] = pydantic.Field(None, description='Metric for the number of times this activity fails.')
    metric_heartbeat_timed_out: typing.Optional[list[TaskStateBaseDefMetricHeartbeatTimedOutParams]] = pydantic.Field(None, description='Metric for the number of times the heartbeat times out for this activity.')
    metric_run_time: typing.Optional[list[TaskStateBaseDefMetricRunTimeParams]] = pydantic.Field(None, description='The interval, in milliseconds, between the time the Task starts and the time it closes.')
    metric_schedule_time: typing.Optional[list[TaskStateBaseDefMetricScheduleTimeParams]] = pydantic.Field(None, description='The interval, in milliseconds, for which the activity stays in the schedule state.')
    metric_scheduled: typing.Optional[list[TaskStateBaseDefMetricScheduledParams]] = pydantic.Field(None, description='Metric for the number of times this activity is scheduled.')
    metric_started: typing.Optional[list[TaskStateBaseDefMetricStartedParams]] = pydantic.Field(None, description='Metric for the number of times this activity is started.')
    metric_succeeded: typing.Optional[list[TaskStateBaseDefMetricSucceededParams]] = pydantic.Field(None, description='Metric for the number of times this activity succeeds.')
    metric_time: typing.Optional[list[TaskStateBaseDefMetricTimeParams]] = pydantic.Field(None, description='The interval, in milliseconds, between the time the activity is scheduled and the time it closes.')
    metric_timed_out: typing.Optional[list[TaskStateBaseDefMetricTimedOutParams]] = pydantic.Field(None, description='Metric for the number of times this activity times out.')
    next: typing.Optional[list[TaskStateBaseDefNextParams]] = pydantic.Field(None, description='Continue normal execution with the given state.')
    prefix_states: typing.Optional[list[TaskStateBaseDefPrefixStatesParams]] = pydantic.Field(None, description='Add a prefix to the stateId of all States found in a construct tree.')

class TaskStateBaseDefAddCatchParams(pydantic.BaseModel):
    handler: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-\n')
    errors: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Errors to recover from by going to the given state. A list of error strings to retry, which can be either predefined errors (for example Errors.NoChoiceMatched) or a self-defined error. Default: All errors\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to indicate where to inject the error data. May also be the special value DISCARD, which will cause the error data to be discarded. Default: $')
    return_config: typing.Optional[list[models.aws_stepfunctions.TaskStateBaseDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefAddPrefixParams(pydantic.BaseModel):
    x: str = pydantic.Field(..., description='-')
    ...

class TaskStateBaseDefAddRetryParams(pydantic.BaseModel):
    backoff_rate: typing.Union[int, float, None] = pydantic.Field(None, description='Multiplication for how much longer the wait interval gets on every retry. Default: 2\n')
    errors: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Errors to retry. A list of error strings to retry, which can be either predefined errors (for example Errors.NoChoiceMatched) or a self-defined error. Default: All errors\n')
    interval: typing.Optional[models.DurationDef] = pydantic.Field(None, description='How many seconds to wait initially before retrying. Default: Duration.seconds(1)\n')
    max_attempts: typing.Union[int, float, None] = pydantic.Field(None, description='How many times to retry this particular error. May be 0 to disable retry for specific errors (in case you have a catch-all retry policy). Default: 3')
    return_config: typing.Optional[list[models.aws_stepfunctions.TaskStateBaseDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefBindToGraphParams(pydantic.BaseModel):
    graph: models.aws_stepfunctions.StateGraphDef = pydantic.Field(..., description='-')
    ...

class TaskStateBaseDefFilterNextablesParams(pydantic.BaseModel):
    states: typing.Sequence[models.aws_stepfunctions.StateDef] = pydantic.Field(..., description='-')
    ...

class TaskStateBaseDefFindReachableEndStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class TaskStateBaseDefFindReachableStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class TaskStateBaseDefMetricParams(pydantic.BaseModel):
    metric_name: str = pydantic.Field(..., description='-\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefMetricFailedParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefMetricHeartbeatTimedOutParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefMetricRunTimeParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - average over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefMetricScheduleTimeParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - average over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefMetricScheduledParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefMetricStartedParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefMetricSucceededParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefMetricTimeParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - average over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefMetricTimedOutParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefNextParams(pydantic.BaseModel):
    next: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...

class TaskStateBaseDefPrefixStatesParams(pydantic.BaseModel):
    root: models.AnyResource = pydantic.Field(..., description='-\n')
    prefix: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Timeout
class TimeoutDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['at', 'duration']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Timeout'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[TimeoutDefConfig] = pydantic.Field(None)


class TimeoutDefConfig(pydantic.BaseModel):
    at: typing.Optional[list[TimeoutDefAtParams]] = pydantic.Field(None, description='Use a dynamic timeout specified by a path in the state input.\nThe path must select a field whose value is a positive integer.')
    duration: typing.Optional[list[TimeoutDefDurationParams]] = pydantic.Field(None, description='Use a duration as timeout.')

class TimeoutDefAtParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.TimeoutDefConfig]] = pydantic.Field(None)
    ...

class TimeoutDefDurationParams(pydantic.BaseModel):
    duration: models.DurationDef = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.TimeoutDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.WaitTime
class WaitTimeDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['duration', 'seconds_path', 'timestamp', 'timestamp_path']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.WaitTime'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[WaitTimeDefConfig] = pydantic.Field(None)


class WaitTimeDefConfig(pydantic.BaseModel):
    duration: typing.Optional[list[WaitTimeDefDurationParams]] = pydantic.Field(None, description='Wait a fixed amount of time.')
    seconds_path: typing.Optional[list[WaitTimeDefSecondsPathParams]] = pydantic.Field(None, description='Wait for a number of seconds stored in the state object.\nExample value: ``$.waitSeconds``')
    timestamp: typing.Optional[list[WaitTimeDefTimestampParams]] = pydantic.Field(None, description='Wait until the given ISO8601 timestamp.\nExample value: ``2016-03-14T01:59:00Z``')
    timestamp_path: typing.Optional[list[WaitTimeDefTimestampPathParams]] = pydantic.Field(None, description='Wait until a timestamp found in the state object.\nExample value: ``$.waitTimestamp``')

class WaitTimeDefDurationParams(pydantic.BaseModel):
    duration: models.DurationDef = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.WaitTimeDefConfig]] = pydantic.Field(None)
    ...

class WaitTimeDefSecondsPathParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.WaitTimeDefConfig]] = pydantic.Field(None)
    ...

class WaitTimeDefTimestampParams(pydantic.BaseModel):
    timestamp: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.WaitTimeDefConfig]] = pydantic.Field(None)
    ...

class WaitTimeDefTimestampPathParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.WaitTimeDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Activity
class ActivityDef(BaseConstruct):
    activity_name: typing.Optional[str] = pydantic.Field(None, description='The name for this activity. Default: - If not supplied, a name is generated')
    _init_params: typing.ClassVar[list[str]] = ['activity_name']
    _method_names: typing.ClassVar[list[str]] = ['apply_removal_policy', 'grant', 'metric', 'metric_failed', 'metric_heartbeat_timed_out', 'metric_run_time', 'metric_schedule_time', 'metric_scheduled', 'metric_started', 'metric_succeeded', 'metric_time', 'metric_timed_out']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_activity_arn', 'from_activity_name']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Activity'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_activity_arn', 'from_activity_name']
    ...


    from_activity_arn: typing.Optional[ActivityDefFromActivityArnParams] = pydantic.Field(None, description='Construct an Activity from an existing Activity ARN.')
    from_activity_name: typing.Optional[ActivityDefFromActivityNameParams] = pydantic.Field(None, description='Construct an Activity from an existing Activity Name.')
    resource_config: typing.Optional[ActivityDefConfig] = pydantic.Field(None)


class ActivityDefConfig(pydantic.BaseModel):
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    grant: typing.Optional[list[ActivityDefGrantParams]] = pydantic.Field(None, description='Grant the given identity permissions on this Activity.')
    metric: typing.Optional[list[ActivityDefMetricParams]] = pydantic.Field(None, description='Return the given named metric for this Activity.')
    metric_failed: typing.Optional[list[ActivityDefMetricFailedParams]] = pydantic.Field(None, description='Metric for the number of times this activity fails.')
    metric_heartbeat_timed_out: typing.Optional[list[ActivityDefMetricHeartbeatTimedOutParams]] = pydantic.Field(None, description='Metric for the number of times the heartbeat times out for this activity.')
    metric_run_time: typing.Optional[list[ActivityDefMetricRunTimeParams]] = pydantic.Field(None, description='The interval, in milliseconds, between the time the activity starts and the time it closes.')
    metric_schedule_time: typing.Optional[list[ActivityDefMetricScheduleTimeParams]] = pydantic.Field(None, description='The interval, in milliseconds, for which the activity stays in the schedule state.')
    metric_scheduled: typing.Optional[list[ActivityDefMetricScheduledParams]] = pydantic.Field(None, description='Metric for the number of times this activity is scheduled.')
    metric_started: typing.Optional[list[ActivityDefMetricStartedParams]] = pydantic.Field(None, description='Metric for the number of times this activity is started.')
    metric_succeeded: typing.Optional[list[ActivityDefMetricSucceededParams]] = pydantic.Field(None, description='Metric for the number of times this activity succeeds.')
    metric_time: typing.Optional[list[ActivityDefMetricTimeParams]] = pydantic.Field(None, description='The interval, in milliseconds, between the time the activity is scheduled and the time it closes.')
    metric_timed_out: typing.Optional[list[ActivityDefMetricTimedOutParams]] = pydantic.Field(None, description='Metric for the number of times this activity times out.')

class ActivityDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class ActivityDefFromActivityArnParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-\n')
    id: str = pydantic.Field(..., description='-\n')
    activity_arn: str = pydantic.Field(..., description='-')
    ...

class ActivityDefFromActivityNameParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-\n')
    id: str = pydantic.Field(..., description='-\n')
    activity_name: str = pydantic.Field(..., description='-')
    ...

class ActivityDefGrantParams(pydantic.BaseModel):
    identity: typing.Union[models.aws_appsync.BackedDataSourceDef, models.aws_appsync.DynamoDbDataSourceDef, models.aws_appsync.ElasticsearchDataSourceDef, models.aws_appsync.EventBridgeDataSourceDef, models.aws_appsync.HttpDataSourceDef, models.aws_appsync.LambdaDataSourceDef, models.aws_appsync.OpenSearchDataSourceDef, models.aws_appsync.RdsDataSourceDef, models.aws_backup.BackupSelectionDef, models.aws_codebuild.UntrustedCodeBoundaryPolicyDef, models.aws_ec2.LaunchTemplateDef, models.aws_iam.ManagedPolicyDef, models.aws_iam.PolicyDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.custom_resources.AwsCustomResourceDef] = pydantic.Field(..., description='The principal.\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class ActivityDefMetricParams(pydantic.BaseModel):
    metric_name: str = pydantic.Field(..., description='-\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class ActivityDefMetricFailedParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class ActivityDefMetricHeartbeatTimedOutParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class ActivityDefMetricRunTimeParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: average over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class ActivityDefMetricScheduleTimeParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: average over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class ActivityDefMetricScheduledParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class ActivityDefMetricStartedParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class ActivityDefMetricSucceededParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class ActivityDefMetricTimeParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: average over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class ActivityDefMetricTimedOutParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Choice
class ChoiceDef(BaseConstruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value DISCARD, which will cause the effective output to be the empty object {}. Default: $')
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'output_path']
    _method_names: typing.ClassVar[list[str]] = ['add_prefix', 'afterwards', 'bind_to_graph', 'otherwise', 'when']
    _classmethod_names: typing.ClassVar[list[str]] = ['filter_nextables', 'find_reachable_end_states', 'find_reachable_states', 'prefix_states']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Choice'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[ChoiceDefConfig] = pydantic.Field(None)


class ChoiceDefConfig(pydantic.BaseModel):
    add_prefix: typing.Optional[list[ChoiceDefAddPrefixParams]] = pydantic.Field(None, description='Add a prefix to the stateId of this state.')
    afterwards: typing.Optional[list[ChoiceDefAfterwardsParams]] = pydantic.Field(None, description='Return a Chain that contains all reachable end states from this Choice.\nUse this to combine all possible choice paths back.')
    bind_to_graph: typing.Optional[list[ChoiceDefBindToGraphParams]] = pydantic.Field(None, description="Register this state as part of the given graph.\nDon't call this. It will be called automatically when you work\nwith states normally.")
    filter_nextables: typing.Optional[list[ChoiceDefFilterNextablesParams]] = pydantic.Field(None, description='Return only the states that allow chaining from an array of states.')
    find_reachable_end_states: typing.Optional[list[ChoiceDefFindReachableEndStatesParams]] = pydantic.Field(None, description='Find the set of end states states reachable through transitions from the given start state.')
    find_reachable_states: typing.Optional[list[ChoiceDefFindReachableStatesParams]] = pydantic.Field(None, description="Find the set of states reachable through transitions from the given start state.\nThis does not retrieve states from within sub-graphs, such as states within a Parallel state's branch.")
    otherwise: typing.Optional[list[ChoiceDefOtherwiseParams]] = pydantic.Field(None, description='If none of the given conditions match, continue execution with the given state.\nIf no conditions match and no otherwise() has been given, an execution\nerror will be raised.')
    prefix_states: typing.Optional[list[ChoiceDefPrefixStatesParams]] = pydantic.Field(None, description='Add a prefix to the stateId of all States found in a construct tree.')
    when: typing.Optional[list[ChoiceDefWhenParams]] = pydantic.Field(None, description='If the given condition matches, continue execution with the given state.')

class ChoiceDefAddPrefixParams(pydantic.BaseModel):
    x: str = pydantic.Field(..., description='-')
    ...

class ChoiceDefAfterwardsParams(pydantic.BaseModel):
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description="Whether to include error handling states. If this is true, all states which are error handlers (added through 'onError') and states reachable via error handlers will be included as well. Default: false\n")
    include_otherwise: typing.Optional[bool] = pydantic.Field(None, description='Whether to include the default/otherwise transition for the current Choice state. If this is true and the current Choice does not have a default outgoing transition, one will be added included when .next() is called on the chain. Default: false')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...

class ChoiceDefBindToGraphParams(pydantic.BaseModel):
    graph: models.aws_stepfunctions.StateGraphDef = pydantic.Field(..., description='-')
    ...

class ChoiceDefFilterNextablesParams(pydantic.BaseModel):
    states: typing.Sequence[models.aws_stepfunctions.StateDef] = pydantic.Field(..., description='-')
    ...

class ChoiceDefFindReachableEndStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class ChoiceDefFindReachableStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class ChoiceDefOtherwiseParams(pydantic.BaseModel):
    def_: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChoiceDefConfig]] = pydantic.Field(None)
    ...

class ChoiceDefPrefixStatesParams(pydantic.BaseModel):
    root: models.AnyResource = pydantic.Field(..., description='-\n')
    prefix: str = pydantic.Field(..., description='-')
    ...

class ChoiceDefWhenParams(pydantic.BaseModel):
    condition: models.aws_stepfunctions.ConditionDef = pydantic.Field(..., description='-\n')
    next: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChoiceDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.CustomState
class CustomStateDef(BaseConstruct):
    state_json: typing.Mapping[str, typing.Any] = pydantic.Field(..., description='Amazon States Language (JSON-based) definition of the state.')
    _init_params: typing.ClassVar[list[str]] = ['state_json']
    _method_names: typing.ClassVar[list[str]] = ['add_prefix', 'bind_to_graph', 'next']
    _classmethod_names: typing.ClassVar[list[str]] = ['filter_nextables', 'find_reachable_end_states', 'find_reachable_states', 'prefix_states']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CustomState'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CustomStateDefConfig] = pydantic.Field(None)


class CustomStateDefConfig(pydantic.BaseModel):
    add_prefix: typing.Optional[list[CustomStateDefAddPrefixParams]] = pydantic.Field(None, description='Add a prefix to the stateId of this state.')
    bind_to_graph: typing.Optional[list[CustomStateDefBindToGraphParams]] = pydantic.Field(None, description="Register this state as part of the given graph.\nDon't call this. It will be called automatically when you work\nwith states normally.")
    filter_nextables: typing.Optional[list[CustomStateDefFilterNextablesParams]] = pydantic.Field(None, description='Return only the states that allow chaining from an array of states.')
    find_reachable_end_states: typing.Optional[list[CustomStateDefFindReachableEndStatesParams]] = pydantic.Field(None, description='Find the set of end states states reachable through transitions from the given start state.')
    find_reachable_states: typing.Optional[list[CustomStateDefFindReachableStatesParams]] = pydantic.Field(None, description="Find the set of states reachable through transitions from the given start state.\nThis does not retrieve states from within sub-graphs, such as states within a Parallel state's branch.")
    next: typing.Optional[list[CustomStateDefNextParams]] = pydantic.Field(None, description='Continue normal execution with the given state.')
    prefix_states: typing.Optional[list[CustomStateDefPrefixStatesParams]] = pydantic.Field(None, description='Add a prefix to the stateId of all States found in a construct tree.')

class CustomStateDefAddPrefixParams(pydantic.BaseModel):
    x: str = pydantic.Field(..., description='-')
    ...

class CustomStateDefBindToGraphParams(pydantic.BaseModel):
    graph: models.aws_stepfunctions.StateGraphDef = pydantic.Field(..., description='-')
    ...

class CustomStateDefFilterNextablesParams(pydantic.BaseModel):
    states: typing.Sequence[models.aws_stepfunctions.StateDef] = pydantic.Field(..., description='-')
    ...

class CustomStateDefFindReachableEndStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class CustomStateDefFindReachableStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class CustomStateDefNextParams(pydantic.BaseModel):
    next: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...

class CustomStateDefPrefixStatesParams(pydantic.BaseModel):
    root: models.AnyResource = pydantic.Field(..., description='-\n')
    prefix: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Fail
class FailDef(BaseConstruct):
    cause: typing.Optional[str] = pydantic.Field(None, description='A description for the cause of the failure. Default: No description\n')
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    error: typing.Optional[str] = pydantic.Field(None, description='Error code used to represent this failure. Default: No error code')
    _init_params: typing.ClassVar[list[str]] = ['cause', 'comment', 'error']
    _method_names: typing.ClassVar[list[str]] = ['add_prefix', 'bind_to_graph']
    _classmethod_names: typing.ClassVar[list[str]] = ['filter_nextables', 'find_reachable_end_states', 'find_reachable_states', 'prefix_states']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Fail'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[FailDefConfig] = pydantic.Field(None)


class FailDefConfig(pydantic.BaseModel):
    add_prefix: typing.Optional[list[FailDefAddPrefixParams]] = pydantic.Field(None, description='Add a prefix to the stateId of this state.')
    bind_to_graph: typing.Optional[list[FailDefBindToGraphParams]] = pydantic.Field(None, description="Register this state as part of the given graph.\nDon't call this. It will be called automatically when you work\nwith states normally.")
    filter_nextables: typing.Optional[list[FailDefFilterNextablesParams]] = pydantic.Field(None, description='Return only the states that allow chaining from an array of states.')
    find_reachable_end_states: typing.Optional[list[FailDefFindReachableEndStatesParams]] = pydantic.Field(None, description='Find the set of end states states reachable through transitions from the given start state.')
    find_reachable_states: typing.Optional[list[FailDefFindReachableStatesParams]] = pydantic.Field(None, description="Find the set of states reachable through transitions from the given start state.\nThis does not retrieve states from within sub-graphs, such as states within a Parallel state's branch.")
    prefix_states: typing.Optional[list[FailDefPrefixStatesParams]] = pydantic.Field(None, description='Add a prefix to the stateId of all States found in a construct tree.')

class FailDefAddPrefixParams(pydantic.BaseModel):
    x: str = pydantic.Field(..., description='-')
    ...

class FailDefBindToGraphParams(pydantic.BaseModel):
    graph: models.aws_stepfunctions.StateGraphDef = pydantic.Field(..., description='-')
    ...

class FailDefFilterNextablesParams(pydantic.BaseModel):
    states: typing.Sequence[models.aws_stepfunctions.StateDef] = pydantic.Field(..., description='-')
    ...

class FailDefFindReachableEndStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class FailDefFindReachableStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class FailDefPrefixStatesParams(pydantic.BaseModel):
    root: models.AnyResource = pydantic.Field(..., description='-\n')
    prefix: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Map
class MapDef(BaseConstruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    items_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select the array to iterate over. Default: $\n')
    max_concurrency: typing.Union[int, float, None] = pydantic.Field(None, description='MaxConcurrency. An upper bound on the number of iterations you want running at once. Default: - full concurrency\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $\n')
    parameters: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='The JSON that you want to override your default iteration input. Default: $\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to indicate where to inject the state's output. May also be the special value JsonPath.DISCARD, which will cause the state's input to become its output. Default: $\n")
    result_selector: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description="The JSON that will replace the state's raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state's raw result. Default: - None")
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'items_path', 'max_concurrency', 'output_path', 'parameters', 'result_path', 'result_selector']
    _method_names: typing.ClassVar[list[str]] = ['add_catch', 'add_prefix', 'add_retry', 'bind_to_graph', 'iterator', 'next']
    _classmethod_names: typing.ClassVar[list[str]] = ['filter_nextables', 'find_reachable_end_states', 'find_reachable_states', 'prefix_states']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Map'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[MapDefConfig] = pydantic.Field(None)


class MapDefConfig(pydantic.BaseModel):
    add_catch: typing.Optional[list[MapDefAddCatchParams]] = pydantic.Field(None, description='Add a recovery handler for this state.\nWhen a particular error occurs, execution will continue at the error\nhandler instead of failing the state machine execution.')
    add_prefix: typing.Optional[list[MapDefAddPrefixParams]] = pydantic.Field(None, description='Add a prefix to the stateId of this state.')
    add_retry: typing.Optional[list[MapDefAddRetryParams]] = pydantic.Field(None, description='Add retry configuration for this state.\nThis controls if and how the execution will be retried if a particular\nerror occurs.')
    bind_to_graph: typing.Optional[list[MapDefBindToGraphParams]] = pydantic.Field(None, description="Register this state as part of the given graph.\nDon't call this. It will be called automatically when you work\nwith states normally.")
    filter_nextables: typing.Optional[list[MapDefFilterNextablesParams]] = pydantic.Field(None, description='Return only the states that allow chaining from an array of states.')
    find_reachable_end_states: typing.Optional[list[MapDefFindReachableEndStatesParams]] = pydantic.Field(None, description='Find the set of end states states reachable through transitions from the given start state.')
    find_reachable_states: typing.Optional[list[MapDefFindReachableStatesParams]] = pydantic.Field(None, description="Find the set of states reachable through transitions from the given start state.\nThis does not retrieve states from within sub-graphs, such as states within a Parallel state's branch.")
    iterator: typing.Optional[list[MapDefIteratorParams]] = pydantic.Field(None, description='Define iterator state machine in Map.')
    next: typing.Optional[list[MapDefNextParams]] = pydantic.Field(None, description='Continue normal execution with the given state.')
    prefix_states: typing.Optional[list[MapDefPrefixStatesParams]] = pydantic.Field(None, description='Add a prefix to the stateId of all States found in a construct tree.')

class MapDefAddCatchParams(pydantic.BaseModel):
    handler: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-\n')
    errors: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Errors to recover from by going to the given state. A list of error strings to retry, which can be either predefined errors (for example Errors.NoChoiceMatched) or a self-defined error. Default: All errors\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to indicate where to inject the error data. May also be the special value DISCARD, which will cause the error data to be discarded. Default: $')
    return_config: typing.Optional[list[models.aws_stepfunctions.MapDefConfig]] = pydantic.Field(None)
    ...

class MapDefAddPrefixParams(pydantic.BaseModel):
    x: str = pydantic.Field(..., description='-')
    ...

class MapDefAddRetryParams(pydantic.BaseModel):
    backoff_rate: typing.Union[int, float, None] = pydantic.Field(None, description='Multiplication for how much longer the wait interval gets on every retry. Default: 2\n')
    errors: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Errors to retry. A list of error strings to retry, which can be either predefined errors (for example Errors.NoChoiceMatched) or a self-defined error. Default: All errors\n')
    interval: typing.Optional[models.DurationDef] = pydantic.Field(None, description='How many seconds to wait initially before retrying. Default: Duration.seconds(1)\n')
    max_attempts: typing.Union[int, float, None] = pydantic.Field(None, description='How many times to retry this particular error. May be 0 to disable retry for specific errors (in case you have a catch-all retry policy). Default: 3')
    return_config: typing.Optional[list[models.aws_stepfunctions.MapDefConfig]] = pydantic.Field(None)
    ...

class MapDefBindToGraphParams(pydantic.BaseModel):
    graph: models.aws_stepfunctions.StateGraphDef = pydantic.Field(..., description='-')
    ...

class MapDefFilterNextablesParams(pydantic.BaseModel):
    states: typing.Sequence[models.aws_stepfunctions.StateDef] = pydantic.Field(..., description='-')
    ...

class MapDefFindReachableEndStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class MapDefFindReachableStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class MapDefIteratorParams(pydantic.BaseModel):
    iterator: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.MapDefConfig]] = pydantic.Field(None)
    ...

class MapDefNextParams(pydantic.BaseModel):
    next: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...

class MapDefPrefixStatesParams(pydantic.BaseModel):
    root: models.AnyResource = pydantic.Field(..., description='-\n')
    prefix: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Parallel
class ParallelDef(BaseConstruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to indicate where to inject the state's output. May also be the special value JsonPath.DISCARD, which will cause the state's input to become its output. Default: $\n")
    result_selector: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description="The JSON that will replace the state's raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state's raw result. Default: - None")
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'output_path', 'result_path', 'result_selector']
    _method_names: typing.ClassVar[list[str]] = ['add_catch', 'add_prefix', 'add_retry', 'bind_to_graph', 'branch', 'next']
    _classmethod_names: typing.ClassVar[list[str]] = ['filter_nextables', 'find_reachable_end_states', 'find_reachable_states', 'prefix_states']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Parallel'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[ParallelDefConfig] = pydantic.Field(None)


class ParallelDefConfig(pydantic.BaseModel):
    add_catch: typing.Optional[list[ParallelDefAddCatchParams]] = pydantic.Field(None, description='Add a recovery handler for this state.\nWhen a particular error occurs, execution will continue at the error\nhandler instead of failing the state machine execution.')
    add_prefix: typing.Optional[list[ParallelDefAddPrefixParams]] = pydantic.Field(None, description='Add a prefix to the stateId of this state.')
    add_retry: typing.Optional[list[ParallelDefAddRetryParams]] = pydantic.Field(None, description='Add retry configuration for this state.\nThis controls if and how the execution will be retried if a particular\nerror occurs.')
    bind_to_graph: typing.Optional[list[ParallelDefBindToGraphParams]] = pydantic.Field(None, description='Overwrites State.bindToGraph. Adds branches to the Parallel state here so that any necessary prefixes are appended first.')
    branch: typing.Optional[list[ParallelDefBranchParams]] = pydantic.Field(None, description='Define one or more branches to run in parallel.')
    filter_nextables: typing.Optional[list[ParallelDefFilterNextablesParams]] = pydantic.Field(None, description='Return only the states that allow chaining from an array of states.')
    find_reachable_end_states: typing.Optional[list[ParallelDefFindReachableEndStatesParams]] = pydantic.Field(None, description='Find the set of end states states reachable through transitions from the given start state.')
    find_reachable_states: typing.Optional[list[ParallelDefFindReachableStatesParams]] = pydantic.Field(None, description="Find the set of states reachable through transitions from the given start state.\nThis does not retrieve states from within sub-graphs, such as states within a Parallel state's branch.")
    next: typing.Optional[list[ParallelDefNextParams]] = pydantic.Field(None, description='Continue normal execution with the given state.')
    prefix_states: typing.Optional[list[ParallelDefPrefixStatesParams]] = pydantic.Field(None, description='Add a prefix to the stateId of all States found in a construct tree.')

class ParallelDefAddCatchParams(pydantic.BaseModel):
    handler: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-\n')
    errors: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Errors to recover from by going to the given state. A list of error strings to retry, which can be either predefined errors (for example Errors.NoChoiceMatched) or a self-defined error. Default: All errors\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to indicate where to inject the error data. May also be the special value DISCARD, which will cause the error data to be discarded. Default: $')
    return_config: typing.Optional[list[models.aws_stepfunctions.ParallelDefConfig]] = pydantic.Field(None)
    ...

class ParallelDefAddPrefixParams(pydantic.BaseModel):
    x: str = pydantic.Field(..., description='-')
    ...

class ParallelDefAddRetryParams(pydantic.BaseModel):
    backoff_rate: typing.Union[int, float, None] = pydantic.Field(None, description='Multiplication for how much longer the wait interval gets on every retry. Default: 2\n')
    errors: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Errors to retry. A list of error strings to retry, which can be either predefined errors (for example Errors.NoChoiceMatched) or a self-defined error. Default: All errors\n')
    interval: typing.Optional[models.DurationDef] = pydantic.Field(None, description='How many seconds to wait initially before retrying. Default: Duration.seconds(1)\n')
    max_attempts: typing.Union[int, float, None] = pydantic.Field(None, description='How many times to retry this particular error. May be 0 to disable retry for specific errors (in case you have a catch-all retry policy). Default: 3')
    return_config: typing.Optional[list[models.aws_stepfunctions.ParallelDefConfig]] = pydantic.Field(None)
    ...

class ParallelDefBindToGraphParams(pydantic.BaseModel):
    graph: models.aws_stepfunctions.StateGraphDef = pydantic.Field(..., description='-')
    ...

class ParallelDefBranchParams(pydantic.BaseModel):
    branches: list[typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef]] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_stepfunctions.ParallelDefConfig]] = pydantic.Field(None)
    ...

class ParallelDefFilterNextablesParams(pydantic.BaseModel):
    states: typing.Sequence[models.aws_stepfunctions.StateDef] = pydantic.Field(..., description='-')
    ...

class ParallelDefFindReachableEndStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class ParallelDefFindReachableStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class ParallelDefNextParams(pydantic.BaseModel):
    next: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...

class ParallelDefPrefixStatesParams(pydantic.BaseModel):
    root: models.AnyResource = pydantic.Field(..., description='-\n')
    prefix: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Pass
class PassDef(BaseConstruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $\n')
    parameters: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Parameters pass a collection of key-value pairs, either static values or JSONPath expressions that select from the input. Default: No parameters\n')
    result: typing.Optional[models.aws_stepfunctions.ResultDef] = pydantic.Field(None, description='If given, treat as the result of this operation. Can be used to inject or replace the current execution state. Default: No injected result\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to indicate where to inject the state's output. May also be the special value JsonPath.DISCARD, which will cause the state's input to become its output. Default: $")
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'output_path', 'parameters', 'result', 'result_path']
    _method_names: typing.ClassVar[list[str]] = ['add_prefix', 'bind_to_graph', 'next']
    _classmethod_names: typing.ClassVar[list[str]] = ['filter_nextables', 'find_reachable_end_states', 'find_reachable_states', 'prefix_states']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Pass'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[PassDefConfig] = pydantic.Field(None)


class PassDefConfig(pydantic.BaseModel):
    add_prefix: typing.Optional[list[PassDefAddPrefixParams]] = pydantic.Field(None, description='Add a prefix to the stateId of this state.')
    bind_to_graph: typing.Optional[list[PassDefBindToGraphParams]] = pydantic.Field(None, description="Register this state as part of the given graph.\nDon't call this. It will be called automatically when you work\nwith states normally.")
    filter_nextables: typing.Optional[list[PassDefFilterNextablesParams]] = pydantic.Field(None, description='Return only the states that allow chaining from an array of states.')
    find_reachable_end_states: typing.Optional[list[PassDefFindReachableEndStatesParams]] = pydantic.Field(None, description='Find the set of end states states reachable through transitions from the given start state.')
    find_reachable_states: typing.Optional[list[PassDefFindReachableStatesParams]] = pydantic.Field(None, description="Find the set of states reachable through transitions from the given start state.\nThis does not retrieve states from within sub-graphs, such as states within a Parallel state's branch.")
    next: typing.Optional[list[PassDefNextParams]] = pydantic.Field(None, description='Continue normal execution with the given state.')
    prefix_states: typing.Optional[list[PassDefPrefixStatesParams]] = pydantic.Field(None, description='Add a prefix to the stateId of all States found in a construct tree.')

class PassDefAddPrefixParams(pydantic.BaseModel):
    x: str = pydantic.Field(..., description='-')
    ...

class PassDefBindToGraphParams(pydantic.BaseModel):
    graph: models.aws_stepfunctions.StateGraphDef = pydantic.Field(..., description='-')
    ...

class PassDefFilterNextablesParams(pydantic.BaseModel):
    states: typing.Sequence[models.aws_stepfunctions.StateDef] = pydantic.Field(..., description='-')
    ...

class PassDefFindReachableEndStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class PassDefFindReachableStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class PassDefNextParams(pydantic.BaseModel):
    next: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...

class PassDefPrefixStatesParams(pydantic.BaseModel):
    root: models.AnyResource = pydantic.Field(..., description='-\n')
    prefix: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.StateMachine
class StateMachineDef(BaseConstruct):
    definition: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='Definition for this state machine.\n')
    logs: typing.Union[models.aws_stepfunctions.LogOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines what execution history events are logged and where they are logged. Default: No logging\n')
    removal_policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='The removal policy to apply to state machine. Default: RemovalPolicy.DESTROY\n')
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The execution role for the state machine service. Default: A role is automatically created\n')
    state_machine_name: typing.Optional[str] = pydantic.Field(None, description='A name for the state machine. Default: A name is automatically generated\n')
    state_machine_type: typing.Optional[aws_cdk.aws_stepfunctions.StateMachineType] = pydantic.Field(None, description='Type of the state machine. Default: StateMachineType.STANDARD\n')
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Maximum run time for this state machine. Default: No timeout\n')
    tracing_enabled: typing.Optional[bool] = pydantic.Field(None, description='Specifies whether Amazon X-Ray tracing is enabled for this state machine. Default: false')
    _init_params: typing.ClassVar[list[str]] = ['definition', 'logs', 'removal_policy', 'role', 'state_machine_name', 'state_machine_type', 'timeout', 'tracing_enabled']
    _method_names: typing.ClassVar[list[str]] = ['add_to_role_policy', 'apply_removal_policy', 'grant', 'grant_execution', 'grant_read', 'grant_start_execution', 'grant_start_sync_execution', 'grant_task_response', 'metric', 'metric_aborted', 'metric_failed', 'metric_started', 'metric_succeeded', 'metric_throttled', 'metric_time', 'metric_timed_out']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_state_machine_arn', 'from_state_machine_name']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.StateMachine'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_state_machine_arn', 'from_state_machine_name']
    ...


    from_state_machine_arn: typing.Optional[StateMachineDefFromStateMachineArnParams] = pydantic.Field(None, description='Import a state machine.')
    from_state_machine_name: typing.Optional[StateMachineDefFromStateMachineNameParams] = pydantic.Field(None, description='Import a state machine via resource name.')
    resource_config: typing.Optional[StateMachineDefConfig] = pydantic.Field(None)


class StateMachineDefConfig(pydantic.BaseModel):
    add_to_role_policy: typing.Optional[list[StateMachineDefAddToRolePolicyParams]] = pydantic.Field(None, description="Add the given statement to the role's policy.")
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    grant: typing.Optional[list[StateMachineDefGrantParams]] = pydantic.Field(None, description='Grant the given identity custom permissions.')
    grant_execution: typing.Optional[list[StateMachineDefGrantExecutionParams]] = pydantic.Field(None, description='Grant the given identity permissions on all executions of the state machine.')
    grant_read: typing.Optional[list[StateMachineDefGrantReadParams]] = pydantic.Field(None, description='Grant the given identity permissions to read results from state machine.')
    grant_start_execution: typing.Optional[list[StateMachineDefGrantStartExecutionParams]] = pydantic.Field(None, description='Grant the given identity permissions to start an execution of this state machine.')
    grant_start_sync_execution: typing.Optional[list[StateMachineDefGrantStartSyncExecutionParams]] = pydantic.Field(None, description='Grant the given identity permissions to start a synchronous execution of this state machine.')
    grant_task_response: typing.Optional[list[StateMachineDefGrantTaskResponseParams]] = pydantic.Field(None, description='Grant the given identity task response permissions on a state machine.')
    metric: typing.Optional[list[StateMachineDefMetricParams]] = pydantic.Field(None, description="Return the given named metric for this State Machine's executions.")
    metric_aborted: typing.Optional[list[StateMachineDefMetricAbortedParams]] = pydantic.Field(None, description='Metric for the number of executions that were aborted.')
    metric_failed: typing.Optional[list[StateMachineDefMetricFailedParams]] = pydantic.Field(None, description='Metric for the number of executions that failed.')
    metric_started: typing.Optional[list[StateMachineDefMetricStartedParams]] = pydantic.Field(None, description='Metric for the number of executions that were started.')
    metric_succeeded: typing.Optional[list[StateMachineDefMetricSucceededParams]] = pydantic.Field(None, description='Metric for the number of executions that succeeded.')
    metric_throttled: typing.Optional[list[StateMachineDefMetricThrottledParams]] = pydantic.Field(None, description='Metric for the number of executions that were throttled.')
    metric_time: typing.Optional[list[StateMachineDefMetricTimeParams]] = pydantic.Field(None, description='Metric for the interval, in milliseconds, between the time the execution starts and the time it closes.')
    metric_timed_out: typing.Optional[list[StateMachineDefMetricTimedOutParams]] = pydantic.Field(None, description='Metric for the number of executions that timed out.')
    grant_principal_config: typing.Optional[models._interface_methods.AwsIamIPrincipalDefConfig] = pydantic.Field(None)
    role_config: typing.Optional[models._interface_methods.AwsIamIRoleDefConfig] = pydantic.Field(None)

class StateMachineDefAddToRolePolicyParams(pydantic.BaseModel):
    statement: models.aws_iam.PolicyStatementDef = pydantic.Field(..., description='-')
    ...

class StateMachineDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class StateMachineDefFromStateMachineArnParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-\n')
    id: str = pydantic.Field(..., description='-\n')
    state_machine_arn: str = pydantic.Field(..., description='-')
    ...

class StateMachineDefFromStateMachineNameParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-\n')
    id: str = pydantic.Field(..., description='-\n')
    state_machine_name: str = pydantic.Field(..., description='-')
    ...

class StateMachineDefGrantParams(pydantic.BaseModel):
    identity: typing.Union[models.aws_appsync.BackedDataSourceDef, models.aws_appsync.DynamoDbDataSourceDef, models.aws_appsync.ElasticsearchDataSourceDef, models.aws_appsync.EventBridgeDataSourceDef, models.aws_appsync.HttpDataSourceDef, models.aws_appsync.LambdaDataSourceDef, models.aws_appsync.OpenSearchDataSourceDef, models.aws_appsync.RdsDataSourceDef, models.aws_backup.BackupSelectionDef, models.aws_codebuild.UntrustedCodeBoundaryPolicyDef, models.aws_ec2.LaunchTemplateDef, models.aws_iam.ManagedPolicyDef, models.aws_iam.PolicyDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.custom_resources.AwsCustomResourceDef] = pydantic.Field(..., description='-\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefGrantExecutionParams(pydantic.BaseModel):
    identity: typing.Union[models.aws_appsync.BackedDataSourceDef, models.aws_appsync.DynamoDbDataSourceDef, models.aws_appsync.ElasticsearchDataSourceDef, models.aws_appsync.EventBridgeDataSourceDef, models.aws_appsync.HttpDataSourceDef, models.aws_appsync.LambdaDataSourceDef, models.aws_appsync.OpenSearchDataSourceDef, models.aws_appsync.RdsDataSourceDef, models.aws_backup.BackupSelectionDef, models.aws_codebuild.UntrustedCodeBoundaryPolicyDef, models.aws_ec2.LaunchTemplateDef, models.aws_iam.ManagedPolicyDef, models.aws_iam.PolicyDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.custom_resources.AwsCustomResourceDef] = pydantic.Field(..., description='-\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefGrantReadParams(pydantic.BaseModel):
    identity: typing.Union[models.aws_appsync.BackedDataSourceDef, models.aws_appsync.DynamoDbDataSourceDef, models.aws_appsync.ElasticsearchDataSourceDef, models.aws_appsync.EventBridgeDataSourceDef, models.aws_appsync.HttpDataSourceDef, models.aws_appsync.LambdaDataSourceDef, models.aws_appsync.OpenSearchDataSourceDef, models.aws_appsync.RdsDataSourceDef, models.aws_backup.BackupSelectionDef, models.aws_codebuild.UntrustedCodeBoundaryPolicyDef, models.aws_ec2.LaunchTemplateDef, models.aws_iam.ManagedPolicyDef, models.aws_iam.PolicyDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.custom_resources.AwsCustomResourceDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefGrantStartExecutionParams(pydantic.BaseModel):
    identity: typing.Union[models.aws_appsync.BackedDataSourceDef, models.aws_appsync.DynamoDbDataSourceDef, models.aws_appsync.ElasticsearchDataSourceDef, models.aws_appsync.EventBridgeDataSourceDef, models.aws_appsync.HttpDataSourceDef, models.aws_appsync.LambdaDataSourceDef, models.aws_appsync.OpenSearchDataSourceDef, models.aws_appsync.RdsDataSourceDef, models.aws_backup.BackupSelectionDef, models.aws_codebuild.UntrustedCodeBoundaryPolicyDef, models.aws_ec2.LaunchTemplateDef, models.aws_iam.ManagedPolicyDef, models.aws_iam.PolicyDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.custom_resources.AwsCustomResourceDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefGrantStartSyncExecutionParams(pydantic.BaseModel):
    identity: typing.Union[models.aws_appsync.BackedDataSourceDef, models.aws_appsync.DynamoDbDataSourceDef, models.aws_appsync.ElasticsearchDataSourceDef, models.aws_appsync.EventBridgeDataSourceDef, models.aws_appsync.HttpDataSourceDef, models.aws_appsync.LambdaDataSourceDef, models.aws_appsync.OpenSearchDataSourceDef, models.aws_appsync.RdsDataSourceDef, models.aws_backup.BackupSelectionDef, models.aws_codebuild.UntrustedCodeBoundaryPolicyDef, models.aws_ec2.LaunchTemplateDef, models.aws_iam.ManagedPolicyDef, models.aws_iam.PolicyDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.custom_resources.AwsCustomResourceDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefGrantTaskResponseParams(pydantic.BaseModel):
    identity: typing.Union[models.aws_appsync.BackedDataSourceDef, models.aws_appsync.DynamoDbDataSourceDef, models.aws_appsync.ElasticsearchDataSourceDef, models.aws_appsync.EventBridgeDataSourceDef, models.aws_appsync.HttpDataSourceDef, models.aws_appsync.LambdaDataSourceDef, models.aws_appsync.OpenSearchDataSourceDef, models.aws_appsync.RdsDataSourceDef, models.aws_backup.BackupSelectionDef, models.aws_codebuild.UntrustedCodeBoundaryPolicyDef, models.aws_ec2.LaunchTemplateDef, models.aws_iam.ManagedPolicyDef, models.aws_iam.PolicyDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.custom_resources.AwsCustomResourceDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefMetricParams(pydantic.BaseModel):
    metric_name: str = pydantic.Field(..., description='-\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefMetricAbortedParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefMetricFailedParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefMetricStartedParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefMetricSucceededParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefMetricThrottledParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefMetricTimeParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - average over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class StateMachineDefMetricTimedOutParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:default: - sum over 5 minutes\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Succeed
class SucceedDef(BaseConstruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $')
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'output_path']
    _method_names: typing.ClassVar[list[str]] = ['add_prefix', 'bind_to_graph']
    _classmethod_names: typing.ClassVar[list[str]] = ['filter_nextables', 'find_reachable_end_states', 'find_reachable_states', 'prefix_states']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Succeed'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[SucceedDefConfig] = pydantic.Field(None)


class SucceedDefConfig(pydantic.BaseModel):
    add_prefix: typing.Optional[list[SucceedDefAddPrefixParams]] = pydantic.Field(None, description='Add a prefix to the stateId of this state.')
    bind_to_graph: typing.Optional[list[SucceedDefBindToGraphParams]] = pydantic.Field(None, description="Register this state as part of the given graph.\nDon't call this. It will be called automatically when you work\nwith states normally.")
    filter_nextables: typing.Optional[list[SucceedDefFilterNextablesParams]] = pydantic.Field(None, description='Return only the states that allow chaining from an array of states.')
    find_reachable_end_states: typing.Optional[list[SucceedDefFindReachableEndStatesParams]] = pydantic.Field(None, description='Find the set of end states states reachable through transitions from the given start state.')
    find_reachable_states: typing.Optional[list[SucceedDefFindReachableStatesParams]] = pydantic.Field(None, description="Find the set of states reachable through transitions from the given start state.\nThis does not retrieve states from within sub-graphs, such as states within a Parallel state's branch.")
    prefix_states: typing.Optional[list[SucceedDefPrefixStatesParams]] = pydantic.Field(None, description='Add a prefix to the stateId of all States found in a construct tree.')

class SucceedDefAddPrefixParams(pydantic.BaseModel):
    x: str = pydantic.Field(..., description='-')
    ...

class SucceedDefBindToGraphParams(pydantic.BaseModel):
    graph: models.aws_stepfunctions.StateGraphDef = pydantic.Field(..., description='-')
    ...

class SucceedDefFilterNextablesParams(pydantic.BaseModel):
    states: typing.Sequence[models.aws_stepfunctions.StateDef] = pydantic.Field(..., description='-')
    ...

class SucceedDefFindReachableEndStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class SucceedDefFindReachableStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class SucceedDefPrefixStatesParams(pydantic.BaseModel):
    root: models.AnyResource = pydantic.Field(..., description='-\n')
    prefix: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.Wait
class WaitDef(BaseConstruct):
    time: models.aws_stepfunctions.WaitTimeDef = pydantic.Field(..., description='Wait duration.\n')
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment')
    _init_params: typing.ClassVar[list[str]] = ['time', 'comment']
    _method_names: typing.ClassVar[list[str]] = ['add_prefix', 'bind_to_graph', 'next']
    _classmethod_names: typing.ClassVar[list[str]] = ['filter_nextables', 'find_reachable_end_states', 'find_reachable_states', 'prefix_states']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Wait'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[WaitDefConfig] = pydantic.Field(None)


class WaitDefConfig(pydantic.BaseModel):
    add_prefix: typing.Optional[list[WaitDefAddPrefixParams]] = pydantic.Field(None, description='Add a prefix to the stateId of this state.')
    bind_to_graph: typing.Optional[list[WaitDefBindToGraphParams]] = pydantic.Field(None, description="Register this state as part of the given graph.\nDon't call this. It will be called automatically when you work\nwith states normally.")
    filter_nextables: typing.Optional[list[WaitDefFilterNextablesParams]] = pydantic.Field(None, description='Return only the states that allow chaining from an array of states.')
    find_reachable_end_states: typing.Optional[list[WaitDefFindReachableEndStatesParams]] = pydantic.Field(None, description='Find the set of end states states reachable through transitions from the given start state.')
    find_reachable_states: typing.Optional[list[WaitDefFindReachableStatesParams]] = pydantic.Field(None, description="Find the set of states reachable through transitions from the given start state.\nThis does not retrieve states from within sub-graphs, such as states within a Parallel state's branch.")
    next: typing.Optional[list[WaitDefNextParams]] = pydantic.Field(None, description='Continue normal execution with the given state.')
    prefix_states: typing.Optional[list[WaitDefPrefixStatesParams]] = pydantic.Field(None, description='Add a prefix to the stateId of all States found in a construct tree.')

class WaitDefAddPrefixParams(pydantic.BaseModel):
    x: str = pydantic.Field(..., description='-')
    ...

class WaitDefBindToGraphParams(pydantic.BaseModel):
    graph: models.aws_stepfunctions.StateGraphDef = pydantic.Field(..., description='-')
    ...

class WaitDefFilterNextablesParams(pydantic.BaseModel):
    states: typing.Sequence[models.aws_stepfunctions.StateDef] = pydantic.Field(..., description='-')
    ...

class WaitDefFindReachableEndStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class WaitDefFindReachableStatesParams(pydantic.BaseModel):
    start: models.aws_stepfunctions.StateDef = pydantic.Field(..., description='-\n')
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false')
    ...

class WaitDefNextParams(pydantic.BaseModel):
    next: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_stepfunctions.ChainDefConfig]] = pydantic.Field(None)
    ...

class WaitDefPrefixStatesParams(pydantic.BaseModel):
    root: models.AnyResource = pydantic.Field(..., description='-\n')
    prefix: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.ActivityProps
class ActivityPropsDef(BaseStruct):
    activity_name: typing.Optional[str] = pydantic.Field(None, description='The name for this activity. Default: - If not supplied, a name is generated\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    activity_props = stepfunctions.ActivityProps(\n        activity_name="activityName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['activity_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.ActivityProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.AfterwardsOptions
class AfterwardsOptionsDef(BaseStruct):
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description="Whether to include error handling states. If this is true, all states which are error handlers (added through 'onError') and states reachable via error handlers will be included as well. Default: false\n")
    include_otherwise: typing.Optional[bool] = pydantic.Field(None, description='Whether to include the default/otherwise transition for the current Choice state. If this is true and the current Choice does not have a default outgoing transition, one will be added included when .next() is called on the chain. Default: false\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    afterwards_options = stepfunctions.AfterwardsOptions(\n        include_error_handlers=False,\n        include_otherwise=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['include_error_handlers', 'include_otherwise']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.AfterwardsOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.CatchProps
class CatchPropsDef(BaseStruct):
    errors: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Errors to recover from by going to the given state. A list of error strings to retry, which can be either predefined errors (for example Errors.NoChoiceMatched) or a self-defined error. Default: All errors\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to indicate where to inject the error data. May also be the special value DISCARD, which will cause the error data to be discarded. Default: $\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    catch_props = stepfunctions.CatchProps(\n        errors=["errors"],\n        result_path="resultPath"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['errors', 'result_path']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CatchProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.CfnActivity.TagsEntryProperty
class CfnActivity_TagsEntryPropertyDef(BaseStruct):
    key: str = pydantic.Field(..., description='The ``key`` for a key-value pair in a tag entry.\n')
    value: str = pydantic.Field(..., description='The ``value`` for a key-value pair in a tag entry.\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-stepfunctions-activity-tagsentry.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    tags_entry_property = stepfunctions.CfnActivity.TagsEntryProperty(\n        key="key",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['key', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CfnActivity.TagsEntryProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.CfnStateMachine.CloudWatchLogsLogGroupProperty
class CfnStateMachine_CloudWatchLogsLogGroupPropertyDef(BaseStruct):
    log_group_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the the CloudWatch log group to which you want your logs emitted to. The ARN must end with ``:*``\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-stepfunctions-statemachine-cloudwatchlogsloggroup.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    cloud_watch_logs_log_group_property = stepfunctions.CfnStateMachine.CloudWatchLogsLogGroupProperty(\n        log_group_arn="logGroupArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['log_group_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CfnStateMachine.CloudWatchLogsLogGroupProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.CfnStateMachine.LogDestinationProperty
class CfnStateMachine_LogDestinationPropertyDef(BaseStruct):
    cloud_watch_logs_log_group: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_stepfunctions.CfnStateMachine_CloudWatchLogsLogGroupPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An object describing a CloudWatch log group. For more information, see `AWS::Logs::LogGroup <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-logs-loggroup.html>`_ in the AWS CloudFormation User Guide.\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-stepfunctions-statemachine-logdestination.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    log_destination_property = stepfunctions.CfnStateMachine.LogDestinationProperty(\n        cloud_watch_logs_log_group=stepfunctions.CfnStateMachine.CloudWatchLogsLogGroupProperty(\n            log_group_arn="logGroupArn"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cloud_watch_logs_log_group']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CfnStateMachine.LogDestinationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.CfnStateMachine.LoggingConfigurationProperty
class CfnStateMachine_LoggingConfigurationPropertyDef(BaseStruct):
    destinations: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], typing.Sequence[typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_stepfunctions.CfnStateMachine_LogDestinationPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='An array of objects that describes where your execution history events will be logged. Limited to size 1. Required, if your log level is not set to ``OFF`` .\n')
    include_execution_data: typing.Union[bool, typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], None] = pydantic.Field(None, description='Determines whether execution data is included in your log. When set to ``false`` , data is excluded.\n')
    level: typing.Optional[str] = pydantic.Field(None, description='Defines which category of execution history events are logged.\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-stepfunctions-statemachine-loggingconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    logging_configuration_property = stepfunctions.CfnStateMachine.LoggingConfigurationProperty(\n        destinations=[stepfunctions.CfnStateMachine.LogDestinationProperty(\n            cloud_watch_logs_log_group=stepfunctions.CfnStateMachine.CloudWatchLogsLogGroupProperty(\n                log_group_arn="logGroupArn"\n            )\n        )],\n        include_execution_data=False,\n        level="level"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['destinations', 'include_execution_data', 'level']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CfnStateMachine.LoggingConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.CfnStateMachine.S3LocationProperty
class CfnStateMachine_S3LocationPropertyDef(BaseStruct):
    bucket: str = pydantic.Field(..., description='The name of the S3 bucket where the state machine definition JSON or YAML file is stored.\n')
    key: str = pydantic.Field(..., description='The name of the state machine definition file (Amazon S3 object name).\n')
    version: typing.Optional[str] = pydantic.Field(None, description='For versioning-enabled buckets, a specific version of the state machine definition.\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-stepfunctions-statemachine-s3location.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    s3_location_property = stepfunctions.CfnStateMachine.S3LocationProperty(\n        bucket="bucket",\n        key="key",\n\n        # the properties below are optional\n        version="version"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket', 'key', 'version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CfnStateMachine.S3LocationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.CfnStateMachine.TagsEntryProperty
class CfnStateMachine_TagsEntryPropertyDef(BaseStruct):
    key: str = pydantic.Field(..., description='The ``key`` for a key-value pair in a tag entry.\n')
    value: str = pydantic.Field(..., description='The ``value`` for a key-value pair in a tag entry.\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-stepfunctions-statemachine-tagsentry.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    tags_entry_property = stepfunctions.CfnStateMachine.TagsEntryProperty(\n        key="key",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['key', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CfnStateMachine.TagsEntryProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.CfnStateMachine.TracingConfigurationProperty
class CfnStateMachine_TracingConfigurationPropertyDef(BaseStruct):
    enabled: typing.Union[bool, typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], None] = pydantic.Field(None, description='When set to ``true`` , X-Ray tracing is enabled.\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-stepfunctions-statemachine-tracingconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    tracing_configuration_property = stepfunctions.CfnStateMachine.TracingConfigurationProperty(\n        enabled=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['enabled']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CfnStateMachine.TracingConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.ChoiceProps
class ChoicePropsDef(BaseStruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value DISCARD, which will cause the effective output to be the empty object {}. Default: $\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    choice_props = stepfunctions.ChoiceProps(\n        comment="comment",\n        input_path="inputPath",\n        output_path="outputPath"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'output_path']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.ChoiceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.Credentials
class CredentialsDef(BaseStruct):
    role: models.aws_stepfunctions.TaskRoleDef = pydantic.Field(..., description='The role to be assumed for executing the Task.\n\n:see: https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-task-state.html#task-state-fields\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_lambda as lambda_\n\n    # submit_lambda: lambda.Function\n    # iam_role: iam.Role\n\n\n    # use a fixed role for all task invocations\n    role = sfn.TaskRole.from_role(iam_role)\n    # or use a json expression to resolve the role at runtime based on task inputs\n    # const role = sfn.TaskRole.fromRoleArnJsonPath(\'$.RoleArn\');\n\n    submit_job = tasks.LambdaInvoke(self, "Submit Job",\n        lambda_function=submit_lambda,\n        output_path="$.Payload",\n        # use credentials\n        credentials=sfn.Credentials(role=role)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['role']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.Credentials'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.CustomStateProps
class CustomStatePropsDef(BaseStruct):
    state_json: typing.Mapping[str, typing.Any] = pydantic.Field(..., description='Amazon States Language (JSON-based) definition of the state.\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_dynamodb as dynamodb\n\n\n    # create a table\n    table = dynamodb.Table(self, "montable",\n        partition_key=dynamodb.Attribute(\n            name="id",\n            type=dynamodb.AttributeType.STRING\n        )\n    )\n\n    final_status = sfn.Pass(self, "final step")\n\n    # States language JSON to put an item into DynamoDB\n    # snippet generated from https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-code-snippet.html#tutorial-code-snippet-1\n    state_json = {\n        "Type": "Task",\n        "Resource": "arn:aws:states:::dynamodb:putItem",\n        "Parameters": {\n            "TableName": table.table_name,\n            "Item": {\n                "id": {\n                    "S": "MyEntry"\n                }\n            }\n        },\n        "ResultPath": null\n    }\n\n    # custom state which represents a task to insert data into DynamoDB\n    custom = sfn.CustomState(self, "my custom task",\n        state_json=state_json\n    )\n\n    chain = sfn.Chain.start(custom).next(final_status)\n\n    sm = sfn.StateMachine(self, "StateMachine",\n        definition=chain,\n        timeout=Duration.seconds(30)\n    )\n\n    # don\'t forget permissions. You need to assign them\n    table.grant_write_data(sm)\n')
    _init_params: typing.ClassVar[list[str]] = ['state_json']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CustomStateProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.FailProps
class FailPropsDef(BaseStruct):
    cause: typing.Optional[str] = pydantic.Field(None, description='A description for the cause of the failure. Default: No description\n')
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    error: typing.Optional[str] = pydantic.Field(None, description='Error code used to represent this failure. Default: No error code\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_lambda as lambda_\n\n    # submit_lambda: lambda.Function\n    # get_status_lambda: lambda.Function\n\n\n    submit_job = tasks.LambdaInvoke(self, "Submit Job",\n        lambda_function=submit_lambda,\n        # Lambda\'s result is in the attribute `guid`\n        output_path="$.guid"\n    )\n\n    wait_x = sfn.Wait(self, "Wait X Seconds",\n        time=sfn.WaitTime.seconds_path("$.waitSeconds")\n    )\n\n    get_status = tasks.LambdaInvoke(self, "Get Job Status",\n        lambda_function=get_status_lambda,\n        # Pass just the field named "guid" into the Lambda, put the\n        # Lambda\'s result in a field called "status" in the response\n        input_path="$.guid",\n        output_path="$.status"\n    )\n\n    job_failed = sfn.Fail(self, "Job Failed",\n        cause="AWS Batch Job Failed",\n        error="DescribeJob returned FAILED"\n    )\n\n    final_status = tasks.LambdaInvoke(self, "Get Final Job Status",\n        lambda_function=get_status_lambda,\n        # Use "guid" field as input\n        input_path="$.guid",\n        output_path="$.Payload"\n    )\n\n    definition = submit_job.next(wait_x).next(get_status).next(sfn.Choice(self, "Job Complete?").when(sfn.Condition.string_equals("$.status", "FAILED"), job_failed).when(sfn.Condition.string_equals("$.status", "SUCCEEDED"), final_status).otherwise(wait_x))\n\n    sfn.StateMachine(self, "StateMachine",\n        definition=definition,\n        timeout=Duration.minutes(5)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cause', 'comment', 'error']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.FailProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.FindStateOptions
class FindStateOptionsDef(BaseStruct):
    include_error_handlers: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to follow error-handling transitions. Default: false\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    find_state_options = stepfunctions.FindStateOptions(\n        include_error_handlers=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['include_error_handlers']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.FindStateOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.LogOptions
class LogOptionsDef(BaseStruct):
    destination: typing.Union[models.aws_logs.LogGroupDef] = pydantic.Field(..., description='The log group where the execution history events will be logged.\n')
    include_execution_data: typing.Optional[bool] = pydantic.Field(None, description='Determines whether execution data is included in your log. Default: false\n')
    level: typing.Optional[aws_cdk.aws_stepfunctions.LogLevel] = pydantic.Field(None, description='Defines which category of execution history events are logged. Default: ERROR\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_logs as logs\n\n\n    log_group = logs.LogGroup(self, "MyLogGroup")\n\n    sfn.StateMachine(self, "MyStateMachine",\n        definition=sfn.Chain.start(sfn.Pass(self, "Pass")),\n        logs=sfn.LogOptions(\n            destination=log_group,\n            level=sfn.LogLevel.ALL\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['destination', 'include_execution_data', 'level']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.LogOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[LogOptionsDefConfig] = pydantic.Field(None)


class LogOptionsDefConfig(pydantic.BaseModel):
    destination_config: typing.Optional[models._interface_methods.AwsLogsILogGroupDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_stepfunctions.MapProps
class MapPropsDef(BaseStruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    items_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select the array to iterate over. Default: $\n')
    max_concurrency: typing.Union[int, float, None] = pydantic.Field(None, description='MaxConcurrency. An upper bound on the number of iterations you want running at once. Default: - full concurrency\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $\n')
    parameters: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='The JSON that you want to override your default iteration input. Default: $\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to indicate where to inject the state's output. May also be the special value JsonPath.DISCARD, which will cause the state's input to become its output. Default: $\n")
    result_selector: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='The JSON that will replace the state\'s raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state\'s raw result. Default: - None\n\n:exampleMetadata: infused\n\nExample::\n\n    map = sfn.Map(self, "Map State",\n        max_concurrency=1,\n        items_path=sfn.JsonPath.string_at("$.inputForMap")\n    )\n    map.iterator(sfn.Pass(self, "Pass State"))\n')
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'items_path', 'max_concurrency', 'output_path', 'parameters', 'result_path', 'result_selector']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.MapProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.ParallelProps
class ParallelPropsDef(BaseStruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to indicate where to inject the state's output. May also be the special value JsonPath.DISCARD, which will cause the state's input to become its output. Default: $\n")
    result_selector: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='The JSON that will replace the state\'s raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state\'s raw result. Default: - None\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    # result_selector: Any\n\n    parallel_props = stepfunctions.ParallelProps(\n        comment="comment",\n        input_path="inputPath",\n        output_path="outputPath",\n        result_path="resultPath",\n        result_selector={\n            "result_selector_key": result_selector\n        }\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'output_path', 'result_path', 'result_selector']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.ParallelProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.PassProps
class PassPropsDef(BaseStruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $\n')
    parameters: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Parameters pass a collection of key-value pairs, either static values or JSONPath expressions that select from the input. Default: No parameters\n')
    result: typing.Optional[models.aws_stepfunctions.ResultDef] = pydantic.Field(None, description='If given, treat as the result of this operation. Can be used to inject or replace the current execution state. Default: No injected result\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to indicate where to inject the state\'s output. May also be the special value JsonPath.DISCARD, which will cause the state\'s input to become its output. Default: $\n\n:exampleMetadata: infused\n\nExample::\n\n    # Makes the current JSON state { ..., "subObject": { "hello": "world" } }\n    pass = sfn.Pass(self, "Add Hello World",\n        result=sfn.Result.from_object({"hello": "world"}),\n        result_path="$.subObject"\n    )\n\n    # Set the next state\n    next_state = sfn.Pass(self, "NextState")\n    pass.next(next_state)\n')
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'output_path', 'parameters', 'result', 'result_path']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.PassProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.RetryProps
class RetryPropsDef(BaseStruct):
    backoff_rate: typing.Union[int, float, None] = pydantic.Field(None, description='Multiplication for how much longer the wait interval gets on every retry. Default: 2\n')
    errors: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Errors to retry. A list of error strings to retry, which can be either predefined errors (for example Errors.NoChoiceMatched) or a self-defined error. Default: All errors\n')
    interval: typing.Optional[models.DurationDef] = pydantic.Field(None, description='How many seconds to wait initially before retrying. Default: Duration.seconds(1)\n')
    max_attempts: typing.Union[int, float, None] = pydantic.Field(None, description='How many times to retry this particular error. May be 0 to disable retry for specific errors (in case you have a catch-all retry policy). Default: 3\n\n:exampleMetadata: infused\n\nExample::\n\n    parallel = sfn.Parallel(self, "Do the work in parallel")\n\n    # Add branches to be executed in parallel\n    ship_item = sfn.Pass(self, "ShipItem")\n    send_invoice = sfn.Pass(self, "SendInvoice")\n    restock = sfn.Pass(self, "Restock")\n    parallel.branch(ship_item)\n    parallel.branch(send_invoice)\n    parallel.branch(restock)\n\n    # Retry the whole workflow if something goes wrong\n    parallel.add_retry(max_attempts=1)\n\n    # How to recover from errors\n    send_failure_notification = sfn.Pass(self, "SendFailureNotification")\n    parallel.add_catch(send_failure_notification)\n\n    # What to do in case everything succeeded\n    close_order = sfn.Pass(self, "CloseOrder")\n    parallel.next(close_order)\n')
    _init_params: typing.ClassVar[list[str]] = ['backoff_rate', 'errors', 'interval', 'max_attempts']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.RetryProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.SingleStateOptions
class SingleStateOptionsDef(BaseStruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to indicate where to inject the state's output. May also be the special value JsonPath.DISCARD, which will cause the state's input to become its output. Default: $\n")
    result_selector: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description="The JSON that will replace the state's raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state's raw result. Default: - None\n")
    prefix_states: typing.Optional[str] = pydantic.Field(None, description='String to prefix all stateIds in the state machine with. Default: stateId\n')
    state_id: typing.Optional[str] = pydantic.Field(None, description='ID of newly created containing state. Default: Construct ID of the StateMachineFragment\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    # result_selector: Any\n\n    single_state_options = stepfunctions.SingleStateOptions(\n        comment="comment",\n        input_path="inputPath",\n        output_path="outputPath",\n        prefix_states="prefixStates",\n        result_path="resultPath",\n        result_selector={\n            "result_selector_key": result_selector\n        },\n        state_id="stateId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'output_path', 'result_path', 'result_selector', 'prefix_states', 'state_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.SingleStateOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.StateMachineProps
class StateMachinePropsDef(BaseStruct):
    definition: typing.Union[models.aws_stepfunctions.ChainDef, models.aws_stepfunctions.StateDef, models.aws_stepfunctions.StateMachineFragmentDef, models.aws_stepfunctions.TaskStateBaseDef, models.aws_stepfunctions.ChoiceDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.CustomStateDef, models.aws_stepfunctions.FailDef, models.aws_stepfunctions.MapDef, models.aws_stepfunctions.ParallelDef, models.aws_stepfunctions.PassDef, models.aws_stepfunctions.SucceedDef, models.aws_stepfunctions.WaitDef, models.aws_stepfunctions_tasks.AthenaGetQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaGetQueryResultsDef, models.aws_stepfunctions_tasks.AthenaStartQueryExecutionDef, models.aws_stepfunctions_tasks.AthenaStopQueryExecutionDef, models.aws_stepfunctions_tasks.BatchSubmitJobDef, models.aws_stepfunctions_tasks.CallApiGatewayHttpApiEndpointDef, models.aws_stepfunctions_tasks.CallApiGatewayRestApiEndpointDef, models.aws_stepfunctions_tasks.CallAwsServiceDef, models.aws_stepfunctions_tasks.CodeBuildStartBuildDef, models.aws_stepfunctions_tasks.DynamoDeleteItemDef, models.aws_stepfunctions_tasks.DynamoGetItemDef, models.aws_stepfunctions_tasks.DynamoPutItemDef, models.aws_stepfunctions_tasks.DynamoUpdateItemDef, models.aws_stepfunctions_tasks.EcsRunTaskDef, models.aws_stepfunctions_tasks.EksCallDef, models.aws_stepfunctions_tasks.EmrAddStepDef, models.aws_stepfunctions_tasks.EmrCancelStepDef, models.aws_stepfunctions_tasks.EmrContainersCreateVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersDeleteVirtualClusterDef, models.aws_stepfunctions_tasks.EmrContainersStartJobRunDef, models.aws_stepfunctions_tasks.EmrCreateClusterDef, models.aws_stepfunctions_tasks.EmrModifyInstanceFleetByNameDef, models.aws_stepfunctions_tasks.EmrModifyInstanceGroupByNameDef, models.aws_stepfunctions_tasks.EmrSetClusterTerminationProtectionDef, models.aws_stepfunctions_tasks.EmrTerminateClusterDef, models.aws_stepfunctions_tasks.EvaluateExpressionDef, models.aws_stepfunctions_tasks.EventBridgePutEventsDef, models.aws_stepfunctions_tasks.GlueDataBrewStartJobRunDef, models.aws_stepfunctions_tasks.GlueStartJobRunDef, models.aws_stepfunctions_tasks.LambdaInvokeDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointDef, models.aws_stepfunctions_tasks.SageMakerCreateEndpointConfigDef, models.aws_stepfunctions_tasks.SageMakerCreateModelDef, models.aws_stepfunctions_tasks.SageMakerCreateTrainingJobDef, models.aws_stepfunctions_tasks.SageMakerCreateTransformJobDef, models.aws_stepfunctions_tasks.SageMakerUpdateEndpointDef, models.aws_stepfunctions_tasks.SnsPublishDef, models.aws_stepfunctions_tasks.SqsSendMessageDef, models.aws_stepfunctions_tasks.StepFunctionsInvokeActivityDef, models.aws_stepfunctions_tasks.StepFunctionsStartExecutionDef] = pydantic.Field(..., description='Definition for this state machine.\n')
    logs: typing.Union[models.aws_stepfunctions.LogOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines what execution history events are logged and where they are logged. Default: No logging\n')
    removal_policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='The removal policy to apply to state machine. Default: RemovalPolicy.DESTROY\n')
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The execution role for the state machine service. Default: A role is automatically created\n')
    state_machine_name: typing.Optional[str] = pydantic.Field(None, description='A name for the state machine. Default: A name is automatically generated\n')
    state_machine_type: typing.Optional[aws_cdk.aws_stepfunctions.StateMachineType] = pydantic.Field(None, description='Type of the state machine. Default: StateMachineType.STANDARD\n')
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Maximum run time for this state machine. Default: No timeout\n')
    tracing_enabled: typing.Optional[bool] = pydantic.Field(None, description='Specifies whether Amazon X-Ray tracing is enabled for this state machine. Default: false\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_stepfunctions as stepfunctions\n\n\n    pipeline = codepipeline.Pipeline(self, "MyPipeline")\n    input_artifact = codepipeline.Artifact()\n    start_state = stepfunctions.Pass(self, "StartState")\n    simple_state_machine = stepfunctions.StateMachine(self, "SimpleStateMachine",\n        definition=start_state\n    )\n    step_function_action = codepipeline_actions.StepFunctionInvokeAction(\n        action_name="Invoke",\n        state_machine=simple_state_machine,\n        state_machine_input=codepipeline_actions.StateMachineInput.file_path(input_artifact.at_path("assets/input.json"))\n    )\n    pipeline.add_stage(\n        stage_name="StepFunctions",\n        actions=[step_function_action]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['definition', 'logs', 'removal_policy', 'role', 'state_machine_name', 'state_machine_type', 'timeout', 'tracing_enabled']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.StateMachineProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.StateProps
class StatePropsDef(BaseStruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='A comment describing this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $\n')
    parameters: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Parameters pass a collection of key-value pairs, either static values or JSONPath expressions that select from the input. Default: No parameters\n')
    result_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to indicate where to inject the state's output. May also be the special value JsonPath.DISCARD, which will cause the state's input to become its output. Default: $\n")
    result_selector: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='The JSON that will replace the state\'s raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state\'s raw result. Default: - None\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    # parameters: Any\n    # result_selector: Any\n\n    state_props = stepfunctions.StateProps(\n        comment="comment",\n        input_path="inputPath",\n        output_path="outputPath",\n        parameters={\n            "parameters_key": parameters\n        },\n        result_path="resultPath",\n        result_selector={\n            "result_selector_key": result_selector\n        }\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'output_path', 'parameters', 'result_path', 'result_selector']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.StateProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.SucceedProps
class SucceedPropsDef(BaseStruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: $\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='JSONPath expression to select part of the state to be the output to this state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: $\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    succeed_props = stepfunctions.SucceedProps(\n        comment="comment",\n        input_path="inputPath",\n        output_path="outputPath"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['comment', 'input_path', 'output_path']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.SucceedProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.TaskMetricsConfig
class TaskMetricsConfigDef(BaseStruct):
    metric_dimensions: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='The dimensions to attach to metrics. Default: - No metrics\n')
    metric_prefix_plural: typing.Optional[str] = pydantic.Field(None, description='Prefix for plural metric names of activity actions. Default: - No such metrics\n')
    metric_prefix_singular: typing.Optional[str] = pydantic.Field(None, description='Prefix for singular metric names of activity actions. Default: - No such metrics\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    # metric_dimensions: Any\n\n    task_metrics_config = stepfunctions.TaskMetricsConfig(\n        metric_dimensions={\n            "metric_dimensions_key": metric_dimensions\n        },\n        metric_prefix_plural="metricPrefixPlural",\n        metric_prefix_singular="metricPrefixSingular"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric_dimensions', 'metric_prefix_plural', 'metric_prefix_singular']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.TaskMetricsConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.TaskStateBaseProps
class TaskStateBasePropsDef(BaseStruct):
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: - No comment\n')
    credentials: typing.Union[models.aws_stepfunctions.CredentialsDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Credentials for an IAM Role that the State Machine assumes for executing the task. This enables cross-account resource invocations. Default: - None (Task is executed using the State Machine's execution role)\n")
    heartbeat: typing.Optional[models.DurationDef] = pydantic.Field(None, description='(deprecated) Timeout for the heartbeat. Default: - None\n')
    heartbeat_timeout: typing.Optional[models.aws_stepfunctions.TimeoutDef] = pydantic.Field(None, description='Timeout for the heartbeat. [disable-awslint:duration-prop-type] is needed because all props interface in aws-stepfunctions-tasks extend this interface Default: - None\n')
    input_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to select part of the state to be the input to this state. May also be the special value JsonPath.DISCARD, which will cause the effective input to be the empty object {}. Default: - The entire task input (JSON path '$')\n")
    integration_pattern: typing.Optional[aws_cdk.aws_stepfunctions.IntegrationPattern] = pydantic.Field(None, description='AWS Step Functions integrates with services directly in the Amazon States Language. You can control these AWS services using service integration patterns Default: - ``IntegrationPattern.REQUEST_RESPONSE`` for most tasks. ``IntegrationPattern.RUN_JOB`` for the following exceptions: ``BatchSubmitJob``, ``EmrAddStep``, ``EmrCreateCluster``, ``EmrTerminationCluster``, and ``EmrContainersStartJobRun``.\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to select select a portion of the state output to pass to the next state. May also be the special value JsonPath.DISCARD, which will cause the effective output to be the empty object {}. Default: - The entire JSON node determined by the state input, the task result, and resultPath is passed to the next state (JSON path '$')\n")
    result_path: typing.Optional[str] = pydantic.Field(None, description="JSONPath expression to indicate where to inject the state's output. May also be the special value JsonPath.DISCARD, which will cause the state's input to become its output. Default: - Replaces the entire input with the result (JSON path '$')\n")
    result_selector: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description="The JSON that will replace the state's raw result and become the effective result before ResultPath is applied. You can use ResultSelector to create a payload with values that are static or selected from the state's raw result. Default: - None\n")
    task_timeout: typing.Optional[models.aws_stepfunctions.TimeoutDef] = pydantic.Field(None, description='Timeout for the task. [disable-awslint:duration-prop-type] is needed because all props interface in aws-stepfunctions-tasks extend this interface Default: - None\n')
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='(deprecated) Timeout for the task. Default: - None\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    # result_selector: Any\n    # task_role: stepfunctions.TaskRole\n    # timeout: stepfunctions.Timeout\n\n    task_state_base_props = stepfunctions.TaskStateBaseProps(\n        comment="comment",\n        credentials=stepfunctions.Credentials(\n            role=task_role\n        ),\n        heartbeat=cdk.Duration.minutes(30),\n        heartbeat_timeout=timeout,\n        input_path="inputPath",\n        integration_pattern=stepfunctions.IntegrationPattern.REQUEST_RESPONSE,\n        output_path="outputPath",\n        result_path="resultPath",\n        result_selector={\n            "result_selector_key": result_selector\n        },\n        task_timeout=timeout,\n        timeout=cdk.Duration.minutes(30)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['comment', 'credentials', 'heartbeat', 'heartbeat_timeout', 'input_path', 'integration_pattern', 'output_path', 'result_path', 'result_selector', 'task_timeout', 'timeout']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.TaskStateBaseProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.WaitProps
class WaitPropsDef(BaseStruct):
    time: models.aws_stepfunctions.WaitTimeDef = pydantic.Field(..., description='Wait duration.\n')
    comment: typing.Optional[str] = pydantic.Field(None, description='An optional description for this state. Default: No comment\n\n:exampleMetadata: infused\n\nExample::\n\n    convert_to_seconds = tasks.EvaluateExpression(self, "Convert to seconds",\n        expression="$.waitMilliseconds / 1000",\n        result_path="$.waitSeconds"\n    )\n\n    create_message = tasks.EvaluateExpression(self, "Create message",\n        # Note: this is a string inside a string.\n        expression="`Now waiting ${$.waitSeconds} seconds...`",\n        runtime=lambda_.Runtime.NODEJS_16_X,\n        result_path="$.message"\n    )\n\n    publish_message = tasks.SnsPublish(self, "Publish message",\n        topic=sns.Topic(self, "cool-topic"),\n        message=sfn.TaskInput.from_json_path_at("$.message"),\n        result_path="$.sns"\n    )\n\n    wait = sfn.Wait(self, "Wait",\n        time=sfn.WaitTime.seconds_path("$.waitSeconds")\n    )\n\n    sfn.StateMachine(self, "StateMachine",\n        definition=convert_to_seconds.next(create_message).next(publish_message).next(wait)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['time', 'comment']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.WaitProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.InputType
# skipping emum

#  autogenerated from aws_cdk.aws_stepfunctions.IntegrationPattern
# skipping emum

#  autogenerated from aws_cdk.aws_stepfunctions.LogLevel
# skipping emum

#  autogenerated from aws_cdk.aws_stepfunctions.ServiceIntegrationPattern
# skipping emum

#  autogenerated from aws_cdk.aws_stepfunctions.StateMachineType
# skipping emum

#  autogenerated from aws_cdk.aws_stepfunctions.IActivity
#  skipping Interface

#  autogenerated from aws_cdk.aws_stepfunctions.IChainable
#  skipping Interface

#  autogenerated from aws_cdk.aws_stepfunctions.INextable
#  skipping Interface

#  autogenerated from aws_cdk.aws_stepfunctions.IStateMachine
#  skipping Interface

#  autogenerated from aws_cdk.aws_stepfunctions.CfnActivity
class CfnActivityDef(BaseCfnResource):
    name: str = pydantic.Field(..., description='The name of the activity. A name must *not* contain: - white space - brackets ``< > { } [ ]`` - wildcard characters ``? *`` - special characters ``" # % \\ ^ | ~ `` $ & , ; : /` - control characters ( ``U+0000-001F`` , ``U+007F-009F`` ) To enable logging with CloudWatch Logs, the name should only contain 0-9, A-Z, a-z, - and _.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.aws_stepfunctions.CfnActivity_TagsEntryPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The list of tags to add to a resource. Tags may only contain Unicode letters, digits, white space, or these symbols: ``_ . : / = + - @`` .')
    _init_params: typing.ClassVar[list[str]] = ['name', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['TagsEntryProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CfnActivity'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnActivityDefConfig] = pydantic.Field(None)


class CfnActivityDefConfig(pydantic.BaseModel):
    TagsEntryProperty: typing.Optional[list[CfnActivityDefTagsentrypropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnActivityDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnActivityDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnActivityDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnActivityDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnActivityDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnActivityDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnActivityDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnActivityDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnActivityDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnActivityDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnActivityDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnActivityDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnActivityDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnActivityDefTagsentrypropertyParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='')
    value: str = pydantic.Field(..., description='')
    ...

class CfnActivityDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnActivityDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnActivityDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnActivityDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnActivityDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnActivityDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnActivityDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnActivityDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnActivityDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnActivityDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnActivityDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='- tree inspector to collect and process attributes.')
    ...

class CfnActivityDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnActivityDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnActivityDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.CfnStateMachine
class CfnStateMachineDef(BaseCfnResource):
    role_arn: str = pydantic.Field(..., description='The Amazon Resource Name (ARN) of the IAM role to use for this state machine.\n')
    definition: typing.Any = pydantic.Field(None, description='The Amazon States Language definition of the state machine. The state machine definition must be in JSON or YAML, and the format of the object must match the format of your AWS Step Functions template file. See `Amazon States Language <https://docs.aws.amazon.com/step-functions/latest/dg/concepts-amazon-states-language.html>`_ .\n')
    definition_s3_location: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_stepfunctions.CfnStateMachine_S3LocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The name of the S3 bucket where the state machine definition is stored. The state machine definition must be a JSON or YAML file.\n')
    definition_string: typing.Optional[str] = pydantic.Field(None, description='The Amazon States Language definition of the state machine. The state machine definition must be in JSON. See `Amazon States Language <https://docs.aws.amazon.com/step-functions/latest/dg/concepts-amazon-states-language.html>`_ .\n')
    definition_substitutions: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], typing.Mapping[str, str], None] = pydantic.Field(None, description='A map (string to string) that specifies the mappings for placeholder variables in the state machine definition. This enables the customer to inject values obtained at runtime, for example from intrinsic functions, in the state machine definition. Variables can be template parameter names, resource logical IDs, resource attributes, or a variable in a key-value map.\n')
    logging_configuration: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_stepfunctions.CfnStateMachine_LoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines what execution history events are logged and where they are logged. .. epigraph:: By default, the ``level`` is set to ``OFF`` . For more information see `Log Levels <https://docs.aws.amazon.com/step-functions/latest/dg/cloudwatch-log-level.html>`_ in the AWS Step Functions User Guide.\n')
    state_machine_name: typing.Optional[str] = pydantic.Field(None, description='The name of the state machine. A name must *not* contain: - white space - brackets ``< > { } [ ]`` - wildcard characters ``? *`` - special characters ``" # % \\ ^ | ~ `` $ & , ; : /` - control characters ( ``U+0000-001F`` , ``U+007F-009F`` ) .. epigraph:: If you specify a name, you cannot perform updates that require replacement of this resource. You can perform updates that require no or some interruption. If you must replace the resource, specify a new name.\n')
    state_machine_type: typing.Optional[str] = pydantic.Field(None, description='Determines whether a ``STANDARD`` or ``EXPRESS`` state machine is created. The default is ``STANDARD`` . You cannot update the ``type`` of a state machine once it has been created. For more information on ``STANDARD`` and ``EXPRESS`` workflows, see `Standard Versus Express Workflows <https://docs.aws.amazon.com/step-functions/latest/dg/concepts-standard-vs-express.html>`_ in the AWS Step Functions Developer Guide.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.aws_stepfunctions.CfnStateMachine_TagsEntryPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The list of tags to add to a resource. Tags may only contain Unicode letters, digits, white space, or these symbols: ``_ . : / = + - @`` .\n')
    tracing_configuration: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_stepfunctions.CfnStateMachine_TracingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Selects whether or not the state machine's AWS X-Ray tracing is enabled.")
    _init_params: typing.ClassVar[list[str]] = ['role_arn', 'definition', 'definition_s3_location', 'definition_string', 'definition_substitutions', 'logging_configuration', 'state_machine_name', 'state_machine_type', 'tags', 'tracing_configuration']
    _method_names: typing.ClassVar[list[str]] = ['CloudWatchLogsLogGroupProperty', 'LogDestinationProperty', 'LoggingConfigurationProperty', 'S3LocationProperty', 'TagsEntryProperty', 'TracingConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CfnStateMachine'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnStateMachineDefConfig] = pydantic.Field(None)


class CfnStateMachineDefConfig(pydantic.BaseModel):
    CloudWatchLogsLogGroupProperty: typing.Optional[list[CfnStateMachineDefCloudwatchlogsloggrouppropertyParams]] = pydantic.Field(None, description='')
    LogDestinationProperty: typing.Optional[list[CfnStateMachineDefLogdestinationpropertyParams]] = pydantic.Field(None, description='')
    LoggingConfigurationProperty: typing.Optional[list[CfnStateMachineDefLoggingconfigurationpropertyParams]] = pydantic.Field(None, description='')
    S3LocationProperty: typing.Optional[list[CfnStateMachineDefS3LocationpropertyParams]] = pydantic.Field(None, description='')
    TagsEntryProperty: typing.Optional[list[CfnStateMachineDefTagsentrypropertyParams]] = pydantic.Field(None, description='')
    TracingConfigurationProperty: typing.Optional[list[CfnStateMachineDefTracingconfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnStateMachineDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnStateMachineDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnStateMachineDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnStateMachineDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnStateMachineDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnStateMachineDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnStateMachineDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnStateMachineDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnStateMachineDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnStateMachineDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnStateMachineDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnStateMachineDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnStateMachineDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnStateMachineDefCloudwatchlogsloggrouppropertyParams(pydantic.BaseModel):
    log_group_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnStateMachineDefLogdestinationpropertyParams(pydantic.BaseModel):
    cloud_watch_logs_log_group: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_stepfunctions.CfnStateMachine_CloudWatchLogsLogGroupPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnStateMachineDefLoggingconfigurationpropertyParams(pydantic.BaseModel):
    destinations: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], typing.Sequence[typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_stepfunctions.CfnStateMachine_LogDestinationPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    include_execution_data: typing.Union[bool, typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], None] = pydantic.Field(None, description='')
    level: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnStateMachineDefS3LocationpropertyParams(pydantic.BaseModel):
    bucket: str = pydantic.Field(..., description='')
    key: str = pydantic.Field(..., description='')
    version: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnStateMachineDefTagsentrypropertyParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='')
    value: str = pydantic.Field(..., description='')
    ...

class CfnStateMachineDefTracingconfigurationpropertyParams(pydantic.BaseModel):
    enabled: typing.Union[bool, typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], None] = pydantic.Field(None, description='')
    ...

class CfnStateMachineDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnStateMachineDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnStateMachineDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnStateMachineDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnStateMachineDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnStateMachineDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnStateMachineDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnStateMachineDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnStateMachineDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnStateMachineDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnStateMachineDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='- tree inspector to collect and process attributes.')
    ...

class CfnStateMachineDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnStateMachineDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnStateMachineDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_stepfunctions.CfnActivityProps
class CfnActivityPropsDef(BaseCfnProperty):
    name: str = pydantic.Field(..., description='The name of the activity. A name must *not* contain: - white space - brackets ``< > { } [ ]`` - wildcard characters ``? *`` - special characters ``" # % \\ ^ | ~ `` $ & , ; : /` - control characters ( ``U+0000-001F`` , ``U+007F-009F`` ) To enable logging with CloudWatch Logs, the name should only contain 0-9, A-Z, a-z, - and _.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.aws_stepfunctions.CfnActivity_TagsEntryPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The list of tags to add to a resource. Tags may only contain Unicode letters, digits, white space, or these symbols: ``_ . : / = + - @`` .\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-stepfunctions-activity.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    cfn_activity_props = stepfunctions.CfnActivityProps(\n        name="name",\n\n        # the properties below are optional\n        tags=[stepfunctions.CfnActivity.TagsEntryProperty(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CfnActivityProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_stepfunctions.CfnStateMachineProps
class CfnStateMachinePropsDef(BaseCfnProperty):
    role_arn: str = pydantic.Field(..., description='The Amazon Resource Name (ARN) of the IAM role to use for this state machine.\n')
    definition: typing.Any = pydantic.Field(None, description='The Amazon States Language definition of the state machine. The state machine definition must be in JSON or YAML, and the format of the object must match the format of your AWS Step Functions template file. See `Amazon States Language <https://docs.aws.amazon.com/step-functions/latest/dg/concepts-amazon-states-language.html>`_ .\n')
    definition_s3_location: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_stepfunctions.CfnStateMachine_S3LocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The name of the S3 bucket where the state machine definition is stored. The state machine definition must be a JSON or YAML file.\n')
    definition_string: typing.Optional[str] = pydantic.Field(None, description='The Amazon States Language definition of the state machine. The state machine definition must be in JSON. See `Amazon States Language <https://docs.aws.amazon.com/step-functions/latest/dg/concepts-amazon-states-language.html>`_ .\n')
    definition_substitutions: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], typing.Mapping[str, str], None] = pydantic.Field(None, description='A map (string to string) that specifies the mappings for placeholder variables in the state machine definition. This enables the customer to inject values obtained at runtime, for example from intrinsic functions, in the state machine definition. Variables can be template parameter names, resource logical IDs, resource attributes, or a variable in a key-value map.\n')
    logging_configuration: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_stepfunctions.CfnStateMachine_LoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines what execution history events are logged and where they are logged. .. epigraph:: By default, the ``level`` is set to ``OFF`` . For more information see `Log Levels <https://docs.aws.amazon.com/step-functions/latest/dg/cloudwatch-log-level.html>`_ in the AWS Step Functions User Guide.\n')
    state_machine_name: typing.Optional[str] = pydantic.Field(None, description='The name of the state machine. A name must *not* contain: - white space - brackets ``< > { } [ ]`` - wildcard characters ``? *`` - special characters ``" # % \\ ^ | ~ `` $ & , ; : /` - control characters ( ``U+0000-001F`` , ``U+007F-009F`` ) .. epigraph:: If you specify a name, you cannot perform updates that require replacement of this resource. You can perform updates that require no or some interruption. If you must replace the resource, specify a new name.\n')
    state_machine_type: typing.Optional[str] = pydantic.Field(None, description='Determines whether a ``STANDARD`` or ``EXPRESS`` state machine is created. The default is ``STANDARD`` . You cannot update the ``type`` of a state machine once it has been created. For more information on ``STANDARD`` and ``EXPRESS`` workflows, see `Standard Versus Express Workflows <https://docs.aws.amazon.com/step-functions/latest/dg/concepts-standard-vs-express.html>`_ in the AWS Step Functions Developer Guide.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.aws_stepfunctions.CfnStateMachine_TagsEntryPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The list of tags to add to a resource. Tags may only contain Unicode letters, digits, white space, or these symbols: ``_ . : / = + - @`` .\n')
    tracing_configuration: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_stepfunctions.CfnStateMachine_TracingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Selects whether or not the state machine\'s AWS X-Ray tracing is enabled.\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-stepfunctions-statemachine.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_stepfunctions as stepfunctions\n\n    # definition: Any\n\n    cfn_state_machine_props = stepfunctions.CfnStateMachineProps(\n        role_arn="roleArn",\n\n        # the properties below are optional\n        definition=definition,\n        definition_s3_location=stepfunctions.CfnStateMachine.S3LocationProperty(\n            bucket="bucket",\n            key="key",\n\n            # the properties below are optional\n            version="version"\n        ),\n        definition_string="definitionString",\n        definition_substitutions={\n            "definition_substitutions_key": "definitionSubstitutions"\n        },\n        logging_configuration=stepfunctions.CfnStateMachine.LoggingConfigurationProperty(\n            destinations=[stepfunctions.CfnStateMachine.LogDestinationProperty(\n                cloud_watch_logs_log_group=stepfunctions.CfnStateMachine.CloudWatchLogsLogGroupProperty(\n                    log_group_arn="logGroupArn"\n                )\n            )],\n            include_execution_data=False,\n            level="level"\n        ),\n        state_machine_name="stateMachineName",\n        state_machine_type="stateMachineType",\n        tags=[stepfunctions.CfnStateMachine.TagsEntryProperty(\n            key="key",\n            value="value"\n        )],\n        tracing_configuration=stepfunctions.CfnStateMachine.TracingConfigurationProperty(\n            enabled=False\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['role_arn', 'definition', 'definition_s3_location', 'definition_string', 'definition_substitutions', 'logging_configuration', 'state_machine_name', 'state_machine_type', 'tags', 'tracing_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_stepfunctions.CfnStateMachineProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




import models

class ModuleModel(pydantic.BaseModel):
    Chain: typing.Optional[dict[str, ChainDef]] = pydantic.Field(None)
    Condition: typing.Optional[dict[str, ConditionDef]] = pydantic.Field(None)
    Errors: typing.Optional[dict[str, ErrorsDef]] = pydantic.Field(None)
    FieldUtils: typing.Optional[dict[str, FieldUtilsDef]] = pydantic.Field(None)
    JsonPath: typing.Optional[dict[str, JsonPathDef]] = pydantic.Field(None)
    Result: typing.Optional[dict[str, ResultDef]] = pydantic.Field(None)
    State: typing.Optional[dict[str, StateDef]] = pydantic.Field(None)
    StateGraph: typing.Optional[dict[str, StateGraphDef]] = pydantic.Field(None)
    StateMachineFragment: typing.Optional[dict[str, StateMachineFragmentDef]] = pydantic.Field(None)
    StateTransitionMetric: typing.Optional[dict[str, StateTransitionMetricDef]] = pydantic.Field(None)
    TaskInput: typing.Optional[dict[str, TaskInputDef]] = pydantic.Field(None)
    TaskRole: typing.Optional[dict[str, TaskRoleDef]] = pydantic.Field(None)
    TaskStateBase: typing.Optional[dict[str, TaskStateBaseDef]] = pydantic.Field(None)
    Timeout: typing.Optional[dict[str, TimeoutDef]] = pydantic.Field(None)
    WaitTime: typing.Optional[dict[str, WaitTimeDef]] = pydantic.Field(None)
    Activity: typing.Optional[dict[str, ActivityDef]] = pydantic.Field(None)
    Choice: typing.Optional[dict[str, ChoiceDef]] = pydantic.Field(None)
    CustomState: typing.Optional[dict[str, CustomStateDef]] = pydantic.Field(None)
    Fail: typing.Optional[dict[str, FailDef]] = pydantic.Field(None)
    Map: typing.Optional[dict[str, MapDef]] = pydantic.Field(None)
    Parallel: typing.Optional[dict[str, ParallelDef]] = pydantic.Field(None)
    Pass: typing.Optional[dict[str, PassDef]] = pydantic.Field(None)
    StateMachine: typing.Optional[dict[str, StateMachineDef]] = pydantic.Field(None)
    Succeed: typing.Optional[dict[str, SucceedDef]] = pydantic.Field(None)
    Wait: typing.Optional[dict[str, WaitDef]] = pydantic.Field(None)
    ActivityProps: typing.Optional[dict[str, ActivityPropsDef]] = pydantic.Field(None)
    AfterwardsOptions: typing.Optional[dict[str, AfterwardsOptionsDef]] = pydantic.Field(None)
    CatchProps: typing.Optional[dict[str, CatchPropsDef]] = pydantic.Field(None)
    CfnActivity_TagsEntryProperty: typing.Optional[dict[str, CfnActivity_TagsEntryPropertyDef]] = pydantic.Field(None)
    CfnStateMachine_CloudWatchLogsLogGroupProperty: typing.Optional[dict[str, CfnStateMachine_CloudWatchLogsLogGroupPropertyDef]] = pydantic.Field(None)
    CfnStateMachine_LogDestinationProperty: typing.Optional[dict[str, CfnStateMachine_LogDestinationPropertyDef]] = pydantic.Field(None)
    CfnStateMachine_LoggingConfigurationProperty: typing.Optional[dict[str, CfnStateMachine_LoggingConfigurationPropertyDef]] = pydantic.Field(None)
    CfnStateMachine_S3LocationProperty: typing.Optional[dict[str, CfnStateMachine_S3LocationPropertyDef]] = pydantic.Field(None)
    CfnStateMachine_TagsEntryProperty: typing.Optional[dict[str, CfnStateMachine_TagsEntryPropertyDef]] = pydantic.Field(None)
    CfnStateMachine_TracingConfigurationProperty: typing.Optional[dict[str, CfnStateMachine_TracingConfigurationPropertyDef]] = pydantic.Field(None)
    ChoiceProps: typing.Optional[dict[str, ChoicePropsDef]] = pydantic.Field(None)
    Credentials: typing.Optional[dict[str, CredentialsDef]] = pydantic.Field(None)
    CustomStateProps: typing.Optional[dict[str, CustomStatePropsDef]] = pydantic.Field(None)
    FailProps: typing.Optional[dict[str, FailPropsDef]] = pydantic.Field(None)
    FindStateOptions: typing.Optional[dict[str, FindStateOptionsDef]] = pydantic.Field(None)
    LogOptions: typing.Optional[dict[str, LogOptionsDef]] = pydantic.Field(None)
    MapProps: typing.Optional[dict[str, MapPropsDef]] = pydantic.Field(None)
    ParallelProps: typing.Optional[dict[str, ParallelPropsDef]] = pydantic.Field(None)
    PassProps: typing.Optional[dict[str, PassPropsDef]] = pydantic.Field(None)
    RetryProps: typing.Optional[dict[str, RetryPropsDef]] = pydantic.Field(None)
    SingleStateOptions: typing.Optional[dict[str, SingleStateOptionsDef]] = pydantic.Field(None)
    StateMachineProps: typing.Optional[dict[str, StateMachinePropsDef]] = pydantic.Field(None)
    StateProps: typing.Optional[dict[str, StatePropsDef]] = pydantic.Field(None)
    SucceedProps: typing.Optional[dict[str, SucceedPropsDef]] = pydantic.Field(None)
    TaskMetricsConfig: typing.Optional[dict[str, TaskMetricsConfigDef]] = pydantic.Field(None)
    TaskStateBaseProps: typing.Optional[dict[str, TaskStateBasePropsDef]] = pydantic.Field(None)
    WaitProps: typing.Optional[dict[str, WaitPropsDef]] = pydantic.Field(None)
    CfnActivity: typing.Optional[dict[str, CfnActivityDef]] = pydantic.Field(None)
    CfnStateMachine: typing.Optional[dict[str, CfnStateMachineDef]] = pydantic.Field(None)
    CfnActivityProps: typing.Optional[dict[str, CfnActivityPropsDef]] = pydantic.Field(None)
    CfnStateMachineProps: typing.Optional[dict[str, CfnStateMachinePropsDef]] = pydantic.Field(None)
    ...
