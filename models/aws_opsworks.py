from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_opsworks.CfnApp.DataSourceProperty
class CfnApp_DataSourcePropertyDef(BaseStruct):
    arn: typing.Optional[str] = pydantic.Field(None, description="The data source's ARN.")
    database_name: typing.Optional[str] = pydantic.Field(None, description='The database name.\n')
    type: typing.Optional[str] = pydantic.Field(None, description='The data source\'s type, ``AutoSelectOpsworksMysqlInstance`` , ``OpsworksMysqlInstance`` , ``RdsDbInstance`` , or ``None`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-app-datasource.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    data_source_property = opsworks.CfnApp.DataSourceProperty(\n        arn="arn",\n        database_name="databaseName",\n        type="type"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['arn', 'database_name', 'type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnApp.DataSourceProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnApp.EnvironmentVariableProperty
class CfnApp_EnvironmentVariablePropertyDef(BaseStruct):
    key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="(Required) The environment variable's name, which can consist of up to 64 characters and must be specified. The name can contain upper- and lowercase letters, numbers, and underscores (_), but it must start with a letter or underscore.")
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="(Optional) The environment variable's value, which can be left empty. If you specify a value, it can contain up to 256 characters, which must all be printable.\n")
    secure: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='(Optional) Whether the variable\'s value is returned by the ``DescribeApps`` action. To hide an environment variable\'s value, set ``Secure`` to ``true`` . ``DescribeApps`` returns ``*****FILTERED*****`` instead of the actual value. The default value for ``Secure`` is ``false`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-app-environmentvariable.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    environment_variable_property = opsworks.CfnApp.EnvironmentVariableProperty(\n        key="key",\n        value="value",\n\n        # the properties below are optional\n        secure=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['key', 'value', 'secure']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnApp.EnvironmentVariableProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnApp.SourceProperty
class CfnApp_SourcePropertyDef(BaseStruct):
    password: typing.Optional[str] = pydantic.Field(None, description='When included in a request, the parameter depends on the repository type. - For Amazon S3 bundles, set ``Password`` to the appropriate IAM secret access key. - For HTTP bundles and Subversion repositories, set ``Password`` to the password. For more information on how to safely handle IAM credentials, see ` <https://docs.aws.amazon.com/general/latest/gr/aws-access-keys-best-practices.html>`_ . In responses, AWS OpsWorks Stacks returns ``*****FILTERED*****`` instead of the actual value.')
    revision: typing.Optional[str] = pydantic.Field(None, description="The application's version. AWS OpsWorks Stacks enables you to easily deploy new versions of an application. One of the simplest approaches is to have branches or revisions in your repository that represent different versions that can potentially be deployed.\n")
    ssh_key: typing.Optional[str] = pydantic.Field(None, description="In requests, the repository's SSH key. In responses, AWS OpsWorks Stacks returns ``*****FILTERED*****`` instead of the actual value.\n")
    type: typing.Optional[str] = pydantic.Field(None, description='The repository type.\n')
    url: typing.Optional[str] = pydantic.Field(None, description='The source URL. The following is an example of an Amazon S3 source URL: ``https://s3.amazonaws.com/opsworks-demo-bucket/opsworks_cookbook_demo.tar.gz`` .\n')
    username: typing.Optional[str] = pydantic.Field(None, description='This parameter depends on the repository type. - For Amazon S3 bundles, set ``Username`` to the appropriate IAM access key ID. - For HTTP bundles, Git repositories, and Subversion repositories, set ``Username`` to the user name.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-app-source.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    source_property = opsworks.CfnApp.SourceProperty(\n        password="password",\n        revision="revision",\n        ssh_key="sshKey",\n        type="type",\n        url="url",\n        username="username"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['password', 'revision', 'ssh_key', 'type', 'url', 'username']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnApp.SourceProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnApp.SslConfigurationProperty
class CfnApp_SslConfigurationPropertyDef(BaseStruct):
    certificate: typing.Optional[str] = pydantic.Field(None, description="The contents of the certificate's domain.crt file.")
    chain: typing.Optional[str] = pydantic.Field(None, description='Optional. Can be used to specify an intermediate certificate authority key or client authentication.\n')
    private_key: typing.Optional[str] = pydantic.Field(None, description='The private key; the contents of the certificate\'s domain.kex file.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-app-sslconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    ssl_configuration_property = opsworks.CfnApp.SslConfigurationProperty(\n        certificate="certificate",\n        chain="chain",\n        private_key="privateKey"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['certificate', 'chain', 'private_key']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnApp.SslConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnInstance.BlockDeviceMappingProperty
class CfnInstance_BlockDeviceMappingPropertyDef(BaseStruct):
    device_name: typing.Optional[str] = pydantic.Field(None, description='The device name that is exposed to the instance, such as ``/dev/sdh`` . For the root device, you can use the explicit device name or you can set this parameter to ``ROOT_DEVICE`` and AWS OpsWorks Stacks will provide the correct device name.')
    ebs: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnInstance_EbsBlockDevicePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An ``EBSBlockDevice`` that defines how to configure an Amazon EBS volume when the instance is launched. You can specify either the ``VirtualName`` or ``Ebs`` , but not both.\n')
    no_device: typing.Optional[str] = pydantic.Field(None, description="Suppresses the specified device included in the AMI's block device mapping.\n")
    virtual_name: typing.Optional[str] = pydantic.Field(None, description='The virtual device name. For more information, see `BlockDeviceMapping <https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_BlockDeviceMapping.html>`_ . You can specify either the ``VirtualName`` or ``Ebs`` , but not both.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-instance-blockdevicemapping.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    block_device_mapping_property = opsworks.CfnInstance.BlockDeviceMappingProperty(\n        device_name="deviceName",\n        ebs=opsworks.CfnInstance.EbsBlockDeviceProperty(\n            delete_on_termination=False,\n            iops=123,\n            snapshot_id="snapshotId",\n            volume_size=123,\n            volume_type="volumeType"\n        ),\n        no_device="noDevice",\n        virtual_name="virtualName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['device_name', 'ebs', 'no_device', 'virtual_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnInstance.BlockDeviceMappingProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnInstance.EbsBlockDeviceProperty
class CfnInstance_EbsBlockDevicePropertyDef(BaseStruct):
    delete_on_termination: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether the volume is deleted on instance termination.')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='The number of I/O operations per second (IOPS) that the volume supports. For more information, see `EbsBlockDevice <https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_EbsBlockDevice.html>`_ .\n')
    snapshot_id: typing.Optional[str] = pydantic.Field(None, description='The snapshot ID.\n')
    volume_size: typing.Union[int, float, None] = pydantic.Field(None, description='The volume size, in GiB. For more information, see `EbsBlockDevice <https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_EbsBlockDevice.html>`_ .\n')
    volume_type: typing.Optional[str] = pydantic.Field(None, description='The volume type. ``gp2`` for General Purpose (SSD) volumes, ``io1`` for Provisioned IOPS (SSD) volumes, ``st1`` for Throughput Optimized hard disk drives (HDD), ``sc1`` for Cold HDD,and ``standard`` for Magnetic volumes. If you specify the ``io1`` volume type, you must also specify a value for the ``Iops`` attribute. The maximum ratio of provisioned IOPS to requested volume size (in GiB) is 50:1. AWS uses the default volume size (in GiB) specified in the AMI attributes to set IOPS to 50 x (volume size).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-instance-ebsblockdevice.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    ebs_block_device_property = opsworks.CfnInstance.EbsBlockDeviceProperty(\n        delete_on_termination=False,\n        iops=123,\n        snapshot_id="snapshotId",\n        volume_size=123,\n        volume_type="volumeType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['delete_on_termination', 'iops', 'snapshot_id', 'volume_size', 'volume_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnInstance.EbsBlockDeviceProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnInstance.TimeBasedAutoScalingProperty
class CfnInstance_TimeBasedAutoScalingPropertyDef(BaseStruct):
    friday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='The schedule for Friday.')
    monday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='The schedule for Monday.\n')
    saturday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='The schedule for Saturday.\n')
    sunday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='The schedule for Sunday.\n')
    thursday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='The schedule for Thursday.\n')
    tuesday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='The schedule for Tuesday.\n')
    wednesday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='The schedule for Wednesday.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-instance-timebasedautoscaling.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    time_based_auto_scaling_property = opsworks.CfnInstance.TimeBasedAutoScalingProperty(\n        friday={\n            "friday_key": "friday"\n        },\n        monday={\n            "monday_key": "monday"\n        },\n        saturday={\n            "saturday_key": "saturday"\n        },\n        sunday={\n            "sunday_key": "sunday"\n        },\n        thursday={\n            "thursday_key": "thursday"\n        },\n        tuesday={\n            "tuesday_key": "tuesday"\n        },\n        wednesday={\n            "wednesday_key": "wednesday"\n        }\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['friday', 'monday', 'saturday', 'sunday', 'thursday', 'tuesday', 'wednesday']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnInstance.TimeBasedAutoScalingProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnLayer.AutoScalingThresholdsProperty
class CfnLayer_AutoScalingThresholdsPropertyDef(BaseStruct):
    cpu_threshold: typing.Union[int, float, None] = pydantic.Field(None, description='The CPU utilization threshold, as a percent of the available CPU. A value of -1 disables the threshold.')
    ignore_metrics_time: typing.Union[int, float, None] = pydantic.Field(None, description="The amount of time (in minutes) after a scaling event occurs that AWS OpsWorks Stacks should ignore metrics and suppress additional scaling events. For example, AWS OpsWorks Stacks adds new instances following an upscaling event but the instances won't start reducing the load until they have been booted and configured. There is no point in raising additional scaling events during that operation, which typically takes several minutes. ``IgnoreMetricsTime`` allows you to direct AWS OpsWorks Stacks to suppress scaling events long enough to get the new instances online.\n")
    instance_count: typing.Union[int, float, None] = pydantic.Field(None, description='The number of instances to add or remove when the load exceeds a threshold.\n')
    load_threshold: typing.Union[int, float, None] = pydantic.Field(None, description='The load threshold. A value of -1 disables the threshold. For more information about how load is computed, see `Load (computing) <https://docs.aws.amazon.com/http://en.wikipedia.org/wiki/Load_%28computing%29>`_ .\n')
    memory_threshold: typing.Union[int, float, None] = pydantic.Field(None, description='The memory utilization threshold, as a percent of the available memory. A value of -1 disables the threshold.\n')
    thresholds_wait_time: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time, in minutes, that the load must exceed a threshold before more instances are added or removed.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-layer-autoscalingthresholds.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    auto_scaling_thresholds_property = opsworks.CfnLayer.AutoScalingThresholdsProperty(\n        cpu_threshold=123,\n        ignore_metrics_time=123,\n        instance_count=123,\n        load_threshold=123,\n        memory_threshold=123,\n        thresholds_wait_time=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cpu_threshold', 'ignore_metrics_time', 'instance_count', 'load_threshold', 'memory_threshold', 'thresholds_wait_time']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnLayer.AutoScalingThresholdsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnLayer.LifecycleEventConfigurationProperty
class CfnLayer_LifecycleEventConfigurationPropertyDef(BaseStruct):
    shutdown_event_configuration: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_ShutdownEventConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Shutdown event configuration.')
    _init_params: typing.ClassVar[list[str]] = ['shutdown_event_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnLayer.LifecycleEventConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnLayer.LoadBasedAutoScalingProperty
class CfnLayer_LoadBasedAutoScalingPropertyDef(BaseStruct):
    down_scaling: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_AutoScalingThresholdsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An ``AutoScalingThresholds`` object that describes the downscaling configuration, which defines how and when AWS OpsWorks Stacks reduces the number of instances.')
    enable: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether load-based auto scaling is enabled for the layer.\n')
    up_scaling: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_AutoScalingThresholdsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An ``AutoScalingThresholds`` object that describes the upscaling configuration, which defines how and when AWS OpsWorks Stacks increases the number of instances.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-layer-loadbasedautoscaling.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    load_based_auto_scaling_property = opsworks.CfnLayer.LoadBasedAutoScalingProperty(\n        down_scaling=opsworks.CfnLayer.AutoScalingThresholdsProperty(\n            cpu_threshold=123,\n            ignore_metrics_time=123,\n            instance_count=123,\n            load_threshold=123,\n            memory_threshold=123,\n            thresholds_wait_time=123\n        ),\n        enable=False,\n        up_scaling=opsworks.CfnLayer.AutoScalingThresholdsProperty(\n            cpu_threshold=123,\n            ignore_metrics_time=123,\n            instance_count=123,\n            load_threshold=123,\n            memory_threshold=123,\n            thresholds_wait_time=123\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['down_scaling', 'enable', 'up_scaling']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnLayer.LoadBasedAutoScalingProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnLayer.RecipesProperty
class CfnLayer_RecipesPropertyDef(BaseStruct):
    configure: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of custom recipe names to be run following a ``configure`` event.')
    deploy: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of custom recipe names to be run following a ``deploy`` event.\n')
    setup: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of custom recipe names to be run following a ``setup`` event.\n')
    shutdown: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of custom recipe names to be run following a ``shutdown`` event.\n')
    undeploy: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of custom recipe names to be run following a ``undeploy`` event.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-layer-recipes.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    recipes_property = opsworks.CfnLayer.RecipesProperty(\n        configure=["configure"],\n        deploy=["deploy"],\n        setup=["setup"],\n        shutdown=["shutdown"],\n        undeploy=["undeploy"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['configure', 'deploy', 'setup', 'shutdown', 'undeploy']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnLayer.RecipesProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnLayer.ShutdownEventConfigurationProperty
class CfnLayer_ShutdownEventConfigurationPropertyDef(BaseStruct):
    delay_until_elb_connections_drained: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to enable Elastic Load Balancing connection draining. For more information, see `Connection Draining <https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html#conn-drain>`_')
    execution_timeout: typing.Union[int, float, None] = pydantic.Field(None, description='The time, in seconds, that AWS OpsWorks Stacks waits after triggering a Shutdown event before shutting down an instance.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-layer-shutdowneventconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    shutdown_event_configuration_property = opsworks.CfnLayer.ShutdownEventConfigurationProperty(\n        delay_until_elb_connections_drained=False,\n        execution_timeout=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['delay_until_elb_connections_drained', 'execution_timeout']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnLayer.ShutdownEventConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnLayer.VolumeConfigurationProperty
class CfnLayer_VolumeConfigurationPropertyDef(BaseStruct):
    encrypted: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Specifies whether an Amazon EBS volume is encrypted. For more information, see `Amazon EBS Encryption <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html>`_ .')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='The number of I/O operations per second (IOPS) to provision for the volume. For PIOPS volumes, the IOPS per disk. If you specify ``io1`` for the volume type, you must specify this property.\n')
    mount_point: typing.Optional[str] = pydantic.Field(None, description='The volume mount point. For example "/dev/sdh".\n')
    number_of_disks: typing.Union[int, float, None] = pydantic.Field(None, description='The number of disks in the volume.\n')
    raid_level: typing.Union[int, float, None] = pydantic.Field(None, description='The volume `RAID level <https://docs.aws.amazon.com/http://en.wikipedia.org/wiki/Standard_RAID_levels>`_ .\n')
    size: typing.Union[int, float, None] = pydantic.Field(None, description='The volume size.\n')
    volume_type: typing.Optional[str] = pydantic.Field(None, description='The volume type. For more information, see `Amazon EBS Volume Types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html>`_ . - ``standard`` - Magnetic. Magnetic volumes must have a minimum size of 1 GiB and a maximum size of 1024 GiB. - ``io1`` - Provisioned IOPS (SSD). PIOPS volumes must have a minimum size of 4 GiB and a maximum size of 16384 GiB. - ``gp2`` - General Purpose (SSD). General purpose volumes must have a minimum size of 1 GiB and a maximum size of 16384 GiB. - ``st1`` - Throughput Optimized hard disk drive (HDD). Throughput optimized HDD volumes must have a minimum size of 500 GiB and a maximum size of 16384 GiB. - ``sc1`` - Cold HDD. Cold HDD volumes must have a minimum size of 500 GiB and a maximum size of 16384 GiB.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-layer-volumeconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    volume_configuration_property = opsworks.CfnLayer.VolumeConfigurationProperty(\n        encrypted=False,\n        iops=123,\n        mount_point="mountPoint",\n        number_of_disks=123,\n        raid_level=123,\n        size=123,\n        volume_type="volumeType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['encrypted', 'iops', 'mount_point', 'number_of_disks', 'raid_level', 'size', 'volume_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnLayer.VolumeConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnStack.ChefConfigurationProperty
class CfnStack_ChefConfigurationPropertyDef(BaseStruct):
    berkshelf_version: typing.Optional[str] = pydantic.Field(None, description='The Berkshelf version.')
    manage_berkshelf: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to enable Berkshelf.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-stack-chefconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    chef_configuration_property = opsworks.CfnStack.ChefConfigurationProperty(\n        berkshelf_version="berkshelfVersion",\n        manage_berkshelf=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['berkshelf_version', 'manage_berkshelf']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnStack.ChefConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnStack.ElasticIpProperty
class CfnStack_ElasticIpPropertyDef(BaseStruct):
    ip: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The IP address.')
    name: typing.Optional[str] = pydantic.Field(None, description='The name, which can be a maximum of 32 characters.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-stack-elasticip.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    elastic_ip_property = opsworks.CfnStack.ElasticIpProperty(\n        ip="ip",\n\n        # the properties below are optional\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['ip', 'name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnStack.ElasticIpProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnStack.RdsDbInstanceProperty
class CfnStack_RdsDbInstancePropertyDef(BaseStruct):
    db_password: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='AWS OpsWorks Stacks returns ``*****FILTERED*****`` instead of the actual value.')
    db_user: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The master user name.\n')
    rds_db_instance_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The instance\'s ARN.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-stack-rdsdbinstance.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    rds_db_instance_property = opsworks.CfnStack.RdsDbInstanceProperty(\n        db_password="dbPassword",\n        db_user="dbUser",\n        rds_db_instance_arn="rdsDbInstanceArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['db_password', 'db_user', 'rds_db_instance_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnStack.RdsDbInstanceProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnStack.SourceProperty
class CfnStack_SourcePropertyDef(BaseStruct):
    password: typing.Optional[str] = pydantic.Field(None, description='When included in a request, the parameter depends on the repository type. - For Amazon S3 bundles, set ``Password`` to the appropriate IAM secret access key. - For HTTP bundles and Subversion repositories, set ``Password`` to the password. For more information on how to safely handle IAM credentials, see ` <https://docs.aws.amazon.com/general/latest/gr/aws-access-keys-best-practices.html>`_ . In responses, AWS OpsWorks Stacks returns ``*****FILTERED*****`` instead of the actual value.')
    revision: typing.Optional[str] = pydantic.Field(None, description="The application's version. AWS OpsWorks Stacks enables you to easily deploy new versions of an application. One of the simplest approaches is to have branches or revisions in your repository that represent different versions that can potentially be deployed.\n")
    ssh_key: typing.Optional[str] = pydantic.Field(None, description='The repository\'s SSH key. For more information, see `Using Git Repository SSH Keys <https://docs.aws.amazon.com/opsworks/latest/userguide/workingapps-deploykeys.html>`_ in the *AWS OpsWorks User Guide* . To pass in an SSH key as a parameter, see the following example: ``"Parameters" : { "GitSSHKey" : { "Description" : "Change SSH key newlines to commas.", "Type" : "CommaDelimitedList", "NoEcho" : "true" }, ... "CustomCookbooksSource": { "Revision" : { "Ref": "GitRevision"}, "SshKey" : { "Fn::Join" : [ "\\n", { "Ref": "GitSSHKey"} ] }, "Type": "git", "Url": { "Ref": "GitURL"} } ...``\n')
    type: typing.Optional[str] = pydantic.Field(None, description='The repository type.\n')
    url: typing.Optional[str] = pydantic.Field(None, description='The source URL. The following is an example of an Amazon S3 source URL: ``https://s3.amazonaws.com/opsworks-demo-bucket/opsworks_cookbook_demo.tar.gz`` .\n')
    username: typing.Optional[str] = pydantic.Field(None, description='This parameter depends on the repository type. - For Amazon S3 bundles, set ``Username`` to the appropriate IAM access key ID. - For HTTP bundles, Git repositories, and Subversion repositories, set ``Username`` to the user name.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-stack-source.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    source_property = opsworks.CfnStack.SourceProperty(\n        password="password",\n        revision="revision",\n        ssh_key="sshKey",\n        type="type",\n        url="url",\n        username="username"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['password', 'revision', 'ssh_key', 'type', 'url', 'username']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnStack.SourceProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnStack.StackConfigurationManagerProperty
class CfnStack_StackConfigurationManagerPropertyDef(BaseStruct):
    name: typing.Optional[str] = pydantic.Field(None, description='The name. This parameter must be set to ``Chef`` .')
    version: typing.Optional[str] = pydantic.Field(None, description='The Chef version. This parameter must be set to 12, 11.10, or 11.4 for Linux stacks, and to 12.2 for Windows stacks. The default value for Linux stacks is 12.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-opsworks-stack-stackconfigurationmanager.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    stack_configuration_manager_property = opsworks.CfnStack.StackConfigurationManagerProperty(\n        name="name",\n        version="version"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnStack.StackConfigurationManagerProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnApp
class CfnAppDef(BaseCfnResource):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The app name.\n')
    stack_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The stack ID.\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The app type. Each supported type is associated with a particular layer. For example, PHP applications are associated with a PHP layer. AWS OpsWorks Stacks deploys an application to those instances that are members of the corresponding layer. If your app isn't one of the standard types, or you prefer to implement your own Deploy recipes, specify ``other`` .\n")
    app_source: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnApp_SourcePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A ``Source`` object that specifies the app repository.\n')
    attributes: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='One or more user-defined key/value pairs to be added to the stack attributes.\n')
    data_sources: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnApp_DataSourcePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="The app's data source.\n")
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the app.\n')
    domains: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="The app virtual host settings, with multiple domains separated by commas. For example: ``'www.example.com, example.com'``\n")
    enable_ssl: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to enable SSL for the app.\n')
    environment: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnApp_EnvironmentVariablePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='An array of ``EnvironmentVariable`` objects that specify environment variables to be associated with the app. After you deploy the app, these variables are defined on the associated app server instance. For more information, see `Environment Variables <https://docs.aws.amazon.com/opsworks/latest/userguide/workingapps-creating.html#workingapps-creating-environment>`_ . There is no specific limit on the number of environment variables. However, the size of the associated data structure - which includes the variables\' names, values, and protected flag values - cannot exceed 20 KB. This limit should accommodate most if not all use cases. Exceeding it will cause an exception with the message, "Environment: is too large (maximum is 20KB)." .. epigraph:: If you have specified one or more environment variables, you cannot modify the stack\'s Chef version.\n')
    shortname: typing.Optional[str] = pydantic.Field(None, description="The app's short name.\n")
    ssl_configuration: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnApp_SslConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An ``SslConfiguration`` object with the SSL configuration.')
    _init_params: typing.ClassVar[list[str]] = ['name', 'stack_id', 'type', 'app_source', 'attributes', 'data_sources', 'description', 'domains', 'enable_ssl', 'environment', 'shortname', 'ssl_configuration']
    _method_names: typing.ClassVar[list[str]] = ['DataSourceProperty', 'EnvironmentVariableProperty', 'SourceProperty', 'SslConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnApp'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnAppDefConfig] = pydantic.Field(None)


class CfnAppDefConfig(pydantic.BaseModel):
    DataSourceProperty: typing.Optional[list[CfnAppDefDatasourcepropertyParams]] = pydantic.Field(None, description='')
    EnvironmentVariableProperty: typing.Optional[list[CfnAppDefEnvironmentvariablepropertyParams]] = pydantic.Field(None, description='')
    SourceProperty: typing.Optional[list[CfnAppDefSourcepropertyParams]] = pydantic.Field(None, description='')
    SslConfigurationProperty: typing.Optional[list[CfnAppDefSslconfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnAppDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnAppDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnAppDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnAppDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnAppDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnAppDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnAppDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnAppDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnAppDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnAppDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnAppDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnAppDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnAppDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnAppDefDatasourcepropertyParams(pydantic.BaseModel):
    arn: typing.Optional[str] = pydantic.Field(None, description='')
    database_name: typing.Optional[str] = pydantic.Field(None, description='')
    type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnAppDefEnvironmentvariablepropertyParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='')
    value: str = pydantic.Field(..., description='')
    secure: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnAppDefSourcepropertyParams(pydantic.BaseModel):
    password: typing.Optional[str] = pydantic.Field(None, description='')
    revision: typing.Optional[str] = pydantic.Field(None, description='')
    ssh_key: typing.Optional[str] = pydantic.Field(None, description='')
    type: typing.Optional[str] = pydantic.Field(None, description='')
    url: typing.Optional[str] = pydantic.Field(None, description='')
    username: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnAppDefSslconfigurationpropertyParams(pydantic.BaseModel):
    certificate: typing.Optional[str] = pydantic.Field(None, description='')
    chain: typing.Optional[str] = pydantic.Field(None, description='')
    private_key: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnAppDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnAppDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnAppDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnAppDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnAppDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnAppDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnAppDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnAppDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnAppDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnAppDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnAppDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnAppDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnAppDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnAppDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_opsworks.CfnElasticLoadBalancerAttachment
class CfnElasticLoadBalancerAttachmentDef(BaseCfnResource):
    elastic_load_balancer_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Elastic Load Balancing instance name.\n')
    layer_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS OpsWorks layer ID to which the Elastic Load Balancing load balancer is attached.')
    _init_params: typing.ClassVar[list[str]] = ['elastic_load_balancer_name', 'layer_id']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnElasticLoadBalancerAttachment'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnElasticLoadBalancerAttachmentDefConfig] = pydantic.Field(None)


class CfnElasticLoadBalancerAttachmentDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnElasticLoadBalancerAttachmentDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnElasticLoadBalancerAttachmentDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnElasticLoadBalancerAttachmentDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnElasticLoadBalancerAttachmentDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnElasticLoadBalancerAttachmentDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnElasticLoadBalancerAttachmentDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnElasticLoadBalancerAttachmentDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnElasticLoadBalancerAttachmentDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnElasticLoadBalancerAttachmentDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnElasticLoadBalancerAttachmentDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnElasticLoadBalancerAttachmentDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnElasticLoadBalancerAttachmentDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnElasticLoadBalancerAttachmentDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnElasticLoadBalancerAttachmentDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnElasticLoadBalancerAttachmentDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_opsworks.CfnInstance
class CfnInstanceDef(BaseCfnResource):
    instance_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The instance type, such as ``t2.micro`` . For a list of supported instance types, open the stack in the console, choose *Instances* , and choose *+ Instance* . The *Size* list contains the currently supported types. For more information, see `Instance Families and Types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html>`_ . The parameter values that you use to specify the various types are in the *API Name* column of the *Available Instance Types* table.\n')
    layer_ids: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="An array that contains the instance's layer IDs.\n")
    stack_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The stack ID.\n')
    agent_version: typing.Optional[str] = pydantic.Field(None, description="The default AWS OpsWorks Stacks agent version. You have the following options:. - ``INHERIT`` - Use the stack's default agent version setting. - *version_number* - Use the specified agent version. This value overrides the stack's default setting. To update the agent version, edit the instance configuration and specify a new version. AWS OpsWorks Stacks installs that version on the instance. The default setting is ``INHERIT`` . To specify an agent version, you must use the complete version number, not the abbreviated number shown on the console. For a list of available agent version numbers, call ``DescribeAgentVersions`` . AgentVersion cannot be set to Chef 12.2.\n")
    ami_id: typing.Optional[str] = pydantic.Field(None, description='A custom AMI ID to be used to create the instance. The AMI should be based on one of the supported operating systems. For more information, see `Using Custom AMIs <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-custom-ami.html>`_ . .. epigraph:: If you specify a custom AMI, you must set ``Os`` to ``Custom`` .\n')
    architecture: typing.Optional[str] = pydantic.Field(None, description='The instance architecture. The default option is ``x86_64`` . Instance types do not necessarily support both architectures. For a list of the architectures that are supported by the different instance types, see `Instance Families and Types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html>`_ .\n')
    auto_scaling_type: typing.Optional[str] = pydantic.Field(None, description='For load-based or time-based instances, the type. Windows stacks can use only time-based instances.\n')
    availability_zone: typing.Optional[str] = pydantic.Field(None, description='The Availability Zone of the AWS OpsWorks instance, such as ``us-east-2a`` .\n')
    block_device_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnInstance_BlockDeviceMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="An array of ``BlockDeviceMapping`` objects that specify the instance's block devices. For more information, see `Block Device Mapping <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html>`_ . Note that block device mappings are not supported for custom AMIs.\n")
    ebs_optimized: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to create an Amazon EBS-optimized instance.\n')
    elastic_ips: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of Elastic IP addresses to associate with the instance.\n')
    hostname: typing.Optional[str] = pydantic.Field(None, description='The instance host name. The following are character limits for instance host names. - Linux-based instances: 63 characters - Windows-based instances: 15 characters\n')
    install_updates_on_boot: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to install operating system and package updates when the instance boots. The default value is ``true`` . To control when updates are installed, set this value to ``false`` . You must then update your instances manually by using ``CreateDeployment`` to run the ``update_dependencies`` stack command or by manually running ``yum`` (Amazon Linux) or ``apt-get`` (Ubuntu) on the instances. .. epigraph:: We strongly recommend using the default value of ``true`` to ensure that your instances have the latest security updates.\n')
    os: typing.Optional[str] = pydantic.Field(None, description="The instance's operating system, which must be set to one of the following. - A supported Linux operating system: An Amazon Linux version, such as ``Amazon Linux 2`` , ``Amazon Linux 2018.03`` , ``Amazon Linux 2017.09`` , ``Amazon Linux 2017.03`` , ``Amazon Linux 2016.09`` , ``Amazon Linux 2016.03`` , ``Amazon Linux 2015.09`` , or ``Amazon Linux 2015.03`` . - A supported Ubuntu operating system, such as ``Ubuntu 18.04 LTS`` , ``Ubuntu 16.04 LTS`` , ``Ubuntu 14.04 LTS`` , or ``Ubuntu 12.04 LTS`` . - ``CentOS Linux 7`` - ``Red Hat Enterprise Linux 7`` - A supported Windows operating system, such as ``Microsoft Windows Server 2012 R2 Base`` , ``Microsoft Windows Server 2012 R2 with SQL Server Express`` , ``Microsoft Windows Server 2012 R2 with SQL Server Standard`` , or ``Microsoft Windows Server 2012 R2 with SQL Server Web`` . - A custom AMI: ``Custom`` . Not all operating systems are supported with all versions of Chef. For more information about the supported operating systems, see `AWS OpsWorks Stacks Operating Systems <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-os.html>`_ . The default option is the current Amazon Linux version. If you set this parameter to ``Custom`` , you must use the ``CreateInstance`` action's AmiId parameter to specify the custom AMI that you want to use. Block device mappings are not supported if the value is ``Custom`` . For more information about how to use custom AMIs with AWS OpsWorks Stacks, see `Using Custom AMIs <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-custom-ami.html>`_ .\n")
    root_device_type: typing.Optional[str] = pydantic.Field(None, description='The instance root device type. For more information, see `Storage for the Root Device <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ComponentsAMIs.html#storage-for-the-root-device>`_ .\n')
    ssh_key_name: typing.Optional[str] = pydantic.Field(None, description="The instance's Amazon EC2 key-pair name.\n")
    subnet_id: typing.Optional[str] = pydantic.Field(None, description="The ID of the instance's subnet. If the stack is running in a VPC, you can use this parameter to override the stack's default subnet ID value and direct AWS OpsWorks Stacks to launch the instance in a different subnet.\n")
    tenancy: typing.Optional[str] = pydantic.Field(None, description="The instance's tenancy option. The default option is no tenancy, or if the instance is running in a VPC, inherit tenancy settings from the VPC. The following are valid values for this parameter: ``dedicated`` , ``default`` , or ``host`` . Because there are costs associated with changes in tenancy options, we recommend that you research tenancy options before choosing them for your instances. For more information about dedicated hosts, see `Dedicated Hosts Overview <https://docs.aws.amazon.com/ec2/dedicated-hosts/>`_ and `Amazon EC2 Dedicated Hosts <https://docs.aws.amazon.com/ec2/dedicated-hosts/>`_ . For more information about dedicated instances, see `Dedicated Instances <https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/dedicated-instance.html>`_ and `Amazon EC2 Dedicated Instances <https://docs.aws.amazon.com/ec2/purchasing-options/dedicated-instances/>`_ .\n")
    time_based_auto_scaling: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnInstance_TimeBasedAutoScalingPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The time-based scaling configuration for the instance.\n')
    virtualization_type: typing.Optional[str] = pydantic.Field(None, description="The instance's virtualization type, ``paravirtual`` or ``hvm`` .\n")
    volumes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of AWS OpsWorks volume IDs to associate with the instance. For more information, see ```AWS::OpsWorks::Volume`` <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-opsworks-volume.html>`_ .')
    _init_params: typing.ClassVar[list[str]] = ['instance_type', 'layer_ids', 'stack_id', 'agent_version', 'ami_id', 'architecture', 'auto_scaling_type', 'availability_zone', 'block_device_mappings', 'ebs_optimized', 'elastic_ips', 'hostname', 'install_updates_on_boot', 'os', 'root_device_type', 'ssh_key_name', 'subnet_id', 'tenancy', 'time_based_auto_scaling', 'virtualization_type', 'volumes']
    _method_names: typing.ClassVar[list[str]] = ['BlockDeviceMappingProperty', 'EbsBlockDeviceProperty', 'TimeBasedAutoScalingProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnInstance'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnInstanceDefConfig] = pydantic.Field(None)


class CfnInstanceDefConfig(pydantic.BaseModel):
    BlockDeviceMappingProperty: typing.Optional[list[CfnInstanceDefBlockdevicemappingpropertyParams]] = pydantic.Field(None, description='')
    EbsBlockDeviceProperty: typing.Optional[list[CfnInstanceDefEbsblockdevicepropertyParams]] = pydantic.Field(None, description='')
    TimeBasedAutoScalingProperty: typing.Optional[list[CfnInstanceDefTimebasedautoscalingpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnInstanceDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnInstanceDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnInstanceDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnInstanceDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnInstanceDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnInstanceDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnInstanceDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnInstanceDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnInstanceDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnInstanceDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnInstanceDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnInstanceDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnInstanceDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnInstanceDefBlockdevicemappingpropertyParams(pydantic.BaseModel):
    device_name: typing.Optional[str] = pydantic.Field(None, description='')
    ebs: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnInstance_EbsBlockDevicePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    no_device: typing.Optional[str] = pydantic.Field(None, description='')
    virtual_name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnInstanceDefEbsblockdevicepropertyParams(pydantic.BaseModel):
    delete_on_termination: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='')
    snapshot_id: typing.Optional[str] = pydantic.Field(None, description='')
    volume_size: typing.Union[int, float, None] = pydantic.Field(None, description='')
    volume_type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnInstanceDefTimebasedautoscalingpropertyParams(pydantic.BaseModel):
    friday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    monday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    saturday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    sunday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    thursday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    tuesday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    wednesday: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    ...

class CfnInstanceDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnInstanceDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnInstanceDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnInstanceDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnInstanceDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnInstanceDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnInstanceDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnInstanceDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnInstanceDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnInstanceDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnInstanceDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnInstanceDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnInstanceDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnInstanceDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_opsworks.CfnLayer
class CfnLayerDef(BaseCfnResource):
    auto_assign_elastic_ips: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description="Whether to automatically assign an `Elastic IP address <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html>`_ to the layer's instances. For more information, see `How to Edit a Layer <https://docs.aws.amazon.com/opsworks/latest/userguide/workinglayers-basics-edit.html>`_ .\n")
    auto_assign_public_ips: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description="For stacks that are running in a VPC, whether to automatically assign a public IP address to the layer's instances. For more information, see `How to Edit a Layer <https://docs.aws.amazon.com/opsworks/latest/userguide/workinglayers-basics-edit.html>`_ .\n")
    enable_auto_healing: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Whether to disable auto healing for the layer.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The layer name, which is used by the console. Layer names can be a maximum of 32 characters.\n')
    shortname: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="For custom layers only, use this parameter to specify the layer's short name, which is used internally by AWS OpsWorks Stacks and by Chef recipes. The short name is also used as the name for the directory where your app files are installed. It can have a maximum of 32 characters, which are limited to the alphanumeric characters, '-', '_', and '.'. Built-in layer short names are defined by AWS OpsWorks Stacks. For more information, see the `Layer Reference <https://docs.aws.amazon.com/opsworks/latest/userguide/layers.html>`_ .\n")
    stack_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The layer stack ID.\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The layer type. A stack cannot have more than one built-in layer of the same type. It can have any number of custom layers. Built-in layers are not available in Chef 12 stacks.\n')
    attributes: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description="One or more user-defined key-value pairs to be added to the stack attributes. To create a cluster layer, set the ``EcsClusterArn`` attribute to the cluster's ARN.\n")
    custom_instance_profile_arn: typing.Optional[str] = pydantic.Field(None, description="The ARN of an IAM profile to be used for the layer's EC2 instances. For more information about IAM ARNs, see `Using Identifiers <https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html>`_ .\n")
    custom_json: typing.Any = pydantic.Field(None, description="A JSON-formatted string containing custom stack configuration and deployment attributes to be installed on the layer's instances. For more information, see `Using Custom JSON <https://docs.aws.amazon.com/opsworks/latest/userguide/workingcookbook-json-override.html>`_ . This feature is supported as of version 1.7.42 of the AWS CLI .\n")
    custom_recipes: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_RecipesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A ``LayerCustomRecipes`` object that specifies the layer custom recipes.\n')
    custom_security_group_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array containing the layer custom security group IDs.\n')
    install_updates_on_boot: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to install operating system and package updates when the instance boots. The default value is ``true`` . To control when updates are installed, set this value to ``false`` . You must then update your instances manually by using ``CreateDeployment`` to run the ``update_dependencies`` stack command or by manually running ``yum`` (Amazon Linux) or ``apt-get`` (Ubuntu) on the instances. .. epigraph:: To ensure that your instances have the latest security updates, we strongly recommend using the default value of ``true`` .\n')
    lifecycle_event_configuration: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_LifecycleEventConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A ``LifeCycleEventConfiguration`` object that you can use to configure the Shutdown event to specify an execution timeout and enable or disable Elastic Load Balancer connection draining.\n')
    load_based_auto_scaling: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_LoadBasedAutoScalingPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The load-based scaling configuration for the AWS OpsWorks layer.\n')
    packages: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of ``Package`` objects that describes the layer packages.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies one or more sets of tags (keyvalue pairs) to associate with this AWS OpsWorks layer. Use tags to manage your resources.\n')
    use_ebs_optimized_instances: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to use Amazon EBS-optimized instances.\n')
    volume_configurations: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_VolumeConfigurationPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="A ``VolumeConfigurations`` object that describes the layer's Amazon EBS volumes.")
    _init_params: typing.ClassVar[list[str]] = ['auto_assign_elastic_ips', 'auto_assign_public_ips', 'enable_auto_healing', 'name', 'shortname', 'stack_id', 'type', 'attributes', 'custom_instance_profile_arn', 'custom_json', 'custom_recipes', 'custom_security_group_ids', 'install_updates_on_boot', 'lifecycle_event_configuration', 'load_based_auto_scaling', 'packages', 'tags', 'use_ebs_optimized_instances', 'volume_configurations']
    _method_names: typing.ClassVar[list[str]] = ['AutoScalingThresholdsProperty', 'LifecycleEventConfigurationProperty', 'LoadBasedAutoScalingProperty', 'RecipesProperty', 'ShutdownEventConfigurationProperty', 'VolumeConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnLayer'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnLayerDefConfig] = pydantic.Field(None)


class CfnLayerDefConfig(pydantic.BaseModel):
    AutoScalingThresholdsProperty: typing.Optional[list[CfnLayerDefAutoscalingthresholdspropertyParams]] = pydantic.Field(None, description='')
    LifecycleEventConfigurationProperty: typing.Optional[list[CfnLayerDefLifecycleeventconfigurationpropertyParams]] = pydantic.Field(None, description='')
    LoadBasedAutoScalingProperty: typing.Optional[list[CfnLayerDefLoadbasedautoscalingpropertyParams]] = pydantic.Field(None, description='')
    RecipesProperty: typing.Optional[list[CfnLayerDefRecipespropertyParams]] = pydantic.Field(None, description='')
    ShutdownEventConfigurationProperty: typing.Optional[list[CfnLayerDefShutdowneventconfigurationpropertyParams]] = pydantic.Field(None, description='')
    VolumeConfigurationProperty: typing.Optional[list[CfnLayerDefVolumeconfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnLayerDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnLayerDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnLayerDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnLayerDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnLayerDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnLayerDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnLayerDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnLayerDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnLayerDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnLayerDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnLayerDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnLayerDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnLayerDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLayerDefAutoscalingthresholdspropertyParams(pydantic.BaseModel):
    cpu_threshold: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ignore_metrics_time: typing.Union[int, float, None] = pydantic.Field(None, description='')
    instance_count: typing.Union[int, float, None] = pydantic.Field(None, description='')
    load_threshold: typing.Union[int, float, None] = pydantic.Field(None, description='')
    memory_threshold: typing.Union[int, float, None] = pydantic.Field(None, description='')
    thresholds_wait_time: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnLayerDefLifecycleeventconfigurationpropertyParams(pydantic.BaseModel):
    shutdown_event_configuration: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_ShutdownEventConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnLayerDefLoadbasedautoscalingpropertyParams(pydantic.BaseModel):
    down_scaling: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_AutoScalingThresholdsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    enable: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    up_scaling: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_AutoScalingThresholdsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnLayerDefRecipespropertyParams(pydantic.BaseModel):
    configure: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    deploy: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    setup: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    shutdown: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    undeploy: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnLayerDefShutdowneventconfigurationpropertyParams(pydantic.BaseModel):
    delay_until_elb_connections_drained: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    execution_timeout: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnLayerDefVolumeconfigurationpropertyParams(pydantic.BaseModel):
    encrypted: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    iops: typing.Union[int, float, None] = pydantic.Field(None, description='')
    mount_point: typing.Optional[str] = pydantic.Field(None, description='')
    number_of_disks: typing.Union[int, float, None] = pydantic.Field(None, description='')
    raid_level: typing.Union[int, float, None] = pydantic.Field(None, description='')
    size: typing.Union[int, float, None] = pydantic.Field(None, description='')
    volume_type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnLayerDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLayerDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLayerDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLayerDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLayerDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLayerDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLayerDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLayerDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLayerDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLayerDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLayerDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLayerDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLayerDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLayerDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_opsworks.CfnStack
class CfnStackDef(BaseCfnResource):
    default_instance_profile_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The Amazon Resource Name (ARN) of an IAM profile that is the default profile for all of the stack's EC2 instances. For more information about IAM ARNs, see `Using Identifiers <https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html>`_ .\n")
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The stack name. Stack names can be a maximum of 64 characters.\n')
    service_role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The stack's IAM role, which allows AWS OpsWorks Stacks to work with AWS resources on your behalf. You must set this parameter to the Amazon Resource Name (ARN) for an existing IAM role. For more information about IAM ARNs, see `Using Identifiers <https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html>`_ .\n")
    agent_version: typing.Optional[str] = pydantic.Field(None, description="The default AWS OpsWorks Stacks agent version. You have the following options:. - Auto-update - Set this parameter to ``LATEST`` . AWS OpsWorks Stacks automatically installs new agent versions on the stack's instances as soon as they are available. - Fixed version - Set this parameter to your preferred agent version. To update the agent version, you must edit the stack configuration and specify a new version. AWS OpsWorks Stacks installs that version on the stack's instances. The default setting is the most recent release of the agent. To specify an agent version, you must use the complete version number, not the abbreviated number shown on the console. For a list of available agent version numbers, call ``DescribeAgentVersions`` . AgentVersion cannot be set to Chef 12.2. .. epigraph:: You can also specify an agent version when you create or update an instance, which overrides the stack's default setting.\n")
    attributes: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='One or more user-defined key-value pairs to be added to the stack attributes.\n')
    chef_configuration: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnStack_ChefConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A ``ChefConfiguration`` object that specifies whether to enable Berkshelf and the Berkshelf version on Chef 11.10 stacks. For more information, see `Create a New Stack <https://docs.aws.amazon.com/opsworks/latest/userguide/workingstacks-creating.html>`_ .\n')
    clone_app_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="If you're cloning an AWS OpsWorks stack, a list of AWS OpsWorks application stack IDs from the source stack to include in the cloned stack.\n")
    clone_permissions: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="If you're cloning an AWS OpsWorks stack, indicates whether to clone the source stack's permissions.\n")
    configuration_manager: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnStack_StackConfigurationManagerPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration manager. When you create a stack we recommend that you use the configuration manager to specify the Chef version: 12, 11.10, or 11.4 for Linux stacks, or 12.2 for Windows stacks. The default value for Linux stacks is currently 12.\n')
    custom_cookbooks_source: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnStack_SourcePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Contains the information required to retrieve an app or cookbook from a repository. For more information, see `Adding Apps <https://docs.aws.amazon.com/opsworks/latest/userguide/workingapps-creating.html>`_ or `Cookbooks and Recipes <https://docs.aws.amazon.com/opsworks/latest/userguide/workingcookbook.html>`_ .\n')
    custom_json: typing.Any = pydantic.Field(None, description='A string that contains user-defined, custom JSON. It can be used to override the corresponding default stack configuration attribute values or to pass data to recipes. The string should be in the following format: ``"{\\"key1\\": \\"value1\\", \\"key2\\": \\"value2\\",...}"`` For more information about custom JSON, see `Use Custom JSON to Modify the Stack Configuration Attributes <https://docs.aws.amazon.com/opsworks/latest/userguide/workingstacks-json.html>`_ .\n')
    default_availability_zone: typing.Optional[str] = pydantic.Field(None, description="The stack's default Availability Zone, which must be in the specified region. For more information, see `Regions and Endpoints <https://docs.aws.amazon.com/general/latest/gr/rande.html>`_ . If you also specify a value for ``DefaultSubnetId`` , the subnet must be in the same zone. For more information, see the ``VpcId`` parameter description.\n")
    default_os: typing.Optional[str] = pydantic.Field(None, description="The stack's default operating system, which is installed on every instance unless you specify a different operating system when you create the instance. You can specify one of the following. - A supported Linux operating system: An Amazon Linux version, such as ``Amazon Linux 2`` , ``Amazon Linux 2018.03`` , ``Amazon Linux 2017.09`` , ``Amazon Linux 2017.03`` , ``Amazon Linux 2016.09`` , ``Amazon Linux 2016.03`` , ``Amazon Linux 2015.09`` , or ``Amazon Linux 2015.03`` . - A supported Ubuntu operating system, such as ``Ubuntu 18.04 LTS`` , ``Ubuntu 16.04 LTS`` , ``Ubuntu 14.04 LTS`` , or ``Ubuntu 12.04 LTS`` . - ``CentOS Linux 7`` - ``Red Hat Enterprise Linux 7`` - A supported Windows operating system, such as ``Microsoft Windows Server 2012 R2 Base`` , ``Microsoft Windows Server 2012 R2 with SQL Server Express`` , ``Microsoft Windows Server 2012 R2 with SQL Server Standard`` , or ``Microsoft Windows Server 2012 R2 with SQL Server Web`` . - A custom AMI: ``Custom`` . You specify the custom AMI you want to use when you create instances. For more information, see `Using Custom AMIs <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-custom-ami.html>`_ . The default option is the current Amazon Linux version. Not all operating systems are supported with all versions of Chef. For more information about supported operating systems, see `AWS OpsWorks Stacks Operating Systems <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-os.html>`_ .\n")
    default_root_device_type: typing.Optional[str] = pydantic.Field(None, description='The default root device type. This value is the default for all instances in the stack, but you can override it when you create an instance. The default option is ``instance-store`` . For more information, see `Storage for the Root Device <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ComponentsAMIs.html#storage-for-the-root-device>`_ .\n')
    default_ssh_key_name: typing.Optional[str] = pydantic.Field(None, description='A default Amazon EC2 key pair name. The default value is none. If you specify a key pair name, AWS OpsWorks installs the public key on the instance and you can use the private key with an SSH client to log in to the instance. For more information, see `Using SSH to Communicate with an Instance <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-ssh.html>`_ and `Managing SSH Access <https://docs.aws.amazon.com/opsworks/latest/userguide/security-ssh-access.html>`_ . You can override this setting by specifying a different key pair, or no key pair, when you `create an instance <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-add.html>`_ .\n')
    default_subnet_id: typing.Optional[str] = pydantic.Field(None, description="The stack's default subnet ID. All instances are launched into this subnet unless you specify another subnet ID when you create the instance. This parameter is required if you specify a value for the ``VpcId`` parameter. If you also specify a value for ``DefaultAvailabilityZone`` , the subnet must be in that zone.\n")
    ecs_cluster_arn: typing.Optional[str] = pydantic.Field(None, description="The Amazon Resource Name (ARN) of the Amazon Elastic Container Service ( Amazon ECS ) cluster to register with the AWS OpsWorks stack. .. epigraph:: If you specify a cluster that's registered with another AWS OpsWorks stack, AWS CloudFormation deregisters the existing association before registering the cluster.\n")
    elastic_ips: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnStack_ElasticIpPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="A list of Elastic IP addresses to register with the AWS OpsWorks stack. .. epigraph:: If you specify an IP address that's registered with another AWS OpsWorks stack, AWS CloudFormation deregisters the existing association before registering the IP address.\n")
    hostname_theme: typing.Optional[str] = pydantic.Field(None, description="The stack's host name theme, with spaces replaced by underscores. The theme is used to generate host names for the stack's instances. By default, ``HostnameTheme`` is set to ``Layer_Dependent`` , which creates host names by appending integers to the layer's short name. The other themes are: - ``Baked_Goods`` - ``Clouds`` - ``Europe_Cities`` - ``Fruits`` - ``Greek_Deities_and_Titans`` - ``Legendary_creatures_from_Japan`` - ``Planets_and_Moons`` - ``Roman_Deities`` - ``Scottish_Islands`` - ``US_Cities`` - ``Wild_Cats`` To obtain a generated host name, call ``GetHostNameSuggestion`` , which returns a host name based on the current theme.\n")
    rds_db_instances: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnStack_RdsDbInstancePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="The Amazon Relational Database Service ( Amazon RDS ) database instance to register with the AWS OpsWorks stack. .. epigraph:: If you specify a database instance that's registered with another AWS OpsWorks stack, AWS CloudFormation deregisters the existing association before registering the database instance.\n")
    source_stack_id: typing.Optional[str] = pydantic.Field(None, description="If you're cloning an AWS OpsWorks stack, the stack ID of the source AWS OpsWorks stack to clone.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='A map that contains tag keys and tag values that are attached to a stack or layer. - The key cannot be empty. - The key can be a maximum of 127 characters, and can contain only Unicode letters, numbers, or separators, or the following special characters: ``+ - = . _ : /`` - The value can be a maximum 255 characters, and contain only Unicode letters, numbers, or separators, or the following special characters: ``+ - = . _ : /`` - Leading and trailing white spaces are trimmed from both the key and value. - A maximum of 40 tags is allowed for any resource.\n')
    use_custom_cookbooks: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether the stack uses custom cookbooks.\n')
    use_opsworks_security_groups: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="Whether to associate the AWS OpsWorks Stacks built-in security groups with the stack's layers. AWS OpsWorks Stacks provides a standard set of built-in security groups, one for each layer, which are associated with layers by default. With ``UseOpsworksSecurityGroups`` you can instead provide your own custom security groups. ``UseOpsworksSecurityGroups`` has the following settings: - True - AWS OpsWorks Stacks automatically associates the appropriate built-in security group with each layer (default setting). You can associate additional security groups with a layer after you create it, but you cannot delete the built-in security group. - False - AWS OpsWorks Stacks does not associate built-in security groups with layers. You must create appropriate EC2 security groups and associate a security group with each layer that you create. However, you can still manually associate a built-in security group with a layer on creation; custom security groups are required only for those layers that need custom settings. For more information, see `Create a New Stack <https://docs.aws.amazon.com/opsworks/latest/userguide/workingstacks-creating.html>`_ .\n")
    vpc_id: typing.Optional[str] = pydantic.Field(None, description="The ID of the VPC that the stack is to be launched into. The VPC must be in the stack's region. All instances are launched into this VPC. You cannot change the ID later. - If your account supports EC2-Classic, the default value is ``no VPC`` . - If your account does not support EC2-Classic, the default value is the default VPC for the specified region. If the VPC ID corresponds to a default VPC and you have specified either the ``DefaultAvailabilityZone`` or the ``DefaultSubnetId`` parameter only, AWS OpsWorks Stacks infers the value of the other parameter. If you specify neither parameter, AWS OpsWorks Stacks sets these parameters to the first valid Availability Zone for the specified region and the corresponding default VPC subnet ID, respectively. If you specify a nondefault VPC ID, note the following: - It must belong to a VPC in your account that is in the specified region. - You must specify a value for ``DefaultSubnetId`` . For more information about how to use AWS OpsWorks Stacks with a VPC, see `Running a Stack in a VPC <https://docs.aws.amazon.com/opsworks/latest/userguide/workingstacks-vpc.html>`_ . For more information about default VPC and EC2-Classic, see `Supported Platforms <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-supported-platforms.html>`_ .")
    _init_params: typing.ClassVar[list[str]] = ['default_instance_profile_arn', 'name', 'service_role_arn', 'agent_version', 'attributes', 'chef_configuration', 'clone_app_ids', 'clone_permissions', 'configuration_manager', 'custom_cookbooks_source', 'custom_json', 'default_availability_zone', 'default_os', 'default_root_device_type', 'default_ssh_key_name', 'default_subnet_id', 'ecs_cluster_arn', 'elastic_ips', 'hostname_theme', 'rds_db_instances', 'source_stack_id', 'tags', 'use_custom_cookbooks', 'use_opsworks_security_groups', 'vpc_id']
    _method_names: typing.ClassVar[list[str]] = ['ChefConfigurationProperty', 'ElasticIpProperty', 'RdsDbInstanceProperty', 'SourceProperty', 'StackConfigurationManagerProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnStack'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnStackDefConfig] = pydantic.Field(None)


class CfnStackDefConfig(pydantic.BaseModel):
    ChefConfigurationProperty: typing.Optional[list[CfnStackDefChefconfigurationpropertyParams]] = pydantic.Field(None, description='')
    ElasticIpProperty: typing.Optional[list[CfnStackDefElasticippropertyParams]] = pydantic.Field(None, description='')
    RdsDbInstanceProperty: typing.Optional[list[CfnStackDefRdsdbinstancepropertyParams]] = pydantic.Field(None, description='')
    SourceProperty: typing.Optional[list[CfnStackDefSourcepropertyParams]] = pydantic.Field(None, description='')
    StackConfigurationManagerProperty: typing.Optional[list[CfnStackDefStackconfigurationmanagerpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnStackDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnStackDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnStackDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnStackDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnStackDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnStackDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnStackDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnStackDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnStackDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnStackDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnStackDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnStackDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnStackDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnStackDefChefconfigurationpropertyParams(pydantic.BaseModel):
    berkshelf_version: typing.Optional[str] = pydantic.Field(None, description='')
    manage_berkshelf: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnStackDefElasticippropertyParams(pydantic.BaseModel):
    ip: str = pydantic.Field(..., description='')
    name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnStackDefRdsdbinstancepropertyParams(pydantic.BaseModel):
    db_password: str = pydantic.Field(..., description='')
    db_user: str = pydantic.Field(..., description='')
    rds_db_instance_arn: str = pydantic.Field(..., description='')
    ...

class CfnStackDefSourcepropertyParams(pydantic.BaseModel):
    password: typing.Optional[str] = pydantic.Field(None, description='')
    revision: typing.Optional[str] = pydantic.Field(None, description='')
    ssh_key: typing.Optional[str] = pydantic.Field(None, description='')
    type: typing.Optional[str] = pydantic.Field(None, description='')
    url: typing.Optional[str] = pydantic.Field(None, description='')
    username: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnStackDefStackconfigurationmanagerpropertyParams(pydantic.BaseModel):
    name: typing.Optional[str] = pydantic.Field(None, description='')
    version: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnStackDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnStackDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnStackDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnStackDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnStackDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnStackDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnStackDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnStackDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnStackDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnStackDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnStackDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnStackDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnStackDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnStackDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_opsworks.CfnUserProfile
class CfnUserProfileDef(BaseCfnResource):
    iam_user_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The user's IAM ARN.\n")
    allow_self_management: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether users can specify their own SSH public key through the My Settings page. For more information, see `Managing User Permissions <https://docs.aws.amazon.com/opsworks/latest/userguide/security-settingsshkey.html>`_ .\n')
    ssh_public_key: typing.Optional[str] = pydantic.Field(None, description="The user's SSH public key.\n")
    ssh_username: typing.Optional[str] = pydantic.Field(None, description="The user's SSH user name.")
    _init_params: typing.ClassVar[list[str]] = ['iam_user_arn', 'allow_self_management', 'ssh_public_key', 'ssh_username']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnUserProfile'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnUserProfileDefConfig] = pydantic.Field(None)


class CfnUserProfileDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnUserProfileDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnUserProfileDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnUserProfileDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnUserProfileDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnUserProfileDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnUserProfileDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnUserProfileDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnUserProfileDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnUserProfileDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnUserProfileDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnUserProfileDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnUserProfileDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnUserProfileDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnUserProfileDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnUserProfileDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnUserProfileDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnUserProfileDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnUserProfileDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnUserProfileDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnUserProfileDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnUserProfileDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnUserProfileDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnUserProfileDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnUserProfileDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnUserProfileDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnUserProfileDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnUserProfileDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_opsworks.CfnVolume
class CfnVolumeDef(BaseCfnResource):
    ec2_volume_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon EC2 volume ID.\n')
    stack_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The stack ID.\n')
    mount_point: typing.Optional[str] = pydantic.Field(None, description='The volume mount point. For example, "/mnt/disk1".\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The volume name. Volume names are a maximum of 128 characters.')
    _init_params: typing.ClassVar[list[str]] = ['ec2_volume_id', 'stack_id', 'mount_point', 'name']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnVolume'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnVolumeDefConfig] = pydantic.Field(None)


class CfnVolumeDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnVolumeDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnVolumeDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnVolumeDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnVolumeDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnVolumeDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnVolumeDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnVolumeDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnVolumeDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnVolumeDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnVolumeDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnVolumeDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnVolumeDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnVolumeDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnVolumeDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnVolumeDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnVolumeDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnVolumeDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnVolumeDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnVolumeDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnVolumeDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnVolumeDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnVolumeDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnVolumeDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnVolumeDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnVolumeDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnVolumeDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnVolumeDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_opsworks.CfnAppProps
class CfnAppPropsDef(BaseCfnProperty):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The app name.\n')
    stack_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The stack ID.\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The app type. Each supported type is associated with a particular layer. For example, PHP applications are associated with a PHP layer. AWS OpsWorks Stacks deploys an application to those instances that are members of the corresponding layer. If your app isn't one of the standard types, or you prefer to implement your own Deploy recipes, specify ``other`` .\n")
    app_source: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnApp_SourcePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A ``Source`` object that specifies the app repository.\n')
    attributes: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='One or more user-defined key/value pairs to be added to the stack attributes.\n')
    data_sources: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnApp_DataSourcePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="The app's data source.\n")
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the app.\n')
    domains: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="The app virtual host settings, with multiple domains separated by commas. For example: ``'www.example.com, example.com'``\n")
    enable_ssl: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to enable SSL for the app.\n')
    environment: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnApp_EnvironmentVariablePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='An array of ``EnvironmentVariable`` objects that specify environment variables to be associated with the app. After you deploy the app, these variables are defined on the associated app server instance. For more information, see `Environment Variables <https://docs.aws.amazon.com/opsworks/latest/userguide/workingapps-creating.html#workingapps-creating-environment>`_ . There is no specific limit on the number of environment variables. However, the size of the associated data structure - which includes the variables\' names, values, and protected flag values - cannot exceed 20 KB. This limit should accommodate most if not all use cases. Exceeding it will cause an exception with the message, "Environment: is too large (maximum is 20KB)." .. epigraph:: If you have specified one or more environment variables, you cannot modify the stack\'s Chef version.\n')
    shortname: typing.Optional[str] = pydantic.Field(None, description="The app's short name.\n")
    ssl_configuration: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnApp_SslConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An ``SslConfiguration`` object with the SSL configuration.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-opsworks-app.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    cfn_app_props = opsworks.CfnAppProps(\n        name="name",\n        stack_id="stackId",\n        type="type",\n\n        # the properties below are optional\n        app_source=opsworks.CfnApp.SourceProperty(\n            password="password",\n            revision="revision",\n            ssh_key="sshKey",\n            type="type",\n            url="url",\n            username="username"\n        ),\n        attributes={\n            "attributes_key": "attributes"\n        },\n        data_sources=[opsworks.CfnApp.DataSourceProperty(\n            arn="arn",\n            database_name="databaseName",\n            type="type"\n        )],\n        description="description",\n        domains=["domains"],\n        enable_ssl=False,\n        environment=[opsworks.CfnApp.EnvironmentVariableProperty(\n            key="key",\n            value="value",\n\n            # the properties below are optional\n            secure=False\n        )],\n        shortname="shortname",\n        ssl_configuration=opsworks.CfnApp.SslConfigurationProperty(\n            certificate="certificate",\n            chain="chain",\n            private_key="privateKey"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'stack_id', 'type', 'app_source', 'attributes', 'data_sources', 'description', 'domains', 'enable_ssl', 'environment', 'shortname', 'ssl_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnAppProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnElasticLoadBalancerAttachmentProps
class CfnElasticLoadBalancerAttachmentPropsDef(BaseCfnProperty):
    elastic_load_balancer_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Elastic Load Balancing instance name.\n')
    layer_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS OpsWorks layer ID to which the Elastic Load Balancing load balancer is attached.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-opsworks-elasticloadbalancerattachment.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    cfn_elastic_load_balancer_attachment_props = opsworks.CfnElasticLoadBalancerAttachmentProps(\n        elastic_load_balancer_name="elasticLoadBalancerName",\n        layer_id="layerId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['elastic_load_balancer_name', 'layer_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnElasticLoadBalancerAttachmentProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnInstanceProps
class CfnInstancePropsDef(BaseCfnProperty):
    instance_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The instance type, such as ``t2.micro`` . For a list of supported instance types, open the stack in the console, choose *Instances* , and choose *+ Instance* . The *Size* list contains the currently supported types. For more information, see `Instance Families and Types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html>`_ . The parameter values that you use to specify the various types are in the *API Name* column of the *Available Instance Types* table.\n')
    layer_ids: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="An array that contains the instance's layer IDs.\n")
    stack_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The stack ID.\n')
    agent_version: typing.Optional[str] = pydantic.Field(None, description="The default AWS OpsWorks Stacks agent version. You have the following options:. - ``INHERIT`` - Use the stack's default agent version setting. - *version_number* - Use the specified agent version. This value overrides the stack's default setting. To update the agent version, edit the instance configuration and specify a new version. AWS OpsWorks Stacks installs that version on the instance. The default setting is ``INHERIT`` . To specify an agent version, you must use the complete version number, not the abbreviated number shown on the console. For a list of available agent version numbers, call ``DescribeAgentVersions`` . AgentVersion cannot be set to Chef 12.2.\n")
    ami_id: typing.Optional[str] = pydantic.Field(None, description='A custom AMI ID to be used to create the instance. The AMI should be based on one of the supported operating systems. For more information, see `Using Custom AMIs <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-custom-ami.html>`_ . .. epigraph:: If you specify a custom AMI, you must set ``Os`` to ``Custom`` .\n')
    architecture: typing.Optional[str] = pydantic.Field(None, description='The instance architecture. The default option is ``x86_64`` . Instance types do not necessarily support both architectures. For a list of the architectures that are supported by the different instance types, see `Instance Families and Types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html>`_ .\n')
    auto_scaling_type: typing.Optional[str] = pydantic.Field(None, description='For load-based or time-based instances, the type. Windows stacks can use only time-based instances.\n')
    availability_zone: typing.Optional[str] = pydantic.Field(None, description='The Availability Zone of the AWS OpsWorks instance, such as ``us-east-2a`` .\n')
    block_device_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnInstance_BlockDeviceMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="An array of ``BlockDeviceMapping`` objects that specify the instance's block devices. For more information, see `Block Device Mapping <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/block-device-mapping-concepts.html>`_ . Note that block device mappings are not supported for custom AMIs.\n")
    ebs_optimized: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to create an Amazon EBS-optimized instance.\n')
    elastic_ips: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of Elastic IP addresses to associate with the instance.\n')
    hostname: typing.Optional[str] = pydantic.Field(None, description='The instance host name. The following are character limits for instance host names. - Linux-based instances: 63 characters - Windows-based instances: 15 characters\n')
    install_updates_on_boot: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to install operating system and package updates when the instance boots. The default value is ``true`` . To control when updates are installed, set this value to ``false`` . You must then update your instances manually by using ``CreateDeployment`` to run the ``update_dependencies`` stack command or by manually running ``yum`` (Amazon Linux) or ``apt-get`` (Ubuntu) on the instances. .. epigraph:: We strongly recommend using the default value of ``true`` to ensure that your instances have the latest security updates.\n')
    os: typing.Optional[str] = pydantic.Field(None, description="The instance's operating system, which must be set to one of the following. - A supported Linux operating system: An Amazon Linux version, such as ``Amazon Linux 2`` , ``Amazon Linux 2018.03`` , ``Amazon Linux 2017.09`` , ``Amazon Linux 2017.03`` , ``Amazon Linux 2016.09`` , ``Amazon Linux 2016.03`` , ``Amazon Linux 2015.09`` , or ``Amazon Linux 2015.03`` . - A supported Ubuntu operating system, such as ``Ubuntu 18.04 LTS`` , ``Ubuntu 16.04 LTS`` , ``Ubuntu 14.04 LTS`` , or ``Ubuntu 12.04 LTS`` . - ``CentOS Linux 7`` - ``Red Hat Enterprise Linux 7`` - A supported Windows operating system, such as ``Microsoft Windows Server 2012 R2 Base`` , ``Microsoft Windows Server 2012 R2 with SQL Server Express`` , ``Microsoft Windows Server 2012 R2 with SQL Server Standard`` , or ``Microsoft Windows Server 2012 R2 with SQL Server Web`` . - A custom AMI: ``Custom`` . Not all operating systems are supported with all versions of Chef. For more information about the supported operating systems, see `AWS OpsWorks Stacks Operating Systems <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-os.html>`_ . The default option is the current Amazon Linux version. If you set this parameter to ``Custom`` , you must use the ``CreateInstance`` action's AmiId parameter to specify the custom AMI that you want to use. Block device mappings are not supported if the value is ``Custom`` . For more information about how to use custom AMIs with AWS OpsWorks Stacks, see `Using Custom AMIs <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-custom-ami.html>`_ .\n")
    root_device_type: typing.Optional[str] = pydantic.Field(None, description='The instance root device type. For more information, see `Storage for the Root Device <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ComponentsAMIs.html#storage-for-the-root-device>`_ .\n')
    ssh_key_name: typing.Optional[str] = pydantic.Field(None, description="The instance's Amazon EC2 key-pair name.\n")
    subnet_id: typing.Optional[str] = pydantic.Field(None, description="The ID of the instance's subnet. If the stack is running in a VPC, you can use this parameter to override the stack's default subnet ID value and direct AWS OpsWorks Stacks to launch the instance in a different subnet.\n")
    tenancy: typing.Optional[str] = pydantic.Field(None, description="The instance's tenancy option. The default option is no tenancy, or if the instance is running in a VPC, inherit tenancy settings from the VPC. The following are valid values for this parameter: ``dedicated`` , ``default`` , or ``host`` . Because there are costs associated with changes in tenancy options, we recommend that you research tenancy options before choosing them for your instances. For more information about dedicated hosts, see `Dedicated Hosts Overview <https://docs.aws.amazon.com/ec2/dedicated-hosts/>`_ and `Amazon EC2 Dedicated Hosts <https://docs.aws.amazon.com/ec2/dedicated-hosts/>`_ . For more information about dedicated instances, see `Dedicated Instances <https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/dedicated-instance.html>`_ and `Amazon EC2 Dedicated Instances <https://docs.aws.amazon.com/ec2/purchasing-options/dedicated-instances/>`_ .\n")
    time_based_auto_scaling: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnInstance_TimeBasedAutoScalingPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The time-based scaling configuration for the instance.\n')
    virtualization_type: typing.Optional[str] = pydantic.Field(None, description="The instance's virtualization type, ``paravirtual`` or ``hvm`` .\n")
    volumes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of AWS OpsWorks volume IDs to associate with the instance. For more information, see ```AWS::OpsWorks::Volume`` <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-opsworks-volume.html>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-opsworks-instance.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    cfn_instance_props = opsworks.CfnInstanceProps(\n        instance_type="instanceType",\n        layer_ids=["layerIds"],\n        stack_id="stackId",\n\n        # the properties below are optional\n        agent_version="agentVersion",\n        ami_id="amiId",\n        architecture="architecture",\n        auto_scaling_type="autoScalingType",\n        availability_zone="availabilityZone",\n        block_device_mappings=[opsworks.CfnInstance.BlockDeviceMappingProperty(\n            device_name="deviceName",\n            ebs=opsworks.CfnInstance.EbsBlockDeviceProperty(\n                delete_on_termination=False,\n                iops=123,\n                snapshot_id="snapshotId",\n                volume_size=123,\n                volume_type="volumeType"\n            ),\n            no_device="noDevice",\n            virtual_name="virtualName"\n        )],\n        ebs_optimized=False,\n        elastic_ips=["elasticIps"],\n        hostname="hostname",\n        install_updates_on_boot=False,\n        os="os",\n        root_device_type="rootDeviceType",\n        ssh_key_name="sshKeyName",\n        subnet_id="subnetId",\n        tenancy="tenancy",\n        time_based_auto_scaling=opsworks.CfnInstance.TimeBasedAutoScalingProperty(\n            friday={\n                "friday_key": "friday"\n            },\n            monday={\n                "monday_key": "monday"\n            },\n            saturday={\n                "saturday_key": "saturday"\n            },\n            sunday={\n                "sunday_key": "sunday"\n            },\n            thursday={\n                "thursday_key": "thursday"\n            },\n            tuesday={\n                "tuesday_key": "tuesday"\n            },\n            wednesday={\n                "wednesday_key": "wednesday"\n            }\n        ),\n        virtualization_type="virtualizationType",\n        volumes=["volumes"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['instance_type', 'layer_ids', 'stack_id', 'agent_version', 'ami_id', 'architecture', 'auto_scaling_type', 'availability_zone', 'block_device_mappings', 'ebs_optimized', 'elastic_ips', 'hostname', 'install_updates_on_boot', 'os', 'root_device_type', 'ssh_key_name', 'subnet_id', 'tenancy', 'time_based_auto_scaling', 'virtualization_type', 'volumes']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnInstanceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnLayerProps
class CfnLayerPropsDef(BaseCfnProperty):
    auto_assign_elastic_ips: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description="Whether to automatically assign an `Elastic IP address <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html>`_ to the layer's instances. For more information, see `How to Edit a Layer <https://docs.aws.amazon.com/opsworks/latest/userguide/workinglayers-basics-edit.html>`_ .\n")
    auto_assign_public_ips: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description="For stacks that are running in a VPC, whether to automatically assign a public IP address to the layer's instances. For more information, see `How to Edit a Layer <https://docs.aws.amazon.com/opsworks/latest/userguide/workinglayers-basics-edit.html>`_ .\n")
    enable_auto_healing: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Whether to disable auto healing for the layer.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The layer name, which is used by the console. Layer names can be a maximum of 32 characters.\n')
    shortname: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="For custom layers only, use this parameter to specify the layer's short name, which is used internally by AWS OpsWorks Stacks and by Chef recipes. The short name is also used as the name for the directory where your app files are installed. It can have a maximum of 32 characters, which are limited to the alphanumeric characters, '-', '_', and '.'. Built-in layer short names are defined by AWS OpsWorks Stacks. For more information, see the `Layer Reference <https://docs.aws.amazon.com/opsworks/latest/userguide/layers.html>`_ .\n")
    stack_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The layer stack ID.\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The layer type. A stack cannot have more than one built-in layer of the same type. It can have any number of custom layers. Built-in layers are not available in Chef 12 stacks.\n')
    attributes: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description="One or more user-defined key-value pairs to be added to the stack attributes. To create a cluster layer, set the ``EcsClusterArn`` attribute to the cluster's ARN.\n")
    custom_instance_profile_arn: typing.Optional[str] = pydantic.Field(None, description="The ARN of an IAM profile to be used for the layer's EC2 instances. For more information about IAM ARNs, see `Using Identifiers <https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html>`_ .\n")
    custom_json: typing.Any = pydantic.Field(None, description="A JSON-formatted string containing custom stack configuration and deployment attributes to be installed on the layer's instances. For more information, see `Using Custom JSON <https://docs.aws.amazon.com/opsworks/latest/userguide/workingcookbook-json-override.html>`_ . This feature is supported as of version 1.7.42 of the AWS CLI .\n")
    custom_recipes: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_RecipesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A ``LayerCustomRecipes`` object that specifies the layer custom recipes.\n')
    custom_security_group_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array containing the layer custom security group IDs.\n')
    install_updates_on_boot: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to install operating system and package updates when the instance boots. The default value is ``true`` . To control when updates are installed, set this value to ``false`` . You must then update your instances manually by using ``CreateDeployment`` to run the ``update_dependencies`` stack command or by manually running ``yum`` (Amazon Linux) or ``apt-get`` (Ubuntu) on the instances. .. epigraph:: To ensure that your instances have the latest security updates, we strongly recommend using the default value of ``true`` .\n')
    lifecycle_event_configuration: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_LifecycleEventConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A ``LifeCycleEventConfiguration`` object that you can use to configure the Shutdown event to specify an execution timeout and enable or disable Elastic Load Balancer connection draining.\n')
    load_based_auto_scaling: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_LoadBasedAutoScalingPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The load-based scaling configuration for the AWS OpsWorks layer.\n')
    packages: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of ``Package`` objects that describes the layer packages.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies one or more sets of tags (keyvalue pairs) to associate with this AWS OpsWorks layer. Use tags to manage your resources.\n')
    use_ebs_optimized_instances: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to use Amazon EBS-optimized instances.\n')
    volume_configurations: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnLayer_VolumeConfigurationPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A ``VolumeConfigurations`` object that describes the layer\'s Amazon EBS volumes.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-opsworks-layer.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    # custom_json: Any\n\n    cfn_layer_props = opsworks.CfnLayerProps(\n        auto_assign_elastic_ips=False,\n        auto_assign_public_ips=False,\n        enable_auto_healing=False,\n        name="name",\n        shortname="shortname",\n        stack_id="stackId",\n        type="type",\n\n        # the properties below are optional\n        attributes={\n            "attributes_key": "attributes"\n        },\n        custom_instance_profile_arn="customInstanceProfileArn",\n        custom_json=custom_json,\n        custom_recipes=opsworks.CfnLayer.RecipesProperty(\n            configure=["configure"],\n            deploy=["deploy"],\n            setup=["setup"],\n            shutdown=["shutdown"],\n            undeploy=["undeploy"]\n        ),\n        custom_security_group_ids=["customSecurityGroupIds"],\n        install_updates_on_boot=False,\n        lifecycle_event_configuration=opsworks.CfnLayer.LifecycleEventConfigurationProperty(\n            shutdown_event_configuration=opsworks.CfnLayer.ShutdownEventConfigurationProperty(\n                delay_until_elb_connections_drained=False,\n                execution_timeout=123\n            )\n        ),\n        load_based_auto_scaling=opsworks.CfnLayer.LoadBasedAutoScalingProperty(\n            down_scaling=opsworks.CfnLayer.AutoScalingThresholdsProperty(\n                cpu_threshold=123,\n                ignore_metrics_time=123,\n                instance_count=123,\n                load_threshold=123,\n                memory_threshold=123,\n                thresholds_wait_time=123\n            ),\n            enable=False,\n            up_scaling=opsworks.CfnLayer.AutoScalingThresholdsProperty(\n                cpu_threshold=123,\n                ignore_metrics_time=123,\n                instance_count=123,\n                load_threshold=123,\n                memory_threshold=123,\n                thresholds_wait_time=123\n            )\n        ),\n        packages=["packages"],\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        use_ebs_optimized_instances=False,\n        volume_configurations=[opsworks.CfnLayer.VolumeConfigurationProperty(\n            encrypted=False,\n            iops=123,\n            mount_point="mountPoint",\n            number_of_disks=123,\n            raid_level=123,\n            size=123,\n            volume_type="volumeType"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['auto_assign_elastic_ips', 'auto_assign_public_ips', 'enable_auto_healing', 'name', 'shortname', 'stack_id', 'type', 'attributes', 'custom_instance_profile_arn', 'custom_json', 'custom_recipes', 'custom_security_group_ids', 'install_updates_on_boot', 'lifecycle_event_configuration', 'load_based_auto_scaling', 'packages', 'tags', 'use_ebs_optimized_instances', 'volume_configurations']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnLayerProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnStackProps
class CfnStackPropsDef(BaseCfnProperty):
    default_instance_profile_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The Amazon Resource Name (ARN) of an IAM profile that is the default profile for all of the stack's EC2 instances. For more information about IAM ARNs, see `Using Identifiers <https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html>`_ .\n")
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The stack name. Stack names can be a maximum of 64 characters.\n')
    service_role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The stack's IAM role, which allows AWS OpsWorks Stacks to work with AWS resources on your behalf. You must set this parameter to the Amazon Resource Name (ARN) for an existing IAM role. For more information about IAM ARNs, see `Using Identifiers <https://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html>`_ .\n")
    agent_version: typing.Optional[str] = pydantic.Field(None, description="The default AWS OpsWorks Stacks agent version. You have the following options:. - Auto-update - Set this parameter to ``LATEST`` . AWS OpsWorks Stacks automatically installs new agent versions on the stack's instances as soon as they are available. - Fixed version - Set this parameter to your preferred agent version. To update the agent version, you must edit the stack configuration and specify a new version. AWS OpsWorks Stacks installs that version on the stack's instances. The default setting is the most recent release of the agent. To specify an agent version, you must use the complete version number, not the abbreviated number shown on the console. For a list of available agent version numbers, call ``DescribeAgentVersions`` . AgentVersion cannot be set to Chef 12.2. .. epigraph:: You can also specify an agent version when you create or update an instance, which overrides the stack's default setting.\n")
    attributes: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='One or more user-defined key-value pairs to be added to the stack attributes.\n')
    chef_configuration: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnStack_ChefConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A ``ChefConfiguration`` object that specifies whether to enable Berkshelf and the Berkshelf version on Chef 11.10 stacks. For more information, see `Create a New Stack <https://docs.aws.amazon.com/opsworks/latest/userguide/workingstacks-creating.html>`_ .\n')
    clone_app_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="If you're cloning an AWS OpsWorks stack, a list of AWS OpsWorks application stack IDs from the source stack to include in the cloned stack.\n")
    clone_permissions: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="If you're cloning an AWS OpsWorks stack, indicates whether to clone the source stack's permissions.\n")
    configuration_manager: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnStack_StackConfigurationManagerPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration manager. When you create a stack we recommend that you use the configuration manager to specify the Chef version: 12, 11.10, or 11.4 for Linux stacks, or 12.2 for Windows stacks. The default value for Linux stacks is currently 12.\n')
    custom_cookbooks_source: typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnStack_SourcePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Contains the information required to retrieve an app or cookbook from a repository. For more information, see `Adding Apps <https://docs.aws.amazon.com/opsworks/latest/userguide/workingapps-creating.html>`_ or `Cookbooks and Recipes <https://docs.aws.amazon.com/opsworks/latest/userguide/workingcookbook.html>`_ .\n')
    custom_json: typing.Any = pydantic.Field(None, description='A string that contains user-defined, custom JSON. It can be used to override the corresponding default stack configuration attribute values or to pass data to recipes. The string should be in the following format: ``"{\\"key1\\": \\"value1\\", \\"key2\\": \\"value2\\",...}"`` For more information about custom JSON, see `Use Custom JSON to Modify the Stack Configuration Attributes <https://docs.aws.amazon.com/opsworks/latest/userguide/workingstacks-json.html>`_ .\n')
    default_availability_zone: typing.Optional[str] = pydantic.Field(None, description="The stack's default Availability Zone, which must be in the specified region. For more information, see `Regions and Endpoints <https://docs.aws.amazon.com/general/latest/gr/rande.html>`_ . If you also specify a value for ``DefaultSubnetId`` , the subnet must be in the same zone. For more information, see the ``VpcId`` parameter description.\n")
    default_os: typing.Optional[str] = pydantic.Field(None, description="The stack's default operating system, which is installed on every instance unless you specify a different operating system when you create the instance. You can specify one of the following. - A supported Linux operating system: An Amazon Linux version, such as ``Amazon Linux 2`` , ``Amazon Linux 2018.03`` , ``Amazon Linux 2017.09`` , ``Amazon Linux 2017.03`` , ``Amazon Linux 2016.09`` , ``Amazon Linux 2016.03`` , ``Amazon Linux 2015.09`` , or ``Amazon Linux 2015.03`` . - A supported Ubuntu operating system, such as ``Ubuntu 18.04 LTS`` , ``Ubuntu 16.04 LTS`` , ``Ubuntu 14.04 LTS`` , or ``Ubuntu 12.04 LTS`` . - ``CentOS Linux 7`` - ``Red Hat Enterprise Linux 7`` - A supported Windows operating system, such as ``Microsoft Windows Server 2012 R2 Base`` , ``Microsoft Windows Server 2012 R2 with SQL Server Express`` , ``Microsoft Windows Server 2012 R2 with SQL Server Standard`` , or ``Microsoft Windows Server 2012 R2 with SQL Server Web`` . - A custom AMI: ``Custom`` . You specify the custom AMI you want to use when you create instances. For more information, see `Using Custom AMIs <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-custom-ami.html>`_ . The default option is the current Amazon Linux version. Not all operating systems are supported with all versions of Chef. For more information about supported operating systems, see `AWS OpsWorks Stacks Operating Systems <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-os.html>`_ .\n")
    default_root_device_type: typing.Optional[str] = pydantic.Field(None, description='The default root device type. This value is the default for all instances in the stack, but you can override it when you create an instance. The default option is ``instance-store`` . For more information, see `Storage for the Root Device <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ComponentsAMIs.html#storage-for-the-root-device>`_ .\n')
    default_ssh_key_name: typing.Optional[str] = pydantic.Field(None, description='A default Amazon EC2 key pair name. The default value is none. If you specify a key pair name, AWS OpsWorks installs the public key on the instance and you can use the private key with an SSH client to log in to the instance. For more information, see `Using SSH to Communicate with an Instance <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-ssh.html>`_ and `Managing SSH Access <https://docs.aws.amazon.com/opsworks/latest/userguide/security-ssh-access.html>`_ . You can override this setting by specifying a different key pair, or no key pair, when you `create an instance <https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-add.html>`_ .\n')
    default_subnet_id: typing.Optional[str] = pydantic.Field(None, description="The stack's default subnet ID. All instances are launched into this subnet unless you specify another subnet ID when you create the instance. This parameter is required if you specify a value for the ``VpcId`` parameter. If you also specify a value for ``DefaultAvailabilityZone`` , the subnet must be in that zone.\n")
    ecs_cluster_arn: typing.Optional[str] = pydantic.Field(None, description="The Amazon Resource Name (ARN) of the Amazon Elastic Container Service ( Amazon ECS ) cluster to register with the AWS OpsWorks stack. .. epigraph:: If you specify a cluster that's registered with another AWS OpsWorks stack, AWS CloudFormation deregisters the existing association before registering the cluster.\n")
    elastic_ips: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnStack_ElasticIpPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="A list of Elastic IP addresses to register with the AWS OpsWorks stack. .. epigraph:: If you specify an IP address that's registered with another AWS OpsWorks stack, AWS CloudFormation deregisters the existing association before registering the IP address.\n")
    hostname_theme: typing.Optional[str] = pydantic.Field(None, description="The stack's host name theme, with spaces replaced by underscores. The theme is used to generate host names for the stack's instances. By default, ``HostnameTheme`` is set to ``Layer_Dependent`` , which creates host names by appending integers to the layer's short name. The other themes are: - ``Baked_Goods`` - ``Clouds`` - ``Europe_Cities`` - ``Fruits`` - ``Greek_Deities_and_Titans`` - ``Legendary_creatures_from_Japan`` - ``Planets_and_Moons`` - ``Roman_Deities`` - ``Scottish_Islands`` - ``US_Cities`` - ``Wild_Cats`` To obtain a generated host name, call ``GetHostNameSuggestion`` , which returns a host name based on the current theme.\n")
    rds_db_instances: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_opsworks.CfnStack_RdsDbInstancePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="The Amazon Relational Database Service ( Amazon RDS ) database instance to register with the AWS OpsWorks stack. .. epigraph:: If you specify a database instance that's registered with another AWS OpsWorks stack, AWS CloudFormation deregisters the existing association before registering the database instance.\n")
    source_stack_id: typing.Optional[str] = pydantic.Field(None, description="If you're cloning an AWS OpsWorks stack, the stack ID of the source AWS OpsWorks stack to clone.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='A map that contains tag keys and tag values that are attached to a stack or layer. - The key cannot be empty. - The key can be a maximum of 127 characters, and can contain only Unicode letters, numbers, or separators, or the following special characters: ``+ - = . _ : /`` - The value can be a maximum 255 characters, and contain only Unicode letters, numbers, or separators, or the following special characters: ``+ - = . _ : /`` - Leading and trailing white spaces are trimmed from both the key and value. - A maximum of 40 tags is allowed for any resource.\n')
    use_custom_cookbooks: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether the stack uses custom cookbooks.\n')
    use_opsworks_security_groups: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="Whether to associate the AWS OpsWorks Stacks built-in security groups with the stack's layers. AWS OpsWorks Stacks provides a standard set of built-in security groups, one for each layer, which are associated with layers by default. With ``UseOpsworksSecurityGroups`` you can instead provide your own custom security groups. ``UseOpsworksSecurityGroups`` has the following settings: - True - AWS OpsWorks Stacks automatically associates the appropriate built-in security group with each layer (default setting). You can associate additional security groups with a layer after you create it, but you cannot delete the built-in security group. - False - AWS OpsWorks Stacks does not associate built-in security groups with layers. You must create appropriate EC2 security groups and associate a security group with each layer that you create. However, you can still manually associate a built-in security group with a layer on creation; custom security groups are required only for those layers that need custom settings. For more information, see `Create a New Stack <https://docs.aws.amazon.com/opsworks/latest/userguide/workingstacks-creating.html>`_ .\n")
    vpc_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the VPC that the stack is to be launched into. The VPC must be in the stack\'s region. All instances are launched into this VPC. You cannot change the ID later. - If your account supports EC2-Classic, the default value is ``no VPC`` . - If your account does not support EC2-Classic, the default value is the default VPC for the specified region. If the VPC ID corresponds to a default VPC and you have specified either the ``DefaultAvailabilityZone`` or the ``DefaultSubnetId`` parameter only, AWS OpsWorks Stacks infers the value of the other parameter. If you specify neither parameter, AWS OpsWorks Stacks sets these parameters to the first valid Availability Zone for the specified region and the corresponding default VPC subnet ID, respectively. If you specify a nondefault VPC ID, note the following: - It must belong to a VPC in your account that is in the specified region. - You must specify a value for ``DefaultSubnetId`` . For more information about how to use AWS OpsWorks Stacks with a VPC, see `Running a Stack in a VPC <https://docs.aws.amazon.com/opsworks/latest/userguide/workingstacks-vpc.html>`_ . For more information about default VPC and EC2-Classic, see `Supported Platforms <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-supported-platforms.html>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-opsworks-stack.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    # custom_json: Any\n\n    cfn_stack_props = opsworks.CfnStackProps(\n        default_instance_profile_arn="defaultInstanceProfileArn",\n        name="name",\n        service_role_arn="serviceRoleArn",\n\n        # the properties below are optional\n        agent_version="agentVersion",\n        attributes={\n            "attributes_key": "attributes"\n        },\n        chef_configuration=opsworks.CfnStack.ChefConfigurationProperty(\n            berkshelf_version="berkshelfVersion",\n            manage_berkshelf=False\n        ),\n        clone_app_ids=["cloneAppIds"],\n        clone_permissions=False,\n        configuration_manager=opsworks.CfnStack.StackConfigurationManagerProperty(\n            name="name",\n            version="version"\n        ),\n        custom_cookbooks_source=opsworks.CfnStack.SourceProperty(\n            password="password",\n            revision="revision",\n            ssh_key="sshKey",\n            type="type",\n            url="url",\n            username="username"\n        ),\n        custom_json=custom_json,\n        default_availability_zone="defaultAvailabilityZone",\n        default_os="defaultOs",\n        default_root_device_type="defaultRootDeviceType",\n        default_ssh_key_name="defaultSshKeyName",\n        default_subnet_id="defaultSubnetId",\n        ecs_cluster_arn="ecsClusterArn",\n        elastic_ips=[opsworks.CfnStack.ElasticIpProperty(\n            ip="ip",\n\n            # the properties below are optional\n            name="name"\n        )],\n        hostname_theme="hostnameTheme",\n        rds_db_instances=[opsworks.CfnStack.RdsDbInstanceProperty(\n            db_password="dbPassword",\n            db_user="dbUser",\n            rds_db_instance_arn="rdsDbInstanceArn"\n        )],\n        source_stack_id="sourceStackId",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        use_custom_cookbooks=False,\n        use_opsworks_security_groups=False,\n        vpc_id="vpcId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['default_instance_profile_arn', 'name', 'service_role_arn', 'agent_version', 'attributes', 'chef_configuration', 'clone_app_ids', 'clone_permissions', 'configuration_manager', 'custom_cookbooks_source', 'custom_json', 'default_availability_zone', 'default_os', 'default_root_device_type', 'default_ssh_key_name', 'default_subnet_id', 'ecs_cluster_arn', 'elastic_ips', 'hostname_theme', 'rds_db_instances', 'source_stack_id', 'tags', 'use_custom_cookbooks', 'use_opsworks_security_groups', 'vpc_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnStackProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnUserProfileProps
class CfnUserProfilePropsDef(BaseCfnProperty):
    iam_user_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The user's IAM ARN.\n")
    allow_self_management: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether users can specify their own SSH public key through the My Settings page. For more information, see `Managing User Permissions <https://docs.aws.amazon.com/opsworks/latest/userguide/security-settingsshkey.html>`_ .\n')
    ssh_public_key: typing.Optional[str] = pydantic.Field(None, description="The user's SSH public key.\n")
    ssh_username: typing.Optional[str] = pydantic.Field(None, description='The user\'s SSH user name.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-opsworks-userprofile.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    cfn_user_profile_props = opsworks.CfnUserProfileProps(\n        iam_user_arn="iamUserArn",\n\n        # the properties below are optional\n        allow_self_management=False,\n        ssh_public_key="sshPublicKey",\n        ssh_username="sshUsername"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['iam_user_arn', 'allow_self_management', 'ssh_public_key', 'ssh_username']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnUserProfileProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_opsworks.CfnVolumeProps
class CfnVolumePropsDef(BaseCfnProperty):
    ec2_volume_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon EC2 volume ID.\n')
    stack_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The stack ID.\n')
    mount_point: typing.Optional[str] = pydantic.Field(None, description='The volume mount point. For example, "/mnt/disk1".\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The volume name. Volume names are a maximum of 128 characters.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-opsworks-volume.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_opsworks as opsworks\n\n    cfn_volume_props = opsworks.CfnVolumeProps(\n        ec2_volume_id="ec2VolumeId",\n        stack_id="stackId",\n\n        # the properties below are optional\n        mount_point="mountPoint",\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['ec2_volume_id', 'stack_id', 'mount_point', 'name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_opsworks.CfnVolumeProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




import models

class ModuleModel(pydantic.BaseModel):
    CfnApp_DataSourceProperty: typing.Optional[dict[str, CfnApp_DataSourcePropertyDef]] = pydantic.Field(None)
    CfnApp_EnvironmentVariableProperty: typing.Optional[dict[str, CfnApp_EnvironmentVariablePropertyDef]] = pydantic.Field(None)
    CfnApp_SourceProperty: typing.Optional[dict[str, CfnApp_SourcePropertyDef]] = pydantic.Field(None)
    CfnApp_SslConfigurationProperty: typing.Optional[dict[str, CfnApp_SslConfigurationPropertyDef]] = pydantic.Field(None)
    CfnInstance_BlockDeviceMappingProperty: typing.Optional[dict[str, CfnInstance_BlockDeviceMappingPropertyDef]] = pydantic.Field(None)
    CfnInstance_EbsBlockDeviceProperty: typing.Optional[dict[str, CfnInstance_EbsBlockDevicePropertyDef]] = pydantic.Field(None)
    CfnInstance_TimeBasedAutoScalingProperty: typing.Optional[dict[str, CfnInstance_TimeBasedAutoScalingPropertyDef]] = pydantic.Field(None)
    CfnLayer_AutoScalingThresholdsProperty: typing.Optional[dict[str, CfnLayer_AutoScalingThresholdsPropertyDef]] = pydantic.Field(None)
    CfnLayer_LifecycleEventConfigurationProperty: typing.Optional[dict[str, CfnLayer_LifecycleEventConfigurationPropertyDef]] = pydantic.Field(None)
    CfnLayer_LoadBasedAutoScalingProperty: typing.Optional[dict[str, CfnLayer_LoadBasedAutoScalingPropertyDef]] = pydantic.Field(None)
    CfnLayer_RecipesProperty: typing.Optional[dict[str, CfnLayer_RecipesPropertyDef]] = pydantic.Field(None)
    CfnLayer_ShutdownEventConfigurationProperty: typing.Optional[dict[str, CfnLayer_ShutdownEventConfigurationPropertyDef]] = pydantic.Field(None)
    CfnLayer_VolumeConfigurationProperty: typing.Optional[dict[str, CfnLayer_VolumeConfigurationPropertyDef]] = pydantic.Field(None)
    CfnStack_ChefConfigurationProperty: typing.Optional[dict[str, CfnStack_ChefConfigurationPropertyDef]] = pydantic.Field(None)
    CfnStack_ElasticIpProperty: typing.Optional[dict[str, CfnStack_ElasticIpPropertyDef]] = pydantic.Field(None)
    CfnStack_RdsDbInstanceProperty: typing.Optional[dict[str, CfnStack_RdsDbInstancePropertyDef]] = pydantic.Field(None)
    CfnStack_SourceProperty: typing.Optional[dict[str, CfnStack_SourcePropertyDef]] = pydantic.Field(None)
    CfnStack_StackConfigurationManagerProperty: typing.Optional[dict[str, CfnStack_StackConfigurationManagerPropertyDef]] = pydantic.Field(None)
    CfnApp: typing.Optional[dict[str, CfnAppDef]] = pydantic.Field(None)
    CfnElasticLoadBalancerAttachment: typing.Optional[dict[str, CfnElasticLoadBalancerAttachmentDef]] = pydantic.Field(None)
    CfnInstance: typing.Optional[dict[str, CfnInstanceDef]] = pydantic.Field(None)
    CfnLayer: typing.Optional[dict[str, CfnLayerDef]] = pydantic.Field(None)
    CfnStack: typing.Optional[dict[str, CfnStackDef]] = pydantic.Field(None)
    CfnUserProfile: typing.Optional[dict[str, CfnUserProfileDef]] = pydantic.Field(None)
    CfnVolume: typing.Optional[dict[str, CfnVolumeDef]] = pydantic.Field(None)
    CfnAppProps: typing.Optional[dict[str, CfnAppPropsDef]] = pydantic.Field(None)
    CfnElasticLoadBalancerAttachmentProps: typing.Optional[dict[str, CfnElasticLoadBalancerAttachmentPropsDef]] = pydantic.Field(None)
    CfnInstanceProps: typing.Optional[dict[str, CfnInstancePropsDef]] = pydantic.Field(None)
    CfnLayerProps: typing.Optional[dict[str, CfnLayerPropsDef]] = pydantic.Field(None)
    CfnStackProps: typing.Optional[dict[str, CfnStackPropsDef]] = pydantic.Field(None)
    CfnUserProfileProps: typing.Optional[dict[str, CfnUserProfilePropsDef]] = pydantic.Field(None)
    CfnVolumeProps: typing.Optional[dict[str, CfnVolumePropsDef]] = pydantic.Field(None)
    ...
