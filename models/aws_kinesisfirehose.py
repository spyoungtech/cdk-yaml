from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonOpenSearchServerlessBufferingHintsProperty
class CfnDeliveryStream_AmazonOpenSearchServerlessBufferingHintsPropertyDef(BaseStruct):
    interval_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300 (5 minutes).\n')
    size_in_m_bs: typing.Union[int, float, None] = pydantic.Field(None, description='Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5. We recommend setting this parameter to a value greater than the amount of data you typically ingest into the delivery stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec, the value should be 10 MB or higher.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-amazonopensearchserverlessbufferinghints.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    amazon_open_search_serverless_buffering_hints_property = kinesisfirehose.CfnDeliveryStream.AmazonOpenSearchServerlessBufferingHintsProperty(\n        interval_in_seconds=123,\n        size_in_mBs=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['interval_in_seconds', 'size_in_m_bs']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonOpenSearchServerlessBufferingHintsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonOpenSearchServerlessDestinationConfigurationProperty
class CfnDeliveryStream_AmazonOpenSearchServerlessDestinationConfigurationPropertyDef(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Serverless offering for Amazon OpenSearch Service index name.\n')
    role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data Firehose for calling the Serverless offering for Amazon OpenSearch Service Configuration API and for indexing documents.\n')
    s3_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonOpenSearchServerlessBufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The buffering options. If no value is specified, the default values for AmazonopensearchserviceBufferingHints are used.\n')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    collection_endpoint: typing.Optional[str] = pydantic.Field(None, description='The endpoint to use when communicating with the collection in the Serverless offering for Amazon OpenSearch Service.\n')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonOpenSearchServerlessRetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The retry behavior in case Kinesis Data Firehose is unable to deliver documents to the Serverless offering for Amazon OpenSearch Service. The default value is 300 (5 minutes).\n')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='Defines how documents should be delivered to Amazon S3. When it is set to FailedDocumentsOnly, Kinesis Data Firehose writes any documents that could not be indexed to the configured Amazon S3 destination, with AmazonOpenSearchService-failed/ appended to the key prefix. When set to AllDocuments, Kinesis Data Firehose delivers all incoming records to Amazon S3, and also writes failed documents with AmazonOpenSearchService-failed/ appended to the prefix.\n')
    vpc_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_VpcConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'role_arn', 's3_configuration', 'buffering_hints', 'cloud_watch_logging_options', 'collection_endpoint', 'processing_configuration', 'retry_options', 's3_backup_mode', 'vpc_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonOpenSearchServerlessDestinationConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonOpenSearchServerlessRetryOptionsProperty
class CfnDeliveryStream_AmazonOpenSearchServerlessRetryOptionsPropertyDef(BaseStruct):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='After an initial failure to deliver to the Serverless offering for Amazon OpenSearch Service, the total amount of time during which Kinesis Data Firehose retries delivery (including the first attempt). After this time has elapsed, the failed documents are written to Amazon S3. Default value is 300 seconds (5 minutes). A value of 0 (zero) results in no retries.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-amazonopensearchserverlessretryoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    amazon_open_search_serverless_retry_options_property = kinesisfirehose.CfnDeliveryStream.AmazonOpenSearchServerlessRetryOptionsProperty(\n        duration_in_seconds=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['duration_in_seconds']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonOpenSearchServerlessRetryOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonopensearchserviceBufferingHintsProperty
class CfnDeliveryStream_AmazonopensearchserviceBufferingHintsPropertyDef(BaseStruct):
    interval_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300 (5 minutes).\n')
    size_in_m_bs: typing.Union[int, float, None] = pydantic.Field(None, description='Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5. We recommend setting this parameter to a value greater than the amount of data you typically ingest into the delivery stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec, the value should be 10 MB or higher.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-amazonopensearchservicebufferinghints.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    amazonopensearchservice_buffering_hints_property = kinesisfirehose.CfnDeliveryStream.AmazonopensearchserviceBufferingHintsProperty(\n        interval_in_seconds=123,\n        size_in_mBs=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['interval_in_seconds', 'size_in_m_bs']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonopensearchserviceBufferingHintsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonopensearchserviceDestinationConfigurationProperty
class CfnDeliveryStream_AmazonopensearchserviceDestinationConfigurationPropertyDef(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon OpenSearch Service index name.\n')
    role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data Firehose for calling the Amazon OpenSearch Service Configuration API and for indexing documents.\n')
    s3_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Describes the configuration of a destination in Amazon S3.\n')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonopensearchserviceBufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The buffering options. If no value is specified, the default values for AmazonopensearchserviceBufferingHints are used.\n')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes the Amazon CloudWatch logging options for your delivery stream.\n')
    cluster_endpoint: typing.Optional[str] = pydantic.Field(None, description='The endpoint to use when communicating with the cluster. Specify either this ClusterEndpoint or the DomainARN field.\n')
    document_id_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DocumentIdOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Indicates the method for setting up document ID. The supported methods are Kinesis Data Firehose generated document ID and OpenSearch Service generated document ID.\n')
    domain_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Amazon OpenSearch Service domain.\n')
    index_rotation_period: typing.Optional[str] = pydantic.Field(None, description='The Amazon OpenSearch Service index rotation period. Index rotation appends a timestamp to the IndexName to facilitate the expiration of old data.\n')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes a data processing configuration.\n')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonopensearchserviceRetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The retry behavior in case Kinesis Data Firehose is unable to deliver documents to Amazon OpenSearch Service. The default value is 300 (5 minutes).\n')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='Defines how documents should be delivered to Amazon S3.\n')
    type_name: typing.Optional[str] = pydantic.Field(None, description='The Amazon OpenSearch Service type name.\n')
    vpc_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_VpcConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The details of the VPC of the Amazon OpenSearch Service destination.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-amazonopensearchservicedestinationconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    amazonopensearchservice_destination_configuration_property = kinesisfirehose.CfnDeliveryStream.AmazonopensearchserviceDestinationConfigurationProperty(\n        index_name="indexName",\n        role_arn="roleArn",\n        s3_configuration=kinesisfirehose.CfnDeliveryStream.S3DestinationConfigurationProperty(\n            bucket_arn="bucketArn",\n            role_arn="roleArn",\n\n            # the properties below are optional\n            buffering_hints=kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty(\n                interval_in_seconds=123,\n                size_in_mBs=123\n            ),\n            cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n                enabled=False,\n                log_group_name="logGroupName",\n                log_stream_name="logStreamName"\n            ),\n            compression_format="compressionFormat",\n            encryption_configuration=kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty(\n                kms_encryption_config=kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n                    awskms_key_arn="awskmsKeyArn"\n                ),\n                no_encryption_config="noEncryptionConfig"\n            ),\n            error_output_prefix="errorOutputPrefix",\n            prefix="prefix"\n        ),\n\n        # the properties below are optional\n        buffering_hints=kinesisfirehose.CfnDeliveryStream.AmazonopensearchserviceBufferingHintsProperty(\n            interval_in_seconds=123,\n            size_in_mBs=123\n        ),\n        cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n            enabled=False,\n            log_group_name="logGroupName",\n            log_stream_name="logStreamName"\n        ),\n        cluster_endpoint="clusterEndpoint",\n        document_id_options=kinesisfirehose.CfnDeliveryStream.DocumentIdOptionsProperty(\n            default_document_id_format="defaultDocumentIdFormat"\n        ),\n        domain_arn="domainArn",\n        index_rotation_period="indexRotationPeriod",\n        processing_configuration=kinesisfirehose.CfnDeliveryStream.ProcessingConfigurationProperty(\n            enabled=False,\n            processors=[kinesisfirehose.CfnDeliveryStream.ProcessorProperty(\n                type="type",\n\n                # the properties below are optional\n                parameters=[kinesisfirehose.CfnDeliveryStream.ProcessorParameterProperty(\n                    parameter_name="parameterName",\n                    parameter_value="parameterValue"\n                )]\n            )]\n        ),\n        retry_options=kinesisfirehose.CfnDeliveryStream.AmazonopensearchserviceRetryOptionsProperty(\n            duration_in_seconds=123\n        ),\n        s3_backup_mode="s3BackupMode",\n        type_name="typeName",\n        vpc_configuration=kinesisfirehose.CfnDeliveryStream.VpcConfigurationProperty(\n            role_arn="roleArn",\n            security_group_ids=["securityGroupIds"],\n            subnet_ids=["subnetIds"]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'role_arn', 's3_configuration', 'buffering_hints', 'cloud_watch_logging_options', 'cluster_endpoint', 'document_id_options', 'domain_arn', 'index_rotation_period', 'processing_configuration', 'retry_options', 's3_backup_mode', 'type_name', 'vpc_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonopensearchserviceDestinationConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonopensearchserviceRetryOptionsProperty
class CfnDeliveryStream_AmazonopensearchserviceRetryOptionsPropertyDef(BaseStruct):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='After an initial failure to deliver to Amazon OpenSearch Service, the total amount of time during which Kinesis Data Firehose retries delivery (including the first attempt). After this time has elapsed, the failed documents are written to Amazon S3. Default value is 300 seconds (5 minutes). A value of 0 (zero) results in no retries.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-amazonopensearchserviceretryoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    amazonopensearchservice_retry_options_property = kinesisfirehose.CfnDeliveryStream.AmazonopensearchserviceRetryOptionsProperty(\n        duration_in_seconds=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['duration_in_seconds']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AmazonopensearchserviceRetryOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AuthenticationConfigurationProperty
class CfnDeliveryStream_AuthenticationConfigurationPropertyDef(BaseStruct):
    connectivity: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of connectivity used to access the Amazon MSK cluster.\n')
    role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the role used to access the Amazon MSK cluster.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-authenticationconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    authentication_configuration_property = kinesisfirehose.CfnDeliveryStream.AuthenticationConfigurationProperty(\n        connectivity="connectivity",\n        role_arn="roleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['connectivity', 'role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.AuthenticationConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty
class CfnDeliveryStream_BufferingHintsPropertyDef(BaseStruct):
    interval_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='The length of time, in seconds, that Kinesis Data Firehose buffers incoming data before delivering it to the destination. For valid values, see the ``IntervalInSeconds`` content for the `BufferingHints <https://docs.aws.amazon.com/firehose/latest/APIReference/API_BufferingHints.html>`_ data type in the *Amazon Kinesis Data Firehose API Reference* .\n')
    size_in_m_bs: typing.Union[int, float, None] = pydantic.Field(None, description='The size of the buffer, in MBs, that Kinesis Data Firehose uses for incoming data before delivering it to the destination. For valid values, see the ``SizeInMBs`` content for the `BufferingHints <https://docs.aws.amazon.com/firehose/latest/APIReference/API_BufferingHints.html>`_ data type in the *Amazon Kinesis Data Firehose API Reference* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-bufferinghints.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    buffering_hints_property = kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty(\n        interval_in_seconds=123,\n        size_in_mBs=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['interval_in_seconds', 'size_in_m_bs']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty
class CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef(BaseStruct):
    enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether CloudWatch Logs logging is enabled.\n')
    log_group_name: typing.Optional[str] = pydantic.Field(None, description='The name of the CloudWatch Logs log group that contains the log stream that Kinesis Data Firehose will use. Conditional. If you enable logging, you must specify this property.\n')
    log_stream_name: typing.Optional[str] = pydantic.Field(None, description='The name of the CloudWatch Logs log stream that Kinesis Data Firehose uses to send logs about data delivery. Conditional. If you enable logging, you must specify this property.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-cloudwatchloggingoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    cloud_watch_logging_options_property = kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n        enabled=False,\n        log_group_name="logGroupName",\n        log_stream_name="logStreamName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['enabled', 'log_group_name', 'log_stream_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.CopyCommandProperty
class CfnDeliveryStream_CopyCommandPropertyDef(BaseStruct):
    data_table_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the target table. The table must already exist in the database.\n')
    copy_options: typing.Optional[str] = pydantic.Field(None, description='Parameters to use with the Amazon Redshift ``COPY`` command. For examples, see the ``CopyOptions`` content for the `CopyCommand <https://docs.aws.amazon.com/firehose/latest/APIReference/API_CopyCommand.html>`_ data type in the *Amazon Kinesis Data Firehose API Reference* .\n')
    data_table_columns: typing.Optional[str] = pydantic.Field(None, description='A comma-separated list of column names.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-copycommand.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    copy_command_property = kinesisfirehose.CfnDeliveryStream.CopyCommandProperty(\n        data_table_name="dataTableName",\n\n        # the properties below are optional\n        copy_options="copyOptions",\n        data_table_columns="dataTableColumns"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['data_table_name', 'copy_options', 'data_table_columns']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.CopyCommandProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.DataFormatConversionConfigurationProperty
class CfnDeliveryStream_DataFormatConversionConfigurationPropertyDef(BaseStruct):
    enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Defaults to ``true`` . Set it to ``false`` if you want to disable format conversion while preserving the configuration details.\n')
    input_format_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_InputFormatConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the deserializer that you want Kinesis Data Firehose to use to convert the format of your data from JSON. This parameter is required if ``Enabled`` is set to true.\n')
    output_format_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_OutputFormatConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the serializer that you want Kinesis Data Firehose to use to convert the format of your data to the Parquet or ORC format. This parameter is required if ``Enabled`` is set to true.\n')
    schema_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_SchemaConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the AWS Glue Data Catalog table that contains the column information. This parameter is required if ``Enabled`` is set to true.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-dataformatconversionconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    data_format_conversion_configuration_property = kinesisfirehose.CfnDeliveryStream.DataFormatConversionConfigurationProperty(\n        enabled=False,\n        input_format_configuration=kinesisfirehose.CfnDeliveryStream.InputFormatConfigurationProperty(\n            deserializer=kinesisfirehose.CfnDeliveryStream.DeserializerProperty(\n                hive_json_ser_de=kinesisfirehose.CfnDeliveryStream.HiveJsonSerDeProperty(\n                    timestamp_formats=["timestampFormats"]\n                ),\n                open_xJson_ser_de=kinesisfirehose.CfnDeliveryStream.OpenXJsonSerDeProperty(\n                    case_insensitive=False,\n                    column_to_json_key_mappings={\n                        "column_to_json_key_mappings_key": "columnToJsonKeyMappings"\n                    },\n                    convert_dots_in_json_keys_to_underscores=False\n                )\n            )\n        ),\n        output_format_configuration=kinesisfirehose.CfnDeliveryStream.OutputFormatConfigurationProperty(\n            serializer=kinesisfirehose.CfnDeliveryStream.SerializerProperty(\n                orc_ser_de=kinesisfirehose.CfnDeliveryStream.OrcSerDeProperty(\n                    block_size_bytes=123,\n                    bloom_filter_columns=["bloomFilterColumns"],\n                    bloom_filter_false_positive_probability=123,\n                    compression="compression",\n                    dictionary_key_threshold=123,\n                    enable_padding=False,\n                    format_version="formatVersion",\n                    padding_tolerance=123,\n                    row_index_stride=123,\n                    stripe_size_bytes=123\n                ),\n                parquet_ser_de=kinesisfirehose.CfnDeliveryStream.ParquetSerDeProperty(\n                    block_size_bytes=123,\n                    compression="compression",\n                    enable_dictionary_compression=False,\n                    max_padding_bytes=123,\n                    page_size_bytes=123,\n                    writer_version="writerVersion"\n                )\n            )\n        ),\n        schema_configuration=kinesisfirehose.CfnDeliveryStream.SchemaConfigurationProperty(\n            catalog_id="catalogId",\n            database_name="databaseName",\n            region="region",\n            role_arn="roleArn",\n            table_name="tableName",\n            version_id="versionId"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['enabled', 'input_format_configuration', 'output_format_configuration', 'schema_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.DataFormatConversionConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.DeliveryStreamEncryptionConfigurationInputProperty
class CfnDeliveryStream_DeliveryStreamEncryptionConfigurationInputPropertyDef(BaseStruct):
    key_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Indicates the type of customer master key (CMK) to use for encryption. The default setting is ``AWS_OWNED_CMK`` . For more information about CMKs, see `Customer Master Keys (CMKs) <https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys>`_ . You can use a CMK of type CUSTOMER_MANAGED_CMK to encrypt up to 500 delivery streams. .. epigraph:: To encrypt your delivery stream, use symmetric CMKs. Kinesis Data Firehose doesn't support asymmetric CMKs. For information about symmetric and asymmetric CMKs, see `About Symmetric and Asymmetric CMKs <https://docs.aws.amazon.com/kms/latest/developerguide/symm-asymm-concepts.html>`_ in the AWS Key Management Service developer guide.\n")
    key_arn: typing.Optional[str] = pydantic.Field(None, description='If you set ``KeyType`` to ``CUSTOMER_MANAGED_CMK`` , you must specify the Amazon Resource Name (ARN) of the CMK. If you set ``KeyType`` to ``AWS _OWNED_CMK`` , Kinesis Data Firehose uses a service-account CMK.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-deliverystreamencryptionconfigurationinput.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    delivery_stream_encryption_configuration_input_property = kinesisfirehose.CfnDeliveryStream.DeliveryStreamEncryptionConfigurationInputProperty(\n        key_type="keyType",\n\n        # the properties below are optional\n        key_arn="keyArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['key_type', 'key_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.DeliveryStreamEncryptionConfigurationInputProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.DeserializerProperty
class CfnDeliveryStream_DeserializerPropertyDef(BaseStruct):
    hive_json_ser_de: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_HiveJsonSerDePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for deserializing data, which means converting it from the JSON format in preparation for serializing it to the Parquet or ORC format. This is one of two deserializers you can choose, depending on which one offers the functionality you need. The other option is the OpenX SerDe.\n')
    open_x_json_ser_de: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_OpenXJsonSerDePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The OpenX SerDe. Used by Kinesis Data Firehose for deserializing data, which means converting it from the JSON format in preparation for serializing it to the Parquet or ORC format. This is one of two deserializers you can choose, depending on which one offers the functionality you need. The other option is the native Hive / HCatalog JsonSerDe.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-deserializer.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    deserializer_property = kinesisfirehose.CfnDeliveryStream.DeserializerProperty(\n        hive_json_ser_de=kinesisfirehose.CfnDeliveryStream.HiveJsonSerDeProperty(\n            timestamp_formats=["timestampFormats"]\n        ),\n        open_xJson_ser_de=kinesisfirehose.CfnDeliveryStream.OpenXJsonSerDeProperty(\n            case_insensitive=False,\n            column_to_json_key_mappings={\n                "column_to_json_key_mappings_key": "columnToJsonKeyMappings"\n            },\n            convert_dots_in_json_keys_to_underscores=False\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['hive_json_ser_de', 'open_x_json_ser_de']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.DeserializerProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.DocumentIdOptionsProperty
class CfnDeliveryStream_DocumentIdOptionsPropertyDef(BaseStruct):
    default_document_id_format: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='When the ``FIREHOSE_DEFAULT`` option is chosen, Kinesis Data Firehose generates a unique document ID for each record based on a unique internal identifier. The generated document ID is stable across multiple delivery attempts, which helps prevent the same record from being indexed multiple times with different document IDs. When the ``NO_DOCUMENT_ID`` option is chosen, Kinesis Data Firehose does not include any document IDs in the requests it sends to the Amazon OpenSearch Service. This causes the Amazon OpenSearch Service domain to generate document IDs. In case of multiple delivery attempts, this may cause the same record to be indexed more than once with different document IDs. This option enables write-heavy operations, such as the ingestion of logs and observability data, to consume less resources in the Amazon OpenSearch Service domain, resulting in improved performance.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-documentidoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    document_id_options_property = kinesisfirehose.CfnDeliveryStream.DocumentIdOptionsProperty(\n        default_document_id_format="defaultDocumentIdFormat"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['default_document_id_format']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.DocumentIdOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.DynamicPartitioningConfigurationProperty
class CfnDeliveryStream_DynamicPartitioningConfigurationPropertyDef(BaseStruct):
    enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Specifies whether dynamic partitioning is enabled for this Kinesis Data Firehose delivery stream.\n')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_RetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the retry behavior in case Kinesis Data Firehose is unable to deliver data to an Amazon S3 prefix.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-dynamicpartitioningconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    dynamic_partitioning_configuration_property = kinesisfirehose.CfnDeliveryStream.DynamicPartitioningConfigurationProperty(\n        enabled=False,\n        retry_options=kinesisfirehose.CfnDeliveryStream.RetryOptionsProperty(\n            duration_in_seconds=123\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['enabled', 'retry_options']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.DynamicPartitioningConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ElasticsearchBufferingHintsProperty
class CfnDeliveryStream_ElasticsearchBufferingHintsPropertyDef(BaseStruct):
    interval_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='The length of time, in seconds, that Kinesis Data Firehose buffers incoming data before delivering it to the destination. For valid values, see the ``IntervalInSeconds`` content for the `BufferingHints <https://docs.aws.amazon.com/firehose/latest/APIReference/API_BufferingHints.html>`_ data type in the *Amazon Kinesis Data Firehose API Reference* .\n')
    size_in_m_bs: typing.Union[int, float, None] = pydantic.Field(None, description='The size of the buffer, in MBs, that Kinesis Data Firehose uses for incoming data before delivering it to the destination. For valid values, see the ``SizeInMBs`` content for the `BufferingHints <https://docs.aws.amazon.com/firehose/latest/APIReference/API_BufferingHints.html>`_ data type in the *Amazon Kinesis Data Firehose API Reference* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-elasticsearchbufferinghints.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    elasticsearch_buffering_hints_property = kinesisfirehose.CfnDeliveryStream.ElasticsearchBufferingHintsProperty(\n        interval_in_seconds=123,\n        size_in_mBs=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['interval_in_seconds', 'size_in_m_bs']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ElasticsearchBufferingHintsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ElasticsearchDestinationConfigurationProperty
class CfnDeliveryStream_ElasticsearchDestinationConfigurationPropertyDef(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Elasticsearch index to which Kinesis Data Firehose adds data for indexing.\n')
    role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data Firehose for calling the Amazon ES Configuration API and for indexing documents. For more information, see `Controlling Access with Amazon Kinesis Data Firehose <https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html>`_ .\n')
    s3_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The S3 bucket where Kinesis Data Firehose backs up incoming data.\n')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ElasticsearchBufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configures how Kinesis Data Firehose buffers incoming data while delivering it to the Amazon ES domain.\n')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Amazon CloudWatch Logs logging options for the delivery stream.\n')
    cluster_endpoint: typing.Optional[str] = pydantic.Field(None, description='The endpoint to use when communicating with the cluster. Specify either this ``ClusterEndpoint`` or the ``DomainARN`` field.\n')
    document_id_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DocumentIdOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Indicates the method for setting up document ID. The supported methods are Kinesis Data Firehose generated document ID and OpenSearch Service generated document ID.\n')
    domain_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Amazon ES domain. The IAM role must have permissions for ``DescribeElasticsearchDomain`` , ``DescribeElasticsearchDomains`` , and ``DescribeElasticsearchDomainConfig`` after assuming the role specified in *RoleARN* . Specify either ``ClusterEndpoint`` or ``DomainARN`` .\n')
    index_rotation_period: typing.Optional[str] = pydantic.Field(None, description='The frequency of Elasticsearch index rotation. If you enable index rotation, Kinesis Data Firehose appends a portion of the UTC arrival timestamp to the specified index name, and rotates the appended timestamp accordingly. For more information, see `Index Rotation for the Amazon ES Destination <https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation>`_ in the *Amazon Kinesis Data Firehose Developer Guide* .\n')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The data processing configuration for the Kinesis Data Firehose delivery stream.\n')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ElasticsearchRetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The retry behavior when Kinesis Data Firehose is unable to deliver data to Amazon ES.\n')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='The condition under which Kinesis Data Firehose delivers data to Amazon Simple Storage Service (Amazon S3). You can send Amazon S3 all documents (all data) or only the documents that Kinesis Data Firehose could not deliver to the Amazon ES destination. For more information and valid values, see the ``S3BackupMode`` content for the `ElasticsearchDestinationConfiguration <https://docs.aws.amazon.com/firehose/latest/APIReference/API_ElasticsearchDestinationConfiguration.html>`_ data type in the *Amazon Kinesis Data Firehose API Reference* .\n')
    type_name: typing.Optional[str] = pydantic.Field(None, description='The Elasticsearch type name that Amazon ES adds to documents when indexing data.\n')
    vpc_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_VpcConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The details of the VPC of the Amazon ES destination.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-elasticsearchdestinationconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    elasticsearch_destination_configuration_property = kinesisfirehose.CfnDeliveryStream.ElasticsearchDestinationConfigurationProperty(\n        index_name="indexName",\n        role_arn="roleArn",\n        s3_configuration=kinesisfirehose.CfnDeliveryStream.S3DestinationConfigurationProperty(\n            bucket_arn="bucketArn",\n            role_arn="roleArn",\n\n            # the properties below are optional\n            buffering_hints=kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty(\n                interval_in_seconds=123,\n                size_in_mBs=123\n            ),\n            cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n                enabled=False,\n                log_group_name="logGroupName",\n                log_stream_name="logStreamName"\n            ),\n            compression_format="compressionFormat",\n            encryption_configuration=kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty(\n                kms_encryption_config=kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n                    awskms_key_arn="awskmsKeyArn"\n                ),\n                no_encryption_config="noEncryptionConfig"\n            ),\n            error_output_prefix="errorOutputPrefix",\n            prefix="prefix"\n        ),\n\n        # the properties below are optional\n        buffering_hints=kinesisfirehose.CfnDeliveryStream.ElasticsearchBufferingHintsProperty(\n            interval_in_seconds=123,\n            size_in_mBs=123\n        ),\n        cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n            enabled=False,\n            log_group_name="logGroupName",\n            log_stream_name="logStreamName"\n        ),\n        cluster_endpoint="clusterEndpoint",\n        document_id_options=kinesisfirehose.CfnDeliveryStream.DocumentIdOptionsProperty(\n            default_document_id_format="defaultDocumentIdFormat"\n        ),\n        domain_arn="domainArn",\n        index_rotation_period="indexRotationPeriod",\n        processing_configuration=kinesisfirehose.CfnDeliveryStream.ProcessingConfigurationProperty(\n            enabled=False,\n            processors=[kinesisfirehose.CfnDeliveryStream.ProcessorProperty(\n                type="type",\n\n                # the properties below are optional\n                parameters=[kinesisfirehose.CfnDeliveryStream.ProcessorParameterProperty(\n                    parameter_name="parameterName",\n                    parameter_value="parameterValue"\n                )]\n            )]\n        ),\n        retry_options=kinesisfirehose.CfnDeliveryStream.ElasticsearchRetryOptionsProperty(\n            duration_in_seconds=123\n        ),\n        s3_backup_mode="s3BackupMode",\n        type_name="typeName",\n        vpc_configuration=kinesisfirehose.CfnDeliveryStream.VpcConfigurationProperty(\n            role_arn="roleArn",\n            security_group_ids=["securityGroupIds"],\n            subnet_ids=["subnetIds"]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'role_arn', 's3_configuration', 'buffering_hints', 'cloud_watch_logging_options', 'cluster_endpoint', 'document_id_options', 'domain_arn', 'index_rotation_period', 'processing_configuration', 'retry_options', 's3_backup_mode', 'type_name', 'vpc_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ElasticsearchDestinationConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ElasticsearchRetryOptionsProperty
class CfnDeliveryStream_ElasticsearchRetryOptionsPropertyDef(BaseStruct):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description="After an initial failure to deliver to Amazon ES, the total amount of time during which Kinesis Data Firehose re-attempts delivery (including the first attempt). If Kinesis Data Firehose can't deliver the data within the specified time, it writes the data to the backup S3 bucket. For valid values, see the ``DurationInSeconds`` content for the `ElasticsearchRetryOptions <https://docs.aws.amazon.com/firehose/latest/APIReference/API_ElasticsearchRetryOptions.html>`_ data type in the *Amazon Kinesis Data Firehose API Reference* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-elasticsearchretryoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    elasticsearch_retry_options_property = kinesisfirehose.CfnDeliveryStream.ElasticsearchRetryOptionsProperty(\n        duration_in_seconds=123\n    )\n")
    _init_params: typing.ClassVar[list[str]] = ['duration_in_seconds']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ElasticsearchRetryOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty
class CfnDeliveryStream_EncryptionConfigurationPropertyDef(BaseStruct):
    kms_encryption_config: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_KMSEncryptionConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The AWS Key Management Service ( AWS KMS) encryption key that Amazon S3 uses to encrypt your data.\n')
    no_encryption_config: typing.Optional[str] = pydantic.Field(None, description='Disables encryption. For valid values, see the ``NoEncryptionConfig`` content for the `EncryptionConfiguration <https://docs.aws.amazon.com/firehose/latest/APIReference/API_EncryptionConfiguration.html>`_ data type in the *Amazon Kinesis Data Firehose API Reference* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-encryptionconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    encryption_configuration_property = kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty(\n        kms_encryption_config=kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n            awskms_key_arn="awskmsKeyArn"\n        ),\n        no_encryption_config="noEncryptionConfig"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['kms_encryption_config', 'no_encryption_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ExtendedS3DestinationConfigurationProperty
class CfnDeliveryStream_ExtendedS3DestinationConfigurationPropertyDef(BaseStruct):
    bucket_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the Amazon S3 bucket. For constraints, see `ExtendedS3DestinationConfiguration <https://docs.aws.amazon.com/firehose/latest/APIReference/API_ExtendedS3DestinationConfiguration.html>`_ in the *Amazon Kinesis Data Firehose API Reference* .\n')
    role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the AWS credentials. For constraints, see `ExtendedS3DestinationConfiguration <https://docs.aws.amazon.com/firehose/latest/APIReference/API_ExtendedS3DestinationConfiguration.html>`_ in the *Amazon Kinesis Data Firehose API Reference* .\n')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_BufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The buffering option.\n')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Amazon CloudWatch logging options for your delivery stream.\n')
    compression_format: typing.Optional[str] = pydantic.Field(None, description='The compression format. If no value is specified, the default is ``UNCOMPRESSED`` .\n')
    data_format_conversion_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DataFormatConversionConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The serializer, deserializer, and schema for converting data from the JSON format to the Parquet or ORC format before writing it to Amazon S3.\n')
    dynamic_partitioning_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DynamicPartitioningConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration of the dynamic partitioning mechanism that creates targeted data sets from the streaming data by partitioning it based on partition keys.\n')
    encryption_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_EncryptionConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The encryption configuration for the Kinesis Data Firehose delivery stream. The default value is ``NoEncryption`` .\n')
    error_output_prefix: typing.Optional[str] = pydantic.Field(None, description='A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing them to S3. This prefix appears immediately following the bucket name. For information about how to specify this prefix, see `Custom Prefixes for Amazon S3 Objects <https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html>`_ .\n')
    prefix: typing.Optional[str] = pydantic.Field(None, description='The ``YYYY/MM/DD/HH`` time format prefix is automatically used for delivered Amazon S3 files. For more information, see `ExtendedS3DestinationConfiguration <https://docs.aws.amazon.com/firehose/latest/APIReference/API_ExtendedS3DestinationConfiguration.html>`_ in the *Amazon Kinesis Data Firehose API Reference* .\n')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The data processing configuration for the Kinesis Data Firehose delivery stream.\n')
    s3_backup_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration for backup in Amazon S3.\n')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='The Amazon S3 backup mode. After you create a delivery stream, you can update it to enable Amazon S3 backup if it is disabled. If backup is enabled, you can\'t update the delivery stream to disable it.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-extendeds3destinationconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    extended_s3_destination_configuration_property = kinesisfirehose.CfnDeliveryStream.ExtendedS3DestinationConfigurationProperty(\n        bucket_arn="bucketArn",\n        role_arn="roleArn",\n\n        # the properties below are optional\n        buffering_hints=kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty(\n            interval_in_seconds=123,\n            size_in_mBs=123\n        ),\n        cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n            enabled=False,\n            log_group_name="logGroupName",\n            log_stream_name="logStreamName"\n        ),\n        compression_format="compressionFormat",\n        data_format_conversion_configuration=kinesisfirehose.CfnDeliveryStream.DataFormatConversionConfigurationProperty(\n            enabled=False,\n            input_format_configuration=kinesisfirehose.CfnDeliveryStream.InputFormatConfigurationProperty(\n                deserializer=kinesisfirehose.CfnDeliveryStream.DeserializerProperty(\n                    hive_json_ser_de=kinesisfirehose.CfnDeliveryStream.HiveJsonSerDeProperty(\n                        timestamp_formats=["timestampFormats"]\n                    ),\n                    open_xJson_ser_de=kinesisfirehose.CfnDeliveryStream.OpenXJsonSerDeProperty(\n                        case_insensitive=False,\n                        column_to_json_key_mappings={\n                            "column_to_json_key_mappings_key": "columnToJsonKeyMappings"\n                        },\n                        convert_dots_in_json_keys_to_underscores=False\n                    )\n                )\n            ),\n            output_format_configuration=kinesisfirehose.CfnDeliveryStream.OutputFormatConfigurationProperty(\n                serializer=kinesisfirehose.CfnDeliveryStream.SerializerProperty(\n                    orc_ser_de=kinesisfirehose.CfnDeliveryStream.OrcSerDeProperty(\n                        block_size_bytes=123,\n                        bloom_filter_columns=["bloomFilterColumns"],\n                        bloom_filter_false_positive_probability=123,\n                        compression="compression",\n                        dictionary_key_threshold=123,\n                        enable_padding=False,\n                        format_version="formatVersion",\n                        padding_tolerance=123,\n                        row_index_stride=123,\n                        stripe_size_bytes=123\n                    ),\n                    parquet_ser_de=kinesisfirehose.CfnDeliveryStream.ParquetSerDeProperty(\n                        block_size_bytes=123,\n                        compression="compression",\n                        enable_dictionary_compression=False,\n                        max_padding_bytes=123,\n                        page_size_bytes=123,\n                        writer_version="writerVersion"\n                    )\n                )\n            ),\n            schema_configuration=kinesisfirehose.CfnDeliveryStream.SchemaConfigurationProperty(\n                catalog_id="catalogId",\n                database_name="databaseName",\n                region="region",\n                role_arn="roleArn",\n                table_name="tableName",\n                version_id="versionId"\n            )\n        ),\n        dynamic_partitioning_configuration=kinesisfirehose.CfnDeliveryStream.DynamicPartitioningConfigurationProperty(\n            enabled=False,\n            retry_options=kinesisfirehose.CfnDeliveryStream.RetryOptionsProperty(\n                duration_in_seconds=123\n            )\n        ),\n        encryption_configuration=kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty(\n            kms_encryption_config=kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n                awskms_key_arn="awskmsKeyArn"\n            ),\n            no_encryption_config="noEncryptionConfig"\n        ),\n        error_output_prefix="errorOutputPrefix",\n        prefix="prefix",\n        processing_configuration=kinesisfirehose.CfnDeliveryStream.ProcessingConfigurationProperty(\n            enabled=False,\n            processors=[kinesisfirehose.CfnDeliveryStream.ProcessorProperty(\n                type="type",\n\n                # the properties below are optional\n                parameters=[kinesisfirehose.CfnDeliveryStream.ProcessorParameterProperty(\n                    parameter_name="parameterName",\n                    parameter_value="parameterValue"\n                )]\n            )]\n        ),\n        s3_backup_configuration=kinesisfirehose.CfnDeliveryStream.S3DestinationConfigurationProperty(\n            bucket_arn="bucketArn",\n            role_arn="roleArn",\n\n            # the properties below are optional\n            buffering_hints=kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty(\n                interval_in_seconds=123,\n                size_in_mBs=123\n            ),\n            cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n                enabled=False,\n                log_group_name="logGroupName",\n                log_stream_name="logStreamName"\n            ),\n            compression_format="compressionFormat",\n            encryption_configuration=kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty(\n                kms_encryption_config=kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n                    awskms_key_arn="awskmsKeyArn"\n                ),\n                no_encryption_config="noEncryptionConfig"\n            ),\n            error_output_prefix="errorOutputPrefix",\n            prefix="prefix"\n        ),\n        s3_backup_mode="s3BackupMode"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket_arn', 'role_arn', 'buffering_hints', 'cloud_watch_logging_options', 'compression_format', 'data_format_conversion_configuration', 'dynamic_partitioning_configuration', 'encryption_configuration', 'error_output_prefix', 'prefix', 'processing_configuration', 's3_backup_configuration', 's3_backup_mode']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ExtendedS3DestinationConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.HiveJsonSerDeProperty
class CfnDeliveryStream_HiveJsonSerDePropertyDef(BaseStruct):
    timestamp_formats: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Indicates how you want Kinesis Data Firehose to parse the date and timestamps that may be present in your input data JSON. To specify these format strings, follow the pattern syntax of JodaTime\'s DateTimeFormat format strings. For more information, see `Class DateTimeFormat <https://docs.aws.amazon.com/https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html>`_ . You can also use the special value ``millis`` to parse timestamps in epoch milliseconds. If you don\'t specify a format, Kinesis Data Firehose uses ``java.sql.Timestamp::valueOf`` by default.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-hivejsonserde.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    hive_json_ser_de_property = kinesisfirehose.CfnDeliveryStream.HiveJsonSerDeProperty(\n        timestamp_formats=["timestampFormats"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['timestamp_formats']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.HiveJsonSerDeProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.HttpEndpointCommonAttributeProperty
class CfnDeliveryStream_HttpEndpointCommonAttributePropertyDef(BaseStruct):
    attribute_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the HTTP endpoint common attribute.\n')
    attribute_value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The value of the HTTP endpoint common attribute.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-httpendpointcommonattribute.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    http_endpoint_common_attribute_property = kinesisfirehose.CfnDeliveryStream.HttpEndpointCommonAttributeProperty(\n        attribute_name="attributeName",\n        attribute_value="attributeValue"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['attribute_name', 'attribute_value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.HttpEndpointCommonAttributeProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.HttpEndpointConfigurationProperty
class CfnDeliveryStream_HttpEndpointConfigurationPropertyDef(BaseStruct):
    url: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The URL of the HTTP endpoint selected as the destination.\n')
    access_key: typing.Optional[str] = pydantic.Field(None, description='The access key required for Kinesis Firehose to authenticate with the HTTP endpoint selected as the destination.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the HTTP endpoint selected as the destination.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-httpendpointconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    http_endpoint_configuration_property = kinesisfirehose.CfnDeliveryStream.HttpEndpointConfigurationProperty(\n        url="url",\n\n        # the properties below are optional\n        access_key="accessKey",\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['url', 'access_key', 'name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.HttpEndpointConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.HttpEndpointDestinationConfigurationProperty
class CfnDeliveryStream_HttpEndpointDestinationConfigurationPropertyDef(BaseStruct):
    endpoint_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The configuration of the HTTP endpoint selected as the destination.\n')
    s3_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Describes the configuration of a destination in Amazon S3.\n')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_BufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The buffering options that can be used before data is delivered to the specified destination. Kinesis Data Firehose treats these options as hints, and it might choose to use more optimal values. The SizeInMBs and IntervalInSeconds parameters are optional. However, if you specify a value for one of them, you must also provide a value for the other.\n')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes the Amazon CloudWatch logging options for your delivery stream.\n')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes the data processing configuration.\n')
    request_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointRequestConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration of the request sent to the HTTP endpoint specified as the destination.\n')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_RetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of receipt from the specified HTTP endpoint destination.\n")
    role_arn: typing.Optional[str] = pydantic.Field(None, description='Kinesis Data Firehose uses this IAM role for all the permissions that the delivery stream needs.\n')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='Describes the S3 bucket backup options for the data that Kinesis Data Firehose delivers to the HTTP endpoint destination. You can back up all documents (AllData) or only the documents that Kinesis Data Firehose could not deliver to the specified HTTP endpoint destination (FailedDataOnly).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-httpendpointdestinationconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    http_endpoint_destination_configuration_property = kinesisfirehose.CfnDeliveryStream.HttpEndpointDestinationConfigurationProperty(\n        endpoint_configuration=kinesisfirehose.CfnDeliveryStream.HttpEndpointConfigurationProperty(\n            url="url",\n\n            # the properties below are optional\n            access_key="accessKey",\n            name="name"\n        ),\n        s3_configuration=kinesisfirehose.CfnDeliveryStream.S3DestinationConfigurationProperty(\n            bucket_arn="bucketArn",\n            role_arn="roleArn",\n\n            # the properties below are optional\n            buffering_hints=kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty(\n                interval_in_seconds=123,\n                size_in_mBs=123\n            ),\n            cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n                enabled=False,\n                log_group_name="logGroupName",\n                log_stream_name="logStreamName"\n            ),\n            compression_format="compressionFormat",\n            encryption_configuration=kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty(\n                kms_encryption_config=kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n                    awskms_key_arn="awskmsKeyArn"\n                ),\n                no_encryption_config="noEncryptionConfig"\n            ),\n            error_output_prefix="errorOutputPrefix",\n            prefix="prefix"\n        ),\n\n        # the properties below are optional\n        buffering_hints=kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty(\n            interval_in_seconds=123,\n            size_in_mBs=123\n        ),\n        cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n            enabled=False,\n            log_group_name="logGroupName",\n            log_stream_name="logStreamName"\n        ),\n        processing_configuration=kinesisfirehose.CfnDeliveryStream.ProcessingConfigurationProperty(\n            enabled=False,\n            processors=[kinesisfirehose.CfnDeliveryStream.ProcessorProperty(\n                type="type",\n\n                # the properties below are optional\n                parameters=[kinesisfirehose.CfnDeliveryStream.ProcessorParameterProperty(\n                    parameter_name="parameterName",\n                    parameter_value="parameterValue"\n                )]\n            )]\n        ),\n        request_configuration=kinesisfirehose.CfnDeliveryStream.HttpEndpointRequestConfigurationProperty(\n            common_attributes=[kinesisfirehose.CfnDeliveryStream.HttpEndpointCommonAttributeProperty(\n                attribute_name="attributeName",\n                attribute_value="attributeValue"\n            )],\n            content_encoding="contentEncoding"\n        ),\n        retry_options=kinesisfirehose.CfnDeliveryStream.RetryOptionsProperty(\n            duration_in_seconds=123\n        ),\n        role_arn="roleArn",\n        s3_backup_mode="s3BackupMode"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['endpoint_configuration', 's3_configuration', 'buffering_hints', 'cloud_watch_logging_options', 'processing_configuration', 'request_configuration', 'retry_options', 'role_arn', 's3_backup_mode']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.HttpEndpointDestinationConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.HttpEndpointRequestConfigurationProperty
class CfnDeliveryStream_HttpEndpointRequestConfigurationPropertyDef(BaseStruct):
    common_attributes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointCommonAttributePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Describes the metadata sent to the HTTP endpoint destination.\n')
    content_encoding: typing.Optional[str] = pydantic.Field(None, description='Kinesis Data Firehose uses the content encoding to compress the body of a request before sending the request to the destination. For more information, see Content-Encoding in MDN Web Docs, the official Mozilla documentation.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-httpendpointrequestconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    http_endpoint_request_configuration_property = kinesisfirehose.CfnDeliveryStream.HttpEndpointRequestConfigurationProperty(\n        common_attributes=[kinesisfirehose.CfnDeliveryStream.HttpEndpointCommonAttributeProperty(\n            attribute_name="attributeName",\n            attribute_value="attributeValue"\n        )],\n        content_encoding="contentEncoding"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['common_attributes', 'content_encoding']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.HttpEndpointRequestConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.InputFormatConfigurationProperty
class CfnDeliveryStream_InputFormatConfigurationPropertyDef(BaseStruct):
    deserializer: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DeserializerPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies which deserializer to use. You can choose either the Apache Hive JSON SerDe or the OpenX JSON SerDe. If both are non-null, the server rejects the request.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-inputformatconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    input_format_configuration_property = kinesisfirehose.CfnDeliveryStream.InputFormatConfigurationProperty(\n        deserializer=kinesisfirehose.CfnDeliveryStream.DeserializerProperty(\n            hive_json_ser_de=kinesisfirehose.CfnDeliveryStream.HiveJsonSerDeProperty(\n                timestamp_formats=["timestampFormats"]\n            ),\n            open_xJson_ser_de=kinesisfirehose.CfnDeliveryStream.OpenXJsonSerDeProperty(\n                case_insensitive=False,\n                column_to_json_key_mappings={\n                    "column_to_json_key_mappings_key": "columnToJsonKeyMappings"\n                },\n                convert_dots_in_json_keys_to_underscores=False\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['deserializer']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.InputFormatConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.KinesisStreamSourceConfigurationProperty
class CfnDeliveryStream_KinesisStreamSourceConfigurationPropertyDef(BaseStruct):
    kinesis_stream_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the source Kinesis data stream.\n')
    role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the role that provides access to the source Kinesis data stream.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-kinesisstreamsourceconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    kinesis_stream_source_configuration_property = kinesisfirehose.CfnDeliveryStream.KinesisStreamSourceConfigurationProperty(\n        kinesis_stream_arn="kinesisStreamArn",\n        role_arn="roleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['kinesis_stream_arn', 'role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.KinesisStreamSourceConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty
class CfnDeliveryStream_KMSEncryptionConfigPropertyDef(BaseStruct):
    awskms_key_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the AWS KMS encryption key that Amazon S3 uses to encrypt data delivered by the Kinesis Data Firehose stream. The key must belong to the same region as the destination S3 bucket.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-kmsencryptionconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    k_mSEncryption_config_property = kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n        awskms_key_arn="awskmsKeyArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['awskms_key_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.MSKSourceConfigurationProperty
class CfnDeliveryStream_MSKSourceConfigurationPropertyDef(BaseStruct):
    authentication_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AuthenticationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The authentication configuration of the Amazon MSK cluster.\n')
    msk_cluster_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the Amazon MSK cluster.\n')
    topic_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The topic name within the Amazon MSK cluster.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-msksourceconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    m_sKSource_configuration_property = kinesisfirehose.CfnDeliveryStream.MSKSourceConfigurationProperty(\n        authentication_configuration=kinesisfirehose.CfnDeliveryStream.AuthenticationConfigurationProperty(\n            connectivity="connectivity",\n            role_arn="roleArn"\n        ),\n        msk_cluster_arn="mskClusterArn",\n        topic_name="topicName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['authentication_configuration', 'msk_cluster_arn', 'topic_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.MSKSourceConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.OpenXJsonSerDeProperty
class CfnDeliveryStream_OpenXJsonSerDePropertyDef(BaseStruct):
    case_insensitive: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='When set to ``true`` , which is the default, Kinesis Data Firehose converts JSON keys to lowercase before deserializing them.\n')
    column_to_json_key_mappings: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='Maps column names to JSON keys that aren\'t identical to the column names. This is useful when the JSON contains keys that are Hive keywords. For example, ``timestamp`` is a Hive keyword. If you have a JSON key named ``timestamp`` , set this parameter to ``{"ts": "timestamp"}`` to map this key to a column named ``ts`` .\n')
    convert_dots_in_json_keys_to_underscores: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='When set to ``true`` , specifies that the names of the keys include dots and that you want Kinesis Data Firehose to replace them with underscores. This is useful because Apache Hive does not allow dots in column names. For example, if the JSON contains a key whose name is "a.b", you can define the column name to be "a_b" when using this option. The default is ``false`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-openxjsonserde.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    open_xJson_ser_de_property = kinesisfirehose.CfnDeliveryStream.OpenXJsonSerDeProperty(\n        case_insensitive=False,\n        column_to_json_key_mappings={\n            "column_to_json_key_mappings_key": "columnToJsonKeyMappings"\n        },\n        convert_dots_in_json_keys_to_underscores=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['case_insensitive', 'column_to_json_key_mappings', 'convert_dots_in_json_keys_to_underscores']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.OpenXJsonSerDeProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.OrcSerDeProperty
class CfnDeliveryStream_OrcSerDePropertyDef(BaseStruct):
    block_size_bytes: typing.Union[int, float, None] = pydantic.Field(None, description='The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.\n')
    bloom_filter_columns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The column names for which you want Kinesis Data Firehose to create bloom filters. The default is ``null`` .\n')
    bloom_filter_false_positive_probability: typing.Union[int, float, None] = pydantic.Field(None, description='The Bloom filter false positive probability (FPP). The lower the FPP, the bigger the Bloom filter. The default value is 0.05, the minimum is 0, and the maximum is 1.\n')
    compression: typing.Optional[str] = pydantic.Field(None, description='The compression code to use over data blocks. The default is ``SNAPPY`` .\n')
    dictionary_key_threshold: typing.Union[int, float, None] = pydantic.Field(None, description='Represents the fraction of the total number of non-null rows. To turn off dictionary encoding, set this fraction to a number that is less than the number of distinct keys in a dictionary. To always use dictionary encoding, set this threshold to 1.\n')
    enable_padding: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Set this to ``true`` to indicate that you want stripes to be padded to the HDFS block boundaries. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is ``false`` .\n')
    format_version: typing.Optional[str] = pydantic.Field(None, description='The version of the file to write. The possible values are ``V0_11`` and ``V0_12`` . The default is ``V0_12`` .\n')
    padding_tolerance: typing.Union[int, float, None] = pydantic.Field(None, description='A number between 0 and 1 that defines the tolerance for block padding as a decimal fraction of stripe size. The default value is 0.05, which means 5 percent of stripe size. For the default values of 64 MiB ORC stripes and 256 MiB HDFS blocks, the default block padding tolerance of 5 percent reserves a maximum of 3.2 MiB for padding within the 256 MiB block. In such a case, if the available size within the block is more than 3.2 MiB, a new, smaller stripe is inserted to fit within that space. This ensures that no stripe crosses block boundaries and causes remote reads within a node-local task. Kinesis Data Firehose ignores this parameter when ``EnablePadding`` is ``false`` .\n')
    row_index_stride: typing.Union[int, float, None] = pydantic.Field(None, description='The number of rows between index entries. The default is 10,000 and the minimum is 1,000.\n')
    stripe_size_bytes: typing.Union[int, float, None] = pydantic.Field(None, description='The number of bytes in each stripe. The default is 64 MiB and the minimum is 8 MiB.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-orcserde.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    orc_ser_de_property = kinesisfirehose.CfnDeliveryStream.OrcSerDeProperty(\n        block_size_bytes=123,\n        bloom_filter_columns=["bloomFilterColumns"],\n        bloom_filter_false_positive_probability=123,\n        compression="compression",\n        dictionary_key_threshold=123,\n        enable_padding=False,\n        format_version="formatVersion",\n        padding_tolerance=123,\n        row_index_stride=123,\n        stripe_size_bytes=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['block_size_bytes', 'bloom_filter_columns', 'bloom_filter_false_positive_probability', 'compression', 'dictionary_key_threshold', 'enable_padding', 'format_version', 'padding_tolerance', 'row_index_stride', 'stripe_size_bytes']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.OrcSerDeProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.OutputFormatConfigurationProperty
class CfnDeliveryStream_OutputFormatConfigurationPropertyDef(BaseStruct):
    serializer: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_SerializerPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies which serializer to use. You can choose either the ORC SerDe or the Parquet SerDe. If both are non-null, the server rejects the request.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-outputformatconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    output_format_configuration_property = kinesisfirehose.CfnDeliveryStream.OutputFormatConfigurationProperty(\n        serializer=kinesisfirehose.CfnDeliveryStream.SerializerProperty(\n            orc_ser_de=kinesisfirehose.CfnDeliveryStream.OrcSerDeProperty(\n                block_size_bytes=123,\n                bloom_filter_columns=["bloomFilterColumns"],\n                bloom_filter_false_positive_probability=123,\n                compression="compression",\n                dictionary_key_threshold=123,\n                enable_padding=False,\n                format_version="formatVersion",\n                padding_tolerance=123,\n                row_index_stride=123,\n                stripe_size_bytes=123\n            ),\n            parquet_ser_de=kinesisfirehose.CfnDeliveryStream.ParquetSerDeProperty(\n                block_size_bytes=123,\n                compression="compression",\n                enable_dictionary_compression=False,\n                max_padding_bytes=123,\n                page_size_bytes=123,\n                writer_version="writerVersion"\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['serializer']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.OutputFormatConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ParquetSerDeProperty
class CfnDeliveryStream_ParquetSerDePropertyDef(BaseStruct):
    block_size_bytes: typing.Union[int, float, None] = pydantic.Field(None, description='The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.\n')
    compression: typing.Optional[str] = pydantic.Field(None, description='The compression code to use over data blocks. The possible values are ``UNCOMPRESSED`` , ``SNAPPY`` , and ``GZIP`` , with the default being ``SNAPPY`` . Use ``SNAPPY`` for higher decompression speed. Use ``GZIP`` if the compression ratio is more important than speed.\n')
    enable_dictionary_compression: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether to enable dictionary compression.\n')
    max_padding_bytes: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum amount of padding to apply. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 0.\n')
    page_size_bytes: typing.Union[int, float, None] = pydantic.Field(None, description='The Parquet page size. Column chunks are divided into pages. A page is conceptually an indivisible unit (in terms of compression and encoding). The minimum value is 64 KiB and the default is 1 MiB.\n')
    writer_version: typing.Optional[str] = pydantic.Field(None, description='Indicates the version of row format to output. The possible values are ``V1`` and ``V2`` . The default is ``V1`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-parquetserde.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    parquet_ser_de_property = kinesisfirehose.CfnDeliveryStream.ParquetSerDeProperty(\n        block_size_bytes=123,\n        compression="compression",\n        enable_dictionary_compression=False,\n        max_padding_bytes=123,\n        page_size_bytes=123,\n        writer_version="writerVersion"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['block_size_bytes', 'compression', 'enable_dictionary_compression', 'max_padding_bytes', 'page_size_bytes', 'writer_version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ParquetSerDeProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ProcessingConfigurationProperty
class CfnDeliveryStream_ProcessingConfigurationPropertyDef(BaseStruct):
    enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether data processing is enabled (true) or disabled (false).\n')
    processors: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessorPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The data processors.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-processingconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    processing_configuration_property = kinesisfirehose.CfnDeliveryStream.ProcessingConfigurationProperty(\n        enabled=False,\n        processors=[kinesisfirehose.CfnDeliveryStream.ProcessorProperty(\n            type="type",\n\n            # the properties below are optional\n            parameters=[kinesisfirehose.CfnDeliveryStream.ProcessorParameterProperty(\n                parameter_name="parameterName",\n                parameter_value="parameterValue"\n            )]\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['enabled', 'processors']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ProcessingConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ProcessorParameterProperty
class CfnDeliveryStream_ProcessorParameterPropertyDef(BaseStruct):
    parameter_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the parameter. Currently the following default values are supported: 3 for ``NumberOfRetries`` and 60 for the ``BufferIntervalInSeconds`` . The ``BufferSizeInMBs`` ranges between 0.2 MB and up to 3MB. The default buffering hint is 1MB for all destinations, except Splunk. For Splunk, the default buffering hint is 256 KB.\n')
    parameter_value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The parameter value.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-processorparameter.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    processor_parameter_property = kinesisfirehose.CfnDeliveryStream.ProcessorParameterProperty(\n        parameter_name="parameterName",\n        parameter_value="parameterValue"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['parameter_name', 'parameter_value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ProcessorParameterProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ProcessorProperty
class CfnDeliveryStream_ProcessorPropertyDef(BaseStruct):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of processor. Valid values: ``Lambda`` .\n')
    parameters: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessorParameterPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The processor parameters.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-processor.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    processor_property = kinesisfirehose.CfnDeliveryStream.ProcessorProperty(\n        type="type",\n\n        # the properties below are optional\n        parameters=[kinesisfirehose.CfnDeliveryStream.ProcessorParameterProperty(\n            parameter_name="parameterName",\n            parameter_value="parameterValue"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type', 'parameters']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.ProcessorProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.RedshiftDestinationConfigurationProperty
class CfnDeliveryStream_RedshiftDestinationConfigurationPropertyDef(BaseStruct):
    cluster_jdbcurl: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The connection string that Kinesis Data Firehose uses to connect to the Amazon Redshift cluster.\n')
    copy_command: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CopyCommandPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Configures the Amazon Redshift ``COPY`` command that Kinesis Data Firehose uses to load data into the cluster from the Amazon S3 bucket.\n')
    password: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The password for the Amazon Redshift user that you specified in the ``Username`` property.\n')
    role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the AWS Identity and Access Management (IAM) role that grants Kinesis Data Firehose access to your Amazon S3 bucket and AWS KMS (if you enable data encryption). For more information, see `Grant Kinesis Data Firehose Access to an Amazon Redshift Destination <https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-rs>`_ in the *Amazon Kinesis Data Firehose Developer Guide* .\n')
    s3_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description="The S3 bucket where Kinesis Data Firehose first delivers data. After the data is in the bucket, Kinesis Data Firehose uses the ``COPY`` command to load the data into the Amazon Redshift cluster. For the Amazon S3 bucket's compression format, don't specify ``SNAPPY`` or ``ZIP`` because the Amazon Redshift ``COPY`` command doesn't support them.\n")
    username: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Redshift user that has permission to access the Amazon Redshift cluster. This user must have ``INSERT`` privileges for copying data from the Amazon S3 bucket to the cluster.\n')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The CloudWatch logging options for your delivery stream.\n')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The data processing configuration for the Kinesis Data Firehose delivery stream.\n')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_RedshiftRetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The retry behavior in case Kinesis Data Firehose is unable to deliver documents to Amazon Redshift. Default value is 3600 (60 minutes).\n')
    s3_backup_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration for backup in Amazon S3.\n')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='The Amazon S3 backup mode. After you create a delivery stream, you can update it to enable Amazon S3 backup if it is disabled. If backup is enabled, you can\'t update the delivery stream to disable it.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-redshiftdestinationconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    redshift_destination_configuration_property = kinesisfirehose.CfnDeliveryStream.RedshiftDestinationConfigurationProperty(\n        cluster_jdbcurl="clusterJdbcurl",\n        copy_command=kinesisfirehose.CfnDeliveryStream.CopyCommandProperty(\n            data_table_name="dataTableName",\n\n            # the properties below are optional\n            copy_options="copyOptions",\n            data_table_columns="dataTableColumns"\n        ),\n        password="password",\n        role_arn="roleArn",\n        s3_configuration=kinesisfirehose.CfnDeliveryStream.S3DestinationConfigurationProperty(\n            bucket_arn="bucketArn",\n            role_arn="roleArn",\n\n            # the properties below are optional\n            buffering_hints=kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty(\n                interval_in_seconds=123,\n                size_in_mBs=123\n            ),\n            cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n                enabled=False,\n                log_group_name="logGroupName",\n                log_stream_name="logStreamName"\n            ),\n            compression_format="compressionFormat",\n            encryption_configuration=kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty(\n                kms_encryption_config=kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n                    awskms_key_arn="awskmsKeyArn"\n                ),\n                no_encryption_config="noEncryptionConfig"\n            ),\n            error_output_prefix="errorOutputPrefix",\n            prefix="prefix"\n        ),\n        username="username",\n\n        # the properties below are optional\n        cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n            enabled=False,\n            log_group_name="logGroupName",\n            log_stream_name="logStreamName"\n        ),\n        processing_configuration=kinesisfirehose.CfnDeliveryStream.ProcessingConfigurationProperty(\n            enabled=False,\n            processors=[kinesisfirehose.CfnDeliveryStream.ProcessorProperty(\n                type="type",\n\n                # the properties below are optional\n                parameters=[kinesisfirehose.CfnDeliveryStream.ProcessorParameterProperty(\n                    parameter_name="parameterName",\n                    parameter_value="parameterValue"\n                )]\n            )]\n        ),\n        retry_options=kinesisfirehose.CfnDeliveryStream.RedshiftRetryOptionsProperty(\n            duration_in_seconds=123\n        ),\n        s3_backup_configuration=kinesisfirehose.CfnDeliveryStream.S3DestinationConfigurationProperty(\n            bucket_arn="bucketArn",\n            role_arn="roleArn",\n\n            # the properties below are optional\n            buffering_hints=kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty(\n                interval_in_seconds=123,\n                size_in_mBs=123\n            ),\n            cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n                enabled=False,\n                log_group_name="logGroupName",\n                log_stream_name="logStreamName"\n            ),\n            compression_format="compressionFormat",\n            encryption_configuration=kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty(\n                kms_encryption_config=kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n                    awskms_key_arn="awskmsKeyArn"\n                ),\n                no_encryption_config="noEncryptionConfig"\n            ),\n            error_output_prefix="errorOutputPrefix",\n            prefix="prefix"\n        ),\n        s3_backup_mode="s3BackupMode"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cluster_jdbcurl', 'copy_command', 'password', 'role_arn', 's3_configuration', 'username', 'cloud_watch_logging_options', 'processing_configuration', 'retry_options', 's3_backup_configuration', 's3_backup_mode']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.RedshiftDestinationConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.RedshiftRetryOptionsProperty
class CfnDeliveryStream_RedshiftRetryOptionsPropertyDef(BaseStruct):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='The length of time during which Kinesis Data Firehose retries delivery after a failure, starting from the initial request and including the first attempt. The default value is 3600 seconds (60 minutes). Kinesis Data Firehose does not retry if the value of ``DurationInSeconds`` is 0 (zero) or if the first delivery attempt takes longer than the current value.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-redshiftretryoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    redshift_retry_options_property = kinesisfirehose.CfnDeliveryStream.RedshiftRetryOptionsProperty(\n        duration_in_seconds=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['duration_in_seconds']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.RedshiftRetryOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.RetryOptionsProperty
class CfnDeliveryStream_RetryOptionsPropertyDef(BaseStruct):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description="The total amount of time that Kinesis Data Firehose spends on retries. This duration starts after the initial attempt to send data to the custom destination via HTTPS endpoint fails. It doesn't include the periods during which Kinesis Data Firehose waits for acknowledgment from the specified destination after each attempt.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-retryoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    retry_options_property = kinesisfirehose.CfnDeliveryStream.RetryOptionsProperty(\n        duration_in_seconds=123\n    )\n")
    _init_params: typing.ClassVar[list[str]] = ['duration_in_seconds']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.RetryOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.S3DestinationConfigurationProperty
class CfnDeliveryStream_S3DestinationConfigurationPropertyDef(BaseStruct):
    bucket_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the Amazon S3 bucket to send data to.\n')
    role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of an AWS Identity and Access Management (IAM) role that grants Kinesis Data Firehose access to your Amazon S3 bucket and AWS KMS (if you enable data encryption). For more information, see `Grant Kinesis Data Firehose Access to an Amazon S3 Destination <https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3>`_ in the *Amazon Kinesis Data Firehose Developer Guide* .\n')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_BufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configures how Kinesis Data Firehose buffers incoming data while delivering it to the Amazon S3 bucket.\n')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The CloudWatch logging options for your delivery stream.\n')
    compression_format: typing.Optional[str] = pydantic.Field(None, description='The type of compression that Kinesis Data Firehose uses to compress the data that it delivers to the Amazon S3 bucket. For valid values, see the ``CompressionFormat`` content for the `S3DestinationConfiguration <https://docs.aws.amazon.com/firehose/latest/APIReference/API_S3DestinationConfiguration.html>`_ data type in the *Amazon Kinesis Data Firehose API Reference* .\n')
    encryption_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_EncryptionConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configures Amazon Simple Storage Service (Amazon S3) server-side encryption. Kinesis Data Firehose uses AWS Key Management Service ( AWS KMS) to encrypt the data that it delivers to your Amazon S3 bucket.\n')
    error_output_prefix: typing.Optional[str] = pydantic.Field(None, description='A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing them to S3. This prefix appears immediately following the bucket name. For information about how to specify this prefix, see `Custom Prefixes for Amazon S3 Objects <https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html>`_ .\n')
    prefix: typing.Optional[str] = pydantic.Field(None, description='A prefix that Kinesis Data Firehose adds to the files that it delivers to the Amazon S3 bucket. The prefix helps you identify the files that Kinesis Data Firehose delivered.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-s3destinationconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    s3_destination_configuration_property = kinesisfirehose.CfnDeliveryStream.S3DestinationConfigurationProperty(\n        bucket_arn="bucketArn",\n        role_arn="roleArn",\n\n        # the properties below are optional\n        buffering_hints=kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty(\n            interval_in_seconds=123,\n            size_in_mBs=123\n        ),\n        cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n            enabled=False,\n            log_group_name="logGroupName",\n            log_stream_name="logStreamName"\n        ),\n        compression_format="compressionFormat",\n        encryption_configuration=kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty(\n            kms_encryption_config=kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n                awskms_key_arn="awskmsKeyArn"\n            ),\n            no_encryption_config="noEncryptionConfig"\n        ),\n        error_output_prefix="errorOutputPrefix",\n        prefix="prefix"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket_arn', 'role_arn', 'buffering_hints', 'cloud_watch_logging_options', 'compression_format', 'encryption_configuration', 'error_output_prefix', 'prefix']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.S3DestinationConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.SchemaConfigurationProperty
class CfnDeliveryStream_SchemaConfigurationPropertyDef(BaseStruct):
    catalog_id: typing.Optional[str] = pydantic.Field(None, description="The ID of the AWS Glue Data Catalog. If you don't supply this, the AWS account ID is used by default.\n")
    database_name: typing.Optional[str] = pydantic.Field(None, description='Specifies the name of the AWS Glue database that contains the schema for the output data. .. epigraph:: If the ``SchemaConfiguration`` request parameter is used as part of invoking the ``CreateDeliveryStream`` API, then the ``DatabaseName`` property is required and its value must be specified.\n')
    region: typing.Optional[str] = pydantic.Field(None, description="If you don't specify an AWS Region, the default is the current Region.\n")
    role_arn: typing.Optional[str] = pydantic.Field(None, description="The role that Kinesis Data Firehose can use to access AWS Glue. This role must be in the same account you use for Kinesis Data Firehose. Cross-account roles aren't allowed. .. epigraph:: If the ``SchemaConfiguration`` request parameter is used as part of invoking the ``CreateDeliveryStream`` API, then the ``RoleARN`` property is required and its value must be specified.\n")
    table_name: typing.Optional[str] = pydantic.Field(None, description='Specifies the AWS Glue table that contains the column information that constitutes your data schema. .. epigraph:: If the ``SchemaConfiguration`` request parameter is used as part of invoking the ``CreateDeliveryStream`` API, then the ``TableName`` property is required and its value must be specified.\n')
    version_id: typing.Optional[str] = pydantic.Field(None, description='Specifies the table version for the output data schema. If you don\'t specify this version ID, or if you set it to ``LATEST`` , Kinesis Data Firehose uses the most recent version. This means that any updates to the table are automatically picked up.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-schemaconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    schema_configuration_property = kinesisfirehose.CfnDeliveryStream.SchemaConfigurationProperty(\n        catalog_id="catalogId",\n        database_name="databaseName",\n        region="region",\n        role_arn="roleArn",\n        table_name="tableName",\n        version_id="versionId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['catalog_id', 'database_name', 'region', 'role_arn', 'table_name', 'version_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.SchemaConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.SerializerProperty
class CfnDeliveryStream_SerializerPropertyDef(BaseStruct):
    orc_ser_de: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_OrcSerDePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A serializer to use for converting data to the ORC format before storing it in Amazon S3. For more information, see `Apache ORC <https://docs.aws.amazon.com/https://orc.apache.org/docs/>`_ .\n')
    parquet_ser_de: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ParquetSerDePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A serializer to use for converting data to the Parquet format before storing it in Amazon S3. For more information, see `Apache Parquet <https://docs.aws.amazon.com/https://parquet.apache.org/documentation/latest/>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-serializer.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    serializer_property = kinesisfirehose.CfnDeliveryStream.SerializerProperty(\n        orc_ser_de=kinesisfirehose.CfnDeliveryStream.OrcSerDeProperty(\n            block_size_bytes=123,\n            bloom_filter_columns=["bloomFilterColumns"],\n            bloom_filter_false_positive_probability=123,\n            compression="compression",\n            dictionary_key_threshold=123,\n            enable_padding=False,\n            format_version="formatVersion",\n            padding_tolerance=123,\n            row_index_stride=123,\n            stripe_size_bytes=123\n        ),\n        parquet_ser_de=kinesisfirehose.CfnDeliveryStream.ParquetSerDeProperty(\n            block_size_bytes=123,\n            compression="compression",\n            enable_dictionary_compression=False,\n            max_padding_bytes=123,\n            page_size_bytes=123,\n            writer_version="writerVersion"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['orc_ser_de', 'parquet_ser_de']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.SerializerProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.SplunkDestinationConfigurationProperty
class CfnDeliveryStream_SplunkDestinationConfigurationPropertyDef(BaseStruct):
    hec_endpoint: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your data.\n')
    hec_endpoint_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='This type can be either ``Raw`` or ``Event`` .\n')
    hec_token: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='This is a GUID that you obtain from your Splunk cluster when you create a new HEC endpoint.\n')
    s3_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The configuration for the backup Amazon S3 location.\n')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Amazon CloudWatch logging options for your delivery stream.\n')
    hec_acknowledgment_timeout_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time that Kinesis Data Firehose waits to receive an acknowledgment from Splunk after it sends it data. At the end of the timeout period, Kinesis Data Firehose either tries to send the data again or considers it an error, based on your retry settings.\n')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The data processing configuration.\n')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_SplunkRetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="The retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk, or if it doesn't receive an acknowledgment of receipt from Splunk.\n")
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='Defines how documents should be delivered to Amazon S3. When set to ``FailedEventsOnly`` , Kinesis Data Firehose writes any data that could not be indexed to the configured Amazon S3 destination. When set to ``AllEvents`` , Kinesis Data Firehose delivers all incoming records to Amazon S3, and also writes failed documents to Amazon S3. The default value is ``FailedEventsOnly`` . You can update this backup mode from ``FailedEventsOnly`` to ``AllEvents`` . You can\'t update it from ``AllEvents`` to ``FailedEventsOnly`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-splunkdestinationconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    splunk_destination_configuration_property = kinesisfirehose.CfnDeliveryStream.SplunkDestinationConfigurationProperty(\n        hec_endpoint="hecEndpoint",\n        hec_endpoint_type="hecEndpointType",\n        hec_token="hecToken",\n        s3_configuration=kinesisfirehose.CfnDeliveryStream.S3DestinationConfigurationProperty(\n            bucket_arn="bucketArn",\n            role_arn="roleArn",\n\n            # the properties below are optional\n            buffering_hints=kinesisfirehose.CfnDeliveryStream.BufferingHintsProperty(\n                interval_in_seconds=123,\n                size_in_mBs=123\n            ),\n            cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n                enabled=False,\n                log_group_name="logGroupName",\n                log_stream_name="logStreamName"\n            ),\n            compression_format="compressionFormat",\n            encryption_configuration=kinesisfirehose.CfnDeliveryStream.EncryptionConfigurationProperty(\n                kms_encryption_config=kinesisfirehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n                    awskms_key_arn="awskmsKeyArn"\n                ),\n                no_encryption_config="noEncryptionConfig"\n            ),\n            error_output_prefix="errorOutputPrefix",\n            prefix="prefix"\n        ),\n\n        # the properties below are optional\n        cloud_watch_logging_options=kinesisfirehose.CfnDeliveryStream.CloudWatchLoggingOptionsProperty(\n            enabled=False,\n            log_group_name="logGroupName",\n            log_stream_name="logStreamName"\n        ),\n        hec_acknowledgment_timeout_in_seconds=123,\n        processing_configuration=kinesisfirehose.CfnDeliveryStream.ProcessingConfigurationProperty(\n            enabled=False,\n            processors=[kinesisfirehose.CfnDeliveryStream.ProcessorProperty(\n                type="type",\n\n                # the properties below are optional\n                parameters=[kinesisfirehose.CfnDeliveryStream.ProcessorParameterProperty(\n                    parameter_name="parameterName",\n                    parameter_value="parameterValue"\n                )]\n            )]\n        ),\n        retry_options=kinesisfirehose.CfnDeliveryStream.SplunkRetryOptionsProperty(\n            duration_in_seconds=123\n        ),\n        s3_backup_mode="s3BackupMode"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['hec_endpoint', 'hec_endpoint_type', 'hec_token', 's3_configuration', 'cloud_watch_logging_options', 'hec_acknowledgment_timeout_in_seconds', 'processing_configuration', 'retry_options', 's3_backup_mode']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.SplunkDestinationConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.SplunkRetryOptionsProperty
class CfnDeliveryStream_SplunkRetryOptionsPropertyDef(BaseStruct):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description="The total amount of time that Kinesis Data Firehose spends on retries. This duration starts after the initial attempt to send data to Splunk fails. It doesn't include the periods during which Kinesis Data Firehose waits for acknowledgment from Splunk after each attempt.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-splunkretryoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    splunk_retry_options_property = kinesisfirehose.CfnDeliveryStream.SplunkRetryOptionsProperty(\n        duration_in_seconds=123\n    )\n")
    _init_params: typing.ClassVar[list[str]] = ['duration_in_seconds']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.SplunkRetryOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.VpcConfigurationProperty
class CfnDeliveryStream_VpcConfigurationPropertyDef(BaseStruct):
    role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The ARN of the IAM role that you want the delivery stream to use to create endpoints in the destination VPC. You can use your existing Kinesis Data Firehose delivery role or you can specify a new role. In either case, make sure that the role trusts the Kinesis Data Firehose service principal and that it grants the following permissions: - ``ec2:DescribeVpcs`` - ``ec2:DescribeVpcAttribute`` - ``ec2:DescribeSubnets`` - ``ec2:DescribeSecurityGroups`` - ``ec2:DescribeNetworkInterfaces`` - ``ec2:CreateNetworkInterface`` - ``ec2:CreateNetworkInterfacePermission`` - ``ec2:DeleteNetworkInterface`` If you revoke these permissions after you create the delivery stream, Kinesis Data Firehose can't scale out by creating more ENIs when necessary. You might therefore see a degradation in performance.\n")
    security_group_ids: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The IDs of the security groups that you want Kinesis Data Firehose to use when it creates ENIs in the VPC of the Amazon ES destination. You can use the same security group that the Amazon ES domain uses or different ones. If you specify different security groups here, ensure that they allow outbound HTTPS traffic to the Amazon ES domain's security group. Also ensure that the Amazon ES domain's security group allows HTTPS traffic from the security groups specified here. If you use the same security group for both your delivery stream and the Amazon ES domain, make sure the security group inbound rule allows HTTPS traffic.\n")
    subnet_ids: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The IDs of the subnets that Kinesis Data Firehose uses to create ENIs in the VPC of the Amazon ES destination. Make sure that the routing tables and inbound and outbound rules allow traffic to flow from the subnets whose IDs are specified here to the subnets that have the destination Amazon ES endpoints. Kinesis Data Firehose creates at least one ENI in each of the subnets that are specified here. Do not delete or modify these ENIs. The number of ENIs that Kinesis Data Firehose creates in the subnets specified here scales up and down automatically based on throughput. To enable Kinesis Data Firehose to scale up the number of ENIs to match throughput, ensure that you have sufficient quota. To help you calculate the quota you need, assume that Kinesis Data Firehose can create up to three ENIs for this delivery stream for each of the subnets specified here.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-vpcconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_kinesisfirehose as kinesisfirehose\n\n    vpc_configuration_property = kinesisfirehose.CfnDeliveryStream.VpcConfigurationProperty(\n        role_arn="roleArn",\n        security_group_ids=["securityGroupIds"],\n        subnet_ids=["subnetIds"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['role_arn', 'security_group_ids', 'subnet_ids']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream.VpcConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStream
class CfnDeliveryStreamDef(BaseCfnResource):
    amazon_open_search_serverless_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonOpenSearchServerlessDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes the configuration of a destination in the Serverless offering for Amazon OpenSearch Service.\n')
    amazonopensearchservice_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonopensearchserviceDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The destination in Amazon OpenSearch Service. You can specify only one destination.\n')
    delivery_stream_encryption_configuration_input: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DeliveryStreamEncryptionConfigurationInputPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the type and Amazon Resource Name (ARN) of the CMK to use for Server-Side Encryption (SSE).\n')
    delivery_stream_name: typing.Optional[str] = pydantic.Field(None, description='The name of the delivery stream.\n')
    delivery_stream_type: typing.Optional[str] = pydantic.Field(None, description='The delivery stream type. This can be one of the following values:. - ``DirectPut`` : Provider applications access the delivery stream directly. - ``KinesisStreamAsSource`` : The delivery stream uses a Kinesis data stream as a source.\n')
    elasticsearch_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ElasticsearchDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An Amazon ES destination for the delivery stream. Conditional. You must specify only one destination configuration. If you change the delivery stream destination from an Amazon ES destination to an Amazon S3 or Amazon Redshift destination, update requires `some interruptions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-some-interrupt>`_ .\n')
    extended_s3_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ExtendedS3DestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An Amazon S3 destination for the delivery stream. Conditional. You must specify only one destination configuration. If you change the delivery stream destination from an Amazon Extended S3 destination to an Amazon ES destination, update requires `some interruptions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-some-interrupt>`_ .\n')
    http_endpoint_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Enables configuring Kinesis Firehose to deliver data to any HTTP endpoint destination. You can specify only one destination.\n')
    kinesis_stream_source_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_KinesisStreamSourceConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='When a Kinesis stream is used as the source for the delivery stream, a `KinesisStreamSourceConfiguration <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-kinesisstreamsourceconfiguration.html>`_ containing the Kinesis stream ARN and the role ARN for the source stream.\n')
    msk_source_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_MSKSourceConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration for the Amazon MSK cluster to be used as the source for a delivery stream.\n')
    redshift_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_RedshiftDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An Amazon Redshift destination for the delivery stream. Conditional. You must specify only one destination configuration. If you change the delivery stream destination from an Amazon Redshift destination to an Amazon ES destination, update requires `some interruptions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-some-interrupt>`_ .\n')
    s3_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The ``S3DestinationConfiguration`` property type specifies an Amazon Simple Storage Service (Amazon S3) destination to which Amazon Kinesis Data Firehose (Kinesis Data Firehose) delivers data. Conditional. You must specify only one destination configuration. If you change the delivery stream destination from an Amazon S3 destination to an Amazon ES destination, update requires `some interruptions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-some-interrupt>`_ .\n')
    splunk_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_SplunkDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration of a destination in Splunk for the delivery stream.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='A set of tags to assign to the delivery stream. A tag is a key-value pair that you can define and assign to AWS resources. Tags are metadata. For example, you can add friendly names and descriptions or other types of information that can help you distinguish the delivery stream. For more information about tags, see `Using Cost Allocation Tags <https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html>`_ in the AWS Billing and Cost Management User Guide. You can specify up to 50 tags when creating a delivery stream.')
    _init_params: typing.ClassVar[list[str]] = ['amazon_open_search_serverless_destination_configuration', 'amazonopensearchservice_destination_configuration', 'delivery_stream_encryption_configuration_input', 'delivery_stream_name', 'delivery_stream_type', 'elasticsearch_destination_configuration', 'extended_s3_destination_configuration', 'http_endpoint_destination_configuration', 'kinesis_stream_source_configuration', 'msk_source_configuration', 'redshift_destination_configuration', 's3_destination_configuration', 'splunk_destination_configuration', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['AmazonOpenSearchServerlessBufferingHintsProperty', 'AmazonOpenSearchServerlessDestinationConfigurationProperty', 'AmazonOpenSearchServerlessRetryOptionsProperty', 'AmazonopensearchserviceBufferingHintsProperty', 'AmazonopensearchserviceDestinationConfigurationProperty', 'AmazonopensearchserviceRetryOptionsProperty', 'AuthenticationConfigurationProperty', 'BufferingHintsProperty', 'CloudWatchLoggingOptionsProperty', 'CopyCommandProperty', 'DataFormatConversionConfigurationProperty', 'DeliveryStreamEncryptionConfigurationInputProperty', 'DeserializerProperty', 'DocumentIdOptionsProperty', 'DynamicPartitioningConfigurationProperty', 'ElasticsearchBufferingHintsProperty', 'ElasticsearchDestinationConfigurationProperty', 'ElasticsearchRetryOptionsProperty', 'EncryptionConfigurationProperty', 'ExtendedS3DestinationConfigurationProperty', 'HiveJsonSerDeProperty', 'HttpEndpointCommonAttributeProperty', 'HttpEndpointConfigurationProperty', 'HttpEndpointDestinationConfigurationProperty', 'HttpEndpointRequestConfigurationProperty', 'InputFormatConfigurationProperty', 'KMSEncryptionConfigProperty', 'KinesisStreamSourceConfigurationProperty', 'MSKSourceConfigurationProperty', 'OpenXJsonSerDeProperty', 'OrcSerDeProperty', 'OutputFormatConfigurationProperty', 'ParquetSerDeProperty', 'ProcessingConfigurationProperty', 'ProcessorParameterProperty', 'ProcessorProperty', 'RedshiftDestinationConfigurationProperty', 'RedshiftRetryOptionsProperty', 'RetryOptionsProperty', 'S3DestinationConfigurationProperty', 'SchemaConfigurationProperty', 'SerializerProperty', 'SplunkDestinationConfigurationProperty', 'SplunkRetryOptionsProperty', 'VpcConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStream'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_kinesisfirehose.CfnDeliveryStreamDefConfig] = pydantic.Field(None)


class CfnDeliveryStreamDefConfig(pydantic.BaseModel):
    AmazonOpenSearchServerlessBufferingHintsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAmazonopensearchserverlessbufferinghintspropertyParams]] = pydantic.Field(None, description='')
    AmazonOpenSearchServerlessDestinationConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAmazonopensearchserverlessdestinationconfigurationpropertyParams]] = pydantic.Field(None, description='')
    AmazonOpenSearchServerlessRetryOptionsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAmazonopensearchserverlessretryoptionspropertyParams]] = pydantic.Field(None, description='')
    AmazonopensearchserviceBufferingHintsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAmazonopensearchservicebufferinghintspropertyParams]] = pydantic.Field(None, description='')
    AmazonopensearchserviceDestinationConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAmazonopensearchservicedestinationconfigurationpropertyParams]] = pydantic.Field(None, description='')
    AmazonopensearchserviceRetryOptionsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAmazonopensearchserviceretryoptionspropertyParams]] = pydantic.Field(None, description='')
    AuthenticationConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAuthenticationconfigurationpropertyParams]] = pydantic.Field(None, description='')
    BufferingHintsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefBufferinghintspropertyParams]] = pydantic.Field(None, description='')
    CloudWatchLoggingOptionsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefCloudwatchloggingoptionspropertyParams]] = pydantic.Field(None, description='')
    CopyCommandProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefCopycommandpropertyParams]] = pydantic.Field(None, description='')
    DataFormatConversionConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefDataformatconversionconfigurationpropertyParams]] = pydantic.Field(None, description='')
    DeliveryStreamEncryptionConfigurationInputProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefDeliverystreamencryptionconfigurationinputpropertyParams]] = pydantic.Field(None, description='')
    DeserializerProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefDeserializerpropertyParams]] = pydantic.Field(None, description='')
    DocumentIdOptionsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefDocumentidoptionspropertyParams]] = pydantic.Field(None, description='')
    DynamicPartitioningConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefDynamicpartitioningconfigurationpropertyParams]] = pydantic.Field(None, description='')
    ElasticsearchBufferingHintsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefElasticsearchbufferinghintspropertyParams]] = pydantic.Field(None, description='')
    ElasticsearchDestinationConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefElasticsearchdestinationconfigurationpropertyParams]] = pydantic.Field(None, description='')
    ElasticsearchRetryOptionsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefElasticsearchretryoptionspropertyParams]] = pydantic.Field(None, description='')
    EncryptionConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefEncryptionconfigurationpropertyParams]] = pydantic.Field(None, description='')
    ExtendedS3DestinationConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefExtendeds3DestinationconfigurationpropertyParams]] = pydantic.Field(None, description='')
    HiveJsonSerDeProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefHivejsonserdepropertyParams]] = pydantic.Field(None, description='')
    HttpEndpointCommonAttributeProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefHttpendpointcommonattributepropertyParams]] = pydantic.Field(None, description='')
    HttpEndpointConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefHttpendpointconfigurationpropertyParams]] = pydantic.Field(None, description='')
    HttpEndpointDestinationConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefHttpendpointdestinationconfigurationpropertyParams]] = pydantic.Field(None, description='')
    HttpEndpointRequestConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefHttpendpointrequestconfigurationpropertyParams]] = pydantic.Field(None, description='')
    InputFormatConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefInputformatconfigurationpropertyParams]] = pydantic.Field(None, description='')
    KMSEncryptionConfigProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefKmsencryptionconfigpropertyParams]] = pydantic.Field(None, description='')
    KinesisStreamSourceConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefKinesisstreamsourceconfigurationpropertyParams]] = pydantic.Field(None, description='')
    MSKSourceConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefMsksourceconfigurationpropertyParams]] = pydantic.Field(None, description='')
    OpenXJsonSerDeProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefOpenxjsonserdepropertyParams]] = pydantic.Field(None, description='')
    OrcSerDeProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefOrcserdepropertyParams]] = pydantic.Field(None, description='')
    OutputFormatConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefOutputformatconfigurationpropertyParams]] = pydantic.Field(None, description='')
    ParquetSerDeProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefParquetserdepropertyParams]] = pydantic.Field(None, description='')
    ProcessingConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefProcessingconfigurationpropertyParams]] = pydantic.Field(None, description='')
    ProcessorParameterProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefProcessorparameterpropertyParams]] = pydantic.Field(None, description='')
    ProcessorProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefProcessorpropertyParams]] = pydantic.Field(None, description='')
    RedshiftDestinationConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefRedshiftdestinationconfigurationpropertyParams]] = pydantic.Field(None, description='')
    RedshiftRetryOptionsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefRedshiftretryoptionspropertyParams]] = pydantic.Field(None, description='')
    RetryOptionsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefRetryoptionspropertyParams]] = pydantic.Field(None, description='')
    S3DestinationConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefS3DestinationconfigurationpropertyParams]] = pydantic.Field(None, description='')
    SchemaConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefSchemaconfigurationpropertyParams]] = pydantic.Field(None, description='')
    SerializerProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefSerializerpropertyParams]] = pydantic.Field(None, description='')
    SplunkDestinationConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefSplunkdestinationconfigurationpropertyParams]] = pydantic.Field(None, description='')
    SplunkRetryOptionsProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefSplunkretryoptionspropertyParams]] = pydantic.Field(None, description='')
    VpcConfigurationProperty: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefVpcconfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_kinesisfirehose.CfnDeliveryStreamDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnDeliveryStreamDefAmazonopensearchserverlessbufferinghintspropertyParams(pydantic.BaseModel):
    interval_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    size_in_m_bs: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefAmazonopensearchserverlessdestinationconfigurationpropertyParams(pydantic.BaseModel):
    index_name: str = pydantic.Field(..., description='')
    role_arn: str = pydantic.Field(..., description='')
    s3_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonOpenSearchServerlessBufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    collection_endpoint: typing.Optional[str] = pydantic.Field(None, description='')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonOpenSearchServerlessRetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='')
    vpc_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_VpcConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefAmazonopensearchserverlessretryoptionspropertyParams(pydantic.BaseModel):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefAmazonopensearchservicebufferinghintspropertyParams(pydantic.BaseModel):
    interval_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    size_in_m_bs: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefAmazonopensearchservicedestinationconfigurationpropertyParams(pydantic.BaseModel):
    index_name: str = pydantic.Field(..., description='')
    role_arn: str = pydantic.Field(..., description='')
    s3_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonopensearchserviceBufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    cluster_endpoint: typing.Optional[str] = pydantic.Field(None, description='')
    document_id_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DocumentIdOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    domain_arn: typing.Optional[str] = pydantic.Field(None, description='')
    index_rotation_period: typing.Optional[str] = pydantic.Field(None, description='')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonopensearchserviceRetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='')
    type_name: typing.Optional[str] = pydantic.Field(None, description='')
    vpc_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_VpcConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefAmazonopensearchserviceretryoptionspropertyParams(pydantic.BaseModel):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefAuthenticationconfigurationpropertyParams(pydantic.BaseModel):
    connectivity: str = pydantic.Field(..., description='')
    role_arn: str = pydantic.Field(..., description='')
    ...

class CfnDeliveryStreamDefBufferinghintspropertyParams(pydantic.BaseModel):
    interval_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    size_in_m_bs: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefCloudwatchloggingoptionspropertyParams(pydantic.BaseModel):
    enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    log_group_name: typing.Optional[str] = pydantic.Field(None, description='')
    log_stream_name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefCopycommandpropertyParams(pydantic.BaseModel):
    data_table_name: str = pydantic.Field(..., description='')
    copy_options: typing.Optional[str] = pydantic.Field(None, description='')
    data_table_columns: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefDataformatconversionconfigurationpropertyParams(pydantic.BaseModel):
    enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    input_format_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_InputFormatConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    output_format_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_OutputFormatConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    schema_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_SchemaConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefDeliverystreamencryptionconfigurationinputpropertyParams(pydantic.BaseModel):
    key_type: str = pydantic.Field(..., description='')
    key_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefDeserializerpropertyParams(pydantic.BaseModel):
    hive_json_ser_de: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_HiveJsonSerDePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    open_x_json_ser_de: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_OpenXJsonSerDePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefDocumentidoptionspropertyParams(pydantic.BaseModel):
    default_document_id_format: str = pydantic.Field(..., description='')
    ...

class CfnDeliveryStreamDefDynamicpartitioningconfigurationpropertyParams(pydantic.BaseModel):
    enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_RetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefElasticsearchbufferinghintspropertyParams(pydantic.BaseModel):
    interval_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    size_in_m_bs: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefElasticsearchdestinationconfigurationpropertyParams(pydantic.BaseModel):
    index_name: str = pydantic.Field(..., description='')
    role_arn: str = pydantic.Field(..., description='')
    s3_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ElasticsearchBufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    cluster_endpoint: typing.Optional[str] = pydantic.Field(None, description='')
    document_id_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DocumentIdOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    domain_arn: typing.Optional[str] = pydantic.Field(None, description='')
    index_rotation_period: typing.Optional[str] = pydantic.Field(None, description='')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ElasticsearchRetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='')
    type_name: typing.Optional[str] = pydantic.Field(None, description='')
    vpc_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_VpcConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefElasticsearchretryoptionspropertyParams(pydantic.BaseModel):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefEncryptionconfigurationpropertyParams(pydantic.BaseModel):
    kms_encryption_config: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_KMSEncryptionConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    no_encryption_config: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefExtendeds3DestinationconfigurationpropertyParams(pydantic.BaseModel):
    bucket_arn: str = pydantic.Field(..., description='')
    role_arn: str = pydantic.Field(..., description='')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_BufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    compression_format: typing.Optional[str] = pydantic.Field(None, description='')
    data_format_conversion_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DataFormatConversionConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    dynamic_partitioning_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DynamicPartitioningConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    encryption_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_EncryptionConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    error_output_prefix: typing.Optional[str] = pydantic.Field(None, description='')
    prefix: typing.Optional[str] = pydantic.Field(None, description='')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    s3_backup_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefHivejsonserdepropertyParams(pydantic.BaseModel):
    timestamp_formats: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefHttpendpointcommonattributepropertyParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='')
    attribute_value: str = pydantic.Field(..., description='')
    ...

class CfnDeliveryStreamDefHttpendpointconfigurationpropertyParams(pydantic.BaseModel):
    url: str = pydantic.Field(..., description='')
    access_key: typing.Optional[str] = pydantic.Field(None, description='')
    name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefHttpendpointdestinationconfigurationpropertyParams(pydantic.BaseModel):
    endpoint_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    s3_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_BufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    request_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointRequestConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_RetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefHttpendpointrequestconfigurationpropertyParams(pydantic.BaseModel):
    common_attributes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointCommonAttributePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    content_encoding: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefInputformatconfigurationpropertyParams(pydantic.BaseModel):
    deserializer: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DeserializerPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefKmsencryptionconfigpropertyParams(pydantic.BaseModel):
    awskms_key_arn: str = pydantic.Field(..., description='')
    ...

class CfnDeliveryStreamDefKinesisstreamsourceconfigurationpropertyParams(pydantic.BaseModel):
    kinesis_stream_arn: str = pydantic.Field(..., description='')
    role_arn: str = pydantic.Field(..., description='')
    ...

class CfnDeliveryStreamDefMsksourceconfigurationpropertyParams(pydantic.BaseModel):
    authentication_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AuthenticationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    msk_cluster_arn: str = pydantic.Field(..., description='')
    topic_name: str = pydantic.Field(..., description='')
    ...

class CfnDeliveryStreamDefOpenxjsonserdepropertyParams(pydantic.BaseModel):
    case_insensitive: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    column_to_json_key_mappings: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    convert_dots_in_json_keys_to_underscores: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefOrcserdepropertyParams(pydantic.BaseModel):
    block_size_bytes: typing.Union[int, float, None] = pydantic.Field(None, description='')
    bloom_filter_columns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    bloom_filter_false_positive_probability: typing.Union[int, float, None] = pydantic.Field(None, description='')
    compression: typing.Optional[str] = pydantic.Field(None, description='')
    dictionary_key_threshold: typing.Union[int, float, None] = pydantic.Field(None, description='')
    enable_padding: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    format_version: typing.Optional[str] = pydantic.Field(None, description='')
    padding_tolerance: typing.Union[int, float, None] = pydantic.Field(None, description='')
    row_index_stride: typing.Union[int, float, None] = pydantic.Field(None, description='')
    stripe_size_bytes: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefOutputformatconfigurationpropertyParams(pydantic.BaseModel):
    serializer: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_SerializerPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefParquetserdepropertyParams(pydantic.BaseModel):
    block_size_bytes: typing.Union[int, float, None] = pydantic.Field(None, description='')
    compression: typing.Optional[str] = pydantic.Field(None, description='')
    enable_dictionary_compression: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    max_padding_bytes: typing.Union[int, float, None] = pydantic.Field(None, description='')
    page_size_bytes: typing.Union[int, float, None] = pydantic.Field(None, description='')
    writer_version: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefProcessingconfigurationpropertyParams(pydantic.BaseModel):
    enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    processors: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessorPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefProcessorparameterpropertyParams(pydantic.BaseModel):
    parameter_name: str = pydantic.Field(..., description='')
    parameter_value: str = pydantic.Field(..., description='')
    ...

class CfnDeliveryStreamDefProcessorpropertyParams(pydantic.BaseModel):
    type: str = pydantic.Field(..., description='')
    parameters: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessorParameterPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefRedshiftdestinationconfigurationpropertyParams(pydantic.BaseModel):
    cluster_jdbcurl: str = pydantic.Field(..., description='')
    copy_command: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CopyCommandPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    password: str = pydantic.Field(..., description='')
    role_arn: str = pydantic.Field(..., description='')
    s3_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    username: str = pydantic.Field(..., description='')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_RedshiftRetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    s3_backup_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefRedshiftretryoptionspropertyParams(pydantic.BaseModel):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefRetryoptionspropertyParams(pydantic.BaseModel):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefS3DestinationconfigurationpropertyParams(pydantic.BaseModel):
    bucket_arn: str = pydantic.Field(..., description='')
    role_arn: str = pydantic.Field(..., description='')
    buffering_hints: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_BufferingHintsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    compression_format: typing.Optional[str] = pydantic.Field(None, description='')
    encryption_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_EncryptionConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    error_output_prefix: typing.Optional[str] = pydantic.Field(None, description='')
    prefix: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefSchemaconfigurationpropertyParams(pydantic.BaseModel):
    catalog_id: typing.Optional[str] = pydantic.Field(None, description='')
    database_name: typing.Optional[str] = pydantic.Field(None, description='')
    region: typing.Optional[str] = pydantic.Field(None, description='')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    table_name: typing.Optional[str] = pydantic.Field(None, description='')
    version_id: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefSerializerpropertyParams(pydantic.BaseModel):
    orc_ser_de: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_OrcSerDePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    parquet_ser_de: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ParquetSerDePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefSplunkdestinationconfigurationpropertyParams(pydantic.BaseModel):
    hec_endpoint: str = pydantic.Field(..., description='')
    hec_endpoint_type: str = pydantic.Field(..., description='')
    hec_token: str = pydantic.Field(..., description='')
    s3_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    cloud_watch_logging_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    hec_acknowledgment_timeout_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    processing_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    retry_options: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_SplunkRetryOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    s3_backup_mode: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefSplunkretryoptionspropertyParams(pydantic.BaseModel):
    duration_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnDeliveryStreamDefVpcconfigurationpropertyParams(pydantic.BaseModel):
    role_arn: str = pydantic.Field(..., description='')
    security_group_ids: typing.Sequence[str] = pydantic.Field(..., description='')
    subnet_ids: typing.Sequence[str] = pydantic.Field(..., description='')
    ...

class CfnDeliveryStreamDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnDeliveryStreamDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDeliveryStreamDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnDeliveryStreamDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDeliveryStreamDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnDeliveryStreamDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnDeliveryStreamDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnDeliveryStreamDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnDeliveryStreamDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnDeliveryStreamDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDeliveryStreamDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnDeliveryStreamDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnDeliveryStreamDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDeliveryStreamDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_kinesisfirehose.CfnDeliveryStreamProps
class CfnDeliveryStreamPropsDef(BaseCfnProperty):
    amazon_open_search_serverless_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonOpenSearchServerlessDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes the configuration of a destination in the Serverless offering for Amazon OpenSearch Service.\n')
    amazonopensearchservice_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonopensearchserviceDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The destination in Amazon OpenSearch Service. You can specify only one destination.\n')
    delivery_stream_encryption_configuration_input: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_DeliveryStreamEncryptionConfigurationInputPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the type and Amazon Resource Name (ARN) of the CMK to use for Server-Side Encryption (SSE).\n')
    delivery_stream_name: typing.Optional[str] = pydantic.Field(None, description='The name of the delivery stream.\n')
    delivery_stream_type: typing.Optional[str] = pydantic.Field(None, description='The delivery stream type. This can be one of the following values:. - ``DirectPut`` : Provider applications access the delivery stream directly. - ``KinesisStreamAsSource`` : The delivery stream uses a Kinesis data stream as a source.\n')
    elasticsearch_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ElasticsearchDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An Amazon ES destination for the delivery stream. Conditional. You must specify only one destination configuration. If you change the delivery stream destination from an Amazon ES destination to an Amazon S3 or Amazon Redshift destination, update requires `some interruptions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-some-interrupt>`_ .\n')
    extended_s3_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_ExtendedS3DestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An Amazon S3 destination for the delivery stream. Conditional. You must specify only one destination configuration. If you change the delivery stream destination from an Amazon Extended S3 destination to an Amazon ES destination, update requires `some interruptions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-some-interrupt>`_ .\n')
    http_endpoint_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Enables configuring Kinesis Firehose to deliver data to any HTTP endpoint destination. You can specify only one destination.\n')
    kinesis_stream_source_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_KinesisStreamSourceConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='When a Kinesis stream is used as the source for the delivery stream, a `KinesisStreamSourceConfiguration <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-kinesisfirehose-deliverystream-kinesisstreamsourceconfiguration.html>`_ containing the Kinesis stream ARN and the role ARN for the source stream.\n')
    msk_source_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_MSKSourceConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration for the Amazon MSK cluster to be used as the source for a delivery stream.\n')
    redshift_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_RedshiftDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An Amazon Redshift destination for the delivery stream. Conditional. You must specify only one destination configuration. If you change the delivery stream destination from an Amazon Redshift destination to an Amazon ES destination, update requires `some interruptions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-some-interrupt>`_ .\n')
    s3_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The ``S3DestinationConfiguration`` property type specifies an Amazon Simple Storage Service (Amazon S3) destination to which Amazon Kinesis Data Firehose (Kinesis Data Firehose) delivers data. Conditional. You must specify only one destination configuration. If you change the delivery stream destination from an Amazon S3 destination to an Amazon ES destination, update requires `some interruptions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-some-interrupt>`_ .\n')
    splunk_destination_configuration: typing.Union[models.UnsupportedResource, models.aws_kinesisfirehose.CfnDeliveryStream_SplunkDestinationConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration of a destination in Splunk for the delivery stream.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='A set of tags to assign to the delivery stream. A tag is a key-value pair that you can define and assign to AWS resources. Tags are metadata. For example, you can add friendly names and descriptions or other types of information that can help you distinguish the delivery stream. For more information about tags, see `Using Cost Allocation Tags <https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html>`_ in the AWS Billing and Cost Management User Guide. You can specify up to 50 tags when creating a delivery stream.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-kinesisfirehose-deliverystream.html\n:exampleMetadata: fixture=_generated\n\nExample::\n')
    _init_params: typing.ClassVar[list[str]] = ['amazon_open_search_serverless_destination_configuration', 'amazonopensearchservice_destination_configuration', 'delivery_stream_encryption_configuration_input', 'delivery_stream_name', 'delivery_stream_type', 'elasticsearch_destination_configuration', 'extended_s3_destination_configuration', 'http_endpoint_destination_configuration', 'kinesis_stream_source_configuration', 'msk_source_configuration', 'redshift_destination_configuration', 's3_destination_configuration', 'splunk_destination_configuration', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_kinesisfirehose.CfnDeliveryStreamProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




class ModuleModel(pydantic.BaseModel):
    CfnDeliveryStream_AmazonOpenSearchServerlessBufferingHintsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonOpenSearchServerlessBufferingHintsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_AmazonOpenSearchServerlessDestinationConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonOpenSearchServerlessDestinationConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_AmazonOpenSearchServerlessRetryOptionsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonOpenSearchServerlessRetryOptionsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_AmazonopensearchserviceBufferingHintsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonopensearchserviceBufferingHintsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_AmazonopensearchserviceDestinationConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonopensearchserviceDestinationConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_AmazonopensearchserviceRetryOptionsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_AmazonopensearchserviceRetryOptionsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_AuthenticationConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_AuthenticationConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_BufferingHintsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_BufferingHintsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_CloudWatchLoggingOptionsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_CloudWatchLoggingOptionsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_CopyCommandProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_CopyCommandPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_DataFormatConversionConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_DataFormatConversionConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_DeliveryStreamEncryptionConfigurationInputProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_DeliveryStreamEncryptionConfigurationInputPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_DeserializerProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_DeserializerPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_DocumentIdOptionsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_DocumentIdOptionsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_DynamicPartitioningConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_DynamicPartitioningConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_ElasticsearchBufferingHintsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_ElasticsearchBufferingHintsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_ElasticsearchDestinationConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_ElasticsearchDestinationConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_ElasticsearchRetryOptionsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_ElasticsearchRetryOptionsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_EncryptionConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_EncryptionConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_ExtendedS3DestinationConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_ExtendedS3DestinationConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_HiveJsonSerDeProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_HiveJsonSerDePropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_HttpEndpointCommonAttributeProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointCommonAttributePropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_HttpEndpointConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_HttpEndpointDestinationConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointDestinationConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_HttpEndpointRequestConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_HttpEndpointRequestConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_InputFormatConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_InputFormatConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_KinesisStreamSourceConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_KinesisStreamSourceConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_KMSEncryptionConfigProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_KMSEncryptionConfigPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_MSKSourceConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_MSKSourceConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_OpenXJsonSerDeProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_OpenXJsonSerDePropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_OrcSerDeProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_OrcSerDePropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_OutputFormatConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_OutputFormatConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_ParquetSerDeProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_ParquetSerDePropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_ProcessingConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessingConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_ProcessorParameterProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessorParameterPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_ProcessorProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_ProcessorPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_RedshiftDestinationConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_RedshiftDestinationConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_RedshiftRetryOptionsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_RedshiftRetryOptionsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_RetryOptionsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_RetryOptionsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_S3DestinationConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_S3DestinationConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_SchemaConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_SchemaConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_SerializerProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_SerializerPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_SplunkDestinationConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_SplunkDestinationConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_SplunkRetryOptionsProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_SplunkRetryOptionsPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream_VpcConfigurationProperty: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStream_VpcConfigurationPropertyDef]] = pydantic.Field(None)
    CfnDeliveryStream: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStreamDef]] = pydantic.Field(None)
    CfnDeliveryStreamProps: typing.Optional[dict[str, models.aws_kinesisfirehose.CfnDeliveryStreamPropsDef]] = pydantic.Field(None)
    ...

import models
