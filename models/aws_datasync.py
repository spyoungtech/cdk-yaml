from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_datasync.CfnLocationAzureBlob.AzureBlobSasConfigurationProperty
class CfnLocationAzureBlob_AzureBlobSasConfigurationPropertyDef(BaseStruct):
    azure_blob_sas_token: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies a SAS token that provides permissions to access your Azure Blob Storage. The token is part of the SAS URI string that comes after the storage resource URI and a question mark. A token looks something like this: ``sp=r&st=2023-12-20T14:54:52Z&se=2023-12-20T22:54:52Z&spr=https&sv=2021-06-08&sr=c&sig=aBBKDWQvyuVcTPH9EBp%2FXTI9E%2F%2Fmq171%2BZU178wcwqU%3D``\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationazureblob-azureblobsasconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    azure_blob_sas_configuration_property = datasync.CfnLocationAzureBlob.AzureBlobSasConfigurationProperty(\n        azure_blob_sas_token="azureBlobSasToken"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['azure_blob_sas_token']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationAzureBlob.AzureBlobSasConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationEFS.Ec2ConfigProperty
class CfnLocationEFS_Ec2ConfigPropertyDef(BaseStruct):
    security_group_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies the Amazon Resource Names (ARNs) of the security groups associated with an Amazon EFS file system's mount target.\n")
    subnet_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the ARN of a subnet where DataSync creates the `network interfaces <https://docs.aws.amazon.com/datasync/latest/userguide/datasync-network.html#required-network-interfaces>`_ for managing traffic during your transfer. The subnet must be located: - In the same virtual private cloud (VPC) as the Amazon EFS file system. - In the same Availability Zone as at least one mount target for the Amazon EFS file system. .. epigraph:: You don\'t need to specify a subnet that includes a file system mount target.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationefs-ec2config.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    ec2_config_property = datasync.CfnLocationEFS.Ec2ConfigProperty(\n        security_group_arns=["securityGroupArns"],\n        subnet_arn="subnetArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['security_group_arns', 'subnet_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationEFS.Ec2ConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxONTAP.NfsMountOptionsProperty
class CfnLocationFSxONTAP_NfsMountOptionsPropertyDef(BaseStruct):
    version: typing.Optional[str] = pydantic.Field(None, description='Specifies the NFS version that you want DataSync to use when mounting your NFS share. If the server refuses to use the version specified, the task fails. You can specify the following options: - ``AUTOMATIC`` (default): DataSync chooses NFS version 4.1. - ``NFS3`` : Stateless protocol version that allows for asynchronous writes on the server. - ``NFSv4_0`` : Stateful, firewall-friendly protocol version that supports delegations and pseudo file systems. - ``NFSv4_1`` : Stateful protocol version that supports sessions, directory delegations, and parallel data processing. NFS version 4.1 also includes all features available in version 4.0. .. epigraph:: DataSync currently only supports NFS version 3 with Amazon FSx for NetApp ONTAP locations.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationfsxontap-nfsmountoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    nfs_mount_options_property = datasync.CfnLocationFSxONTAP.NfsMountOptionsProperty(\n        version="version"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxONTAP.NfsMountOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxONTAP.NFSProperty
class CfnLocationFSxONTAP_NFSPropertyDef(BaseStruct):
    mount_options: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnLocationFSxONTAP_NfsMountOptionsPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies how DataSync can access a location using the NFS protocol.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationfsxontap-nfs.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    n_fSProperty = datasync.CfnLocationFSxONTAP.NFSProperty(\n        mount_options=datasync.CfnLocationFSxONTAP.NfsMountOptionsProperty(\n            version="version"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['mount_options']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxONTAP.NFSProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxONTAP.ProtocolProperty
class CfnLocationFSxONTAP_ProtocolPropertyDef(BaseStruct):
    nfs: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationFSxONTAP_NFSPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Specifies the Network File System (NFS) protocol configuration that DataSync uses to access your FSx for ONTAP file system's storage virtual machine (SVM).\n")
    smb: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationFSxONTAP_SMBPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the Server Message Block (SMB) protocol configuration that DataSync uses to access your FSx for ONTAP file system\'s SVM.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationfsxontap-protocol.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    protocol_property = datasync.CfnLocationFSxONTAP.ProtocolProperty(\n        nfs=datasync.CfnLocationFSxONTAP.NFSProperty(\n            mount_options=datasync.CfnLocationFSxONTAP.NfsMountOptionsProperty(\n                version="version"\n            )\n        ),\n        smb=datasync.CfnLocationFSxONTAP.SMBProperty(\n            mount_options=datasync.CfnLocationFSxONTAP.SmbMountOptionsProperty(\n                version="version"\n            ),\n            password="password",\n            user="user",\n\n            # the properties below are optional\n            domain="domain"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['nfs', 'smb']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxONTAP.ProtocolProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxONTAP.SmbMountOptionsProperty
class CfnLocationFSxONTAP_SmbMountOptionsPropertyDef(BaseStruct):
    version: typing.Optional[str] = pydantic.Field(None, description='By default, DataSync automatically chooses an SMB protocol version based on negotiation with your SMB file server. You also can configure DataSync to use a specific SMB version, but we recommend doing this only if DataSync has trouble negotiating with the SMB file server automatically. These are the following options for configuring the SMB version: - ``AUTOMATIC`` (default): DataSync and the SMB file server negotiate the highest version of SMB that they mutually support between 2.1 and 3.1.1. This is the recommended option. If you instead choose a specific version that your file server doesn\'t support, you may get an ``Operation Not Supported`` error. - ``SMB3`` : Restricts the protocol negotiation to only SMB version 3.0.2. - ``SMB2`` : Restricts the protocol negotiation to only SMB version 2.1. - ``SMB2_0`` : Restricts the protocol negotiation to only SMB version 2.0. - ``SMB1`` : Restricts the protocol negotiation to only SMB version 1.0. .. epigraph:: The ``SMB1`` option isn\'t available when `creating an Amazon FSx for NetApp ONTAP location <https://docs.aws.amazon.com/datasync/latest/userguide/API_CreateLocationFsxOntap.html>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationfsxontap-smbmountoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    smb_mount_options_property = datasync.CfnLocationFSxONTAP.SmbMountOptionsProperty(\n        version="version"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxONTAP.SmbMountOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxONTAP.SMBProperty
class CfnLocationFSxONTAP_SMBPropertyDef(BaseStruct):
    mount_options: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnLocationFSxONTAP_SmbMountOptionsPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies how DataSync can access a location using the SMB protocol.\n')
    password: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the password of a user who has permission to access your SVM.\n')
    user: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies a user name that can mount the location and access the files, folders, and metadata that you need in the SVM. If you provide a user in your Active Directory, note the following: - If you're using AWS Directory Service for Microsoft Active Directory , the user must be a member of the AWS Delegated FSx Administrators group. - If you're using a self-managed Active Directory, the user must be a member of either the Domain Admins group or a custom group that you specified for file system administration when you created your file system. Make sure that the user has the permissions it needs to copy the data you want: - ``SE_TCB_NAME`` : Required to set object ownership and file metadata. With this privilege, you also can copy NTFS discretionary access lists (DACLs). - ``SE_SECURITY_NAME`` : May be needed to copy NTFS system access control lists (SACLs). This operation specifically requires the Windows privilege, which is granted to members of the Domain Admins group. If you configure your task to copy SACLs, make sure that the user has the required privileges. For information about copying SACLs, see `Ownership and permissions-related options <https://docs.aws.amazon.com/datasync/latest/userguide/create-task.html#configure-ownership-and-permissions>`_ .\n")
    domain: typing.Optional[str] = pydantic.Field(None, description='Specifies the fully qualified domain name (FQDN) of the Microsoft Active Directory that your storage virtual machine (SVM) belongs to. If you have multiple domains in your environment, configuring this setting makes sure that DataSync connects to the right SVM.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationfsxontap-smb.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    s_mBProperty = datasync.CfnLocationFSxONTAP.SMBProperty(\n        mount_options=datasync.CfnLocationFSxONTAP.SmbMountOptionsProperty(\n            version="version"\n        ),\n        password="password",\n        user="user",\n\n        # the properties below are optional\n        domain="domain"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['mount_options', 'password', 'user', 'domain']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxONTAP.SMBProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxOpenZFS.MountOptionsProperty
class CfnLocationFSxOpenZFS_MountOptionsPropertyDef(BaseStruct):
    version: typing.Optional[str] = pydantic.Field(None, description='The specific NFS version that you want DataSync to use to mount your NFS share. If the server refuses to use the version specified, the sync will fail. If you don\'t specify a version, DataSync defaults to ``AUTOMATIC`` . That is, DataSync automatically selects a version based on negotiation with the NFS server. You can specify the following NFS versions: - *`NFSv3 <https://docs.aws.amazon.com/https://tools.ietf.org/html/rfc1813>`_* : Stateless protocol version that allows for asynchronous writes on the server. - *`NFSv4.0 <https://docs.aws.amazon.com/https://tools.ietf.org/html/rfc3530>`_* : Stateful, firewall-friendly protocol version that supports delegations and pseudo file systems. - *`NFSv4.1 <https://docs.aws.amazon.com/https://tools.ietf.org/html/rfc5661>`_* : Stateful protocol version that supports sessions, directory delegations, and parallel data processing. Version 4.1 also includes all features available in version 4.0.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationfsxopenzfs-mountoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    mount_options_property = datasync.CfnLocationFSxOpenZFS.MountOptionsProperty(\n        version="version"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxOpenZFS.MountOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxOpenZFS.NFSProperty
class CfnLocationFSxOpenZFS_NFSPropertyDef(BaseStruct):
    mount_options: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnLocationFSxOpenZFS_MountOptionsPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Represents the mount options that are available for DataSync to access an NFS location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationfsxopenzfs-nfs.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    n_fSProperty = datasync.CfnLocationFSxOpenZFS.NFSProperty(\n        mount_options=datasync.CfnLocationFSxOpenZFS.MountOptionsProperty(\n            version="version"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['mount_options']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxOpenZFS.NFSProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxOpenZFS.ProtocolProperty
class CfnLocationFSxOpenZFS_ProtocolPropertyDef(BaseStruct):
    nfs: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationFSxOpenZFS_NFSPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Represents the Network File System (NFS) protocol that DataSync uses to access your FSx for OpenZFS file system.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationfsxopenzfs-protocol.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    protocol_property = datasync.CfnLocationFSxOpenZFS.ProtocolProperty(\n        nfs=datasync.CfnLocationFSxOpenZFS.NFSProperty(\n            mount_options=datasync.CfnLocationFSxOpenZFS.MountOptionsProperty(\n                version="version"\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['nfs']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxOpenZFS.ProtocolProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationHDFS.NameNodeProperty
class CfnLocationHDFS_NameNodePropertyDef(BaseStruct):
    hostname: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The hostname of the NameNode in the HDFS cluster. This value is the IP address or Domain Name Service (DNS) name of the NameNode. An agent that's installed on-premises uses this hostname to communicate with the NameNode in the network.\n")
    port: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The port that the NameNode uses to listen to client requests.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationhdfs-namenode.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    name_node_property = datasync.CfnLocationHDFS.NameNodeProperty(\n        hostname="hostname",\n        port=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['hostname', 'port']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationHDFS.NameNodeProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationHDFS.QopConfigurationProperty
class CfnLocationHDFS_QopConfigurationPropertyDef(BaseStruct):
    data_transfer_protection: typing.Optional[str] = pydantic.Field(None, description='The data transfer protection setting configured on the HDFS cluster. This setting corresponds to your ``dfs.data.transfer.protection`` setting in the ``hdfs-site.xml`` file on your Hadoop cluster. Default: - "PRIVACY"\n')
    rpc_protection: typing.Optional[str] = pydantic.Field(None, description='The Remote Procedure Call (RPC) protection setting configured on the HDFS cluster. This setting corresponds to your ``hadoop.rpc.protection`` setting in your ``core-site.xml`` file on your Hadoop cluster. Default: - "PRIVACY"\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationhdfs-qopconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    qop_configuration_property = datasync.CfnLocationHDFS.QopConfigurationProperty(\n        data_transfer_protection="dataTransferProtection",\n        rpc_protection="rpcProtection"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['data_transfer_protection', 'rpc_protection']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationHDFS.QopConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationNFS.MountOptionsProperty
class CfnLocationNFS_MountOptionsPropertyDef(BaseStruct):
    version: typing.Optional[str] = pydantic.Field(None, description='Specifies the NFS version that you want DataSync to use when mounting your NFS share. If the server refuses to use the version specified, the task fails. You can specify the following options: - ``AUTOMATIC`` (default): DataSync chooses NFS version 4.1. - ``NFS3`` : Stateless protocol version that allows for asynchronous writes on the server. - ``NFSv4_0`` : Stateful, firewall-friendly protocol version that supports delegations and pseudo file systems. - ``NFSv4_1`` : Stateful protocol version that supports sessions, directory delegations, and parallel data processing. NFS version 4.1 also includes all features available in version 4.0. .. epigraph:: DataSync currently only supports NFS version 3 with Amazon FSx for NetApp ONTAP locations.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationnfs-mountoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    mount_options_property = datasync.CfnLocationNFS.MountOptionsProperty(\n        version="version"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationNFS.MountOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationNFS.OnPremConfigProperty
class CfnLocationNFS_OnPremConfigPropertyDef(BaseStruct):
    agent_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Names (ARNs) of the agents connecting to a transfer location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationnfs-onpremconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    on_prem_config_property = datasync.CfnLocationNFS.OnPremConfigProperty(\n        agent_arns=["agentArns"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['agent_arns']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationNFS.OnPremConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationS3.S3ConfigProperty
class CfnLocationS3_S3ConfigPropertyDef(BaseStruct):
    bucket_access_role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the ARN of the IAM role that DataSync uses to access your S3 bucket.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locations3-s3config.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    s3_config_property = datasync.CfnLocationS3.S3ConfigProperty(\n        bucket_access_role_arn="bucketAccessRoleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket_access_role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationS3.S3ConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationSMB.MountOptionsProperty
class CfnLocationSMB_MountOptionsPropertyDef(BaseStruct):
    version: typing.Optional[str] = pydantic.Field(None, description='By default, DataSync automatically chooses an SMB protocol version based on negotiation with your SMB file server. You also can configure DataSync to use a specific SMB version, but we recommend doing this only if DataSync has trouble negotiating with the SMB file server automatically. These are the following options for configuring the SMB version: - ``AUTOMATIC`` (default): DataSync and the SMB file server negotiate the highest version of SMB that they mutually support between 2.1 and 3.1.1. This is the recommended option. If you instead choose a specific version that your file server doesn\'t support, you may get an ``Operation Not Supported`` error. - ``SMB3`` : Restricts the protocol negotiation to only SMB version 3.0.2. - ``SMB2`` : Restricts the protocol negotiation to only SMB version 2.1. - ``SMB2_0`` : Restricts the protocol negotiation to only SMB version 2.0. - ``SMB1`` : Restricts the protocol negotiation to only SMB version 1.0. .. epigraph:: The ``SMB1`` option isn\'t available when `creating an Amazon FSx for NetApp ONTAP location <https://docs.aws.amazon.com/datasync/latest/userguide/API_CreateLocationFsxOntap.html>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-locationsmb-mountoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    mount_options_property = datasync.CfnLocationSMB.MountOptionsProperty(\n        version="version"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationSMB.MountOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnStorageSystem.ServerConfigurationProperty
class CfnStorageSystem_ServerConfigurationPropertyDef(BaseStruct):
    server_hostname: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The domain name or IP address of your storage system's management interface.\n")
    server_port: typing.Union[int, float, None] = pydantic.Field(None, description='The network port for accessing the storage system\'s management interface.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-storagesystem-serverconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    server_configuration_property = datasync.CfnStorageSystem.ServerConfigurationProperty(\n        server_hostname="serverHostname",\n\n        # the properties below are optional\n        server_port=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['server_hostname', 'server_port']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnStorageSystem.ServerConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnStorageSystem.ServerCredentialsProperty
class CfnStorageSystem_ServerCredentialsPropertyDef(BaseStruct):
    password: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies the password for your storage system's management interface.\n")
    username: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the user name for your storage system\'s management interface.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-storagesystem-servercredentials.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    server_credentials_property = datasync.CfnStorageSystem.ServerCredentialsProperty(\n        password="password",\n        username="username"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['password', 'username']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnStorageSystem.ServerCredentialsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.DeletedProperty
class CfnTask_DeletedPropertyDef(BaseStruct):
    report_level: typing.Optional[str] = pydantic.Field(None, description='Specifies whether you want your task report to include only what went wrong with your transfer or a list of what succeeded and didn\'t. - ``ERRORS_ONLY`` : A report shows what DataSync was unable to delete. - ``SUCCESSES_AND_ERRORS`` : A report shows what DataSync was able and unable to delete.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-deleted.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    deleted_property = datasync.CfnTask.DeletedProperty(\n        report_level="reportLevel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['report_level']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.DeletedProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.DestinationProperty
class CfnTask_DestinationPropertyDef(BaseStruct):
    s3: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_S3PropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the Amazon S3 bucket where DataSync uploads your task report.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-destination.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    destination_property = datasync.CfnTask.DestinationProperty(\n        s3=datasync.CfnTask.S3Property(\n            bucket_access_role_arn="bucketAccessRoleArn",\n            s3_bucket_arn="s3BucketArn",\n            subdirectory="subdirectory"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['s3']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.DestinationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.FilterRuleProperty
class CfnTask_FilterRulePropertyDef(BaseStruct):
    filter_type: typing.Optional[str] = pydantic.Field(None, description='The type of filter rule to apply. AWS DataSync only supports the SIMPLE_PATTERN rule type.\n')
    value: typing.Optional[str] = pydantic.Field(None, description='A single filter string that consists of the patterns to include or exclude. The patterns are delimited by "|" (that is, a pipe), for example: ``/folder1|/folder2``\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-filterrule.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    filter_rule_property = datasync.CfnTask.FilterRuleProperty(\n        filter_type="filterType",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['filter_type', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.FilterRuleProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.ManifestConfigProperty
class CfnTask_ManifestConfigPropertyDef(BaseStruct):
    source: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnTask_SourcePropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies the manifest that you want DataSync to use and where it's hosted. .. epigraph:: You must specify this parameter if you're configuring a new manifest on or after February 7, 2024. If you don't, you'll get a 400 status code and ``ValidationException`` error stating that you're missing the IAM role for DataSync to access the S3 bucket where you're hosting your manifest. For more information, see `Providing DataSync access to your manifest <https://docs.aws.amazon.com/datasync/latest/userguide/transferring-with-manifest.html#transferring-with-manifest-access>`_ .\n")
    action: typing.Optional[str] = pydantic.Field(None, description='Specifies what DataSync uses the manifest for.\n')
    format: typing.Optional[str] = pydantic.Field(None, description='Specifies the file format of your manifest. For more information, see `Creating a manifest <https://docs.aws.amazon.com/datasync/latest/userguide/transferring-with-manifest.html#transferring-with-manifest-create>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-manifestconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    manifest_config_property = datasync.CfnTask.ManifestConfigProperty(\n        source=datasync.CfnTask.SourceProperty(\n            s3=datasync.CfnTask.ManifestConfigSourceS3Property(\n                bucket_access_role_arn="bucketAccessRoleArn",\n                manifest_object_path="manifestObjectPath",\n                manifest_object_version_id="manifestObjectVersionId",\n                s3_bucket_arn="s3BucketArn"\n            )\n        ),\n\n        # the properties below are optional\n        action="action",\n        format="format"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['source', 'action', 'format']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.ManifestConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.ManifestConfigSourceS3Property
class CfnTask_ManifestConfigSourceS3PropertyDef(BaseStruct):
    bucket_access_role_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the AWS Identity and Access Management (IAM) role that allows DataSync to access your manifest. For more information, see `Providing DataSync access to your manifest <https://docs.aws.amazon.com/datasync/latest/userguide/transferring-with-manifest.html#transferring-with-manifest-access>`_ .\n')
    manifest_object_path: typing.Optional[str] = pydantic.Field(None, description='Specifies the Amazon S3 object key of your manifest. This can include a prefix (for example, ``prefix/my-manifest.csv`` ).\n')
    manifest_object_version_id: typing.Optional[str] = pydantic.Field(None, description="Specifies the object version ID of the manifest that you want DataSync to use. If you don't set this, DataSync uses the latest version of the object.\n")
    s3_bucket_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the Amazon Resource Name (ARN) of the S3 bucket where you\'re hosting your manifest.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-manifestconfigsources3.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    manifest_config_source_s3_property = datasync.CfnTask.ManifestConfigSourceS3Property(\n        bucket_access_role_arn="bucketAccessRoleArn",\n        manifest_object_path="manifestObjectPath",\n        manifest_object_version_id="manifestObjectVersionId",\n        s3_bucket_arn="s3BucketArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket_access_role_arn', 'manifest_object_path', 'manifest_object_version_id', 's3_bucket_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.ManifestConfigSourceS3Property'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.OptionsProperty
class CfnTask_OptionsPropertyDef(BaseStruct):
    atime: typing.Optional[str] = pydantic.Field(None, description="A file metadata value that shows the last time that a file was accessed (that is, when the file was read or written to). If you set ``Atime`` to ``BEST_EFFORT`` , AWS DataSync attempts to preserve the original ``Atime`` attribute on all source files (that is, the version before the PREPARING phase). However, ``Atime`` 's behavior is not fully standard across platforms, so AWS DataSync can only do this on a best-effort basis. Default value: ``BEST_EFFORT`` ``BEST_EFFORT`` : Attempt to preserve the per-file ``Atime`` value (recommended). ``NONE`` : Ignore ``Atime`` . .. epigraph:: If ``Atime`` is set to ``BEST_EFFORT`` , ``Mtime`` must be set to ``PRESERVE`` . If ``Atime`` is set to ``NONE`` , ``Mtime`` must also be ``NONE`` .\n")
    bytes_per_second: typing.Union[int, float, None] = pydantic.Field(None, description='A value that limits the bandwidth used by AWS DataSync . For example, if you want AWS DataSync to use a maximum of 1 MB, set this value to ``1048576`` (=1024*1024).\n')
    gid: typing.Optional[str] = pydantic.Field(None, description="The group ID (GID) of the file's owners. Default value: ``INT_VALUE`` ``INT_VALUE`` : Preserve the integer value of the user ID (UID) and group ID (GID) (recommended). ``NAME`` : Currently not supported. ``NONE`` : Ignore the UID and GID.\n")
    log_level: typing.Optional[str] = pydantic.Field(None, description='Specifies the type of logs that DataSync publishes to a Amazon CloudWatch Logs log group. To specify the log group, see `CloudWatchLogGroupArn <https://docs.aws.amazon.com/datasync/latest/userguide/API_CreateTask.html#DataSync-CreateTask-request-CloudWatchLogGroupArn>`_ . - ``BASIC`` - Publishes logs with only basic information (such as transfer errors). - ``TRANSFER`` - Publishes logs for all files or objects that your DataSync task transfers and performs data-integrity checks on. - ``OFF`` - No logs are published.\n')
    mtime: typing.Optional[str] = pydantic.Field(None, description='A value that indicates the last time that a file was modified (that is, a file was written to) before the PREPARING phase. This option is required for cases when you need to run the same task more than one time. Default value: ``PRESERVE`` ``PRESERVE`` : Preserve original ``Mtime`` (recommended) ``NONE`` : Ignore ``Mtime`` . .. epigraph:: If ``Mtime`` is set to ``PRESERVE`` , ``Atime`` must be set to ``BEST_EFFORT`` . If ``Mtime`` is set to ``NONE`` , ``Atime`` must also be set to ``NONE`` .\n')
    object_tags: typing.Optional[str] = pydantic.Field(None, description='Specifies whether you want DataSync to ``PRESERVE`` object tags (default behavior) when transferring between object storage systems. If you want your DataSync task to ignore object tags, specify the ``NONE`` value.\n')
    overwrite_mode: typing.Optional[str] = pydantic.Field(None, description="Specifies whether DataSync should modify or preserve data at the destination location. - ``ALWAYS`` (default) - DataSync modifies data in the destination location when source data (including metadata) has changed. If DataSync overwrites objects, you might incur additional charges for certain Amazon S3 storage classes (for example, for retrieval or early deletion). For more information, see `Storage class considerations with Amazon S3 transfers <https://docs.aws.amazon.com/datasync/latest/userguide/create-s3-location.html#using-storage-classes>`_ . - ``NEVER`` - DataSync doesn't overwrite data in the destination location even if the source data has changed. You can use this option to protect against overwriting changes made to files or objects in the destination.\n")
    posix_permissions: typing.Optional[str] = pydantic.Field(None, description='A value that determines which users or groups can access a file for a specific purpose, such as reading, writing, or execution of the file. This option should be set only for Network File System (NFS), Amazon EFS, and Amazon S3 locations. For more information about what metadata is copied by DataSync, see `Metadata Copied by DataSync <https://docs.aws.amazon.com/datasync/latest/userguide/special-files.html#metadata-copied>`_ . Default value: ``PRESERVE`` ``PRESERVE`` : Preserve POSIX-style permissions (recommended). ``NONE`` : Ignore permissions. .. epigraph:: AWS DataSync can preserve extant permissions of a source location.\n')
    preserve_deleted_files: typing.Optional[str] = pydantic.Field(None, description="A value that specifies whether files in the destination that don't exist in the source file system are preserved. This option can affect your storage costs. If your task deletes objects, you might incur minimum storage duration charges for certain storage classes. For detailed information, see `Considerations when working with Amazon S3 storage classes in DataSync <https://docs.aws.amazon.com/datasync/latest/userguide/create-s3-location.html#using-storage-classes>`_ in the *AWS DataSync User Guide* . Default value: ``PRESERVE`` ``PRESERVE`` : Ignore destination files that aren't present in the source (recommended). ``REMOVE`` : Delete destination files that aren't present in the source.\n")
    preserve_devices: typing.Optional[str] = pydantic.Field(None, description="A value that determines whether AWS DataSync should preserve the metadata of block and character devices in the source file system, and re-create the files with that device name and metadata on the destination. DataSync does not copy the contents of such devices, only the name and metadata. .. epigraph:: AWS DataSync can't sync the actual contents of such devices, because they are nonterminal and don't return an end-of-file (EOF) marker. Default value: ``NONE`` ``NONE`` : Ignore special devices (recommended). ``PRESERVE`` : Preserve character and block device metadata. This option isn't currently supported for Amazon EFS.\n")
    security_descriptor_copy_flags: typing.Optional[str] = pydantic.Field(None, description='A value that determines which components of the SMB security descriptor are copied from source to destination objects. This value is only used for transfers between SMB and Amazon FSx for Windows File Server locations, or between two Amazon FSx for Windows File Server locations. For more information about how DataSync handles metadata, see `How DataSync Handles Metadata and Special Files <https://docs.aws.amazon.com/datasync/latest/userguide/special-files.html>`_ . Default value: ``OWNER_DACL`` ``OWNER_DACL`` : For each copied object, DataSync copies the following metadata: - Object owner. - NTFS discretionary access control lists (DACLs), which determine whether to grant access to an object. When you use option, DataSync does NOT copy the NTFS system access control lists (SACLs), which are used by administrators to log attempts to access a secured object. ``OWNER_DACL_SACL`` : For each copied object, DataSync copies the following metadata: - Object owner. - NTFS discretionary access control lists (DACLs), which determine whether to grant access to an object. - NTFS system access control lists (SACLs), which are used by administrators to log attempts to access a secured object. Copying SACLs requires granting additional permissions to the Windows user that DataSync uses to access your SMB location. For information about choosing a user that ensures sufficient permissions to files, folders, and metadata, see `user <https://docs.aws.amazon.com/datasync/latest/userguide/create-smb-location.html#SMBuser>`_ . ``NONE`` : None of the SMB security descriptor components are copied. Destination objects are owned by the user that was provided for accessing the destination location. DACLs and SACLs are set based on the destination server’s configuration.\n')
    task_queueing: typing.Optional[str] = pydantic.Field(None, description='Specifies whether your transfer tasks should be put into a queue during certain scenarios when `running multiple tasks <https://docs.aws.amazon.com/datasync/latest/userguide/run-task.html#running-multiple-tasks>`_ . This is ``ENABLED`` by default.\n')
    transfer_mode: typing.Optional[str] = pydantic.Field(None, description='A value that determines whether DataSync transfers only the data and metadata that differ between the source and the destination location, or whether DataSync transfers all the content from the source, without comparing it to the destination location. ``CHANGED`` : DataSync copies only data or metadata that is new or different from the source location to the destination location. ``ALL`` : DataSync copies all source location content to the destination, without comparing it to existing content on the destination.\n')
    uid: typing.Optional[str] = pydantic.Field(None, description="The user ID (UID) of the file's owner. Default value: ``INT_VALUE`` ``INT_VALUE`` : Preserve the integer value of the UID and group ID (GID) (recommended). ``NAME`` : Currently not supported ``NONE`` : Ignore the UID and GID.\n")
    verify_mode: typing.Optional[str] = pydantic.Field(None, description='A value that determines whether a data integrity verification is performed at the end of a task execution after all data and metadata have been transferred. For more information, see `Configure task settings <https://docs.aws.amazon.com/datasync/latest/userguide/create-task.html>`_ . Default value: ``POINT_IN_TIME_CONSISTENT`` ``ONLY_FILES_TRANSFERRED`` (recommended): Perform verification only on files that were transferred. ``POINT_IN_TIME_CONSISTENT`` : Scan the entire source and entire destination at the end of the transfer to verify that the source and destination are fully synchronized. This option isn\'t supported when transferring to S3 Glacier or S3 Glacier Deep Archive storage classes. ``NONE`` : No additional verification is done at the end of the transfer, but all data transmissions are integrity-checked with checksum verification during the transfer.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-options.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    options_property = datasync.CfnTask.OptionsProperty(\n        atime="atime",\n        bytes_per_second=123,\n        gid="gid",\n        log_level="logLevel",\n        mtime="mtime",\n        object_tags="objectTags",\n        overwrite_mode="overwriteMode",\n        posix_permissions="posixPermissions",\n        preserve_deleted_files="preserveDeletedFiles",\n        preserve_devices="preserveDevices",\n        security_descriptor_copy_flags="securityDescriptorCopyFlags",\n        task_queueing="taskQueueing",\n        transfer_mode="transferMode",\n        uid="uid",\n        verify_mode="verifyMode"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['atime', 'bytes_per_second', 'gid', 'log_level', 'mtime', 'object_tags', 'overwrite_mode', 'posix_permissions', 'preserve_deleted_files', 'preserve_devices', 'security_descriptor_copy_flags', 'task_queueing', 'transfer_mode', 'uid', 'verify_mode']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.OptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.OverridesProperty
class CfnTask_OverridesPropertyDef(BaseStruct):
    deleted: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_DeletedPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Specifies the level of reporting for the files, objects, and directories that DataSync attempted to delete in your destination location. This only applies if you `configure your task <https://docs.aws.amazon.com/datasync/latest/userguide/configure-metadata.html>`_ to delete data in the destination that isn't in the source.\n")
    skipped: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_SkippedPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the level of reporting for the files, objects, and directories that DataSync attempted to skip during your transfer.\n')
    transferred: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_TransferredPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the level of reporting for the files, objects, and directories that DataSync attempted to transfer.\n')
    verified: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_VerifiedPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the level of reporting for the files, objects, and directories that DataSync attempted to verify during your transfer.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-overrides.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    overrides_property = datasync.CfnTask.OverridesProperty(\n        deleted=datasync.CfnTask.DeletedProperty(\n            report_level="reportLevel"\n        ),\n        skipped=datasync.CfnTask.SkippedProperty(\n            report_level="reportLevel"\n        ),\n        transferred=datasync.CfnTask.TransferredProperty(\n            report_level="reportLevel"\n        ),\n        verified=datasync.CfnTask.VerifiedProperty(\n            report_level="reportLevel"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['deleted', 'skipped', 'transferred', 'verified']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.OverridesProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.S3Property
class CfnTask_S3PropertyDef(BaseStruct):
    bucket_access_role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    s3_bucket_arn: typing.Optional[str] = pydantic.Field(None, description='')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='')
    _init_params: typing.ClassVar[list[str]] = ['bucket_access_role_arn', 's3_bucket_arn', 'subdirectory']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.S3Property'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.SkippedProperty
class CfnTask_SkippedPropertyDef(BaseStruct):
    report_level: typing.Optional[str] = pydantic.Field(None, description='Specifies whether you want your task report to include only what went wrong with your transfer or a list of what succeeded and didn\'t. - ``ERRORS_ONLY`` : A report shows what DataSync was unable to skip. - ``SUCCESSES_AND_ERRORS`` : A report shows what DataSync was able and unable to skip.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-skipped.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    skipped_property = datasync.CfnTask.SkippedProperty(\n        report_level="reportLevel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['report_level']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.SkippedProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.SourceProperty
class CfnTask_SourcePropertyDef(BaseStruct):
    s3: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_ManifestConfigSourceS3PropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the S3 bucket where you\'re hosting your manifest.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-source.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    source_property = datasync.CfnTask.SourceProperty(\n        s3=datasync.CfnTask.ManifestConfigSourceS3Property(\n            bucket_access_role_arn="bucketAccessRoleArn",\n            manifest_object_path="manifestObjectPath",\n            manifest_object_version_id="manifestObjectVersionId",\n            s3_bucket_arn="s3BucketArn"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['s3']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.SourceProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.TaskReportConfigProperty
class CfnTask_TaskReportConfigPropertyDef(BaseStruct):
    destination: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnTask_DestinationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the Amazon S3 bucket where DataSync uploads your task report. For more information, see `Task reports <https://docs.aws.amazon.com/datasync/latest/userguide/task-reports.html#task-report-access>`_ .\n')
    output_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the type of task report that you want:. - ``SUMMARY_ONLY`` : Provides necessary details about your task, including the number of files, objects, and directories transferred and transfer duration. - ``STANDARD`` : Provides complete details about your task, including a full list of files, objects, and directories that were transferred, skipped, verified, and more.\n')
    object_version_ids: typing.Optional[str] = pydantic.Field(None, description='Specifies whether your task report includes the new version of each object transferred into an S3 bucket. This only applies if you `enable versioning on your bucket <https://docs.aws.amazon.com/AmazonS3/latest/userguide/manage-versioning-examples.html>`_ . Keep in mind that setting this to ``INCLUDE`` can increase the duration of your task execution.\n')
    overrides: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_OverridesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Customizes the reporting level for aspects of your task report. For example, your report might generally only include errors, but you could specify that you want a list of successes and errors just for the files that DataSync attempted to delete in your destination location.\n')
    report_level: typing.Optional[str] = pydantic.Field(None, description='Specifies whether you want your task report to include only what went wrong with your transfer or a list of what succeeded and didn\'t. - ``ERRORS_ONLY`` : A report shows what DataSync was unable to transfer, skip, verify, and delete. - ``SUCCESSES_AND_ERRORS`` : A report shows what DataSync was able and unable to transfer, skip, verify, and delete.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-taskreportconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    task_report_config_property = datasync.CfnTask.TaskReportConfigProperty(\n        destination=datasync.CfnTask.DestinationProperty(\n            s3=datasync.CfnTask.S3Property(\n                bucket_access_role_arn="bucketAccessRoleArn",\n                s3_bucket_arn="s3BucketArn",\n                subdirectory="subdirectory"\n            )\n        ),\n        output_type="outputType",\n\n        # the properties below are optional\n        object_version_ids="objectVersionIds",\n        overrides=datasync.CfnTask.OverridesProperty(\n            deleted=datasync.CfnTask.DeletedProperty(\n                report_level="reportLevel"\n            ),\n            skipped=datasync.CfnTask.SkippedProperty(\n                report_level="reportLevel"\n            ),\n            transferred=datasync.CfnTask.TransferredProperty(\n                report_level="reportLevel"\n            ),\n            verified=datasync.CfnTask.VerifiedProperty(\n                report_level="reportLevel"\n            )\n        ),\n        report_level="reportLevel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['destination', 'output_type', 'object_version_ids', 'overrides', 'report_level']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.TaskReportConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.TaskScheduleProperty
class CfnTask_TaskSchedulePropertyDef(BaseStruct):
    schedule_expression: typing.Optional[str] = pydantic.Field(None, description='Specifies your task schedule by using a cron expression in UTC time. For information about cron expression syntax, see the `*Amazon EventBridge User Guide* <https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-cron-expressions.html>`_ .\n')
    status: typing.Optional[str] = pydantic.Field(None, description='Specifies whether to enable or disable your task schedule. Your schedule is enabled by default, but there can be situations where you need to disable it. For example, you might need to perform maintenance on a storage system before you can begin a recurring DataSync transfer. DataSync might disable your schedule automatically if your task fails repeatedly with the same error. For more information, see the `*DataSync User Guide* <https://docs.aws.amazon.com/datasync/latest/userguide/task-scheduling.html#pause-task-schedule>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-taskschedule.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    task_schedule_property = datasync.CfnTask.TaskScheduleProperty(\n        schedule_expression="scheduleExpression",\n        status="status"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['schedule_expression', 'status']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.TaskScheduleProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.TransferredProperty
class CfnTask_TransferredPropertyDef(BaseStruct):
    report_level: typing.Optional[str] = pydantic.Field(None, description='Specifies whether you want your task report to include only what went wrong with your transfer or a list of what succeeded and didn\'t. - ``ERRORS_ONLY`` : A report shows what DataSync was unable to transfer. - ``SUCCESSES_AND_ERRORS`` : A report shows what DataSync was able and unable to transfer.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-transferred.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    transferred_property = datasync.CfnTask.TransferredProperty(\n        report_level="reportLevel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['report_level']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.TransferredProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTask.VerifiedProperty
class CfnTask_VerifiedPropertyDef(BaseStruct):
    report_level: typing.Optional[str] = pydantic.Field(None, description='Specifies whether you want your task report to include only what went wrong with your transfer or a list of what succeeded and didn\'t. - ``ERRORS_ONLY`` : A report shows what DataSync was unable to verify. - ``SUCCESSES_AND_ERRORS`` : A report shows what DataSync was able and unable to verify.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-datasync-task-verified.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    verified_property = datasync.CfnTask.VerifiedProperty(\n        report_level="reportLevel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['report_level']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask.VerifiedProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnAgent
class CfnAgentDef(BaseCfnResource):
    activation_key: typing.Optional[str] = pydantic.Field(None, description="Specifies your DataSync agent's activation key. If you don't have an activation key, see `Activating your agent <https://docs.aws.amazon.com/datasync/latest/userguide/activate-agent.html>`_ .\n")
    agent_name: typing.Optional[str] = pydantic.Field(None, description='Specifies a name for your agent. We recommend specifying a name that you can remember.\n')
    security_group_arns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The Amazon Resource Names (ARNs) of the security groups used to protect your data transfer task subnets. See `SecurityGroupArns <https://docs.aws.amazon.com/datasync/latest/userguide/API_Ec2Config.html#DataSync-Type-Ec2Config-SecurityGroupArns>`_ . *Pattern* : ``^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):ec2:[a-z\\-0-9]*:[0-9]{12}:security-group/.*$``\n')
    subnet_arns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Specifies the ARN of the subnet where your VPC service endpoint is located. You can only specify one ARN.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least one tag for your agent.\n')
    vpc_endpoint_id: typing.Optional[str] = pydantic.Field(None, description="The ID of the virtual private cloud (VPC) endpoint that the agent has access to. This is the client-side VPC endpoint, powered by AWS PrivateLink . If you don't have an AWS PrivateLink VPC endpoint, see `AWS PrivateLink and VPC endpoints <https://docs.aws.amazon.com//vpc/latest/userguide/endpoint-services-overview.html>`_ in the *Amazon VPC User Guide* . For more information about activating your agent in a private network based on a VPC, see `Using AWS DataSync in a Virtual Private Cloud <https://docs.aws.amazon.com/datasync/latest/userguide/datasync-in-vpc.html>`_ in the *AWS DataSync User Guide.* A VPC endpoint ID looks like this: ``vpce-01234d5aff67890e1`` .")
    _init_params: typing.ClassVar[list[str]] = ['activation_key', 'agent_name', 'security_group_arns', 'subnet_arns', 'tags', 'vpc_endpoint_id']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnAgent'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnAgentDefConfig] = pydantic.Field(None)


class CfnAgentDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnAgentDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnAgentDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnAgentDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnAgentDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnAgentDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnAgentDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnAgentDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnAgentDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnAgentDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnAgentDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnAgentDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnAgentDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnAgentDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnAgentDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnAgentDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnAgentDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnAgentDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnAgentDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnAgentDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnAgentDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnAgentDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnAgentDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnAgentDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnAgentDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnAgentDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnAgentDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnAgentDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnLocationAzureBlob
class CfnLocationAzureBlobDef(BaseCfnResource):
    agent_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the Amazon Resource Name (ARN) of the DataSync agent that can connect with your Azure Blob Storage container. You can specify more than one agent. For more information, see `Using multiple agents for your transfer <https://docs.aws.amazon.com/datasync/latest/userguide/multiple-agents.html>`_ .\n')
    azure_blob_authentication_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the authentication method DataSync uses to access your Azure Blob Storage. DataSync can access blob storage using a shared access signature (SAS). Default: - "SAS"\n')
    azure_access_tier: typing.Optional[str] = pydantic.Field(None, description='Specifies the access tier that you want your objects or files transferred into. This only applies when using the location as a transfer destination. For more information, see `Access tiers <https://docs.aws.amazon.com/datasync/latest/userguide/creating-azure-blob-location.html#azure-blob-access-tiers>`_ . Default: - "HOT"\n')
    azure_blob_container_url: typing.Optional[str] = pydantic.Field(None, description='Specifies the URL of the Azure Blob Storage container involved in your transfer.\n')
    azure_blob_sas_configuration: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationAzureBlob_AzureBlobSasConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the SAS configuration that allows DataSync to access your Azure Blob Storage.\n')
    azure_blob_type: typing.Optional[str] = pydantic.Field(None, description='Specifies the type of blob that you want your objects or files to be when transferring them into Azure Blob Storage. Currently, DataSync only supports moving data into Azure Blob Storage as block blobs. For more information on blob types, see the `Azure Blob Storage documentation <https://docs.aws.amazon.com/https://learn.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs>`_ . Default: - "BLOCK"\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='Specifies path segments if you want to limit your transfer to a virtual directory in your container (for example, ``/my/images`` ).\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your transfer location.')
    _init_params: typing.ClassVar[list[str]] = ['agent_arns', 'azure_blob_authentication_type', 'azure_access_tier', 'azure_blob_container_url', 'azure_blob_sas_configuration', 'azure_blob_type', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['AzureBlobSasConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationAzureBlob'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnLocationAzureBlobDefConfig] = pydantic.Field(None)


class CfnLocationAzureBlobDefConfig(pydantic.BaseModel):
    AzureBlobSasConfigurationProperty: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefAzureblobsasconfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnLocationAzureBlobDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    cdk_tag_manager_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLocationAzureBlobDefAzureblobsasconfigurationpropertyParams(pydantic.BaseModel):
    azure_blob_sas_token: str = pydantic.Field(..., description='')
    ...

class CfnLocationAzureBlobDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLocationAzureBlobDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationAzureBlobDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLocationAzureBlobDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationAzureBlobDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLocationAzureBlobDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLocationAzureBlobDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLocationAzureBlobDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLocationAzureBlobDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLocationAzureBlobDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationAzureBlobDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLocationAzureBlobDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLocationAzureBlobDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationAzureBlobDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnLocationEFS
class CfnLocationEFSDef(BaseCfnResource):
    ec2_config: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnLocationEFS_Ec2ConfigPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the subnet and security groups DataSync uses to access your Amazon EFS file system.\n')
    access_point_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the Amazon Resource Name (ARN) of the access point that DataSync uses to access the Amazon EFS file system.\n')
    efs_filesystem_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the ARN for the Amazon EFS file system.\n')
    file_system_access_role_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies an AWS Identity and Access Management (IAM) role that DataSync assumes when mounting the Amazon EFS file system.\n')
    in_transit_encryption: typing.Optional[str] = pydantic.Field(None, description='Specifies whether you want DataSync to use Transport Layer Security (TLS) 1.2 encryption when it copies data to or from the Amazon EFS file system. If you specify an access point using ``AccessPointArn`` or an IAM role using ``FileSystemAccessRoleArn`` , you must set this parameter to ``TLS1_2`` .\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='Specifies a mount path for your Amazon EFS file system. This is where DataSync reads or writes data (depending on if this is a source or destination location). By default, DataSync uses the root directory, but you can also include subdirectories. .. epigraph:: You must specify a value with forward slashes (for example, ``/path/to/folder`` ).\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies the key-value pair that represents a tag that you want to add to the resource. The value can be an empty string. This value helps you manage, filter, and search for your resources. We recommend that you create a name tag for your location.')
    _init_params: typing.ClassVar[list[str]] = ['ec2_config', 'access_point_arn', 'efs_filesystem_arn', 'file_system_access_role_arn', 'in_transit_encryption', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['Ec2ConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationEFS'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnLocationEFSDefConfig] = pydantic.Field(None)


class CfnLocationEFSDefConfig(pydantic.BaseModel):
    Ec2ConfigProperty: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefEc2ConfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnLocationEFSDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLocationEFSDefEc2ConfigpropertyParams(pydantic.BaseModel):
    security_group_arns: typing.Sequence[str] = pydantic.Field(..., description='')
    subnet_arn: str = pydantic.Field(..., description='')
    ...

class CfnLocationEFSDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLocationEFSDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationEFSDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLocationEFSDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationEFSDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLocationEFSDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLocationEFSDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLocationEFSDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLocationEFSDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLocationEFSDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationEFSDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLocationEFSDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLocationEFSDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationEFSDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxLustre
class CfnLocationFSxLustreDef(BaseCfnResource):
    security_group_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARNs of the security groups that are used to configure the FSx for Lustre file system. *Pattern* : ``^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):ec2:[a-z\\-0-9]*:[0-9]{12}:security-group/.*$`` *Length constraints* : Maximum length of 128.\n')
    fsx_filesystem_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) for the FSx for Lustre file system.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="A subdirectory in the location's path. This subdirectory in the FSx for Lustre file system is used to read data from the FSx for Lustre source location or write data to the FSx for Lustre destination.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The key-value pair that represents a tag that you want to add to the resource. The value can be an empty string. This value helps you manage, filter, and search for your resources. We recommend that you create a name tag for your location.')
    _init_params: typing.ClassVar[list[str]] = ['security_group_arns', 'fsx_filesystem_arn', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxLustre'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnLocationFSxLustreDefConfig] = pydantic.Field(None)


class CfnLocationFSxLustreDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxLustreDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLocationFSxLustreDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLocationFSxLustreDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationFSxLustreDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLocationFSxLustreDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationFSxLustreDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLocationFSxLustreDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLocationFSxLustreDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLocationFSxLustreDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLocationFSxLustreDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLocationFSxLustreDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationFSxLustreDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLocationFSxLustreDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLocationFSxLustreDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationFSxLustreDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxONTAP
class CfnLocationFSxONTAPDef(BaseCfnResource):
    security_group_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies the Amazon Resource Names (ARNs) of the security groups that DataSync can use to access your FSx for ONTAP file system. You must configure the security groups to allow outbound traffic on the following ports (depending on the protocol that you're using): - *Network File System (NFS)* : TCP ports 111, 635, and 2049 - *Server Message Block (SMB)* : TCP port 445 Your file system's security groups must also allow inbound traffic on the same port.\n")
    storage_virtual_machine_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the ARN of the storage virtual machine (SVM) in your file system where you want to copy data to or from.\n')
    protocol: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationFSxONTAP_ProtocolPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the data transfer protocol that DataSync uses to access your Amazon FSx file system.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="Specifies a path to the file share in the SVM where you'll copy your data. You can specify a junction path (also known as a mount point), qtree path (for NFS file shares), or share name (for SMB file shares). For example, your mount path might be ``/vol1`` , ``/vol1/tree1`` , or ``/share1`` . .. epigraph:: Don't specify a junction path in the SVM's root volume. For more information, see `Managing FSx for ONTAP storage virtual machines <https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/managing-svms.html>`_ in the *Amazon FSx for NetApp ONTAP User Guide* .\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your location.')
    _init_params: typing.ClassVar[list[str]] = ['security_group_arns', 'storage_virtual_machine_arn', 'protocol', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['NFSProperty', 'NfsMountOptionsProperty', 'ProtocolProperty', 'SMBProperty', 'SmbMountOptionsProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxONTAP'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnLocationFSxONTAPDefConfig] = pydantic.Field(None)


class CfnLocationFSxONTAPDefConfig(pydantic.BaseModel):
    NFSProperty: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefNfspropertyParams]] = pydantic.Field(None, description='')
    NfsMountOptionsProperty: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefNfsmountoptionspropertyParams]] = pydantic.Field(None, description='')
    ProtocolProperty: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefProtocolpropertyParams]] = pydantic.Field(None, description='')
    SMBProperty: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefSmbpropertyParams]] = pydantic.Field(None, description='')
    SmbMountOptionsProperty: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefSmbmountoptionspropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxONTAPDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLocationFSxONTAPDefNfspropertyParams(pydantic.BaseModel):
    mount_options: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationFSxONTAP_NfsMountOptionsPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    ...

class CfnLocationFSxONTAPDefNfsmountoptionspropertyParams(pydantic.BaseModel):
    version: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnLocationFSxONTAPDefProtocolpropertyParams(pydantic.BaseModel):
    nfs: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationFSxONTAP_NFSPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    smb: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationFSxONTAP_SMBPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnLocationFSxONTAPDefSmbpropertyParams(pydantic.BaseModel):
    mount_options: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationFSxONTAP_SmbMountOptionsPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    password: str = pydantic.Field(..., description='')
    user: str = pydantic.Field(..., description='')
    domain: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnLocationFSxONTAPDefSmbmountoptionspropertyParams(pydantic.BaseModel):
    version: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnLocationFSxONTAPDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLocationFSxONTAPDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationFSxONTAPDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLocationFSxONTAPDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationFSxONTAPDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLocationFSxONTAPDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLocationFSxONTAPDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLocationFSxONTAPDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLocationFSxONTAPDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLocationFSxONTAPDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationFSxONTAPDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLocationFSxONTAPDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLocationFSxONTAPDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationFSxONTAPDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxOpenZFS
class CfnLocationFSxOpenZFSDef(BaseCfnResource):
    protocol: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnLocationFSxOpenZFS_ProtocolPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of protocol that AWS DataSync uses to access your file system.\n')
    security_group_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARNs of the security groups that are used to configure the FSx for OpenZFS file system. *Pattern* : ``^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):ec2:[a-z\\-0-9]*:[0-9]{12}:security-group/.*$`` *Length constraints* : Maximum length of 128.\n')
    fsx_filesystem_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the FSx for OpenZFS file system.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="A subdirectory in the location's path that must begin with ``/fsx`` . DataSync uses this subdirectory to read or write data (depending on whether the file system is a source or destination location).\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The key-value pair that represents a tag that you want to add to the resource. The value can be an empty string. This value helps you manage, filter, and search for your resources. We recommend that you create a name tag for your location.')
    _init_params: typing.ClassVar[list[str]] = ['protocol', 'security_group_arns', 'fsx_filesystem_arn', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['MountOptionsProperty', 'NFSProperty', 'ProtocolProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxOpenZFS'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnLocationFSxOpenZFSDefConfig] = pydantic.Field(None)


class CfnLocationFSxOpenZFSDefConfig(pydantic.BaseModel):
    MountOptionsProperty: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefMountoptionspropertyParams]] = pydantic.Field(None, description='')
    NFSProperty: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefNfspropertyParams]] = pydantic.Field(None, description='')
    ProtocolProperty: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefProtocolpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxOpenZFSDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLocationFSxOpenZFSDefMountoptionspropertyParams(pydantic.BaseModel):
    version: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnLocationFSxOpenZFSDefNfspropertyParams(pydantic.BaseModel):
    mount_options: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationFSxOpenZFS_MountOptionsPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    ...

class CfnLocationFSxOpenZFSDefProtocolpropertyParams(pydantic.BaseModel):
    nfs: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationFSxOpenZFS_NFSPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnLocationFSxOpenZFSDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLocationFSxOpenZFSDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationFSxOpenZFSDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLocationFSxOpenZFSDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationFSxOpenZFSDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLocationFSxOpenZFSDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLocationFSxOpenZFSDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLocationFSxOpenZFSDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLocationFSxOpenZFSDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLocationFSxOpenZFSDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationFSxOpenZFSDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLocationFSxOpenZFSDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLocationFSxOpenZFSDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationFSxOpenZFSDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxWindows
class CfnLocationFSxWindowsDef(BaseCfnResource):
    security_group_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Names (ARNs) of the security groups that are used to configure the FSx for Windows File Server file system. *Pattern* : ``^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):ec2:[a-z\\-0-9]*:[0-9]{12}:security-group/.*$`` *Length constraints* : Maximum length of 128.\n')
    user: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The user who has the permissions to access files and folders in the FSx for Windows File Server file system. For information about choosing a user name that ensures sufficient permissions to files, folders, and metadata, see `user <https://docs.aws.amazon.com/datasync/latest/userguide/create-fsx-location.html#FSxWuser>`_ .\n')
    domain: typing.Optional[str] = pydantic.Field(None, description='Specifies the name of the Microsoft Active Directory domain that the FSx for Windows File Server file system belongs to. If you have multiple Active Directory domains in your environment, configuring this parameter makes sure that DataSync connects to the right file system.\n')
    fsx_filesystem_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the Amazon Resource Name (ARN) for the FSx for Windows File Server file system.\n')
    password: typing.Optional[str] = pydantic.Field(None, description='Specifies the password of the user with the permissions to mount and access the files, folders, and file metadata in your FSx for Windows File Server file system.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='Specifies a mount path for your file system using forward slashes. This is where DataSync reads or writes data (depending on if this is a source or destination location).\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your location.')
    _init_params: typing.ClassVar[list[str]] = ['security_group_arns', 'user', 'domain', 'fsx_filesystem_arn', 'password', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxWindows'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnLocationFSxWindowsDefConfig] = pydantic.Field(None)


class CfnLocationFSxWindowsDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnLocationFSxWindowsDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLocationFSxWindowsDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLocationFSxWindowsDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationFSxWindowsDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLocationFSxWindowsDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationFSxWindowsDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLocationFSxWindowsDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLocationFSxWindowsDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLocationFSxWindowsDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLocationFSxWindowsDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLocationFSxWindowsDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationFSxWindowsDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLocationFSxWindowsDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLocationFSxWindowsDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationFSxWindowsDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnLocationHDFS
class CfnLocationHDFSDef(BaseCfnResource):
    agent_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Names (ARNs) of the agents that are used to connect to the HDFS cluster.\n')
    authentication_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The authentication mode used to determine identity of user.\n')
    name_nodes: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationHDFS_NameNodePropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The NameNode that manages the HDFS namespace. The NameNode performs operations such as opening, closing, and renaming files and directories. The NameNode contains the information to map blocks of data to the DataNodes. You can use only one NameNode.\n')
    block_size: typing.Union[int, float, None] = pydantic.Field(None, description='The size of data blocks to write into the HDFS cluster. The block size must be a multiple of 512 bytes. The default block size is 128 mebibytes (MiB).\n')
    kerberos_keytab: typing.Optional[str] = pydantic.Field(None, description='The Kerberos key table (keytab) that contains mappings between the defined Kerberos principal and the encrypted keys. Provide the base64-encoded file text. If ``KERBEROS`` is specified for ``AuthType`` , this value is required.\n')
    kerberos_krb5_conf: typing.Optional[str] = pydantic.Field(None, description="The ``krb5.conf`` file that contains the Kerberos configuration information. You can load the ``krb5.conf`` by providing a string of the file's contents or an Amazon S3 presigned URL of the file. If ``KERBEROS`` is specified for ``AuthType`` , this value is required.\n")
    kerberos_principal: typing.Optional[str] = pydantic.Field(None, description='The Kerberos principal with access to the files and folders on the HDFS cluster. .. epigraph:: If ``KERBEROS`` is specified for ``AuthenticationType`` , this parameter is required.\n')
    kms_key_provider_uri: typing.Optional[str] = pydantic.Field(None, description="The URI of the HDFS cluster's Key Management Server (KMS).\n")
    qop_configuration: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationHDFS_QopConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="The Quality of Protection (QOP) configuration specifies the Remote Procedure Call (RPC) and data transfer protection settings configured on the Hadoop Distributed File System (HDFS) cluster. If ``QopConfiguration`` isn't specified, ``RpcProtection`` and ``DataTransferProtection`` default to ``PRIVACY`` . If you set ``RpcProtection`` or ``DataTransferProtection`` , the other parameter assumes the same value.\n")
    replication_factor: typing.Union[int, float, None] = pydantic.Field(None, description='The number of DataNodes to replicate the data to when writing to the HDFS cluster. By default, data is replicated to three DataNodes. Default: - 3\n')
    simple_user: typing.Optional[str] = pydantic.Field(None, description='The user name used to identify the client on the host operating system. .. epigraph:: If ``SIMPLE`` is specified for ``AuthenticationType`` , this parameter is required.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="A subdirectory in the HDFS cluster. This subdirectory is used to read data from or write data to the HDFS cluster. If the subdirectory isn't specified, it will default to ``/`` .\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The key-value pair that represents the tag that you want to add to the location. The value can be an empty string. We recommend using tags to name your resources.')
    _init_params: typing.ClassVar[list[str]] = ['agent_arns', 'authentication_type', 'name_nodes', 'block_size', 'kerberos_keytab', 'kerberos_krb5_conf', 'kerberos_principal', 'kms_key_provider_uri', 'qop_configuration', 'replication_factor', 'simple_user', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['NameNodeProperty', 'QopConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationHDFS'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnLocationHDFSDefConfig] = pydantic.Field(None)


class CfnLocationHDFSDefConfig(pydantic.BaseModel):
    NameNodeProperty: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefNamenodepropertyParams]] = pydantic.Field(None, description='')
    QopConfigurationProperty: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefQopconfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnLocationHDFSDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLocationHDFSDefNamenodepropertyParams(pydantic.BaseModel):
    hostname: str = pydantic.Field(..., description='')
    port: typing.Union[int, float] = pydantic.Field(..., description='')
    ...

class CfnLocationHDFSDefQopconfigurationpropertyParams(pydantic.BaseModel):
    data_transfer_protection: typing.Optional[str] = pydantic.Field(None, description='')
    rpc_protection: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnLocationHDFSDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLocationHDFSDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationHDFSDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLocationHDFSDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationHDFSDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLocationHDFSDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLocationHDFSDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLocationHDFSDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLocationHDFSDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLocationHDFSDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationHDFSDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLocationHDFSDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLocationHDFSDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationHDFSDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnLocationNFS
class CfnLocationNFSDef(BaseCfnResource):
    on_prem_config: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnLocationNFS_OnPremConfigPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the Amazon Resource Name (ARN) of the DataSync agent that want to connect to your NFS file server. You can specify more than one agent. For more information, see `Using multiple agents for transfers <https://docs.aws.amazon.com/datasync/latest/userguide/multiple-agents.html>`_ .\n')
    mount_options: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationNFS_MountOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the options that DataSync can use to mount your NFS file server.\n')
    server_hostname: typing.Optional[str] = pydantic.Field(None, description='Specifies the Domain Name System (DNS) name or IP version 4 address of the NFS file server that your DataSync agent connects to.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='Specifies the export path in your NFS file server that you want DataSync to mount. This path (or a subdirectory of the path) is where DataSync transfers data to or from. For information on configuring an export for DataSync, see `Accessing NFS file servers <https://docs.aws.amazon.com/datasync/latest/userguide/create-nfs-location.html#accessing-nfs>`_ .\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your location.')
    _init_params: typing.ClassVar[list[str]] = ['on_prem_config', 'mount_options', 'server_hostname', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['MountOptionsProperty', 'OnPremConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationNFS'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnLocationNFSDefConfig] = pydantic.Field(None)


class CfnLocationNFSDefConfig(pydantic.BaseModel):
    MountOptionsProperty: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefMountoptionspropertyParams]] = pydantic.Field(None, description='')
    OnPremConfigProperty: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefOnpremconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnLocationNFSDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLocationNFSDefMountoptionspropertyParams(pydantic.BaseModel):
    version: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnLocationNFSDefOnpremconfigpropertyParams(pydantic.BaseModel):
    agent_arns: typing.Sequence[str] = pydantic.Field(..., description='')
    ...

class CfnLocationNFSDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLocationNFSDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationNFSDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLocationNFSDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationNFSDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLocationNFSDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLocationNFSDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLocationNFSDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLocationNFSDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLocationNFSDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationNFSDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLocationNFSDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLocationNFSDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationNFSDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnLocationObjectStorage
class CfnLocationObjectStorageDef(BaseCfnResource):
    agent_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the Amazon Resource Names (ARNs) of the DataSync agents that can securely connect with your location.\n')
    access_key: typing.Optional[str] = pydantic.Field(None, description='Specifies the access key (for example, a user name) if credentials are required to authenticate with the object storage server.\n')
    bucket_name: typing.Optional[str] = pydantic.Field(None, description='Specifies the name of the object storage bucket involved in the transfer.\n')
    secret_key: typing.Optional[str] = pydantic.Field(None, description='Specifies the secret key (for example, a password) if credentials are required to authenticate with the object storage server.\n')
    server_certificate: typing.Optional[str] = pydantic.Field(None, description="Specifies a certificate chain for DataSync to authenticate with your object storage system if the system uses a private or self-signed certificate authority (CA). You must specify a single ``.pem`` file with a full certificate chain (for example, ``file:///home/user/.ssh/object_storage_certificates.pem`` ). The certificate chain might include: - The object storage system's certificate - All intermediate certificates (if there are any) - The root certificate of the signing CA You can concatenate your certificates into a ``.pem`` file (which can be up to 32768 bytes before base64 encoding). The following example ``cat`` command creates an ``object_storage_certificates.pem`` file that includes three certificates: ``cat object_server_certificate.pem intermediate_certificate.pem ca_root_certificate.pem > object_storage_certificates.pem`` To use this parameter, configure ``ServerProtocol`` to ``HTTPS`` .\n")
    server_hostname: typing.Optional[str] = pydantic.Field(None, description='Specifies the domain name or IP address of the object storage server. A DataSync agent uses this hostname to mount the object storage server in a network.\n')
    server_port: typing.Union[int, float, None] = pydantic.Field(None, description='Specifies the port that your object storage server accepts inbound network traffic on (for example, port 443).\n')
    server_protocol: typing.Optional[str] = pydantic.Field(None, description='Specifies the protocol that your object storage server uses to communicate.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='Specifies the object prefix for your object storage server. If this is a source location, DataSync only copies objects with this prefix. If this is a destination location, DataSync writes all objects with this prefix.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies the key-value pair that represents a tag that you want to add to the resource. Tags can help you manage, filter, and search for your resources. We recommend creating a name tag for your location.')
    _init_params: typing.ClassVar[list[str]] = ['agent_arns', 'access_key', 'bucket_name', 'secret_key', 'server_certificate', 'server_hostname', 'server_port', 'server_protocol', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationObjectStorage'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnLocationObjectStorageDefConfig] = pydantic.Field(None)


class CfnLocationObjectStorageDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnLocationObjectStorageDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLocationObjectStorageDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLocationObjectStorageDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationObjectStorageDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLocationObjectStorageDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationObjectStorageDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLocationObjectStorageDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLocationObjectStorageDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLocationObjectStorageDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLocationObjectStorageDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLocationObjectStorageDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationObjectStorageDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLocationObjectStorageDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLocationObjectStorageDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationObjectStorageDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnLocationS3
class CfnLocationS3Def(BaseCfnResource):
    s3_config: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnLocationS3_S3ConfigPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that is used to access an Amazon S3 bucket. For detailed information about using such a role, see `Creating a Location for Amazon S3 <https://docs.aws.amazon.com/datasync/latest/userguide/working-with-locations.html#create-s3-location>`_ in the *AWS DataSync User Guide* .\n')
    s3_bucket_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Amazon S3 bucket.\n')
    s3_storage_class: typing.Optional[str] = pydantic.Field(None, description='The Amazon S3 storage class that you want to store your files in when this location is used as a task destination. For buckets in AWS Regions , the storage class defaults to S3 Standard. For more information about S3 storage classes, see `Amazon S3 Storage Classes <https://docs.aws.amazon.com/s3/storage-classes/>`_ . Some storage classes have behaviors that can affect your S3 storage costs. For detailed information, see `Considerations When Working with Amazon S3 Storage Classes in DataSync <https://docs.aws.amazon.com/datasync/latest/userguide/create-s3-location.html#using-storage-classes>`_ . Default: - "STANDARD"\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="Specifies a prefix in the S3 bucket that DataSync reads from or writes to (depending on whether the bucket is a source or destination location). .. epigraph:: DataSync can't transfer objects with a prefix that begins with a slash ( ``/`` ) or includes ``//`` , ``/./`` , or ``/../`` patterns. For example: - ``/photos`` - ``photos//2006/January`` - ``photos/./2006/February`` - ``photos/../2006/March``\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your transfer location.')
    _init_params: typing.ClassVar[list[str]] = ['s3_config', 's3_bucket_arn', 's3_storage_class', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['S3ConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationS3'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnLocationS3DefConfig] = pydantic.Field(None)


class CfnLocationS3DefConfig(pydantic.BaseModel):
    S3ConfigProperty: typing.Optional[list[models.aws_datasync.CfnLocationS3DefS3ConfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationS3DefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnLocationS3DefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnLocationS3DefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnLocationS3DefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnLocationS3DefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationS3DefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnLocationS3DefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnLocationS3DefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnLocationS3DefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnLocationS3DefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnLocationS3DefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnLocationS3DefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnLocationS3DefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLocationS3DefS3ConfigpropertyParams(pydantic.BaseModel):
    bucket_access_role_arn: str = pydantic.Field(..., description='')
    ...

class CfnLocationS3DefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLocationS3DefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationS3DefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLocationS3DefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationS3DefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLocationS3DefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLocationS3DefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLocationS3DefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLocationS3DefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLocationS3DefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationS3DefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLocationS3DefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLocationS3DefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationS3DefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnLocationSMB
class CfnLocationSMBDef(BaseCfnResource):
    agent_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Names (ARNs) of agents to use for a Server Message Block (SMB) location.\n')
    user: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The user who can mount the share and has the permissions to access files and folders in the SMB share. For information about choosing a user name that ensures sufficient permissions to files, folders, and metadata, see `user <https://docs.aws.amazon.com/datasync/latest/userguide/create-smb-location.html#SMBuser>`_ .\n')
    domain: typing.Optional[str] = pydantic.Field(None, description='Specifies the name of the Active Directory domain that your SMB file server belongs to. If you have multiple Active Directory domains in your environment, configuring this parameter makes sure that DataSync connects to the right file server.\n')
    mount_options: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationSMB_MountOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the version of the SMB protocol that DataSync uses to access your SMB file server.\n')
    password: typing.Optional[str] = pydantic.Field(None, description='The password of the user who can mount the share and has the permissions to access files and folders in the SMB share.\n')
    server_hostname: typing.Optional[str] = pydantic.Field(None, description="Specifies the Domain Name Service (DNS) name or IP address of the SMB file server that your DataSync agent will mount. .. epigraph:: You can't specify an IP version 6 (IPv6) address.\n")
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="The subdirectory in the SMB file system that is used to read data from the SMB source location or write data to the SMB destination. The SMB path should be a path that's exported by the SMB server, or a subdirectory of that path. The path should be such that it can be mounted by other SMB clients in your network. .. epigraph:: ``Subdirectory`` must be specified with forward slashes. For example, ``/path/to/folder`` . To transfer all the data in the folder you specified, DataSync must have permissions to mount the SMB share, as well as to access all the data in that share. To ensure this, either make sure that the user name and password specified belongs to the user who can mount the share, and who has the appropriate permissions for all of the files and directories that you want DataSync to access, or use credentials of a member of the Backup Operators group to mount the share. Doing either one enables the agent to access the data. For the agent to access directories, you must additionally enable all execute access.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your location.')
    _init_params: typing.ClassVar[list[str]] = ['agent_arns', 'user', 'domain', 'mount_options', 'password', 'server_hostname', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['MountOptionsProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationSMB'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnLocationSMBDefConfig] = pydantic.Field(None)


class CfnLocationSMBDefConfig(pydantic.BaseModel):
    MountOptionsProperty: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefMountoptionspropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnLocationSMBDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnLocationSMBDefMountoptionspropertyParams(pydantic.BaseModel):
    version: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnLocationSMBDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnLocationSMBDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationSMBDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnLocationSMBDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationSMBDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnLocationSMBDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnLocationSMBDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnLocationSMBDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnLocationSMBDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnLocationSMBDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnLocationSMBDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnLocationSMBDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnLocationSMBDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnLocationSMBDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnStorageSystem
class CfnStorageSystemDef(BaseCfnResource):
    agent_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies the Amazon Resource Name (ARN) of the DataSync agent that connects to and reads from your on-premises storage system's management interface. You can only specify one ARN.\n")
    server_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnStorageSystem_ServerConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the server name and network port required to connect with the management interface of your on-premises storage system.\n')
    system_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the type of on-premises storage system that you want DataSync Discovery to collect information about. .. epigraph:: DataSync Discovery currently supports NetApp Fabric-Attached Storage (FAS) and All Flash FAS (AFF) systems running ONTAP 9.7 or later.\n')
    cloud_watch_log_group_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the ARN of the Amazon CloudWatch log group for monitoring and logging discovery job events.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='Specifies a familiar name for your on-premises storage system.\n')
    server_credentials: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnStorageSystem_ServerCredentialsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Specifies the user name and password for accessing your on-premises storage system's management interface.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your on-premises storage system.')
    _init_params: typing.ClassVar[list[str]] = ['agent_arns', 'server_configuration', 'system_type', 'cloud_watch_log_group_arn', 'name', 'server_credentials', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['ServerConfigurationProperty', 'ServerCredentialsProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnStorageSystem'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnStorageSystemDefConfig] = pydantic.Field(None)


class CfnStorageSystemDefConfig(pydantic.BaseModel):
    ServerConfigurationProperty: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefServerconfigurationpropertyParams]] = pydantic.Field(None, description='')
    ServerCredentialsProperty: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefServercredentialspropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnStorageSystemDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnStorageSystemDefServerconfigurationpropertyParams(pydantic.BaseModel):
    server_hostname: str = pydantic.Field(..., description='')
    server_port: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnStorageSystemDefServercredentialspropertyParams(pydantic.BaseModel):
    password: str = pydantic.Field(..., description='')
    username: str = pydantic.Field(..., description='')
    ...

class CfnStorageSystemDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnStorageSystemDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnStorageSystemDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnStorageSystemDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnStorageSystemDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnStorageSystemDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnStorageSystemDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnStorageSystemDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnStorageSystemDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnStorageSystemDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnStorageSystemDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnStorageSystemDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnStorageSystemDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnStorageSystemDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnTask
class CfnTaskDef(BaseCfnResource):
    destination_location_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The Amazon Resource Name (ARN) of an AWS storage resource's location.\n")
    source_location_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies the ARN of your transfer's source location.\n")
    cloud_watch_log_group_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the Amazon Resource Name (ARN) of an Amazon CloudWatch log group for monitoring your task. For more information, see `Monitoring DataSync with Amazon CloudWatch <https://docs.aws.amazon.com/datasync/latest/userguide/monitor-datasync.html>`_ .\n')
    excludes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_FilterRulePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="Specifies exclude filters that define the files, objects, and folders in your source location that you don't want DataSync to transfer. For more information and examples, see `Specifying what DataSync transfers by using filters <https://docs.aws.amazon.com/datasync/latest/userguide/filtering.html>`_ .\n")
    includes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_FilterRulePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Specifies include filters define the files, objects, and folders in your source location that you want DataSync to transfer. For more information and examples, see `Specifying what DataSync transfers by using filters <https://docs.aws.amazon.com/datasync/latest/userguide/filtering.html>`_ .\n')
    manifest_config: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_ManifestConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration of the manifest that lists the files or objects that you want DataSync to transfer. For more information, see `Specifying what DataSync transfers by using a manifest <https://docs.aws.amazon.com/datasync/latest/userguide/transferring-with-manifest.html>`_ .\n')
    name: typing.Optional[str] = pydantic.Field(None, description='Specifies the name of your task.\n')
    options: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_OptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Specifies your task's settings, such as preserving file metadata, verifying data integrity, among other options.\n")
    schedule: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_TaskSchedulePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies a schedule for when you want your task to run. For more information, see `Scheduling your task <https://docs.aws.amazon.com/datasync/latest/userguide/task-scheduling.html>`_ .\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies the tags that you want to apply to your task. *Tags* are key-value pairs that help you manage, filter, and search for your DataSync resources.\n')
    task_report_config: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_TaskReportConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Specifies how you want to configure a task report, which provides detailed information about your DataSync transfer. For more information, see `Monitoring your DataSync transfers with task reports <https://docs.aws.amazon.com/datasync/latest/userguide/task-reports.html>`_ . When using this parameter, your caller identity (the role that you're using DataSync with) must have the ``iam:PassRole`` permission. The `AWSDataSyncFullAccess <https://docs.aws.amazon.com/datasync/latest/userguide/security-iam-awsmanpol.html#security-iam-awsmanpol-awsdatasyncfullaccess>`_ policy includes this permission.")
    _init_params: typing.ClassVar[list[str]] = ['destination_location_arn', 'source_location_arn', 'cloud_watch_log_group_arn', 'excludes', 'includes', 'manifest_config', 'name', 'options', 'schedule', 'tags', 'task_report_config']
    _method_names: typing.ClassVar[list[str]] = ['DeletedProperty', 'DestinationProperty', 'FilterRuleProperty', 'ManifestConfigProperty', 'ManifestConfigSourceS3Property', 'OptionsProperty', 'OverridesProperty', 'S3Property', 'SkippedProperty', 'SourceProperty', 'TaskReportConfigProperty', 'TaskScheduleProperty', 'TransferredProperty', 'VerifiedProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTask'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_datasync.CfnTaskDefConfig] = pydantic.Field(None)


class CfnTaskDefConfig(pydantic.BaseModel):
    DeletedProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefDeletedpropertyParams]] = pydantic.Field(None, description='')
    DestinationProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefDestinationpropertyParams]] = pydantic.Field(None, description='')
    FilterRuleProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefFilterrulepropertyParams]] = pydantic.Field(None, description='')
    ManifestConfigProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefManifestconfigpropertyParams]] = pydantic.Field(None, description='')
    ManifestConfigSourceS3Property: typing.Optional[list[models.aws_datasync.CfnTaskDefManifestconfigsources3PropertyParams]] = pydantic.Field(None, description='')
    OptionsProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefOptionspropertyParams]] = pydantic.Field(None, description='')
    OverridesProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefOverridespropertyParams]] = pydantic.Field(None, description='')
    S3Property: typing.Optional[list[models.aws_datasync.CfnTaskDefS3PropertyParams]] = pydantic.Field(None, description='')
    SkippedProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefSkippedpropertyParams]] = pydantic.Field(None, description='')
    SourceProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefSourcepropertyParams]] = pydantic.Field(None, description='')
    TaskReportConfigProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefTaskreportconfigpropertyParams]] = pydantic.Field(None, description='')
    TaskScheduleProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefTaskschedulepropertyParams]] = pydantic.Field(None, description='')
    TransferredProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefTransferredpropertyParams]] = pydantic.Field(None, description='')
    VerifiedProperty: typing.Optional[list[models.aws_datasync.CfnTaskDefVerifiedpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_datasync.CfnTaskDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_datasync.CfnTaskDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_datasync.CfnTaskDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_datasync.CfnTaskDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_datasync.CfnTaskDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_datasync.CfnTaskDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_datasync.CfnTaskDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_datasync.CfnTaskDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_datasync.CfnTaskDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_datasync.CfnTaskDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_datasync.CfnTaskDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_datasync.CfnTaskDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_datasync.CfnTaskDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnTaskDefDeletedpropertyParams(pydantic.BaseModel):
    report_level: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTaskDefDestinationpropertyParams(pydantic.BaseModel):
    s3: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_S3PropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnTaskDefFilterrulepropertyParams(pydantic.BaseModel):
    filter_type: typing.Optional[str] = pydantic.Field(None, description='')
    value: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTaskDefManifestconfigpropertyParams(pydantic.BaseModel):
    source: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_SourcePropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    action: typing.Optional[str] = pydantic.Field(None, description='')
    format: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTaskDefManifestconfigsources3PropertyParams(pydantic.BaseModel):
    bucket_access_role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    manifest_object_path: typing.Optional[str] = pydantic.Field(None, description='')
    manifest_object_version_id: typing.Optional[str] = pydantic.Field(None, description='')
    s3_bucket_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTaskDefOptionspropertyParams(pydantic.BaseModel):
    atime: typing.Optional[str] = pydantic.Field(None, description='')
    bytes_per_second: typing.Union[int, float, None] = pydantic.Field(None, description='')
    gid: typing.Optional[str] = pydantic.Field(None, description='')
    log_level: typing.Optional[str] = pydantic.Field(None, description='')
    mtime: typing.Optional[str] = pydantic.Field(None, description='')
    object_tags: typing.Optional[str] = pydantic.Field(None, description='')
    overwrite_mode: typing.Optional[str] = pydantic.Field(None, description='')
    posix_permissions: typing.Optional[str] = pydantic.Field(None, description='')
    preserve_deleted_files: typing.Optional[str] = pydantic.Field(None, description='')
    preserve_devices: typing.Optional[str] = pydantic.Field(None, description='')
    security_descriptor_copy_flags: typing.Optional[str] = pydantic.Field(None, description='')
    task_queueing: typing.Optional[str] = pydantic.Field(None, description='')
    transfer_mode: typing.Optional[str] = pydantic.Field(None, description='')
    uid: typing.Optional[str] = pydantic.Field(None, description='')
    verify_mode: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTaskDefOverridespropertyParams(pydantic.BaseModel):
    deleted: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_DeletedPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    skipped: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_SkippedPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    transferred: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_TransferredPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    verified: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_VerifiedPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnTaskDefS3PropertyParams(pydantic.BaseModel):
    bucket_access_role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    s3_bucket_arn: typing.Optional[str] = pydantic.Field(None, description='')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTaskDefSkippedpropertyParams(pydantic.BaseModel):
    report_level: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTaskDefSourcepropertyParams(pydantic.BaseModel):
    s3: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_ManifestConfigSourceS3PropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnTaskDefTaskreportconfigpropertyParams(pydantic.BaseModel):
    destination: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_DestinationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    output_type: str = pydantic.Field(..., description='')
    object_version_ids: typing.Optional[str] = pydantic.Field(None, description='')
    overrides: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_OverridesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    report_level: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTaskDefTaskschedulepropertyParams(pydantic.BaseModel):
    schedule_expression: typing.Optional[str] = pydantic.Field(None, description='')
    status: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTaskDefTransferredpropertyParams(pydantic.BaseModel):
    report_level: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTaskDefVerifiedpropertyParams(pydantic.BaseModel):
    report_level: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTaskDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnTaskDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnTaskDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnTaskDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnTaskDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnTaskDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnTaskDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnTaskDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnTaskDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnTaskDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnTaskDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnTaskDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnTaskDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnTaskDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_datasync.CfnAgentProps
class CfnAgentPropsDef(BaseCfnProperty):
    activation_key: typing.Optional[str] = pydantic.Field(None, description="Specifies your DataSync agent's activation key. If you don't have an activation key, see `Activating your agent <https://docs.aws.amazon.com/datasync/latest/userguide/activate-agent.html>`_ .\n")
    agent_name: typing.Optional[str] = pydantic.Field(None, description='Specifies a name for your agent. We recommend specifying a name that you can remember.\n')
    security_group_arns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The Amazon Resource Names (ARNs) of the security groups used to protect your data transfer task subnets. See `SecurityGroupArns <https://docs.aws.amazon.com/datasync/latest/userguide/API_Ec2Config.html#DataSync-Type-Ec2Config-SecurityGroupArns>`_ . *Pattern* : ``^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):ec2:[a-z\\-0-9]*:[0-9]{12}:security-group/.*$``\n')
    subnet_arns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Specifies the ARN of the subnet where your VPC service endpoint is located. You can only specify one ARN.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least one tag for your agent.\n')
    vpc_endpoint_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the virtual private cloud (VPC) endpoint that the agent has access to. This is the client-side VPC endpoint, powered by AWS PrivateLink . If you don\'t have an AWS PrivateLink VPC endpoint, see `AWS PrivateLink and VPC endpoints <https://docs.aws.amazon.com//vpc/latest/userguide/endpoint-services-overview.html>`_ in the *Amazon VPC User Guide* . For more information about activating your agent in a private network based on a VPC, see `Using AWS DataSync in a Virtual Private Cloud <https://docs.aws.amazon.com/datasync/latest/userguide/datasync-in-vpc.html>`_ in the *AWS DataSync User Guide.* A VPC endpoint ID looks like this: ``vpce-01234d5aff67890e1`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-agent.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_agent_props = datasync.CfnAgentProps(\n        activation_key="activationKey",\n        agent_name="agentName",\n        security_group_arns=["securityGroupArns"],\n        subnet_arns=["subnetArns"],\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        vpc_endpoint_id="vpcEndpointId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['activation_key', 'agent_name', 'security_group_arns', 'subnet_arns', 'tags', 'vpc_endpoint_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnAgentProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationAzureBlobProps
class CfnLocationAzureBlobPropsDef(BaseCfnProperty):
    agent_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the Amazon Resource Name (ARN) of the DataSync agent that can connect with your Azure Blob Storage container. You can specify more than one agent. For more information, see `Using multiple agents for your transfer <https://docs.aws.amazon.com/datasync/latest/userguide/multiple-agents.html>`_ .\n')
    azure_blob_authentication_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the authentication method DataSync uses to access your Azure Blob Storage. DataSync can access blob storage using a shared access signature (SAS). Default: - "SAS"\n')
    azure_access_tier: typing.Optional[str] = pydantic.Field(None, description='Specifies the access tier that you want your objects or files transferred into. This only applies when using the location as a transfer destination. For more information, see `Access tiers <https://docs.aws.amazon.com/datasync/latest/userguide/creating-azure-blob-location.html#azure-blob-access-tiers>`_ . Default: - "HOT"\n')
    azure_blob_container_url: typing.Optional[str] = pydantic.Field(None, description='Specifies the URL of the Azure Blob Storage container involved in your transfer.\n')
    azure_blob_sas_configuration: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationAzureBlob_AzureBlobSasConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the SAS configuration that allows DataSync to access your Azure Blob Storage.\n')
    azure_blob_type: typing.Optional[str] = pydantic.Field(None, description='Specifies the type of blob that you want your objects or files to be when transferring them into Azure Blob Storage. Currently, DataSync only supports moving data into Azure Blob Storage as block blobs. For more information on blob types, see the `Azure Blob Storage documentation <https://docs.aws.amazon.com/https://learn.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs>`_ . Default: - "BLOCK"\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='Specifies path segments if you want to limit your transfer to a virtual directory in your container (for example, ``/my/images`` ).\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your transfer location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-locationazureblob.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_location_azure_blob_props = datasync.CfnLocationAzureBlobProps(\n        agent_arns=["agentArns"],\n        azure_blob_authentication_type="azureBlobAuthenticationType",\n\n        # the properties below are optional\n        azure_access_tier="azureAccessTier",\n        azure_blob_container_url="azureBlobContainerUrl",\n        azure_blob_sas_configuration=datasync.CfnLocationAzureBlob.AzureBlobSasConfigurationProperty(\n            azure_blob_sas_token="azureBlobSasToken"\n        ),\n        azure_blob_type="azureBlobType",\n        subdirectory="subdirectory",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['agent_arns', 'azure_blob_authentication_type', 'azure_access_tier', 'azure_blob_container_url', 'azure_blob_sas_configuration', 'azure_blob_type', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationAzureBlobProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationEFSProps
class CfnLocationEFSPropsDef(BaseCfnProperty):
    ec2_config: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnLocationEFS_Ec2ConfigPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the subnet and security groups DataSync uses to access your Amazon EFS file system.\n')
    access_point_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the Amazon Resource Name (ARN) of the access point that DataSync uses to access the Amazon EFS file system.\n')
    efs_filesystem_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the ARN for the Amazon EFS file system.\n')
    file_system_access_role_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies an AWS Identity and Access Management (IAM) role that DataSync assumes when mounting the Amazon EFS file system.\n')
    in_transit_encryption: typing.Optional[str] = pydantic.Field(None, description='Specifies whether you want DataSync to use Transport Layer Security (TLS) 1.2 encryption when it copies data to or from the Amazon EFS file system. If you specify an access point using ``AccessPointArn`` or an IAM role using ``FileSystemAccessRoleArn`` , you must set this parameter to ``TLS1_2`` .\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='Specifies a mount path for your Amazon EFS file system. This is where DataSync reads or writes data (depending on if this is a source or destination location). By default, DataSync uses the root directory, but you can also include subdirectories. .. epigraph:: You must specify a value with forward slashes (for example, ``/path/to/folder`` ).\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies the key-value pair that represents a tag that you want to add to the resource. The value can be an empty string. This value helps you manage, filter, and search for your resources. We recommend that you create a name tag for your location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-locationefs.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_location_eFSProps = datasync.CfnLocationEFSProps(\n        ec2_config=datasync.CfnLocationEFS.Ec2ConfigProperty(\n            security_group_arns=["securityGroupArns"],\n            subnet_arn="subnetArn"\n        ),\n\n        # the properties below are optional\n        access_point_arn="accessPointArn",\n        efs_filesystem_arn="efsFilesystemArn",\n        file_system_access_role_arn="fileSystemAccessRoleArn",\n        in_transit_encryption="inTransitEncryption",\n        subdirectory="subdirectory",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['ec2_config', 'access_point_arn', 'efs_filesystem_arn', 'file_system_access_role_arn', 'in_transit_encryption', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationEFSProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxLustreProps
class CfnLocationFSxLustrePropsDef(BaseCfnProperty):
    security_group_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARNs of the security groups that are used to configure the FSx for Lustre file system. *Pattern* : ``^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):ec2:[a-z\\-0-9]*:[0-9]{12}:security-group/.*$`` *Length constraints* : Maximum length of 128.\n')
    fsx_filesystem_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) for the FSx for Lustre file system.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="A subdirectory in the location's path. This subdirectory in the FSx for Lustre file system is used to read data from the FSx for Lustre source location or write data to the FSx for Lustre destination.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The key-value pair that represents a tag that you want to add to the resource. The value can be an empty string. This value helps you manage, filter, and search for your resources. We recommend that you create a name tag for your location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-locationfsxlustre.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_location_fSx_lustre_props = datasync.CfnLocationFSxLustreProps(\n        security_group_arns=["securityGroupArns"],\n\n        # the properties below are optional\n        fsx_filesystem_arn="fsxFilesystemArn",\n        subdirectory="subdirectory",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['security_group_arns', 'fsx_filesystem_arn', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxLustreProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxONTAPProps
class CfnLocationFSxONTAPPropsDef(BaseCfnProperty):
    security_group_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies the Amazon Resource Names (ARNs) of the security groups that DataSync can use to access your FSx for ONTAP file system. You must configure the security groups to allow outbound traffic on the following ports (depending on the protocol that you're using): - *Network File System (NFS)* : TCP ports 111, 635, and 2049 - *Server Message Block (SMB)* : TCP port 445 Your file system's security groups must also allow inbound traffic on the same port.\n")
    storage_virtual_machine_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the ARN of the storage virtual machine (SVM) in your file system where you want to copy data to or from.\n')
    protocol: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationFSxONTAP_ProtocolPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the data transfer protocol that DataSync uses to access your Amazon FSx file system.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="Specifies a path to the file share in the SVM where you'll copy your data. You can specify a junction path (also known as a mount point), qtree path (for NFS file shares), or share name (for SMB file shares). For example, your mount path might be ``/vol1`` , ``/vol1/tree1`` , or ``/share1`` . .. epigraph:: Don't specify a junction path in the SVM's root volume. For more information, see `Managing FSx for ONTAP storage virtual machines <https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/managing-svms.html>`_ in the *Amazon FSx for NetApp ONTAP User Guide* .\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-locationfsxontap.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_location_fSx_oNTAPProps = datasync.CfnLocationFSxONTAPProps(\n        security_group_arns=["securityGroupArns"],\n        storage_virtual_machine_arn="storageVirtualMachineArn",\n\n        # the properties below are optional\n        protocol=datasync.CfnLocationFSxONTAP.ProtocolProperty(\n            nfs=datasync.CfnLocationFSxONTAP.NFSProperty(\n                mount_options=datasync.CfnLocationFSxONTAP.NfsMountOptionsProperty(\n                    version="version"\n                )\n            ),\n            smb=datasync.CfnLocationFSxONTAP.SMBProperty(\n                mount_options=datasync.CfnLocationFSxONTAP.SmbMountOptionsProperty(\n                    version="version"\n                ),\n                password="password",\n                user="user",\n\n                # the properties below are optional\n                domain="domain"\n            )\n        ),\n        subdirectory="subdirectory",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['security_group_arns', 'storage_virtual_machine_arn', 'protocol', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxONTAPProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxOpenZFSProps
class CfnLocationFSxOpenZFSPropsDef(BaseCfnProperty):
    protocol: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnLocationFSxOpenZFS_ProtocolPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of protocol that AWS DataSync uses to access your file system.\n')
    security_group_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARNs of the security groups that are used to configure the FSx for OpenZFS file system. *Pattern* : ``^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):ec2:[a-z\\-0-9]*:[0-9]{12}:security-group/.*$`` *Length constraints* : Maximum length of 128.\n')
    fsx_filesystem_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the FSx for OpenZFS file system.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="A subdirectory in the location's path that must begin with ``/fsx`` . DataSync uses this subdirectory to read or write data (depending on whether the file system is a source or destination location).\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The key-value pair that represents a tag that you want to add to the resource. The value can be an empty string. This value helps you manage, filter, and search for your resources. We recommend that you create a name tag for your location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-locationfsxopenzfs.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_location_fSx_open_zFSProps = datasync.CfnLocationFSxOpenZFSProps(\n        protocol=datasync.CfnLocationFSxOpenZFS.ProtocolProperty(\n            nfs=datasync.CfnLocationFSxOpenZFS.NFSProperty(\n                mount_options=datasync.CfnLocationFSxOpenZFS.MountOptionsProperty(\n                    version="version"\n                )\n            )\n        ),\n        security_group_arns=["securityGroupArns"],\n\n        # the properties below are optional\n        fsx_filesystem_arn="fsxFilesystemArn",\n        subdirectory="subdirectory",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['protocol', 'security_group_arns', 'fsx_filesystem_arn', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxOpenZFSProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationFSxWindowsProps
class CfnLocationFSxWindowsPropsDef(BaseCfnProperty):
    security_group_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Names (ARNs) of the security groups that are used to configure the FSx for Windows File Server file system. *Pattern* : ``^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):ec2:[a-z\\-0-9]*:[0-9]{12}:security-group/.*$`` *Length constraints* : Maximum length of 128.\n')
    user: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The user who has the permissions to access files and folders in the FSx for Windows File Server file system. For information about choosing a user name that ensures sufficient permissions to files, folders, and metadata, see `user <https://docs.aws.amazon.com/datasync/latest/userguide/create-fsx-location.html#FSxWuser>`_ .\n')
    domain: typing.Optional[str] = pydantic.Field(None, description='Specifies the name of the Microsoft Active Directory domain that the FSx for Windows File Server file system belongs to. If you have multiple Active Directory domains in your environment, configuring this parameter makes sure that DataSync connects to the right file system.\n')
    fsx_filesystem_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the Amazon Resource Name (ARN) for the FSx for Windows File Server file system.\n')
    password: typing.Optional[str] = pydantic.Field(None, description='Specifies the password of the user with the permissions to mount and access the files, folders, and file metadata in your FSx for Windows File Server file system.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='Specifies a mount path for your file system using forward slashes. This is where DataSync reads or writes data (depending on if this is a source or destination location).\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-locationfsxwindows.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_location_fSx_windows_props = datasync.CfnLocationFSxWindowsProps(\n        security_group_arns=["securityGroupArns"],\n        user="user",\n\n        # the properties below are optional\n        domain="domain",\n        fsx_filesystem_arn="fsxFilesystemArn",\n        password="password",\n        subdirectory="subdirectory",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['security_group_arns', 'user', 'domain', 'fsx_filesystem_arn', 'password', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationFSxWindowsProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationHDFSProps
class CfnLocationHDFSPropsDef(BaseCfnProperty):
    agent_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Names (ARNs) of the agents that are used to connect to the HDFS cluster.\n')
    authentication_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The authentication mode used to determine identity of user.\n')
    name_nodes: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationHDFS_NameNodePropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The NameNode that manages the HDFS namespace. The NameNode performs operations such as opening, closing, and renaming files and directories. The NameNode contains the information to map blocks of data to the DataNodes. You can use only one NameNode.\n')
    block_size: typing.Union[int, float, None] = pydantic.Field(None, description='The size of data blocks to write into the HDFS cluster. The block size must be a multiple of 512 bytes. The default block size is 128 mebibytes (MiB).\n')
    kerberos_keytab: typing.Optional[str] = pydantic.Field(None, description='The Kerberos key table (keytab) that contains mappings between the defined Kerberos principal and the encrypted keys. Provide the base64-encoded file text. If ``KERBEROS`` is specified for ``AuthType`` , this value is required.\n')
    kerberos_krb5_conf: typing.Optional[str] = pydantic.Field(None, description="The ``krb5.conf`` file that contains the Kerberos configuration information. You can load the ``krb5.conf`` by providing a string of the file's contents or an Amazon S3 presigned URL of the file. If ``KERBEROS`` is specified for ``AuthType`` , this value is required.\n")
    kerberos_principal: typing.Optional[str] = pydantic.Field(None, description='The Kerberos principal with access to the files and folders on the HDFS cluster. .. epigraph:: If ``KERBEROS`` is specified for ``AuthenticationType`` , this parameter is required.\n')
    kms_key_provider_uri: typing.Optional[str] = pydantic.Field(None, description="The URI of the HDFS cluster's Key Management Server (KMS).\n")
    qop_configuration: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationHDFS_QopConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="The Quality of Protection (QOP) configuration specifies the Remote Procedure Call (RPC) and data transfer protection settings configured on the Hadoop Distributed File System (HDFS) cluster. If ``QopConfiguration`` isn't specified, ``RpcProtection`` and ``DataTransferProtection`` default to ``PRIVACY`` . If you set ``RpcProtection`` or ``DataTransferProtection`` , the other parameter assumes the same value.\n")
    replication_factor: typing.Union[int, float, None] = pydantic.Field(None, description='The number of DataNodes to replicate the data to when writing to the HDFS cluster. By default, data is replicated to three DataNodes. Default: - 3\n')
    simple_user: typing.Optional[str] = pydantic.Field(None, description='The user name used to identify the client on the host operating system. .. epigraph:: If ``SIMPLE`` is specified for ``AuthenticationType`` , this parameter is required.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="A subdirectory in the HDFS cluster. This subdirectory is used to read data from or write data to the HDFS cluster. If the subdirectory isn't specified, it will default to ``/`` .\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The key-value pair that represents the tag that you want to add to the location. The value can be an empty string. We recommend using tags to name your resources.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-locationhdfs.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_location_hDFSProps = datasync.CfnLocationHDFSProps(\n        agent_arns=["agentArns"],\n        authentication_type="authenticationType",\n        name_nodes=[datasync.CfnLocationHDFS.NameNodeProperty(\n            hostname="hostname",\n            port=123\n        )],\n\n        # the properties below are optional\n        block_size=123,\n        kerberos_keytab="kerberosKeytab",\n        kerberos_krb5_conf="kerberosKrb5Conf",\n        kerberos_principal="kerberosPrincipal",\n        kms_key_provider_uri="kmsKeyProviderUri",\n        qop_configuration=datasync.CfnLocationHDFS.QopConfigurationProperty(\n            data_transfer_protection="dataTransferProtection",\n            rpc_protection="rpcProtection"\n        ),\n        replication_factor=123,\n        simple_user="simpleUser",\n        subdirectory="subdirectory",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['agent_arns', 'authentication_type', 'name_nodes', 'block_size', 'kerberos_keytab', 'kerberos_krb5_conf', 'kerberos_principal', 'kms_key_provider_uri', 'qop_configuration', 'replication_factor', 'simple_user', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationHDFSProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationNFSProps
class CfnLocationNFSPropsDef(BaseCfnProperty):
    on_prem_config: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnLocationNFS_OnPremConfigPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the Amazon Resource Name (ARN) of the DataSync agent that want to connect to your NFS file server. You can specify more than one agent. For more information, see `Using multiple agents for transfers <https://docs.aws.amazon.com/datasync/latest/userguide/multiple-agents.html>`_ .\n')
    mount_options: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationNFS_MountOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the options that DataSync can use to mount your NFS file server.\n')
    server_hostname: typing.Optional[str] = pydantic.Field(None, description='Specifies the Domain Name System (DNS) name or IP version 4 address of the NFS file server that your DataSync agent connects to.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='Specifies the export path in your NFS file server that you want DataSync to mount. This path (or a subdirectory of the path) is where DataSync transfers data to or from. For information on configuring an export for DataSync, see `Accessing NFS file servers <https://docs.aws.amazon.com/datasync/latest/userguide/create-nfs-location.html#accessing-nfs>`_ .\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-locationnfs.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_location_nFSProps = datasync.CfnLocationNFSProps(\n        on_prem_config=datasync.CfnLocationNFS.OnPremConfigProperty(\n            agent_arns=["agentArns"]\n        ),\n\n        # the properties below are optional\n        mount_options=datasync.CfnLocationNFS.MountOptionsProperty(\n            version="version"\n        ),\n        server_hostname="serverHostname",\n        subdirectory="subdirectory",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['on_prem_config', 'mount_options', 'server_hostname', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationNFSProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationObjectStorageProps
class CfnLocationObjectStoragePropsDef(BaseCfnProperty):
    agent_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the Amazon Resource Names (ARNs) of the DataSync agents that can securely connect with your location.\n')
    access_key: typing.Optional[str] = pydantic.Field(None, description='Specifies the access key (for example, a user name) if credentials are required to authenticate with the object storage server.\n')
    bucket_name: typing.Optional[str] = pydantic.Field(None, description='Specifies the name of the object storage bucket involved in the transfer.\n')
    secret_key: typing.Optional[str] = pydantic.Field(None, description='Specifies the secret key (for example, a password) if credentials are required to authenticate with the object storage server.\n')
    server_certificate: typing.Optional[str] = pydantic.Field(None, description="Specifies a certificate chain for DataSync to authenticate with your object storage system if the system uses a private or self-signed certificate authority (CA). You must specify a single ``.pem`` file with a full certificate chain (for example, ``file:///home/user/.ssh/object_storage_certificates.pem`` ). The certificate chain might include: - The object storage system's certificate - All intermediate certificates (if there are any) - The root certificate of the signing CA You can concatenate your certificates into a ``.pem`` file (which can be up to 32768 bytes before base64 encoding). The following example ``cat`` command creates an ``object_storage_certificates.pem`` file that includes three certificates: ``cat object_server_certificate.pem intermediate_certificate.pem ca_root_certificate.pem > object_storage_certificates.pem`` To use this parameter, configure ``ServerProtocol`` to ``HTTPS`` .\n")
    server_hostname: typing.Optional[str] = pydantic.Field(None, description='Specifies the domain name or IP address of the object storage server. A DataSync agent uses this hostname to mount the object storage server in a network.\n')
    server_port: typing.Union[int, float, None] = pydantic.Field(None, description='Specifies the port that your object storage server accepts inbound network traffic on (for example, port 443).\n')
    server_protocol: typing.Optional[str] = pydantic.Field(None, description='Specifies the protocol that your object storage server uses to communicate.\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description='Specifies the object prefix for your object storage server. If this is a source location, DataSync only copies objects with this prefix. If this is a destination location, DataSync writes all objects with this prefix.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies the key-value pair that represents a tag that you want to add to the resource. Tags can help you manage, filter, and search for your resources. We recommend creating a name tag for your location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-locationobjectstorage.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_location_object_storage_props = datasync.CfnLocationObjectStorageProps(\n        agent_arns=["agentArns"],\n\n        # the properties below are optional\n        access_key="accessKey",\n        bucket_name="bucketName",\n        secret_key="secretKey",\n        server_certificate="serverCertificate",\n        server_hostname="serverHostname",\n        server_port=123,\n        server_protocol="serverProtocol",\n        subdirectory="subdirectory",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['agent_arns', 'access_key', 'bucket_name', 'secret_key', 'server_certificate', 'server_hostname', 'server_port', 'server_protocol', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationObjectStorageProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationS3Props
class CfnLocationS3PropsDef(BaseCfnProperty):
    s3_config: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnLocationS3_S3ConfigPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that is used to access an Amazon S3 bucket. For detailed information about using such a role, see `Creating a Location for Amazon S3 <https://docs.aws.amazon.com/datasync/latest/userguide/working-with-locations.html#create-s3-location>`_ in the *AWS DataSync User Guide* .\n')
    s3_bucket_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Amazon S3 bucket.\n')
    s3_storage_class: typing.Optional[str] = pydantic.Field(None, description='The Amazon S3 storage class that you want to store your files in when this location is used as a task destination. For buckets in AWS Regions , the storage class defaults to S3 Standard. For more information about S3 storage classes, see `Amazon S3 Storage Classes <https://docs.aws.amazon.com/s3/storage-classes/>`_ . Some storage classes have behaviors that can affect your S3 storage costs. For detailed information, see `Considerations When Working with Amazon S3 Storage Classes in DataSync <https://docs.aws.amazon.com/datasync/latest/userguide/create-s3-location.html#using-storage-classes>`_ . Default: - "STANDARD"\n')
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="Specifies a prefix in the S3 bucket that DataSync reads from or writes to (depending on whether the bucket is a source or destination location). .. epigraph:: DataSync can't transfer objects with a prefix that begins with a slash ( ``/`` ) or includes ``//`` , ``/./`` , or ``/../`` patterns. For example: - ``/photos`` - ``photos//2006/January`` - ``photos/./2006/February`` - ``photos/../2006/March``\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your transfer location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-locations3.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_location_s3_props = datasync.CfnLocationS3Props(\n        s3_config=datasync.CfnLocationS3.S3ConfigProperty(\n            bucket_access_role_arn="bucketAccessRoleArn"\n        ),\n\n        # the properties below are optional\n        s3_bucket_arn="s3BucketArn",\n        s3_storage_class="s3StorageClass",\n        subdirectory="subdirectory",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['s3_config', 's3_bucket_arn', 's3_storage_class', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationS3Props'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnLocationSMBProps
class CfnLocationSMBPropsDef(BaseCfnProperty):
    agent_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Names (ARNs) of agents to use for a Server Message Block (SMB) location.\n')
    user: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The user who can mount the share and has the permissions to access files and folders in the SMB share. For information about choosing a user name that ensures sufficient permissions to files, folders, and metadata, see `user <https://docs.aws.amazon.com/datasync/latest/userguide/create-smb-location.html#SMBuser>`_ .\n')
    domain: typing.Optional[str] = pydantic.Field(None, description='Specifies the name of the Active Directory domain that your SMB file server belongs to. If you have multiple Active Directory domains in your environment, configuring this parameter makes sure that DataSync connects to the right file server.\n')
    mount_options: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnLocationSMB_MountOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the version of the SMB protocol that DataSync uses to access your SMB file server.\n')
    password: typing.Optional[str] = pydantic.Field(None, description='The password of the user who can mount the share and has the permissions to access files and folders in the SMB share.\n')
    server_hostname: typing.Optional[str] = pydantic.Field(None, description="Specifies the Domain Name Service (DNS) name or IP address of the SMB file server that your DataSync agent will mount. .. epigraph:: You can't specify an IP version 6 (IPv6) address.\n")
    subdirectory: typing.Optional[str] = pydantic.Field(None, description="The subdirectory in the SMB file system that is used to read data from the SMB source location or write data to the SMB destination. The SMB path should be a path that's exported by the SMB server, or a subdirectory of that path. The path should be such that it can be mounted by other SMB clients in your network. .. epigraph:: ``Subdirectory`` must be specified with forward slashes. For example, ``/path/to/folder`` . To transfer all the data in the folder you specified, DataSync must have permissions to mount the SMB share, as well as to access all the data in that share. To ensure this, either make sure that the user name and password specified belongs to the user who can mount the share, and who has the appropriate permissions for all of the files and directories that you want DataSync to access, or use credentials of a member of the Backup Operators group to mount the share. Doing either one enables the agent to access the data. For the agent to access directories, you must additionally enable all execute access.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your location.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-locationsmb.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_location_sMBProps = datasync.CfnLocationSMBProps(\n        agent_arns=["agentArns"],\n        user="user",\n\n        # the properties below are optional\n        domain="domain",\n        mount_options=datasync.CfnLocationSMB.MountOptionsProperty(\n            version="version"\n        ),\n        password="password",\n        server_hostname="serverHostname",\n        subdirectory="subdirectory",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['agent_arns', 'user', 'domain', 'mount_options', 'password', 'server_hostname', 'subdirectory', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnLocationSMBProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnStorageSystemProps
class CfnStorageSystemPropsDef(BaseCfnProperty):
    agent_arns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies the Amazon Resource Name (ARN) of the DataSync agent that connects to and reads from your on-premises storage system's management interface. You can only specify one ARN.\n")
    server_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_datasync.CfnStorageSystem_ServerConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the server name and network port required to connect with the management interface of your on-premises storage system.\n')
    system_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the type of on-premises storage system that you want DataSync Discovery to collect information about. .. epigraph:: DataSync Discovery currently supports NetApp Fabric-Attached Storage (FAS) and All Flash FAS (AFF) systems running ONTAP 9.7 or later.\n')
    cloud_watch_log_group_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the ARN of the Amazon CloudWatch log group for monitoring and logging discovery job events.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='Specifies a familiar name for your on-premises storage system.\n')
    server_credentials: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnStorageSystem_ServerCredentialsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Specifies the user name and password for accessing your on-premises storage system's management interface.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies labels that help you categorize, filter, and search for your AWS resources. We recommend creating at least a name tag for your on-premises storage system.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-storagesystem.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_storage_system_props = datasync.CfnStorageSystemProps(\n        agent_arns=["agentArns"],\n        server_configuration=datasync.CfnStorageSystem.ServerConfigurationProperty(\n            server_hostname="serverHostname",\n\n            # the properties below are optional\n            server_port=123\n        ),\n        system_type="systemType",\n\n        # the properties below are optional\n        cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n        name="name",\n        server_credentials=datasync.CfnStorageSystem.ServerCredentialsProperty(\n            password="password",\n            username="username"\n        ),\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['agent_arns', 'server_configuration', 'system_type', 'cloud_watch_log_group_arn', 'name', 'server_credentials', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnStorageSystemProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_datasync.CfnTaskProps
class CfnTaskPropsDef(BaseCfnProperty):
    destination_location_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The Amazon Resource Name (ARN) of an AWS storage resource's location.\n")
    source_location_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies the ARN of your transfer's source location.\n")
    cloud_watch_log_group_arn: typing.Optional[str] = pydantic.Field(None, description='Specifies the Amazon Resource Name (ARN) of an Amazon CloudWatch log group for monitoring your task. For more information, see `Monitoring DataSync with Amazon CloudWatch <https://docs.aws.amazon.com/datasync/latest/userguide/monitor-datasync.html>`_ .\n')
    excludes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_FilterRulePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="Specifies exclude filters that define the files, objects, and folders in your source location that you don't want DataSync to transfer. For more information and examples, see `Specifying what DataSync transfers by using filters <https://docs.aws.amazon.com/datasync/latest/userguide/filtering.html>`_ .\n")
    includes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_FilterRulePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Specifies include filters define the files, objects, and folders in your source location that you want DataSync to transfer. For more information and examples, see `Specifying what DataSync transfers by using filters <https://docs.aws.amazon.com/datasync/latest/userguide/filtering.html>`_ .\n')
    manifest_config: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_ManifestConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration of the manifest that lists the files or objects that you want DataSync to transfer. For more information, see `Specifying what DataSync transfers by using a manifest <https://docs.aws.amazon.com/datasync/latest/userguide/transferring-with-manifest.html>`_ .\n')
    name: typing.Optional[str] = pydantic.Field(None, description='Specifies the name of your task.\n')
    options: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_OptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Specifies your task's settings, such as preserving file metadata, verifying data integrity, among other options.\n")
    schedule: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_TaskSchedulePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies a schedule for when you want your task to run. For more information, see `Scheduling your task <https://docs.aws.amazon.com/datasync/latest/userguide/task-scheduling.html>`_ .\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Specifies the tags that you want to apply to your task. *Tags* are key-value pairs that help you manage, filter, and search for your DataSync resources.\n')
    task_report_config: typing.Union[models.UnsupportedResource, models.aws_datasync.CfnTask_TaskReportConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies how you want to configure a task report, which provides detailed information about your DataSync transfer. For more information, see `Monitoring your DataSync transfers with task reports <https://docs.aws.amazon.com/datasync/latest/userguide/task-reports.html>`_ . When using this parameter, your caller identity (the role that you\'re using DataSync with) must have the ``iam:PassRole`` permission. The `AWSDataSyncFullAccess <https://docs.aws.amazon.com/datasync/latest/userguide/security-iam-awsmanpol.html#security-iam-awsmanpol-awsdatasyncfullaccess>`_ policy includes this permission.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-datasync-task.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_datasync as datasync\n\n    cfn_task_props = datasync.CfnTaskProps(\n        destination_location_arn="destinationLocationArn",\n        source_location_arn="sourceLocationArn",\n\n        # the properties below are optional\n        cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n        excludes=[datasync.CfnTask.FilterRuleProperty(\n            filter_type="filterType",\n            value="value"\n        )],\n        includes=[datasync.CfnTask.FilterRuleProperty(\n            filter_type="filterType",\n            value="value"\n        )],\n        manifest_config=datasync.CfnTask.ManifestConfigProperty(\n            source=datasync.CfnTask.SourceProperty(\n                s3=datasync.CfnTask.ManifestConfigSourceS3Property(\n                    bucket_access_role_arn="bucketAccessRoleArn",\n                    manifest_object_path="manifestObjectPath",\n                    manifest_object_version_id="manifestObjectVersionId",\n                    s3_bucket_arn="s3BucketArn"\n                )\n            ),\n\n            # the properties below are optional\n            action="action",\n            format="format"\n        ),\n        name="name",\n        options=datasync.CfnTask.OptionsProperty(\n            atime="atime",\n            bytes_per_second=123,\n            gid="gid",\n            log_level="logLevel",\n            mtime="mtime",\n            object_tags="objectTags",\n            overwrite_mode="overwriteMode",\n            posix_permissions="posixPermissions",\n            preserve_deleted_files="preserveDeletedFiles",\n            preserve_devices="preserveDevices",\n            security_descriptor_copy_flags="securityDescriptorCopyFlags",\n            task_queueing="taskQueueing",\n            transfer_mode="transferMode",\n            uid="uid",\n            verify_mode="verifyMode"\n        ),\n        schedule=datasync.CfnTask.TaskScheduleProperty(\n            schedule_expression="scheduleExpression",\n            status="status"\n        ),\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        task_report_config=datasync.CfnTask.TaskReportConfigProperty(\n            destination=datasync.CfnTask.DestinationProperty(\n                s3=datasync.CfnTask.S3Property(\n                    bucket_access_role_arn="bucketAccessRoleArn",\n                    s3_bucket_arn="s3BucketArn",\n                    subdirectory="subdirectory"\n                )\n            ),\n            output_type="outputType",\n\n            # the properties below are optional\n            object_version_ids="objectVersionIds",\n            overrides=datasync.CfnTask.OverridesProperty(\n                deleted=datasync.CfnTask.DeletedProperty(\n                    report_level="reportLevel"\n                ),\n                skipped=datasync.CfnTask.SkippedProperty(\n                    report_level="reportLevel"\n                ),\n                transferred=datasync.CfnTask.TransferredProperty(\n                    report_level="reportLevel"\n                ),\n                verified=datasync.CfnTask.VerifiedProperty(\n                    report_level="reportLevel"\n                )\n            ),\n            report_level="reportLevel"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['destination_location_arn', 'source_location_arn', 'cloud_watch_log_group_arn', 'excludes', 'includes', 'manifest_config', 'name', 'options', 'schedule', 'tags', 'task_report_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_datasync.CfnTaskProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




class ModuleModel(pydantic.BaseModel):
    CfnLocationAzureBlob_AzureBlobSasConfigurationProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationAzureBlob_AzureBlobSasConfigurationPropertyDef]] = pydantic.Field(None)
    CfnLocationEFS_Ec2ConfigProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationEFS_Ec2ConfigPropertyDef]] = pydantic.Field(None)
    CfnLocationFSxONTAP_NfsMountOptionsProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxONTAP_NfsMountOptionsPropertyDef]] = pydantic.Field(None)
    CfnLocationFSxONTAP_NFSProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxONTAP_NFSPropertyDef]] = pydantic.Field(None)
    CfnLocationFSxONTAP_ProtocolProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxONTAP_ProtocolPropertyDef]] = pydantic.Field(None)
    CfnLocationFSxONTAP_SmbMountOptionsProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxONTAP_SmbMountOptionsPropertyDef]] = pydantic.Field(None)
    CfnLocationFSxONTAP_SMBProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxONTAP_SMBPropertyDef]] = pydantic.Field(None)
    CfnLocationFSxOpenZFS_MountOptionsProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxOpenZFS_MountOptionsPropertyDef]] = pydantic.Field(None)
    CfnLocationFSxOpenZFS_NFSProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxOpenZFS_NFSPropertyDef]] = pydantic.Field(None)
    CfnLocationFSxOpenZFS_ProtocolProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxOpenZFS_ProtocolPropertyDef]] = pydantic.Field(None)
    CfnLocationHDFS_NameNodeProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationHDFS_NameNodePropertyDef]] = pydantic.Field(None)
    CfnLocationHDFS_QopConfigurationProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationHDFS_QopConfigurationPropertyDef]] = pydantic.Field(None)
    CfnLocationNFS_MountOptionsProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationNFS_MountOptionsPropertyDef]] = pydantic.Field(None)
    CfnLocationNFS_OnPremConfigProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationNFS_OnPremConfigPropertyDef]] = pydantic.Field(None)
    CfnLocationS3_S3ConfigProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationS3_S3ConfigPropertyDef]] = pydantic.Field(None)
    CfnLocationSMB_MountOptionsProperty: typing.Optional[dict[str, models.aws_datasync.CfnLocationSMB_MountOptionsPropertyDef]] = pydantic.Field(None)
    CfnStorageSystem_ServerConfigurationProperty: typing.Optional[dict[str, models.aws_datasync.CfnStorageSystem_ServerConfigurationPropertyDef]] = pydantic.Field(None)
    CfnStorageSystem_ServerCredentialsProperty: typing.Optional[dict[str, models.aws_datasync.CfnStorageSystem_ServerCredentialsPropertyDef]] = pydantic.Field(None)
    CfnTask_DeletedProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_DeletedPropertyDef]] = pydantic.Field(None)
    CfnTask_DestinationProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_DestinationPropertyDef]] = pydantic.Field(None)
    CfnTask_FilterRuleProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_FilterRulePropertyDef]] = pydantic.Field(None)
    CfnTask_ManifestConfigProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_ManifestConfigPropertyDef]] = pydantic.Field(None)
    CfnTask_ManifestConfigSourceS3Property: typing.Optional[dict[str, models.aws_datasync.CfnTask_ManifestConfigSourceS3PropertyDef]] = pydantic.Field(None)
    CfnTask_OptionsProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_OptionsPropertyDef]] = pydantic.Field(None)
    CfnTask_OverridesProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_OverridesPropertyDef]] = pydantic.Field(None)
    CfnTask_S3Property: typing.Optional[dict[str, models.aws_datasync.CfnTask_S3PropertyDef]] = pydantic.Field(None)
    CfnTask_SkippedProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_SkippedPropertyDef]] = pydantic.Field(None)
    CfnTask_SourceProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_SourcePropertyDef]] = pydantic.Field(None)
    CfnTask_TaskReportConfigProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_TaskReportConfigPropertyDef]] = pydantic.Field(None)
    CfnTask_TaskScheduleProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_TaskSchedulePropertyDef]] = pydantic.Field(None)
    CfnTask_TransferredProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_TransferredPropertyDef]] = pydantic.Field(None)
    CfnTask_VerifiedProperty: typing.Optional[dict[str, models.aws_datasync.CfnTask_VerifiedPropertyDef]] = pydantic.Field(None)
    CfnAgent: typing.Optional[dict[str, models.aws_datasync.CfnAgentDef]] = pydantic.Field(None)
    CfnLocationAzureBlob: typing.Optional[dict[str, models.aws_datasync.CfnLocationAzureBlobDef]] = pydantic.Field(None)
    CfnLocationEFS: typing.Optional[dict[str, models.aws_datasync.CfnLocationEFSDef]] = pydantic.Field(None)
    CfnLocationFSxLustre: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxLustreDef]] = pydantic.Field(None)
    CfnLocationFSxONTAP: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxONTAPDef]] = pydantic.Field(None)
    CfnLocationFSxOpenZFS: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxOpenZFSDef]] = pydantic.Field(None)
    CfnLocationFSxWindows: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxWindowsDef]] = pydantic.Field(None)
    CfnLocationHDFS: typing.Optional[dict[str, models.aws_datasync.CfnLocationHDFSDef]] = pydantic.Field(None)
    CfnLocationNFS: typing.Optional[dict[str, models.aws_datasync.CfnLocationNFSDef]] = pydantic.Field(None)
    CfnLocationObjectStorage: typing.Optional[dict[str, models.aws_datasync.CfnLocationObjectStorageDef]] = pydantic.Field(None)
    CfnLocationS3: typing.Optional[dict[str, models.aws_datasync.CfnLocationS3Def]] = pydantic.Field(None)
    CfnLocationSMB: typing.Optional[dict[str, models.aws_datasync.CfnLocationSMBDef]] = pydantic.Field(None)
    CfnStorageSystem: typing.Optional[dict[str, models.aws_datasync.CfnStorageSystemDef]] = pydantic.Field(None)
    CfnTask: typing.Optional[dict[str, models.aws_datasync.CfnTaskDef]] = pydantic.Field(None)
    CfnAgentProps: typing.Optional[dict[str, models.aws_datasync.CfnAgentPropsDef]] = pydantic.Field(None)
    CfnLocationAzureBlobProps: typing.Optional[dict[str, models.aws_datasync.CfnLocationAzureBlobPropsDef]] = pydantic.Field(None)
    CfnLocationEFSProps: typing.Optional[dict[str, models.aws_datasync.CfnLocationEFSPropsDef]] = pydantic.Field(None)
    CfnLocationFSxLustreProps: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxLustrePropsDef]] = pydantic.Field(None)
    CfnLocationFSxONTAPProps: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxONTAPPropsDef]] = pydantic.Field(None)
    CfnLocationFSxOpenZFSProps: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxOpenZFSPropsDef]] = pydantic.Field(None)
    CfnLocationFSxWindowsProps: typing.Optional[dict[str, models.aws_datasync.CfnLocationFSxWindowsPropsDef]] = pydantic.Field(None)
    CfnLocationHDFSProps: typing.Optional[dict[str, models.aws_datasync.CfnLocationHDFSPropsDef]] = pydantic.Field(None)
    CfnLocationNFSProps: typing.Optional[dict[str, models.aws_datasync.CfnLocationNFSPropsDef]] = pydantic.Field(None)
    CfnLocationObjectStorageProps: typing.Optional[dict[str, models.aws_datasync.CfnLocationObjectStoragePropsDef]] = pydantic.Field(None)
    CfnLocationS3Props: typing.Optional[dict[str, models.aws_datasync.CfnLocationS3PropsDef]] = pydantic.Field(None)
    CfnLocationSMBProps: typing.Optional[dict[str, models.aws_datasync.CfnLocationSMBPropsDef]] = pydantic.Field(None)
    CfnStorageSystemProps: typing.Optional[dict[str, models.aws_datasync.CfnStorageSystemPropsDef]] = pydantic.Field(None)
    CfnTaskProps: typing.Optional[dict[str, models.aws_datasync.CfnTaskPropsDef]] = pydantic.Field(None)
    ...

import models
