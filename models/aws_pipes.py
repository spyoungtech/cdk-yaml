from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_pipes.CfnPipe.AwsVpcConfigurationProperty
class CfnPipe_AwsVpcConfigurationPropertyDef(BaseStruct):
    subnets: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the subnets associated with the task. These subnets must all be in the same VPC. You can specify as many as 16 subnets.\n')
    assign_public_ip: typing.Optional[str] = pydantic.Field(None, description="Specifies whether the task's elastic network interface receives a public IP address. You can specify ``ENABLED`` only when ``LaunchType`` in ``EcsParameters`` is set to ``FARGATE`` .\n")
    security_groups: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Specifies the security groups associated with the task. These security groups must all be in the same VPC. You can specify as many as five security groups. If you do not specify a security group, the default security group for the VPC is used.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-awsvpcconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    aws_vpc_configuration_property = pipes.CfnPipe.AwsVpcConfigurationProperty(\n        subnets=["subnets"],\n\n        # the properties below are optional\n        assign_public_ip="assignPublicIp",\n        security_groups=["securityGroups"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['subnets', 'assign_public_ip', 'security_groups']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.AwsVpcConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.BatchArrayPropertiesProperty
class CfnPipe_BatchArrayPropertiesPropertyDef(BaseStruct):
    size: typing.Union[int, float, None] = pydantic.Field(None, description='The size of the array, if this is an array batch job. Default: - 0\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-batcharrayproperties.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    batch_array_properties_property = pipes.CfnPipe.BatchArrayPropertiesProperty(\n        size=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['size']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.BatchArrayPropertiesProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.BatchContainerOverridesProperty
class CfnPipe_BatchContainerOverridesPropertyDef(BaseStruct):
    command: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The command to send to the container that overrides the default command from the Docker image or the task definition.\n')
    environment: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchEnvironmentVariablePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. .. epigraph:: Environment variables cannot start with " ``AWS Batch`` ". This naming convention is reserved for variables that AWS Batch sets.\n')
    instance_type: typing.Optional[str] = pydantic.Field(None, description="The instance type to use for a multi-node parallel job. .. epigraph:: This parameter isn't applicable to single-node container jobs or jobs that run on Fargate resources, and shouldn't be provided.\n")
    resource_requirements: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchResourceRequirementPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The type and amount of resources to assign to a container. This overrides the settings in the job definition. The supported resources include ``GPU`` , ``MEMORY`` , and ``VCPU`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-batchcontaineroverrides.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    batch_container_overrides_property = pipes.CfnPipe.BatchContainerOverridesProperty(\n        command=["command"],\n        environment=[pipes.CfnPipe.BatchEnvironmentVariableProperty(\n            name="name",\n            value="value"\n        )],\n        instance_type="instanceType",\n        resource_requirements=[pipes.CfnPipe.BatchResourceRequirementProperty(\n            type="type",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['command', 'environment', 'instance_type', 'resource_requirements']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.BatchContainerOverridesProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.BatchEnvironmentVariableProperty
class CfnPipe_BatchEnvironmentVariablePropertyDef(BaseStruct):
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the key-value pair. For environment variables, this is the name of the environment variable.\n')
    value: typing.Optional[str] = pydantic.Field(None, description='The value of the key-value pair. For environment variables, this is the value of the environment variable.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-batchenvironmentvariable.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    batch_environment_variable_property = pipes.CfnPipe.BatchEnvironmentVariableProperty(\n        name="name",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.BatchEnvironmentVariableProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.BatchJobDependencyProperty
class CfnPipe_BatchJobDependencyPropertyDef(BaseStruct):
    job_id: typing.Optional[str] = pydantic.Field(None, description="The job ID of the AWS Batch job that's associated with this dependency.\n")
    type: typing.Optional[str] = pydantic.Field(None, description='The type of the job dependency.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-batchjobdependency.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    batch_job_dependency_property = pipes.CfnPipe.BatchJobDependencyProperty(\n        job_id="jobId",\n        type="type"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['job_id', 'type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.BatchJobDependencyProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.BatchResourceRequirementProperty
class CfnPipe_BatchResourceRequirementPropertyDef(BaseStruct):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of resource to assign to a container. The supported resources include ``GPU`` , ``MEMORY`` , and ``VCPU`` .\n')
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The quantity of the specified resource to reserve for the container. The values vary based on the ``type`` specified. - **type="GPU"** - The number of physical GPUs to reserve for the container. Make sure that the number of GPUs reserved for all containers in a job doesn\'t exceed the number of available GPUs on the compute resource that the job is launched on. .. epigraph:: GPUs aren\'t available for jobs that are running on Fargate resources. - **type="MEMORY"** - The memory hard limit (in MiB) present to the container. This parameter is supported for jobs that are running on EC2 resources. If your container attempts to exceed the memory specified, the container is terminated. This parameter maps to ``Memory`` in the `Create a container <https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container>`_ section of the `Docker Remote API <https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/>`_ and the ``--memory`` option to `docker run <https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/>`_ . You must specify at least 4 MiB of memory for a job. This is required but can be specified in several places for multi-node parallel (MNP) jobs. It must be specified for each node at least once. This parameter maps to ``Memory`` in the `Create a container <https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container>`_ section of the `Docker Remote API <https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/>`_ and the ``--memory`` option to `docker run <https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/>`_ . .. epigraph:: If you\'re trying to maximize your resource utilization by providing your jobs as much memory as possible for a particular instance type, see `Memory management <https://docs.aws.amazon.com/batch/latest/userguide/memory-management.html>`_ in the *AWS Batch User Guide* . For jobs that are running on Fargate resources, then ``value`` is the hard limit (in MiB), and must match one of the supported values and the ``VCPU`` values must be one of the values supported for that memory value. - **value = 512** - ``VCPU`` = 0.25 - **value = 1024** - ``VCPU`` = 0.25 or 0.5 - **value = 2048** - ``VCPU`` = 0.25, 0.5, or 1 - **value = 3072** - ``VCPU`` = 0.5, or 1 - **value = 4096** - ``VCPU`` = 0.5, 1, or 2 - **value = 5120, 6144, or 7168** - ``VCPU`` = 1 or 2 - **value = 8192** - ``VCPU`` = 1, 2, 4, or 8 - **value = 9216, 10240, 11264, 12288, 13312, 14336, or 15360** - ``VCPU`` = 2 or 4 - **value = 16384** - ``VCPU`` = 2, 4, or 8 - **value = 17408, 18432, 19456, 21504, 22528, 23552, 25600, 26624, 27648, 29696, or 30720** - ``VCPU`` = 4 - **value = 20480, 24576, or 28672** - ``VCPU`` = 4 or 8 - **value = 36864, 45056, 53248, or 61440** - ``VCPU`` = 8 - **value = 32768, 40960, 49152, or 57344** - ``VCPU`` = 8 or 16 - **value = 65536, 73728, 81920, 90112, 98304, 106496, 114688, or 122880** - ``VCPU`` = 16 - **type="VCPU"** - The number of vCPUs reserved for the container. This parameter maps to ``CpuShares`` in the `Create a container <https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container>`_ section of the `Docker Remote API <https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/>`_ and the ``--cpu-shares`` option to `docker run <https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/>`_ . Each vCPU is equivalent to 1,024 CPU shares. For EC2 resources, you must specify at least one vCPU. This is required but can be specified in several places; it must be specified for each node at least once. The default for the Fargate On-Demand vCPU resource count quota is 6 vCPUs. For more information about Fargate quotas, see `AWS Fargate quotas <https://docs.aws.amazon.com/general/latest/gr/ecs-service.html#service-quotas-fargate>`_ in the *AWS General Reference* . For jobs that are running on Fargate resources, then ``value`` must match one of the supported values and the ``MEMORY`` values must be one of the values supported for that ``VCPU`` value. The supported values are 0.25, 0.5, 1, 2, 4, 8, and 16 - **value = 0.25** - ``MEMORY`` = 512, 1024, or 2048 - **value = 0.5** - ``MEMORY`` = 1024, 2048, 3072, or 4096 - **value = 1** - ``MEMORY`` = 2048, 3072, 4096, 5120, 6144, 7168, or 8192 - **value = 2** - ``MEMORY`` = 4096, 5120, 6144, 7168, 8192, 9216, 10240, 11264, 12288, 13312, 14336, 15360, or 16384 - **value = 4** - ``MEMORY`` = 8192, 9216, 10240, 11264, 12288, 13312, 14336, 15360, 16384, 17408, 18432, 19456, 20480, 21504, 22528, 23552, 24576, 25600, 26624, 27648, 28672, 29696, or 30720 - **value = 8** - ``MEMORY`` = 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056, 49152, 53248, 57344, or 61440 - **value = 16** - ``MEMORY`` = 32768, 40960, 49152, 57344, 65536, 73728, 81920, 90112, 98304, 106496, 114688, or 122880\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-batchresourcerequirement.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    batch_resource_requirement_property = pipes.CfnPipe.BatchResourceRequirementProperty(\n        type="type",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.BatchResourceRequirementProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.BatchRetryStrategyProperty
class CfnPipe_BatchRetryStrategyPropertyDef(BaseStruct):
    attempts: typing.Union[int, float, None] = pydantic.Field(None, description='The number of times to move a job to the ``RUNNABLE`` status. If the value of ``attempts`` is greater than one, the job is retried on failure the same number of attempts as the value. Default: - 0\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-batchretrystrategy.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    batch_retry_strategy_property = pipes.CfnPipe.BatchRetryStrategyProperty(\n        attempts=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['attempts']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.BatchRetryStrategyProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.CapacityProviderStrategyItemProperty
class CfnPipe_CapacityProviderStrategyItemPropertyDef(BaseStruct):
    capacity_provider: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The short name of the capacity provider.\n')
    base: typing.Union[int, float, None] = pydantic.Field(None, description='The base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used. Default: - 0\n')
    weight: typing.Union[int, float, None] = pydantic.Field(None, description='The weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied. Default: - 0\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-capacityproviderstrategyitem.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    capacity_provider_strategy_item_property = pipes.CfnPipe.CapacityProviderStrategyItemProperty(\n        capacity_provider="capacityProvider",\n\n        # the properties below are optional\n        base=123,\n        weight=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['capacity_provider', 'base', 'weight']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.CapacityProviderStrategyItemProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.CloudwatchLogsLogDestinationProperty
class CfnPipe_CloudwatchLogsLogDestinationPropertyDef(BaseStruct):
    log_group_arn: typing.Optional[str] = pydantic.Field(None, description='The AWS Resource Name (ARN) for the CloudWatch log group to which EventBridge sends the log records.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-cloudwatchlogslogdestination.html\n:exampleMetadata: infused\n\nExample::\n\n    # source_queue: sqs.Queue\n    # target_queue: sqs.Queue\n\n\n    source_filter = pipes.Filter([\n        pipes.FilterPattern.from_object({\n            "body": {\n                # only forward events with customerType B2B or B2C\n                "customer_type": ["B2B", "B2C"]\n            }\n        })\n    ])\n\n    pipe = pipes.Pipe(self, "Pipe",\n        source=SqsSource(source_queue),\n        target=SqsTarget(target_queue),\n        filter=source_filter\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['log_group_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.CloudwatchLogsLogDestinationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.DeadLetterConfigProperty
class CfnPipe_DeadLetterConfigPropertyDef(BaseStruct):
    arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the specified target for the dead-letter queue. For Amazon Kinesis stream and Amazon DynamoDB stream sources, specify either an Amazon SNS topic or Amazon SQS queue ARN.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-deadletterconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    dead_letter_config_property = pipes.CfnPipe.DeadLetterConfigProperty(\n        arn="arn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.DeadLetterConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.DimensionMappingProperty
class CfnPipe_DimensionMappingPropertyDef(BaseStruct):
    dimension_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The metadata attributes of the time series. For example, the name and Availability Zone of an Amazon EC2 instance or the name of the manufacturer of a wind turbine are dimensions.\n')
    dimension_value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Dynamic path to the dimension value in the source event.\n')
    dimension_value_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The data type of the dimension for the time-series data.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-dimensionmapping.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    dimension_mapping_property = pipes.CfnPipe.DimensionMappingProperty(\n        dimension_name="dimensionName",\n        dimension_value="dimensionValue",\n        dimension_value_type="dimensionValueType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['dimension_name', 'dimension_value', 'dimension_value_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.DimensionMappingProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.EcsContainerOverrideProperty
class CfnPipe_EcsContainerOverridePropertyDef(BaseStruct):
    command: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The command to send to the container that overrides the default command from the Docker image or the task definition. You must also specify a container name.\n')
    cpu: typing.Union[int, float, None] = pydantic.Field(None, description='The number of ``cpu`` units reserved for the container, instead of the default value from the task definition. You must also specify a container name.\n')
    environment: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsEnvironmentVariablePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.\n')
    environment_files: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsEnvironmentFilePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A list of files containing the environment variables to pass to a container, instead of the value from the container definition.\n')
    memory: typing.Union[int, float, None] = pydantic.Field(None, description='The hard limit (in MiB) of memory to present to the container, instead of the default value from the task definition. If your container attempts to exceed the memory specified here, the container is killed. You must also specify a container name.\n')
    memory_reservation: typing.Union[int, float, None] = pydantic.Field(None, description='The soft limit (in MiB) of memory to reserve for the container, instead of the default value from the task definition. You must also specify a container name.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the container that receives the override. This parameter is required if any override is specified.\n')
    resource_requirements: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsResourceRequirementPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The type and amount of a resource to assign to a container, instead of the default value from the task definition. The only supported resource is a GPU.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-ecscontaineroverride.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    ecs_container_override_property = pipes.CfnPipe.EcsContainerOverrideProperty(\n        command=["command"],\n        cpu=123,\n        environment=[pipes.CfnPipe.EcsEnvironmentVariableProperty(\n            name="name",\n            value="value"\n        )],\n        environment_files=[pipes.CfnPipe.EcsEnvironmentFileProperty(\n            type="type",\n            value="value"\n        )],\n        memory=123,\n        memory_reservation=123,\n        name="name",\n        resource_requirements=[pipes.CfnPipe.EcsResourceRequirementProperty(\n            type="type",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['command', 'cpu', 'environment', 'environment_files', 'memory', 'memory_reservation', 'name', 'resource_requirements']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.EcsContainerOverrideProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.EcsEnvironmentFileProperty
class CfnPipe_EcsEnvironmentFilePropertyDef(BaseStruct):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The file type to use. The only supported value is ``s3`` .\n')
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-ecsenvironmentfile.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    ecs_environment_file_property = pipes.CfnPipe.EcsEnvironmentFileProperty(\n        type="type",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.EcsEnvironmentFileProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.EcsEnvironmentVariableProperty
class CfnPipe_EcsEnvironmentVariablePropertyDef(BaseStruct):
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the key-value pair. For environment variables, this is the name of the environment variable.\n')
    value: typing.Optional[str] = pydantic.Field(None, description='The value of the key-value pair. For environment variables, this is the value of the environment variable.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-ecsenvironmentvariable.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    ecs_environment_variable_property = pipes.CfnPipe.EcsEnvironmentVariableProperty(\n        name="name",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.EcsEnvironmentVariableProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.EcsEphemeralStorageProperty
class CfnPipe_EcsEphemeralStoragePropertyDef(BaseStruct):
    size_in_gib: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is ``21`` GiB and the maximum supported value is ``200`` GiB. Default: - 0\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-ecsephemeralstorage.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    ecs_ephemeral_storage_property = pipes.CfnPipe.EcsEphemeralStorageProperty(\n        size_in_gi_b=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['size_in_gib']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.EcsEphemeralStorageProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.EcsInferenceAcceleratorOverrideProperty
class CfnPipe_EcsInferenceAcceleratorOverridePropertyDef(BaseStruct):
    device_name: typing.Optional[str] = pydantic.Field(None, description='The Elastic Inference accelerator device name to override for the task. This parameter must match a ``deviceName`` specified in the task definition.\n')
    device_type: typing.Optional[str] = pydantic.Field(None, description='The Elastic Inference accelerator type to use.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-ecsinferenceacceleratoroverride.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    ecs_inference_accelerator_override_property = pipes.CfnPipe.EcsInferenceAcceleratorOverrideProperty(\n        device_name="deviceName",\n        device_type="deviceType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['device_name', 'device_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.EcsInferenceAcceleratorOverrideProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.EcsResourceRequirementProperty
class CfnPipe_EcsResourceRequirementPropertyDef(BaseStruct):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of resource to assign to a container. The supported values are ``GPU`` or ``InferenceAccelerator`` .\n')
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The value for the specified resource type. If the ``GPU`` type is used, the value is the number of physical ``GPUs`` the Amazon ECS container agent reserves for the container. The number of GPUs that\'s reserved for all containers in a task can\'t exceed the number of available GPUs on the container instance that the task is launched on. If the ``InferenceAccelerator`` type is used, the ``value`` matches the ``deviceName`` for an InferenceAccelerator specified in a task definition.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-ecsresourcerequirement.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    ecs_resource_requirement_property = pipes.CfnPipe.EcsResourceRequirementProperty(\n        type="type",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.EcsResourceRequirementProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.EcsTaskOverrideProperty
class CfnPipe_EcsTaskOverridePropertyDef(BaseStruct):
    container_overrides: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsContainerOverridePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='One or more container overrides that are sent to a task.\n')
    cpu: typing.Optional[str] = pydantic.Field(None, description='The cpu override for the task.\n')
    ephemeral_storage: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsEphemeralStoragePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The ephemeral storage setting override for the task. .. epigraph:: This parameter is only supported for tasks hosted on Fargate that use the following platform versions: - Linux platform version ``1.4.0`` or later. - Windows platform version ``1.0.0`` or later.\n')
    execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the task execution IAM role override for the task. For more information, see `Amazon ECS task execution IAM role <https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html>`_ in the *Amazon Elastic Container Service Developer Guide* .\n')
    inference_accelerator_overrides: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsInferenceAcceleratorOverridePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The Elastic Inference accelerator override for the task.\n')
    memory: typing.Optional[str] = pydantic.Field(None, description='The memory override for the task.\n')
    task_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see `IAM Role for Tasks <https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html>`_ in the *Amazon Elastic Container Service Developer Guide* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-ecstaskoverride.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    ecs_task_override_property = pipes.CfnPipe.EcsTaskOverrideProperty(\n        container_overrides=[pipes.CfnPipe.EcsContainerOverrideProperty(\n            command=["command"],\n            cpu=123,\n            environment=[pipes.CfnPipe.EcsEnvironmentVariableProperty(\n                name="name",\n                value="value"\n            )],\n            environment_files=[pipes.CfnPipe.EcsEnvironmentFileProperty(\n                type="type",\n                value="value"\n            )],\n            memory=123,\n            memory_reservation=123,\n            name="name",\n            resource_requirements=[pipes.CfnPipe.EcsResourceRequirementProperty(\n                type="type",\n                value="value"\n            )]\n        )],\n        cpu="cpu",\n        ephemeral_storage=pipes.CfnPipe.EcsEphemeralStorageProperty(\n            size_in_gi_b=123\n        ),\n        execution_role_arn="executionRoleArn",\n        inference_accelerator_overrides=[pipes.CfnPipe.EcsInferenceAcceleratorOverrideProperty(\n            device_name="deviceName",\n            device_type="deviceType"\n        )],\n        memory="memory",\n        task_role_arn="taskRoleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['container_overrides', 'cpu', 'ephemeral_storage', 'execution_role_arn', 'inference_accelerator_overrides', 'memory', 'task_role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.EcsTaskOverrideProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.FilterCriteriaProperty
class CfnPipe_FilterCriteriaPropertyDef(BaseStruct):
    filters: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_FilterPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The event patterns.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-filtercriteria.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    filter_criteria_property = pipes.CfnPipe.FilterCriteriaProperty(\n        filters=[pipes.CfnPipe.FilterProperty(\n            pattern="pattern"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['filters']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.FilterCriteriaProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.FilterProperty
class CfnPipe_FilterPropertyDef(BaseStruct):
    pattern: typing.Optional[str] = pydantic.Field(None, description='The event pattern.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-filter.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    filter_property = pipes.CfnPipe.FilterProperty(\n        pattern="pattern"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['pattern']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.FilterProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.FirehoseLogDestinationProperty
class CfnPipe_FirehoseLogDestinationPropertyDef(BaseStruct):
    delivery_stream_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the Firehose delivery stream to which EventBridge delivers the pipe log records.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-firehoselogdestination.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    firehose_log_destination_property = pipes.CfnPipe.FirehoseLogDestinationProperty(\n        delivery_stream_arn="deliveryStreamArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['delivery_stream_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.FirehoseLogDestinationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.MQBrokerAccessCredentialsProperty
class CfnPipe_MQBrokerAccessCredentialsPropertyDef(BaseStruct):
    basic_auth: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the Secrets Manager secret.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-mqbrokeraccesscredentials.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    m_qBroker_access_credentials_property = pipes.CfnPipe.MQBrokerAccessCredentialsProperty(\n        basic_auth="basicAuth"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['basic_auth']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.MQBrokerAccessCredentialsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.MSKAccessCredentialsProperty
class CfnPipe_MSKAccessCredentialsPropertyDef(BaseStruct):
    client_certificate_tls_auth: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Secrets Manager secret.\n')
    sasl_scram512_auth: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Secrets Manager secret.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-mskaccesscredentials.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    m_sKAccess_credentials_property = pipes.CfnPipe.MSKAccessCredentialsProperty(\n        client_certificate_tls_auth="clientCertificateTlsAuth",\n        sasl_scram512_auth="saslScram512Auth"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['client_certificate_tls_auth', 'sasl_scram512_auth']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.MSKAccessCredentialsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.MultiMeasureAttributeMappingProperty
class CfnPipe_MultiMeasureAttributeMappingPropertyDef(BaseStruct):
    measure_value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Dynamic path to the measurement attribute in the source event.\n')
    measure_value_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Data type of the measurement attribute in the source event.\n')
    multi_measure_attribute_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Target measure name to be used.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-multimeasureattributemapping.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    multi_measure_attribute_mapping_property = pipes.CfnPipe.MultiMeasureAttributeMappingProperty(\n        measure_value="measureValue",\n        measure_value_type="measureValueType",\n        multi_measure_attribute_name="multiMeasureAttributeName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['measure_value', 'measure_value_type', 'multi_measure_attribute_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.MultiMeasureAttributeMappingProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.MultiMeasureMappingProperty
class CfnPipe_MultiMeasureMappingPropertyDef(BaseStruct):
    multi_measure_attribute_mappings: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_MultiMeasureAttributeMappingPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Mappings that represent multiple source event fields mapped to measures in the same Timestream for LiveAnalytics record.\n')
    multi_measure_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the multiple measurements per record (multi-measure).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-multimeasuremapping.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    multi_measure_mapping_property = pipes.CfnPipe.MultiMeasureMappingProperty(\n        multi_measure_attribute_mappings=[pipes.CfnPipe.MultiMeasureAttributeMappingProperty(\n            measure_value="measureValue",\n            measure_value_type="measureValueType",\n            multi_measure_attribute_name="multiMeasureAttributeName"\n        )],\n        multi_measure_name="multiMeasureName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['multi_measure_attribute_mappings', 'multi_measure_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.MultiMeasureMappingProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.NetworkConfigurationProperty
class CfnPipe_NetworkConfigurationPropertyDef(BaseStruct):
    awsvpc_configuration: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_AwsVpcConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Use this structure to specify the VPC subnets and security groups for the task, and whether a public IP address is to be used. This structure is relevant only for ECS tasks that use the ``awsvpc`` network mode.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-networkconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    network_configuration_property = pipes.CfnPipe.NetworkConfigurationProperty(\n        awsvpc_configuration=pipes.CfnPipe.AwsVpcConfigurationProperty(\n            subnets=["subnets"],\n\n            # the properties below are optional\n            assign_public_ip="assignPublicIp",\n            security_groups=["securityGroups"]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['awsvpc_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.NetworkConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeEnrichmentHttpParametersProperty
class CfnPipe_PipeEnrichmentHttpParametersPropertyDef(BaseStruct):
    header_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='The headers that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.\n')
    path_parameter_values: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The path parameter values to be used to populate API Gateway REST API or EventBridge ApiDestination path wildcards ("*").\n')
    query_string_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='The query string keys/values that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipeenrichmenthttpparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_enrichment_http_parameters_property = pipes.CfnPipe.PipeEnrichmentHttpParametersProperty(\n        header_parameters={\n            "header_parameters_key": "headerParameters"\n        },\n        path_parameter_values=["pathParameterValues"],\n        query_string_parameters={\n            "query_string_parameters_key": "queryStringParameters"\n        }\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['header_parameters', 'path_parameter_values', 'query_string_parameters']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeEnrichmentHttpParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeEnrichmentParametersProperty
class CfnPipe_PipeEnrichmentParametersPropertyDef(BaseStruct):
    http_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeEnrichmentHttpParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Contains the HTTP parameters to use when the target is a API Gateway REST endpoint or EventBridge ApiDestination. If you specify an API Gateway REST API or EventBridge ApiDestination as a target, you can use this parameter to specify headers, path parameters, and query string keys/values as part of your target invoking request. If you're using ApiDestinations, the corresponding Connection can also have these values configured. In case of any conflicting keys, values from the Connection take precedence.\n")
    input_template: typing.Optional[str] = pydantic.Field(None, description='Valid JSON text passed to the enrichment. In this case, nothing from the event itself is passed to the enrichment. For more information, see `The JavaScript Object Notation (JSON) Data Interchange Format <https://docs.aws.amazon.com/http://www.rfc-editor.org/rfc/rfc7159.txt>`_ . To remove an input template, specify an empty string.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipeenrichmentparameters.html\n:exampleMetadata: infused\n\nExample::\n\n    # source_queue: sqs.Queue\n    # target_queue: sqs.Queue\n    # loggroup: logs.LogGroup\n\n\n    pipe = pipes.Pipe(self, "Pipe",\n        source=SqsSource(source_queue),\n        target=SqsTarget(target_queue),\n\n        log_level=pipes.LogLevel.TRACE,\n        log_include_execution_data=[pipes.IncludeExecutionData.ALL],\n\n        log_destinations=[\n            CloudwatchDestination(loggroup)\n        ]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['http_parameters', 'input_template']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeEnrichmentParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeLogConfigurationProperty
class CfnPipe_PipeLogConfigurationPropertyDef(BaseStruct):
    cloudwatch_logs_log_destination: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_CloudwatchLogsLogDestinationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The logging configuration settings for the pipe.\n')
    firehose_log_destination: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_FirehoseLogDestinationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Amazon Data Firehose logging configuration settings for the pipe.\n')
    include_execution_data: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Whether the execution data (specifically, the ``payload`` , ``awsRequest`` , and ``awsResponse`` fields) is included in the log messages for this pipe. This applies to all log destinations for the pipe. For more information, see `Including execution data in logs <https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-logs.html#eb-pipes-logs-execution-data>`_ in the *Amazon EventBridge User Guide* . *Allowed values:* ``ALL``\n')
    level: typing.Optional[str] = pydantic.Field(None, description='The level of logging detail to include. This applies to all log destinations for the pipe.\n')
    s3_log_destination: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_S3LogDestinationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Amazon S3 logging configuration settings for the pipe.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipelogconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_log_configuration_property = pipes.CfnPipe.PipeLogConfigurationProperty(\n        cloudwatch_logs_log_destination=pipes.CfnPipe.CloudwatchLogsLogDestinationProperty(\n            log_group_arn="logGroupArn"\n        ),\n        firehose_log_destination=pipes.CfnPipe.FirehoseLogDestinationProperty(\n            delivery_stream_arn="deliveryStreamArn"\n        ),\n        include_execution_data=["includeExecutionData"],\n        level="level",\n        s3_log_destination=pipes.CfnPipe.S3LogDestinationProperty(\n            bucket_name="bucketName",\n            bucket_owner="bucketOwner",\n            output_format="outputFormat",\n            prefix="prefix"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cloudwatch_logs_log_destination', 'firehose_log_destination', 'include_execution_data', 'level', 's3_log_destination']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeLogConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeSourceActiveMQBrokerParametersProperty
class CfnPipe_PipeSourceActiveMQBrokerParametersPropertyDef(BaseStruct):
    credentials: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_pipes.CfnPipe_MQBrokerAccessCredentialsPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The credentials needed to access the resource.\n')
    queue_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the destination queue to consume.\n')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of records to include in each batch.\n')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum length of a time to wait for events.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipesourceactivemqbrokerparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_source_active_mQBroker_parameters_property = pipes.CfnPipe.PipeSourceActiveMQBrokerParametersProperty(\n        credentials=pipes.CfnPipe.MQBrokerAccessCredentialsProperty(\n            basic_auth="basicAuth"\n        ),\n        queue_name="queueName",\n\n        # the properties below are optional\n        batch_size=123,\n        maximum_batching_window_in_seconds=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['credentials', 'queue_name', 'batch_size', 'maximum_batching_window_in_seconds']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeSourceActiveMQBrokerParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeSourceDynamoDBStreamParametersProperty
class CfnPipe_PipeSourceDynamoDBStreamParametersPropertyDef(BaseStruct):
    starting_position: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='(Streams only) The position in a stream from which to start reading. *Valid values* : ``TRIM_HORIZON | LATEST``\n')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of records to include in each batch.\n')
    dead_letter_config: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_DeadLetterConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Define the target queue to send dead-letter queue events to.\n')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum length of a time to wait for events.\n')
    maximum_record_age_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='(Streams only) Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.\n')
    maximum_retry_attempts: typing.Union[int, float, None] = pydantic.Field(None, description='(Streams only) Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.\n')
    on_partial_batch_item_failure: typing.Optional[str] = pydantic.Field(None, description='(Streams only) Define how to handle item process failures. ``AUTOMATIC_BISECT`` halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.\n')
    parallelization_factor: typing.Union[int, float, None] = pydantic.Field(None, description='(Streams only) The number of batches to process concurrently from each shard. The default value is 1.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipesourcedynamodbstreamparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_source_dynamo_dBStream_parameters_property = pipes.CfnPipe.PipeSourceDynamoDBStreamParametersProperty(\n        starting_position="startingPosition",\n\n        # the properties below are optional\n        batch_size=123,\n        dead_letter_config=pipes.CfnPipe.DeadLetterConfigProperty(\n            arn="arn"\n        ),\n        maximum_batching_window_in_seconds=123,\n        maximum_record_age_in_seconds=123,\n        maximum_retry_attempts=123,\n        on_partial_batch_item_failure="onPartialBatchItemFailure",\n        parallelization_factor=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['starting_position', 'batch_size', 'dead_letter_config', 'maximum_batching_window_in_seconds', 'maximum_record_age_in_seconds', 'maximum_retry_attempts', 'on_partial_batch_item_failure', 'parallelization_factor']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeSourceDynamoDBStreamParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeSourceKinesisStreamParametersProperty
class CfnPipe_PipeSourceKinesisStreamParametersPropertyDef(BaseStruct):
    starting_position: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='(Streams only) The position in a stream from which to start reading.\n')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of records to include in each batch.\n')
    dead_letter_config: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_DeadLetterConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Define the target queue to send dead-letter queue events to.\n')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum length of a time to wait for events.\n')
    maximum_record_age_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='(Streams only) Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.\n')
    maximum_retry_attempts: typing.Union[int, float, None] = pydantic.Field(None, description='(Streams only) Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.\n')
    on_partial_batch_item_failure: typing.Optional[str] = pydantic.Field(None, description='(Streams only) Define how to handle item process failures. ``AUTOMATIC_BISECT`` halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.\n')
    parallelization_factor: typing.Union[int, float, None] = pydantic.Field(None, description='(Streams only) The number of batches to process concurrently from each shard. The default value is 1.\n')
    starting_position_timestamp: typing.Optional[str] = pydantic.Field(None, description='With ``StartingPosition`` set to ``AT_TIMESTAMP`` , the time from which to start reading, in Unix time seconds.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipesourcekinesisstreamparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_source_kinesis_stream_parameters_property = pipes.CfnPipe.PipeSourceKinesisStreamParametersProperty(\n        starting_position="startingPosition",\n\n        # the properties below are optional\n        batch_size=123,\n        dead_letter_config=pipes.CfnPipe.DeadLetterConfigProperty(\n            arn="arn"\n        ),\n        maximum_batching_window_in_seconds=123,\n        maximum_record_age_in_seconds=123,\n        maximum_retry_attempts=123,\n        on_partial_batch_item_failure="onPartialBatchItemFailure",\n        parallelization_factor=123,\n        starting_position_timestamp="startingPositionTimestamp"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['starting_position', 'batch_size', 'dead_letter_config', 'maximum_batching_window_in_seconds', 'maximum_record_age_in_seconds', 'maximum_retry_attempts', 'on_partial_batch_item_failure', 'parallelization_factor', 'starting_position_timestamp']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeSourceKinesisStreamParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeSourceManagedStreamingKafkaParametersProperty
class CfnPipe_PipeSourceManagedStreamingKafkaParametersPropertyDef(BaseStruct):
    topic_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the topic that the pipe will read from.\n')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of records to include in each batch.\n')
    consumer_group_id: typing.Optional[str] = pydantic.Field(None, description='The name of the destination queue to consume.\n')
    credentials: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_MSKAccessCredentialsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The credentials needed to access the resource.\n')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum length of a time to wait for events.\n')
    starting_position: typing.Optional[str] = pydantic.Field(None, description='(Streams only) The position in a stream from which to start reading.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipesourcemanagedstreamingkafkaparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_source_managed_streaming_kafka_parameters_property = pipes.CfnPipe.PipeSourceManagedStreamingKafkaParametersProperty(\n        topic_name="topicName",\n\n        # the properties below are optional\n        batch_size=123,\n        consumer_group_id="consumerGroupId",\n        credentials=pipes.CfnPipe.MSKAccessCredentialsProperty(\n            client_certificate_tls_auth="clientCertificateTlsAuth",\n            sasl_scram512_auth="saslScram512Auth"\n        ),\n        maximum_batching_window_in_seconds=123,\n        starting_position="startingPosition"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['topic_name', 'batch_size', 'consumer_group_id', 'credentials', 'maximum_batching_window_in_seconds', 'starting_position']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeSourceManagedStreamingKafkaParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeSourceParametersProperty
class CfnPipe_PipeSourceParametersPropertyDef(BaseStruct):
    active_mq_broker_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceActiveMQBrokerParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using an Active MQ broker as a source.\n')
    dynamo_db_stream_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceDynamoDBStreamParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using a DynamoDB stream as a source.\n')
    filter_criteria: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_FilterCriteriaPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The collection of event patterns used to filter events. To remove a filter, specify a ``FilterCriteria`` object with an empty array of ``Filter`` objects. For more information, see `Events and Event Patterns <https://docs.aws.amazon.com/eventbridge/latest/userguide/eventbridge-and-event-patterns.html>`_ in the *Amazon EventBridge User Guide* .\n')
    kinesis_stream_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceKinesisStreamParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using a Kinesis stream as a source.\n')
    managed_streaming_kafka_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceManagedStreamingKafkaParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using an MSK stream as a source.\n')
    rabbit_mq_broker_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceRabbitMQBrokerParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using a Rabbit MQ broker as a source.\n')
    self_managed_kafka_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceSelfManagedKafkaParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using a self-managed Apache Kafka stream as a source. A *self managed* cluster refers to any Apache Kafka cluster not hosted by AWS . This includes both clusters you manage yourself, as well as those hosted by a third-party provider, such as `Confluent Cloud <https://docs.aws.amazon.com/https://www.confluent.io/>`_ , `CloudKarafka <https://docs.aws.amazon.com/https://www.cloudkarafka.com/>`_ , or `Redpanda <https://docs.aws.amazon.com/https://redpanda.com/>`_ . For more information, see `Apache Kafka streams as a source <https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-kafka.html>`_ in the *Amazon EventBridge User Guide* .\n')
    sqs_queue_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceSqsQueueParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using a Amazon SQS stream as a source.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipesourceparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_source_parameters_property = pipes.CfnPipe.PipeSourceParametersProperty(\n        active_mq_broker_parameters=pipes.CfnPipe.PipeSourceActiveMQBrokerParametersProperty(\n            credentials=pipes.CfnPipe.MQBrokerAccessCredentialsProperty(\n                basic_auth="basicAuth"\n            ),\n            queue_name="queueName",\n\n            # the properties below are optional\n            batch_size=123,\n            maximum_batching_window_in_seconds=123\n        ),\n        dynamo_db_stream_parameters=pipes.CfnPipe.PipeSourceDynamoDBStreamParametersProperty(\n            starting_position="startingPosition",\n\n            # the properties below are optional\n            batch_size=123,\n            dead_letter_config=pipes.CfnPipe.DeadLetterConfigProperty(\n                arn="arn"\n            ),\n            maximum_batching_window_in_seconds=123,\n            maximum_record_age_in_seconds=123,\n            maximum_retry_attempts=123,\n            on_partial_batch_item_failure="onPartialBatchItemFailure",\n            parallelization_factor=123\n        ),\n        filter_criteria=pipes.CfnPipe.FilterCriteriaProperty(\n            filters=[pipes.CfnPipe.FilterProperty(\n                pattern="pattern"\n            )]\n        ),\n        kinesis_stream_parameters=pipes.CfnPipe.PipeSourceKinesisStreamParametersProperty(\n            starting_position="startingPosition",\n\n            # the properties below are optional\n            batch_size=123,\n            dead_letter_config=pipes.CfnPipe.DeadLetterConfigProperty(\n                arn="arn"\n            ),\n            maximum_batching_window_in_seconds=123,\n            maximum_record_age_in_seconds=123,\n            maximum_retry_attempts=123,\n            on_partial_batch_item_failure="onPartialBatchItemFailure",\n            parallelization_factor=123,\n            starting_position_timestamp="startingPositionTimestamp"\n        ),\n        managed_streaming_kafka_parameters=pipes.CfnPipe.PipeSourceManagedStreamingKafkaParametersProperty(\n            topic_name="topicName",\n\n            # the properties below are optional\n            batch_size=123,\n            consumer_group_id="consumerGroupId",\n            credentials=pipes.CfnPipe.MSKAccessCredentialsProperty(\n                client_certificate_tls_auth="clientCertificateTlsAuth",\n                sasl_scram512_auth="saslScram512Auth"\n            ),\n            maximum_batching_window_in_seconds=123,\n            starting_position="startingPosition"\n        ),\n        rabbit_mq_broker_parameters=pipes.CfnPipe.PipeSourceRabbitMQBrokerParametersProperty(\n            credentials=pipes.CfnPipe.MQBrokerAccessCredentialsProperty(\n                basic_auth="basicAuth"\n            ),\n            queue_name="queueName",\n\n            # the properties below are optional\n            batch_size=123,\n            maximum_batching_window_in_seconds=123,\n            virtual_host="virtualHost"\n        ),\n        self_managed_kafka_parameters=pipes.CfnPipe.PipeSourceSelfManagedKafkaParametersProperty(\n            topic_name="topicName",\n\n            # the properties below are optional\n            additional_bootstrap_servers=["additionalBootstrapServers"],\n            batch_size=123,\n            consumer_group_id="consumerGroupId",\n            credentials=pipes.CfnPipe.SelfManagedKafkaAccessConfigurationCredentialsProperty(\n                basic_auth="basicAuth",\n                client_certificate_tls_auth="clientCertificateTlsAuth",\n                sasl_scram256_auth="saslScram256Auth",\n                sasl_scram512_auth="saslScram512Auth"\n            ),\n            maximum_batching_window_in_seconds=123,\n            server_root_ca_certificate="serverRootCaCertificate",\n            starting_position="startingPosition",\n            vpc=pipes.CfnPipe.SelfManagedKafkaAccessConfigurationVpcProperty(\n                security_group=["securityGroup"],\n                subnets=["subnets"]\n            )\n        ),\n        sqs_queue_parameters=pipes.CfnPipe.PipeSourceSqsQueueParametersProperty(\n            batch_size=123,\n            maximum_batching_window_in_seconds=123\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['active_mq_broker_parameters', 'dynamo_db_stream_parameters', 'filter_criteria', 'kinesis_stream_parameters', 'managed_streaming_kafka_parameters', 'rabbit_mq_broker_parameters', 'self_managed_kafka_parameters', 'sqs_queue_parameters']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeSourceParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeSourceRabbitMQBrokerParametersProperty
class CfnPipe_PipeSourceRabbitMQBrokerParametersPropertyDef(BaseStruct):
    credentials: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_pipes.CfnPipe_MQBrokerAccessCredentialsPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The credentials needed to access the resource.\n')
    queue_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the destination queue to consume.\n')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of records to include in each batch.\n')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum length of a time to wait for events.\n')
    virtual_host: typing.Optional[str] = pydantic.Field(None, description='The name of the virtual host associated with the source broker.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipesourcerabbitmqbrokerparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_source_rabbit_mQBroker_parameters_property = pipes.CfnPipe.PipeSourceRabbitMQBrokerParametersProperty(\n        credentials=pipes.CfnPipe.MQBrokerAccessCredentialsProperty(\n            basic_auth="basicAuth"\n        ),\n        queue_name="queueName",\n\n        # the properties below are optional\n        batch_size=123,\n        maximum_batching_window_in_seconds=123,\n        virtual_host="virtualHost"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['credentials', 'queue_name', 'batch_size', 'maximum_batching_window_in_seconds', 'virtual_host']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeSourceRabbitMQBrokerParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeSourceSelfManagedKafkaParametersProperty
class CfnPipe_PipeSourceSelfManagedKafkaParametersPropertyDef(BaseStruct):
    topic_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the topic that the pipe will read from.\n')
    additional_bootstrap_servers: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of server URLs.\n')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of records to include in each batch.\n')
    consumer_group_id: typing.Optional[str] = pydantic.Field(None, description='The name of the destination queue to consume.\n')
    credentials: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_SelfManagedKafkaAccessConfigurationCredentialsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The credentials needed to access the resource.\n')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum length of a time to wait for events.\n')
    server_root_ca_certificate: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Secrets Manager secret used for certification.\n')
    starting_position: typing.Optional[str] = pydantic.Field(None, description='(Streams only) The position in a stream from which to start reading.\n')
    vpc: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_SelfManagedKafkaAccessConfigurationVpcPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='This structure specifies the VPC subnets and security groups for the stream, and whether a public IP address is to be used.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipesourceselfmanagedkafkaparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_source_self_managed_kafka_parameters_property = pipes.CfnPipe.PipeSourceSelfManagedKafkaParametersProperty(\n        topic_name="topicName",\n\n        # the properties below are optional\n        additional_bootstrap_servers=["additionalBootstrapServers"],\n        batch_size=123,\n        consumer_group_id="consumerGroupId",\n        credentials=pipes.CfnPipe.SelfManagedKafkaAccessConfigurationCredentialsProperty(\n            basic_auth="basicAuth",\n            client_certificate_tls_auth="clientCertificateTlsAuth",\n            sasl_scram256_auth="saslScram256Auth",\n            sasl_scram512_auth="saslScram512Auth"\n        ),\n        maximum_batching_window_in_seconds=123,\n        server_root_ca_certificate="serverRootCaCertificate",\n        starting_position="startingPosition",\n        vpc=pipes.CfnPipe.SelfManagedKafkaAccessConfigurationVpcProperty(\n            security_group=["securityGroup"],\n            subnets=["subnets"]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['topic_name', 'additional_bootstrap_servers', 'batch_size', 'consumer_group_id', 'credentials', 'maximum_batching_window_in_seconds', 'server_root_ca_certificate', 'starting_position', 'vpc']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeSourceSelfManagedKafkaParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeSourceSqsQueueParametersProperty
class CfnPipe_PipeSourceSqsQueueParametersPropertyDef(BaseStruct):
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of records to include in each batch.\n')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum length of a time to wait for events.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipesourcesqsqueueparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_source_sqs_queue_parameters_property = pipes.CfnPipe.PipeSourceSqsQueueParametersProperty(\n        batch_size=123,\n        maximum_batching_window_in_seconds=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['batch_size', 'maximum_batching_window_in_seconds']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeSourceSqsQueueParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetBatchJobParametersProperty
class CfnPipe_PipeTargetBatchJobParametersPropertyDef(BaseStruct):
    job_definition: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The job definition used by this job. This value can be one of ``name`` , ``name:revision`` , or the Amazon Resource Name (ARN) for the job definition. If name is specified without a revision then the latest active revision is used.\n')
    job_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the job. It can be up to 128 letters long. The first character must be alphanumeric, can contain uppercase and lowercase letters, numbers, hyphens (-), and underscores (_).\n')
    array_properties: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchArrayPropertiesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The array properties for the submitted job, such as the size of the array. The array size can be between 2 and 10,000. If you specify array properties for a job, it becomes an array job. This parameter is used only if the target is an AWS Batch job.\n')
    container_overrides: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchContainerOverridesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The overrides that are sent to a container.\n')
    depends_on: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchJobDependencyPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A list of dependencies for the job. A job can depend upon a maximum of 20 jobs. You can specify a ``SEQUENTIAL`` type dependency without specifying a job ID for array jobs so that each child array job completes sequentially, starting at index 0. You can also specify an ``N_TO_N`` type dependency with a job ID for array jobs. In that case, each index child of this job must wait for the corresponding index child of each dependency to complete before it can begin.\n')
    parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='Additional parameters passed to the job that replace parameter substitution placeholders that are set in the job definition. Parameters are specified as a key and value pair mapping. Parameters included here override any corresponding parameter defaults from the job definition.\n')
    retry_strategy: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchRetryStrategyPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The retry strategy to use for failed jobs. When a retry strategy is specified here, it overrides the retry strategy defined in the job definition.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargetbatchjobparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_batch_job_parameters_property = pipes.CfnPipe.PipeTargetBatchJobParametersProperty(\n        job_definition="jobDefinition",\n        job_name="jobName",\n\n        # the properties below are optional\n        array_properties=pipes.CfnPipe.BatchArrayPropertiesProperty(\n            size=123\n        ),\n        container_overrides=pipes.CfnPipe.BatchContainerOverridesProperty(\n            command=["command"],\n            environment=[pipes.CfnPipe.BatchEnvironmentVariableProperty(\n                name="name",\n                value="value"\n            )],\n            instance_type="instanceType",\n            resource_requirements=[pipes.CfnPipe.BatchResourceRequirementProperty(\n                type="type",\n                value="value"\n            )]\n        ),\n        depends_on=[pipes.CfnPipe.BatchJobDependencyProperty(\n            job_id="jobId",\n            type="type"\n        )],\n        parameters={\n            "parameters_key": "parameters"\n        },\n        retry_strategy=pipes.CfnPipe.BatchRetryStrategyProperty(\n            attempts=123\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['job_definition', 'job_name', 'array_properties', 'container_overrides', 'depends_on', 'parameters', 'retry_strategy']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetBatchJobParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetCloudWatchLogsParametersProperty
class CfnPipe_PipeTargetCloudWatchLogsParametersPropertyDef(BaseStruct):
    log_stream_name: typing.Optional[str] = pydantic.Field(None, description='The name of the log stream.\n')
    timestamp: typing.Optional[str] = pydantic.Field(None, description='The time the event occurred, expressed as the number of milliseconds after Jan 1, 1970 00:00:00 UTC.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargetcloudwatchlogsparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_cloud_watch_logs_parameters_property = pipes.CfnPipe.PipeTargetCloudWatchLogsParametersProperty(\n        log_stream_name="logStreamName",\n        timestamp="timestamp"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['log_stream_name', 'timestamp']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetCloudWatchLogsParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetEcsTaskParametersProperty
class CfnPipe_PipeTargetEcsTaskParametersPropertyDef(BaseStruct):
    task_definition_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the task definition to use if the event target is an Amazon ECS task.\n')
    capacity_provider_strategy: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_CapacityProviderStrategyItemPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The capacity provider strategy to use for the task. If a ``capacityProviderStrategy`` is specified, the ``launchType`` parameter must be omitted. If no ``capacityProviderStrategy`` or launchType is specified, the ``defaultCapacityProviderStrategy`` for the cluster is used.\n')
    enable_ecs_managed_tags: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Specifies whether to enable Amazon ECS managed tags for the task. For more information, see `Tagging Your Amazon ECS Resources <https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html>`_ in the Amazon Elastic Container Service Developer Guide. Default: - false\n')
    enable_execute_command: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether or not to enable the execute command functionality for the containers in this task. If true, this enables execute command functionality on all containers in the task. Default: - false\n')
    group: typing.Optional[str] = pydantic.Field(None, description='Specifies an Amazon ECS task group for the task. The maximum length is 255 characters.\n')
    launch_type: typing.Optional[str] = pydantic.Field(None, description='Specifies the launch type on which your task is running. The launch type that you specify here must match one of the launch type (compatibilities) of the target task. The ``FARGATE`` value is supported only in the Regions where AWS Fargate with Amazon ECS is supported. For more information, see `AWS Fargate on Amazon ECS <https://docs.aws.amazon.com/AmazonECS/latest/developerguide/AWS-Fargate.html>`_ in the *Amazon Elastic Container Service Developer Guide* .\n')
    network_configuration: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_NetworkConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Use this structure if the Amazon ECS task uses the ``awsvpc`` network mode. This structure specifies the VPC subnets and security groups associated with the task, and whether a public IP address is to be used. This structure is required if ``LaunchType`` is ``FARGATE`` because the ``awsvpc`` mode is required for Fargate tasks. If you specify ``NetworkConfiguration`` when the target ECS task does not use the ``awsvpc`` network mode, the task fails.\n')
    overrides: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsTaskOverridePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The overrides that are associated with a task.\n')
    placement_constraints: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PlacementConstraintPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='An array of placement constraint objects to use for the task. You can specify up to 10 constraints per task (including constraints in the task definition and those specified at runtime).\n')
    placement_strategy: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PlacementStrategyPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The placement strategy objects to use for the task. You can specify a maximum of five strategy rules per task.\n')
    platform_version: typing.Optional[str] = pydantic.Field(None, description='Specifies the platform version for the task. Specify only the numeric portion of the platform version, such as ``1.1.0`` . This structure is used only if ``LaunchType`` is ``FARGATE`` . For more information about valid platform versions, see `AWS Fargate Platform Versions <https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html>`_ in the *Amazon Elastic Container Service Developer Guide* .\n')
    propagate_tags: typing.Optional[str] = pydantic.Field(None, description='Specifies whether to propagate the tags from the task definition to the task. If no value is specified, the tags are not propagated. Tags can only be propagated to the task during task creation. To add tags to a task after task creation, use the ``TagResource`` API action.\n')
    reference_id: typing.Optional[str] = pydantic.Field(None, description='The reference ID to use for the task.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The metadata that you apply to the task to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. To learn more, see `RunTask <https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_RunTask.html#ECS-RunTask-request-tags>`_ in the Amazon ECS API Reference.\n')
    task_count: typing.Union[int, float, None] = pydantic.Field(None, description='The number of tasks to create based on ``TaskDefinition`` . The default is 1.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargetecstaskparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_ecs_task_parameters_property = pipes.CfnPipe.PipeTargetEcsTaskParametersProperty(\n        task_definition_arn="taskDefinitionArn",\n\n        # the properties below are optional\n        capacity_provider_strategy=[pipes.CfnPipe.CapacityProviderStrategyItemProperty(\n            capacity_provider="capacityProvider",\n\n            # the properties below are optional\n            base=123,\n            weight=123\n        )],\n        enable_ecs_managed_tags=False,\n        enable_execute_command=False,\n        group="group",\n        launch_type="launchType",\n        network_configuration=pipes.CfnPipe.NetworkConfigurationProperty(\n            awsvpc_configuration=pipes.CfnPipe.AwsVpcConfigurationProperty(\n                subnets=["subnets"],\n\n                # the properties below are optional\n                assign_public_ip="assignPublicIp",\n                security_groups=["securityGroups"]\n            )\n        ),\n        overrides=pipes.CfnPipe.EcsTaskOverrideProperty(\n            container_overrides=[pipes.CfnPipe.EcsContainerOverrideProperty(\n                command=["command"],\n                cpu=123,\n                environment=[pipes.CfnPipe.EcsEnvironmentVariableProperty(\n                    name="name",\n                    value="value"\n                )],\n                environment_files=[pipes.CfnPipe.EcsEnvironmentFileProperty(\n                    type="type",\n                    value="value"\n                )],\n                memory=123,\n                memory_reservation=123,\n                name="name",\n                resource_requirements=[pipes.CfnPipe.EcsResourceRequirementProperty(\n                    type="type",\n                    value="value"\n                )]\n            )],\n            cpu="cpu",\n            ephemeral_storage=pipes.CfnPipe.EcsEphemeralStorageProperty(\n                size_in_gi_b=123\n            ),\n            execution_role_arn="executionRoleArn",\n            inference_accelerator_overrides=[pipes.CfnPipe.EcsInferenceAcceleratorOverrideProperty(\n                device_name="deviceName",\n                device_type="deviceType"\n            )],\n            memory="memory",\n            task_role_arn="taskRoleArn"\n        ),\n        placement_constraints=[pipes.CfnPipe.PlacementConstraintProperty(\n            expression="expression",\n            type="type"\n        )],\n        placement_strategy=[pipes.CfnPipe.PlacementStrategyProperty(\n            field="field",\n            type="type"\n        )],\n        platform_version="platformVersion",\n        propagate_tags="propagateTags",\n        reference_id="referenceId",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        task_count=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['task_definition_arn', 'capacity_provider_strategy', 'enable_ecs_managed_tags', 'enable_execute_command', 'group', 'launch_type', 'network_configuration', 'overrides', 'placement_constraints', 'placement_strategy', 'platform_version', 'propagate_tags', 'reference_id', 'tags', 'task_count']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetEcsTaskParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetEventBridgeEventBusParametersProperty
class CfnPipe_PipeTargetEventBridgeEventBusParametersPropertyDef(BaseStruct):
    detail_type: typing.Optional[str] = pydantic.Field(None, description='A free-form string, with a maximum of 128 characters, used to decide what fields to expect in the event detail.\n')
    endpoint_id: typing.Optional[str] = pydantic.Field(None, description='The URL subdomain of the endpoint. For example, if the URL for Endpoint is https://abcde.veo.endpoints.event.amazonaws.com, then the EndpointId is ``abcde.veo`` .\n')
    resources: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='AWS resources, identified by Amazon Resource Name (ARN), which the event primarily concerns. Any number, including zero, may be present.\n')
    source: typing.Optional[str] = pydantic.Field(None, description='The source of the event.\n')
    time: typing.Optional[str] = pydantic.Field(None, description='The time stamp of the event, per `RFC3339 <https://docs.aws.amazon.com/https://www.rfc-editor.org/rfc/rfc3339.txt>`_ . If no time stamp is provided, the time stamp of the `PutEvents <https://docs.aws.amazon.com/eventbridge/latest/APIReference/API_PutEvents.html>`_ call is used.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargeteventbridgeeventbusparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_event_bridge_event_bus_parameters_property = pipes.CfnPipe.PipeTargetEventBridgeEventBusParametersProperty(\n        detail_type="detailType",\n        endpoint_id="endpointId",\n        resources=["resources"],\n        source="source",\n        time="time"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['detail_type', 'endpoint_id', 'resources', 'source', 'time']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetEventBridgeEventBusParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetHttpParametersProperty
class CfnPipe_PipeTargetHttpParametersPropertyDef(BaseStruct):
    header_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='The headers that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.\n')
    path_parameter_values: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The path parameter values to be used to populate API Gateway REST API or EventBridge ApiDestination path wildcards ("*").\n')
    query_string_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='The query string keys/values that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargethttpparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_http_parameters_property = pipes.CfnPipe.PipeTargetHttpParametersProperty(\n        header_parameters={\n            "header_parameters_key": "headerParameters"\n        },\n        path_parameter_values=["pathParameterValues"],\n        query_string_parameters={\n            "query_string_parameters_key": "queryStringParameters"\n        }\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['header_parameters', 'path_parameter_values', 'query_string_parameters']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetHttpParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetKinesisStreamParametersProperty
class CfnPipe_PipeTargetKinesisStreamParametersPropertyDef(BaseStruct):
    partition_key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Determines which shard in the stream the data record is assigned to. Partition keys are Unicode strings with a maximum length limit of 256 characters for each key. Amazon Kinesis Data Streams uses the partition key as input to a hash function that maps the partition key and associated data to a specific shard. Specifically, an MD5 hash function is used to map partition keys to 128-bit integer values and to map associated data records to shards. As a result of this hashing mechanism, all data records with the same partition key map to the same shard within the stream.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargetkinesisstreamparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_kinesis_stream_parameters_property = pipes.CfnPipe.PipeTargetKinesisStreamParametersProperty(\n        partition_key="partitionKey"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['partition_key']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetKinesisStreamParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetLambdaFunctionParametersProperty
class CfnPipe_PipeTargetLambdaFunctionParametersPropertyDef(BaseStruct):
    invocation_type: typing.Optional[str] = pydantic.Field(None, description='Specify whether to invoke the function synchronously or asynchronously. - ``REQUEST_RESPONSE`` (default) - Invoke synchronously. This corresponds to the ``RequestResponse`` option in the ``InvocationType`` parameter for the Lambda `Invoke <https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_RequestSyntax>`_ API. - ``FIRE_AND_FORGET`` - Invoke asynchronously. This corresponds to the ``Event`` option in the ``InvocationType`` parameter for the Lambda `Invoke <https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_RequestSyntax>`_ API. For more information, see `Invocation types <https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html#pipes-invocation>`_ in the *Amazon EventBridge User Guide* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargetlambdafunctionparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_lambda_function_parameters_property = pipes.CfnPipe.PipeTargetLambdaFunctionParametersProperty(\n        invocation_type="invocationType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['invocation_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetLambdaFunctionParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetParametersProperty
class CfnPipe_PipeTargetParametersPropertyDef(BaseStruct):
    batch_job_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetBatchJobParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using an AWS Batch job as a target.\n')
    cloud_watch_logs_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetCloudWatchLogsParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using an CloudWatch Logs log stream as a target.\n')
    ecs_task_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetEcsTaskParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using an Amazon ECS task as a target.\n')
    event_bridge_event_bus_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetEventBridgeEventBusParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using an EventBridge event bus as a target.\n')
    http_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetHttpParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='These are custom parameter to be used when the target is an API Gateway REST APIs or EventBridge ApiDestinations.\n')
    input_template: typing.Optional[str] = pydantic.Field(None, description='Valid JSON text passed to the target. In this case, nothing from the event itself is passed to the target. For more information, see `The JavaScript Object Notation (JSON) Data Interchange Format <https://docs.aws.amazon.com/http://www.rfc-editor.org/rfc/rfc7159.txt>`_ . To remove an input template, specify an empty string.\n')
    kinesis_stream_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetKinesisStreamParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using a Kinesis stream as a target.\n')
    lambda_function_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetLambdaFunctionParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using a Lambda function as a target.\n')
    redshift_data_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetRedshiftDataParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='These are custom parameters to be used when the target is a Amazon Redshift cluster to invoke the Amazon Redshift Data API BatchExecuteStatement.\n')
    sage_maker_pipeline_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetSageMakerPipelineParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using a SageMaker pipeline as a target.\n')
    sqs_queue_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetSqsQueueParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using a Amazon SQS stream as a target.\n')
    step_function_state_machine_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetStateMachineParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using a Step Functions state machine as a target.\n')
    timestream_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetTimestreamParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters for using a Timestream for LiveAnalytics table as a target.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargetparameters.html\n:exampleMetadata: infused\n\nExample::\n\n    # source_queue: sqs.Queue\n    # target_queue: sqs.Queue\n\n\n    pipe_source = sources.SqsSource(source_queue,\n        batch_size=10,\n        maximum_batching_window=cdk.Duration.seconds(10)\n    )\n\n    pipe = pipes.Pipe(self, "Pipe",\n        source=pipe_source,\n        target=SomeTarget(target_queue)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['batch_job_parameters', 'cloud_watch_logs_parameters', 'ecs_task_parameters', 'event_bridge_event_bus_parameters', 'http_parameters', 'input_template', 'kinesis_stream_parameters', 'lambda_function_parameters', 'redshift_data_parameters', 'sage_maker_pipeline_parameters', 'sqs_queue_parameters', 'step_function_state_machine_parameters', 'timestream_parameters']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetRedshiftDataParametersProperty
class CfnPipe_PipeTargetRedshiftDataParametersPropertyDef(BaseStruct):
    database: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the database. Required when authenticating using temporary credentials.\n')
    sqls: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The SQL statement text to run.\n')
    db_user: typing.Optional[str] = pydantic.Field(None, description='The database user name. Required when authenticating using temporary credentials.\n')
    secret_manager_arn: typing.Optional[str] = pydantic.Field(None, description='The name or ARN of the secret that enables access to the database. Required when authenticating using Secrets Manager.\n')
    statement_name: typing.Optional[str] = pydantic.Field(None, description='The name of the SQL statement. You can name the SQL statement when you create it to identify the query.\n')
    with_event: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether to send an event back to EventBridge after the SQL statement runs. Default: - false\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargetredshiftdataparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_redshift_data_parameters_property = pipes.CfnPipe.PipeTargetRedshiftDataParametersProperty(\n        database="database",\n        sqls=["sqls"],\n\n        # the properties below are optional\n        db_user="dbUser",\n        secret_manager_arn="secretManagerArn",\n        statement_name="statementName",\n        with_event=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['database', 'sqls', 'db_user', 'secret_manager_arn', 'statement_name', 'with_event']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetRedshiftDataParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetSageMakerPipelineParametersProperty
class CfnPipe_PipeTargetSageMakerPipelineParametersPropertyDef(BaseStruct):
    pipeline_parameter_list: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_SageMakerPipelineParameterPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='List of Parameter names and values for SageMaker Model Building Pipeline execution.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargetsagemakerpipelineparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_sage_maker_pipeline_parameters_property = pipes.CfnPipe.PipeTargetSageMakerPipelineParametersProperty(\n        pipeline_parameter_list=[pipes.CfnPipe.SageMakerPipelineParameterProperty(\n            name="name",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['pipeline_parameter_list']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetSageMakerPipelineParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetSqsQueueParametersProperty
class CfnPipe_PipeTargetSqsQueueParametersPropertyDef(BaseStruct):
    message_deduplication_id: typing.Optional[str] = pydantic.Field(None, description='This parameter applies only to FIFO (first-in-first-out) queues. The token used for deduplication of sent messages.\n')
    message_group_id: typing.Optional[str] = pydantic.Field(None, description='The FIFO message group ID to use as the target.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargetsqsqueueparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_sqs_queue_parameters_property = pipes.CfnPipe.PipeTargetSqsQueueParametersProperty(\n        message_deduplication_id="messageDeduplicationId",\n        message_group_id="messageGroupId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['message_deduplication_id', 'message_group_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetSqsQueueParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetStateMachineParametersProperty
class CfnPipe_PipeTargetStateMachineParametersPropertyDef(BaseStruct):
    invocation_type: typing.Optional[str] = pydantic.Field(None, description='Specify whether to invoke the Step Functions state machine synchronously or asynchronously. - ``REQUEST_RESPONSE`` (default) - Invoke synchronously. For more information, see `StartSyncExecution <https://docs.aws.amazon.com/step-functions/latest/apireference/API_StartSyncExecution.html>`_ in the *AWS Step Functions API Reference* . .. epigraph:: ``REQUEST_RESPONSE`` is not supported for ``STANDARD`` state machine workflows. - ``FIRE_AND_FORGET`` - Invoke asynchronously. For more information, see `StartExecution <https://docs.aws.amazon.com/step-functions/latest/apireference/API_StartExecution.html>`_ in the *AWS Step Functions API Reference* . For more information, see `Invocation types <https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html#pipes-invocation>`_ in the *Amazon EventBridge User Guide* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargetstatemachineparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_state_machine_parameters_property = pipes.CfnPipe.PipeTargetStateMachineParametersProperty(\n        invocation_type="invocationType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['invocation_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetStateMachineParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PipeTargetTimestreamParametersProperty
class CfnPipe_PipeTargetTimestreamParametersPropertyDef(BaseStruct):
    dimension_mappings: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_DimensionMappingPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Map source data to dimensions in the target Timestream for LiveAnalytics table. For more information, see `Amazon Timestream for LiveAnalytics concepts <https://docs.aws.amazon.com/timestream/latest/developerguide/concepts.html>`_\n')
    time_value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Dynamic path to the source data field that represents the time value for your data.\n')
    version_value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='64 bit version value or source data field that represents the version value for your data. Write requests with a higher version number will update the existing measure values of the record and version. In cases where the measure value is the same, the version will still be updated. Default value is 1. Timestream for LiveAnalytics does not support updating partial measure values in a record. Write requests for duplicate data with a higher version number will update the existing measure value and version. In cases where the measure value is the same, ``Version`` will still be updated. Default value is ``1`` . .. epigraph:: ``Version`` must be ``1`` or greater, or you will receive a ``ValidationException`` error.\n')
    epoch_time_unit: typing.Optional[str] = pydantic.Field(None, description='The granularity of the time units used. Default is ``MILLISECONDS`` . Required if ``TimeFieldType`` is specified as ``EPOCH`` .\n')
    multi_measure_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_MultiMeasureMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Maps multiple measures from the source event to the same record in the specified Timestream for LiveAnalytics table.\n')
    single_measure_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_SingleMeasureMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Mappings of single source data fields to individual records in the specified Timestream for LiveAnalytics table.\n')
    time_field_type: typing.Optional[str] = pydantic.Field(None, description='The type of time value used. The default is ``EPOCH`` .\n')
    timestamp_format: typing.Optional[str] = pydantic.Field(None, description='How to format the timestamps. For example, ``YYYY-MM-DDThh:mm:ss.sssTZD`` . Required if ``TimeFieldType`` is specified as ``TIMESTAMP_FORMAT`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-pipetargettimestreamparameters.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    pipe_target_timestream_parameters_property = pipes.CfnPipe.PipeTargetTimestreamParametersProperty(\n        dimension_mappings=[pipes.CfnPipe.DimensionMappingProperty(\n            dimension_name="dimensionName",\n            dimension_value="dimensionValue",\n            dimension_value_type="dimensionValueType"\n        )],\n        time_value="timeValue",\n        version_value="versionValue",\n\n        # the properties below are optional\n        epoch_time_unit="epochTimeUnit",\n        multi_measure_mappings=[pipes.CfnPipe.MultiMeasureMappingProperty(\n            multi_measure_attribute_mappings=[pipes.CfnPipe.MultiMeasureAttributeMappingProperty(\n                measure_value="measureValue",\n                measure_value_type="measureValueType",\n                multi_measure_attribute_name="multiMeasureAttributeName"\n            )],\n            multi_measure_name="multiMeasureName"\n        )],\n        single_measure_mappings=[pipes.CfnPipe.SingleMeasureMappingProperty(\n            measure_name="measureName",\n            measure_value="measureValue",\n            measure_value_type="measureValueType"\n        )],\n        time_field_type="timeFieldType",\n        timestamp_format="timestampFormat"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['dimension_mappings', 'time_value', 'version_value', 'epoch_time_unit', 'multi_measure_mappings', 'single_measure_mappings', 'time_field_type', 'timestamp_format']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PipeTargetTimestreamParametersProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PlacementConstraintProperty
class CfnPipe_PlacementConstraintPropertyDef(BaseStruct):
    expression: typing.Optional[str] = pydantic.Field(None, description='A cluster query language expression to apply to the constraint. You cannot specify an expression if the constraint type is ``distinctInstance`` . To learn more, see `Cluster Query Language <https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html>`_ in the Amazon Elastic Container Service Developer Guide.\n')
    type: typing.Optional[str] = pydantic.Field(None, description='The type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-placementconstraint.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    placement_constraint_property = pipes.CfnPipe.PlacementConstraintProperty(\n        expression="expression",\n        type="type"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['expression', 'type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PlacementConstraintProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.PlacementStrategyProperty
class CfnPipe_PlacementStrategyPropertyDef(BaseStruct):
    field: typing.Optional[str] = pydantic.Field(None, description='The field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host, which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone. For the binpack placement strategy, valid values are cpu and memory. For the random placement strategy, this field is not used.\n')
    type: typing.Optional[str] = pydantic.Field(None, description='The type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-placementstrategy.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    placement_strategy_property = pipes.CfnPipe.PlacementStrategyProperty(\n        field="field",\n        type="type"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['field', 'type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.PlacementStrategyProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.S3LogDestinationProperty
class CfnPipe_S3LogDestinationPropertyDef(BaseStruct):
    bucket_name: typing.Optional[str] = pydantic.Field(None, description='The name of the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.\n')
    bucket_owner: typing.Optional[str] = pydantic.Field(None, description='The AWS account that owns the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.\n')
    output_format: typing.Optional[str] = pydantic.Field(None, description='The format EventBridge uses for the log records. - ``json`` : JSON - ``plain`` : Plain text - ``w3c`` : `W3C extended logging file format <https://docs.aws.amazon.com/https://www.w3.org/TR/WD-logfile>`_\n')
    prefix: typing.Optional[str] = pydantic.Field(None, description='The prefix text with which to begin Amazon S3 log object names. For more information, see `Organizing objects using prefixes <https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-prefixes.html>`_ in the *Amazon Simple Storage Service User Guide* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-s3logdestination.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    s3_log_destination_property = pipes.CfnPipe.S3LogDestinationProperty(\n        bucket_name="bucketName",\n        bucket_owner="bucketOwner",\n        output_format="outputFormat",\n        prefix="prefix"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket_name', 'bucket_owner', 'output_format', 'prefix']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.S3LogDestinationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.SageMakerPipelineParameterProperty
class CfnPipe_SageMakerPipelineParameterPropertyDef(BaseStruct):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Name of parameter to start execution of a SageMaker Model Building Pipeline.\n')
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Value of parameter to start execution of a SageMaker Model Building Pipeline.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-sagemakerpipelineparameter.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    sage_maker_pipeline_parameter_property = pipes.CfnPipe.SageMakerPipelineParameterProperty(\n        name="name",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.SageMakerPipelineParameterProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.SelfManagedKafkaAccessConfigurationCredentialsProperty
class CfnPipe_SelfManagedKafkaAccessConfigurationCredentialsPropertyDef(BaseStruct):
    basic_auth: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Secrets Manager secret.\n')
    client_certificate_tls_auth: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Secrets Manager secret.\n')
    sasl_scram256_auth: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Secrets Manager secret.\n')
    sasl_scram512_auth: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Secrets Manager secret.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-selfmanagedkafkaaccessconfigurationcredentials.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    self_managed_kafka_access_configuration_credentials_property = pipes.CfnPipe.SelfManagedKafkaAccessConfigurationCredentialsProperty(\n        basic_auth="basicAuth",\n        client_certificate_tls_auth="clientCertificateTlsAuth",\n        sasl_scram256_auth="saslScram256Auth",\n        sasl_scram512_auth="saslScram512Auth"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['basic_auth', 'client_certificate_tls_auth', 'sasl_scram256_auth', 'sasl_scram512_auth']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.SelfManagedKafkaAccessConfigurationCredentialsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.SelfManagedKafkaAccessConfigurationVpcProperty
class CfnPipe_SelfManagedKafkaAccessConfigurationVpcPropertyDef(BaseStruct):
    security_group: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Specifies the security groups associated with the stream. These security groups must all be in the same VPC. You can specify as many as five security groups. If you do not specify a security group, the default security group for the VPC is used.\n')
    subnets: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Specifies the subnets associated with the stream. These subnets must all be in the same VPC. You can specify as many as 16 subnets.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-selfmanagedkafkaaccessconfigurationvpc.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    self_managed_kafka_access_configuration_vpc_property = pipes.CfnPipe.SelfManagedKafkaAccessConfigurationVpcProperty(\n        security_group=["securityGroup"],\n        subnets=["subnets"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['security_group', 'subnets']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.SelfManagedKafkaAccessConfigurationVpcProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe.SingleMeasureMappingProperty
class CfnPipe_SingleMeasureMappingPropertyDef(BaseStruct):
    measure_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Target measure name for the measurement attribute in the Timestream table.\n')
    measure_value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Dynamic path of the source field to map to the measure in the record.\n')
    measure_value_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Data type of the source field.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-pipes-pipe-singlemeasuremapping.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    single_measure_mapping_property = pipes.CfnPipe.SingleMeasureMappingProperty(\n        measure_name="measureName",\n        measure_value="measureValue",\n        measure_value_type="measureValueType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['measure_name', 'measure_value', 'measure_value_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe.SingleMeasureMappingProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_pipes.CfnPipe
class CfnPipeDef(BaseCfnResource):
    role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the role that allows the pipe to send data to the target.\n')
    source: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the source resource.\n')
    target: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the target resource.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the pipe.\n')
    desired_state: typing.Optional[str] = pydantic.Field(None, description='The state the pipe should be in.\n')
    enrichment: typing.Optional[str] = pydantic.Field(None, description='The ARN of the enrichment resource.\n')
    enrichment_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeEnrichmentParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters required to set up enrichment on your pipe.\n')
    log_configuration: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeLogConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The logging configuration settings for the pipe.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the pipe.\n')
    source_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters required to set up a source for your pipe.\n')
    tags: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='The list of key-value pairs to associate with the pipe.\n')
    target_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters required to set up a target for your pipe. For more information about pipe target parameters, including how to use dynamic path parameters, see `Target parameters <https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-event-target.html>`_ in the *Amazon EventBridge User Guide* .')
    _init_params: typing.ClassVar[list[str]] = ['role_arn', 'source', 'target', 'description', 'desired_state', 'enrichment', 'enrichment_parameters', 'log_configuration', 'name', 'source_parameters', 'tags', 'target_parameters']
    _method_names: typing.ClassVar[list[str]] = ['AwsVpcConfigurationProperty', 'BatchArrayPropertiesProperty', 'BatchContainerOverridesProperty', 'BatchEnvironmentVariableProperty', 'BatchJobDependencyProperty', 'BatchResourceRequirementProperty', 'BatchRetryStrategyProperty', 'CapacityProviderStrategyItemProperty', 'CloudwatchLogsLogDestinationProperty', 'DeadLetterConfigProperty', 'DimensionMappingProperty', 'EcsContainerOverrideProperty', 'EcsEnvironmentFileProperty', 'EcsEnvironmentVariableProperty', 'EcsEphemeralStorageProperty', 'EcsInferenceAcceleratorOverrideProperty', 'EcsResourceRequirementProperty', 'EcsTaskOverrideProperty', 'FilterCriteriaProperty', 'FilterProperty', 'FirehoseLogDestinationProperty', 'MQBrokerAccessCredentialsProperty', 'MSKAccessCredentialsProperty', 'MultiMeasureAttributeMappingProperty', 'MultiMeasureMappingProperty', 'NetworkConfigurationProperty', 'PipeEnrichmentHttpParametersProperty', 'PipeEnrichmentParametersProperty', 'PipeLogConfigurationProperty', 'PipeSourceActiveMQBrokerParametersProperty', 'PipeSourceDynamoDBStreamParametersProperty', 'PipeSourceKinesisStreamParametersProperty', 'PipeSourceManagedStreamingKafkaParametersProperty', 'PipeSourceParametersProperty', 'PipeSourceRabbitMQBrokerParametersProperty', 'PipeSourceSelfManagedKafkaParametersProperty', 'PipeSourceSqsQueueParametersProperty', 'PipeTargetBatchJobParametersProperty', 'PipeTargetCloudWatchLogsParametersProperty', 'PipeTargetEcsTaskParametersProperty', 'PipeTargetEventBridgeEventBusParametersProperty', 'PipeTargetHttpParametersProperty', 'PipeTargetKinesisStreamParametersProperty', 'PipeTargetLambdaFunctionParametersProperty', 'PipeTargetParametersProperty', 'PipeTargetRedshiftDataParametersProperty', 'PipeTargetSageMakerPipelineParametersProperty', 'PipeTargetSqsQueueParametersProperty', 'PipeTargetStateMachineParametersProperty', 'PipeTargetTimestreamParametersProperty', 'PlacementConstraintProperty', 'PlacementStrategyProperty', 'S3LogDestinationProperty', 'SageMakerPipelineParameterProperty', 'SelfManagedKafkaAccessConfigurationCredentialsProperty', 'SelfManagedKafkaAccessConfigurationVpcProperty', 'SingleMeasureMappingProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipe'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_pipes.CfnPipeDefConfig] = pydantic.Field(None)


class CfnPipeDefConfig(pydantic.BaseModel):
    AwsVpcConfigurationProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefAwsvpcconfigurationpropertyParams]] = pydantic.Field(None, description='')
    BatchArrayPropertiesProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefBatcharraypropertiespropertyParams]] = pydantic.Field(None, description='')
    BatchContainerOverridesProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefBatchcontaineroverridespropertyParams]] = pydantic.Field(None, description='')
    BatchEnvironmentVariableProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefBatchenvironmentvariablepropertyParams]] = pydantic.Field(None, description='')
    BatchJobDependencyProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefBatchjobdependencypropertyParams]] = pydantic.Field(None, description='')
    BatchResourceRequirementProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefBatchresourcerequirementpropertyParams]] = pydantic.Field(None, description='')
    BatchRetryStrategyProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefBatchretrystrategypropertyParams]] = pydantic.Field(None, description='')
    CapacityProviderStrategyItemProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefCapacityproviderstrategyitempropertyParams]] = pydantic.Field(None, description='')
    CloudwatchLogsLogDestinationProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefCloudwatchlogslogdestinationpropertyParams]] = pydantic.Field(None, description='')
    DeadLetterConfigProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefDeadletterconfigpropertyParams]] = pydantic.Field(None, description='')
    DimensionMappingProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefDimensionmappingpropertyParams]] = pydantic.Field(None, description='')
    EcsContainerOverrideProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefEcscontaineroverridepropertyParams]] = pydantic.Field(None, description='')
    EcsEnvironmentFileProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefEcsenvironmentfilepropertyParams]] = pydantic.Field(None, description='')
    EcsEnvironmentVariableProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefEcsenvironmentvariablepropertyParams]] = pydantic.Field(None, description='')
    EcsEphemeralStorageProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefEcsephemeralstoragepropertyParams]] = pydantic.Field(None, description='')
    EcsInferenceAcceleratorOverrideProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefEcsinferenceacceleratoroverridepropertyParams]] = pydantic.Field(None, description='')
    EcsResourceRequirementProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefEcsresourcerequirementpropertyParams]] = pydantic.Field(None, description='')
    EcsTaskOverrideProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefEcstaskoverridepropertyParams]] = pydantic.Field(None, description='')
    FilterCriteriaProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefFiltercriteriapropertyParams]] = pydantic.Field(None, description='')
    FilterProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefFilterpropertyParams]] = pydantic.Field(None, description='')
    FirehoseLogDestinationProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefFirehoselogdestinationpropertyParams]] = pydantic.Field(None, description='')
    MQBrokerAccessCredentialsProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefMqbrokeraccesscredentialspropertyParams]] = pydantic.Field(None, description='')
    MSKAccessCredentialsProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefMskaccesscredentialspropertyParams]] = pydantic.Field(None, description='')
    MultiMeasureAttributeMappingProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefMultimeasureattributemappingpropertyParams]] = pydantic.Field(None, description='')
    MultiMeasureMappingProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefMultimeasuremappingpropertyParams]] = pydantic.Field(None, description='')
    NetworkConfigurationProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefNetworkconfigurationpropertyParams]] = pydantic.Field(None, description='')
    PipeEnrichmentHttpParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipeenrichmenthttpparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeEnrichmentParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipeenrichmentparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeLogConfigurationProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipelogconfigurationpropertyParams]] = pydantic.Field(None, description='')
    PipeSourceActiveMQBrokerParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipesourceactivemqbrokerparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeSourceDynamoDBStreamParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipesourcedynamodbstreamparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeSourceKinesisStreamParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipesourcekinesisstreamparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeSourceManagedStreamingKafkaParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipesourcemanagedstreamingkafkaparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeSourceParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipesourceparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeSourceRabbitMQBrokerParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipesourcerabbitmqbrokerparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeSourceSelfManagedKafkaParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipesourceselfmanagedkafkaparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeSourceSqsQueueParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipesourcesqsqueueparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetBatchJobParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargetbatchjobparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetCloudWatchLogsParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargetcloudwatchlogsparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetEcsTaskParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargetecstaskparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetEventBridgeEventBusParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargeteventbridgeeventbusparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetHttpParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargethttpparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetKinesisStreamParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargetkinesisstreamparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetLambdaFunctionParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargetlambdafunctionparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargetparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetRedshiftDataParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargetredshiftdataparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetSageMakerPipelineParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargetsagemakerpipelineparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetSqsQueueParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargetsqsqueueparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetStateMachineParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargetstatemachineparameterspropertyParams]] = pydantic.Field(None, description='')
    PipeTargetTimestreamParametersProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPipetargettimestreamparameterspropertyParams]] = pydantic.Field(None, description='')
    PlacementConstraintProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPlacementconstraintpropertyParams]] = pydantic.Field(None, description='')
    PlacementStrategyProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefPlacementstrategypropertyParams]] = pydantic.Field(None, description='')
    S3LogDestinationProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefS3LogdestinationpropertyParams]] = pydantic.Field(None, description='')
    SageMakerPipelineParameterProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefSagemakerpipelineparameterpropertyParams]] = pydantic.Field(None, description='')
    SelfManagedKafkaAccessConfigurationCredentialsProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefSelfmanagedkafkaaccessconfigurationcredentialspropertyParams]] = pydantic.Field(None, description='')
    SelfManagedKafkaAccessConfigurationVpcProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefSelfmanagedkafkaaccessconfigurationvpcpropertyParams]] = pydantic.Field(None, description='')
    SingleMeasureMappingProperty: typing.Optional[list[models.aws_pipes.CfnPipeDefSinglemeasuremappingpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_pipes.CfnPipeDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_pipes.CfnPipeDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_pipes.CfnPipeDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_pipes.CfnPipeDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_pipes.CfnPipeDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_pipes.CfnPipeDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_pipes.CfnPipeDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_pipes.CfnPipeDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_pipes.CfnPipeDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_pipes.CfnPipeDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_pipes.CfnPipeDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_pipes.CfnPipeDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_pipes.CfnPipeDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnPipeDefAwsvpcconfigurationpropertyParams(pydantic.BaseModel):
    subnets: typing.Sequence[str] = pydantic.Field(..., description='')
    assign_public_ip: typing.Optional[str] = pydantic.Field(None, description='')
    security_groups: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnPipeDefBatcharraypropertiespropertyParams(pydantic.BaseModel):
    size: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefBatchcontaineroverridespropertyParams(pydantic.BaseModel):
    command: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    environment: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchEnvironmentVariablePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    instance_type: typing.Optional[str] = pydantic.Field(None, description='')
    resource_requirements: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchResourceRequirementPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefBatchenvironmentvariablepropertyParams(pydantic.BaseModel):
    name: typing.Optional[str] = pydantic.Field(None, description='')
    value: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefBatchjobdependencypropertyParams(pydantic.BaseModel):
    job_id: typing.Optional[str] = pydantic.Field(None, description='')
    type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefBatchresourcerequirementpropertyParams(pydantic.BaseModel):
    type: str = pydantic.Field(..., description='')
    value: str = pydantic.Field(..., description='')
    ...

class CfnPipeDefBatchretrystrategypropertyParams(pydantic.BaseModel):
    attempts: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefCapacityproviderstrategyitempropertyParams(pydantic.BaseModel):
    capacity_provider: str = pydantic.Field(..., description='')
    base: typing.Union[int, float, None] = pydantic.Field(None, description='')
    weight: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefCloudwatchlogslogdestinationpropertyParams(pydantic.BaseModel):
    log_group_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefDeadletterconfigpropertyParams(pydantic.BaseModel):
    arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefDimensionmappingpropertyParams(pydantic.BaseModel):
    dimension_name: str = pydantic.Field(..., description='')
    dimension_value: str = pydantic.Field(..., description='')
    dimension_value_type: str = pydantic.Field(..., description='')
    ...

class CfnPipeDefEcscontaineroverridepropertyParams(pydantic.BaseModel):
    command: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    cpu: typing.Union[int, float, None] = pydantic.Field(None, description='')
    environment: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsEnvironmentVariablePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    environment_files: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsEnvironmentFilePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    memory: typing.Union[int, float, None] = pydantic.Field(None, description='')
    memory_reservation: typing.Union[int, float, None] = pydantic.Field(None, description='')
    name: typing.Optional[str] = pydantic.Field(None, description='')
    resource_requirements: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsResourceRequirementPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefEcsenvironmentfilepropertyParams(pydantic.BaseModel):
    type: str = pydantic.Field(..., description='')
    value: str = pydantic.Field(..., description='')
    ...

class CfnPipeDefEcsenvironmentvariablepropertyParams(pydantic.BaseModel):
    name: typing.Optional[str] = pydantic.Field(None, description='')
    value: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefEcsephemeralstoragepropertyParams(pydantic.BaseModel):
    size_in_gib: typing.Union[int, float] = pydantic.Field(..., description='')
    ...

class CfnPipeDefEcsinferenceacceleratoroverridepropertyParams(pydantic.BaseModel):
    device_name: typing.Optional[str] = pydantic.Field(None, description='')
    device_type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefEcsresourcerequirementpropertyParams(pydantic.BaseModel):
    type: str = pydantic.Field(..., description='')
    value: str = pydantic.Field(..., description='')
    ...

class CfnPipeDefEcstaskoverridepropertyParams(pydantic.BaseModel):
    container_overrides: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsContainerOverridePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    cpu: typing.Optional[str] = pydantic.Field(None, description='')
    ephemeral_storage: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsEphemeralStoragePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    inference_accelerator_overrides: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsInferenceAcceleratorOverridePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    memory: typing.Optional[str] = pydantic.Field(None, description='')
    task_role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefFiltercriteriapropertyParams(pydantic.BaseModel):
    filters: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_FilterPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefFilterpropertyParams(pydantic.BaseModel):
    pattern: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefFirehoselogdestinationpropertyParams(pydantic.BaseModel):
    delivery_stream_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefMqbrokeraccesscredentialspropertyParams(pydantic.BaseModel):
    basic_auth: str = pydantic.Field(..., description='')
    ...

class CfnPipeDefMskaccesscredentialspropertyParams(pydantic.BaseModel):
    client_certificate_tls_auth: typing.Optional[str] = pydantic.Field(None, description='')
    sasl_scram512_auth: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefMultimeasureattributemappingpropertyParams(pydantic.BaseModel):
    measure_value: str = pydantic.Field(..., description='')
    measure_value_type: str = pydantic.Field(..., description='')
    multi_measure_attribute_name: str = pydantic.Field(..., description='')
    ...

class CfnPipeDefMultimeasuremappingpropertyParams(pydantic.BaseModel):
    multi_measure_attribute_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_MultiMeasureAttributeMappingPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    multi_measure_name: str = pydantic.Field(..., description='')
    ...

class CfnPipeDefNetworkconfigurationpropertyParams(pydantic.BaseModel):
    awsvpc_configuration: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_AwsVpcConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipeenrichmenthttpparameterspropertyParams(pydantic.BaseModel):
    header_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    path_parameter_values: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    query_string_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipeenrichmentparameterspropertyParams(pydantic.BaseModel):
    http_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeEnrichmentHttpParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    input_template: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipelogconfigurationpropertyParams(pydantic.BaseModel):
    cloudwatch_logs_log_destination: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_CloudwatchLogsLogDestinationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    firehose_log_destination: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_FirehoseLogDestinationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    include_execution_data: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    level: typing.Optional[str] = pydantic.Field(None, description='')
    s3_log_destination: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_S3LogDestinationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipesourceactivemqbrokerparameterspropertyParams(pydantic.BaseModel):
    credentials: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_MQBrokerAccessCredentialsPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    queue_name: str = pydantic.Field(..., description='')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipesourcedynamodbstreamparameterspropertyParams(pydantic.BaseModel):
    starting_position: str = pydantic.Field(..., description='')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='')
    dead_letter_config: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_DeadLetterConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    maximum_record_age_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    maximum_retry_attempts: typing.Union[int, float, None] = pydantic.Field(None, description='')
    on_partial_batch_item_failure: typing.Optional[str] = pydantic.Field(None, description='')
    parallelization_factor: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipesourcekinesisstreamparameterspropertyParams(pydantic.BaseModel):
    starting_position: str = pydantic.Field(..., description='')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='')
    dead_letter_config: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_DeadLetterConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    maximum_record_age_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    maximum_retry_attempts: typing.Union[int, float, None] = pydantic.Field(None, description='')
    on_partial_batch_item_failure: typing.Optional[str] = pydantic.Field(None, description='')
    parallelization_factor: typing.Union[int, float, None] = pydantic.Field(None, description='')
    starting_position_timestamp: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipesourcemanagedstreamingkafkaparameterspropertyParams(pydantic.BaseModel):
    topic_name: str = pydantic.Field(..., description='')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='')
    consumer_group_id: typing.Optional[str] = pydantic.Field(None, description='')
    credentials: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_MSKAccessCredentialsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    starting_position: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipesourceparameterspropertyParams(pydantic.BaseModel):
    active_mq_broker_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceActiveMQBrokerParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    dynamo_db_stream_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceDynamoDBStreamParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    filter_criteria: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_FilterCriteriaPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    kinesis_stream_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceKinesisStreamParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    managed_streaming_kafka_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceManagedStreamingKafkaParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    rabbit_mq_broker_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceRabbitMQBrokerParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    self_managed_kafka_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceSelfManagedKafkaParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    sqs_queue_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceSqsQueueParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipesourcerabbitmqbrokerparameterspropertyParams(pydantic.BaseModel):
    credentials: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_MQBrokerAccessCredentialsPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    queue_name: str = pydantic.Field(..., description='')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    virtual_host: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipesourceselfmanagedkafkaparameterspropertyParams(pydantic.BaseModel):
    topic_name: str = pydantic.Field(..., description='')
    additional_bootstrap_servers: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='')
    consumer_group_id: typing.Optional[str] = pydantic.Field(None, description='')
    credentials: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_SelfManagedKafkaAccessConfigurationCredentialsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    server_root_ca_certificate: typing.Optional[str] = pydantic.Field(None, description='')
    starting_position: typing.Optional[str] = pydantic.Field(None, description='')
    vpc: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_SelfManagedKafkaAccessConfigurationVpcPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipesourcesqsqueueparameterspropertyParams(pydantic.BaseModel):
    batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='')
    maximum_batching_window_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargetbatchjobparameterspropertyParams(pydantic.BaseModel):
    job_definition: str = pydantic.Field(..., description='')
    job_name: str = pydantic.Field(..., description='')
    array_properties: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchArrayPropertiesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    container_overrides: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchContainerOverridesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    depends_on: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchJobDependencyPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    retry_strategy: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_BatchRetryStrategyPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargetcloudwatchlogsparameterspropertyParams(pydantic.BaseModel):
    log_stream_name: typing.Optional[str] = pydantic.Field(None, description='')
    timestamp: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargetecstaskparameterspropertyParams(pydantic.BaseModel):
    task_definition_arn: str = pydantic.Field(..., description='')
    capacity_provider_strategy: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_CapacityProviderStrategyItemPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    enable_ecs_managed_tags: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    enable_execute_command: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    group: typing.Optional[str] = pydantic.Field(None, description='')
    launch_type: typing.Optional[str] = pydantic.Field(None, description='')
    network_configuration: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_NetworkConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    overrides: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_EcsTaskOverridePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    placement_constraints: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PlacementConstraintPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    placement_strategy: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PlacementStrategyPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    platform_version: typing.Optional[str] = pydantic.Field(None, description='')
    propagate_tags: typing.Optional[str] = pydantic.Field(None, description='')
    reference_id: typing.Optional[str] = pydantic.Field(None, description='')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='')
    task_count: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargeteventbridgeeventbusparameterspropertyParams(pydantic.BaseModel):
    detail_type: typing.Optional[str] = pydantic.Field(None, description='')
    endpoint_id: typing.Optional[str] = pydantic.Field(None, description='')
    resources: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    source: typing.Optional[str] = pydantic.Field(None, description='')
    time: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargethttpparameterspropertyParams(pydantic.BaseModel):
    header_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    path_parameter_values: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    query_string_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargetkinesisstreamparameterspropertyParams(pydantic.BaseModel):
    partition_key: str = pydantic.Field(..., description='')
    ...

class CfnPipeDefPipetargetlambdafunctionparameterspropertyParams(pydantic.BaseModel):
    invocation_type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargetparameterspropertyParams(pydantic.BaseModel):
    batch_job_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetBatchJobParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    cloud_watch_logs_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetCloudWatchLogsParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ecs_task_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetEcsTaskParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    event_bridge_event_bus_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetEventBridgeEventBusParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    http_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetHttpParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    input_template: typing.Optional[str] = pydantic.Field(None, description='')
    kinesis_stream_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetKinesisStreamParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    lambda_function_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetLambdaFunctionParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    redshift_data_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetRedshiftDataParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    sage_maker_pipeline_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetSageMakerPipelineParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    sqs_queue_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetSqsQueueParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    step_function_state_machine_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetStateMachineParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    timestream_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetTimestreamParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargetredshiftdataparameterspropertyParams(pydantic.BaseModel):
    database: str = pydantic.Field(..., description='')
    sqls: typing.Sequence[str] = pydantic.Field(..., description='')
    db_user: typing.Optional[str] = pydantic.Field(None, description='')
    secret_manager_arn: typing.Optional[str] = pydantic.Field(None, description='')
    statement_name: typing.Optional[str] = pydantic.Field(None, description='')
    with_event: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargetsagemakerpipelineparameterspropertyParams(pydantic.BaseModel):
    pipeline_parameter_list: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_SageMakerPipelineParameterPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargetsqsqueueparameterspropertyParams(pydantic.BaseModel):
    message_deduplication_id: typing.Optional[str] = pydantic.Field(None, description='')
    message_group_id: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargetstatemachineparameterspropertyParams(pydantic.BaseModel):
    invocation_type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPipetargettimestreamparameterspropertyParams(pydantic.BaseModel):
    dimension_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_DimensionMappingPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    time_value: str = pydantic.Field(..., description='')
    version_value: str = pydantic.Field(..., description='')
    epoch_time_unit: typing.Optional[str] = pydantic.Field(None, description='')
    multi_measure_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_MultiMeasureMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    single_measure_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_SingleMeasureMappingPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    time_field_type: typing.Optional[str] = pydantic.Field(None, description='')
    timestamp_format: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPlacementconstraintpropertyParams(pydantic.BaseModel):
    expression: typing.Optional[str] = pydantic.Field(None, description='')
    type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefPlacementstrategypropertyParams(pydantic.BaseModel):
    field: typing.Optional[str] = pydantic.Field(None, description='')
    type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefS3LogdestinationpropertyParams(pydantic.BaseModel):
    bucket_name: typing.Optional[str] = pydantic.Field(None, description='')
    bucket_owner: typing.Optional[str] = pydantic.Field(None, description='')
    output_format: typing.Optional[str] = pydantic.Field(None, description='')
    prefix: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefSagemakerpipelineparameterpropertyParams(pydantic.BaseModel):
    name: str = pydantic.Field(..., description='')
    value: str = pydantic.Field(..., description='')
    ...

class CfnPipeDefSelfmanagedkafkaaccessconfigurationcredentialspropertyParams(pydantic.BaseModel):
    basic_auth: typing.Optional[str] = pydantic.Field(None, description='')
    client_certificate_tls_auth: typing.Optional[str] = pydantic.Field(None, description='')
    sasl_scram256_auth: typing.Optional[str] = pydantic.Field(None, description='')
    sasl_scram512_auth: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnPipeDefSelfmanagedkafkaaccessconfigurationvpcpropertyParams(pydantic.BaseModel):
    security_group: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    subnets: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnPipeDefSinglemeasuremappingpropertyParams(pydantic.BaseModel):
    measure_name: str = pydantic.Field(..., description='')
    measure_value: str = pydantic.Field(..., description='')
    measure_value_type: str = pydantic.Field(..., description='')
    ...

class CfnPipeDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnPipeDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnPipeDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnPipeDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnPipeDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnPipeDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnPipeDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnPipeDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnPipeDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnPipeDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnPipeDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnPipeDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnPipeDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnPipeDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_pipes.CfnPipeProps
class CfnPipePropsDef(BaseCfnProperty):
    role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the role that allows the pipe to send data to the target.\n')
    source: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the source resource.\n')
    target: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the target resource.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the pipe.\n')
    desired_state: typing.Optional[str] = pydantic.Field(None, description='The state the pipe should be in.\n')
    enrichment: typing.Optional[str] = pydantic.Field(None, description='The ARN of the enrichment resource.\n')
    enrichment_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeEnrichmentParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters required to set up enrichment on your pipe.\n')
    log_configuration: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeLogConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The logging configuration settings for the pipe.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the pipe.\n')
    source_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeSourceParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters required to set up a source for your pipe.\n')
    tags: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='The list of key-value pairs to associate with the pipe.\n')
    target_parameters: typing.Union[models.UnsupportedResource, models.aws_pipes.CfnPipe_PipeTargetParametersPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The parameters required to set up a target for your pipe. For more information about pipe target parameters, including how to use dynamic path parameters, see `Target parameters <https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-event-target.html>`_ in the *Amazon EventBridge User Guide* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-pipes-pipe.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_pipes as pipes\n\n    cfn_pipe_props = pipes.CfnPipeProps(\n        role_arn="roleArn",\n        source="source",\n        target="target",\n\n        # the properties below are optional\n        description="description",\n        desired_state="desiredState",\n        enrichment="enrichment",\n        enrichment_parameters=pipes.CfnPipe.PipeEnrichmentParametersProperty(\n            http_parameters=pipes.CfnPipe.PipeEnrichmentHttpParametersProperty(\n                header_parameters={\n                    "header_parameters_key": "headerParameters"\n                },\n                path_parameter_values=["pathParameterValues"],\n                query_string_parameters={\n                    "query_string_parameters_key": "queryStringParameters"\n                }\n            ),\n            input_template="inputTemplate"\n        ),\n        log_configuration=pipes.CfnPipe.PipeLogConfigurationProperty(\n            cloudwatch_logs_log_destination=pipes.CfnPipe.CloudwatchLogsLogDestinationProperty(\n                log_group_arn="logGroupArn"\n            ),\n            firehose_log_destination=pipes.CfnPipe.FirehoseLogDestinationProperty(\n                delivery_stream_arn="deliveryStreamArn"\n            ),\n            include_execution_data=["includeExecutionData"],\n            level="level",\n            s3_log_destination=pipes.CfnPipe.S3LogDestinationProperty(\n                bucket_name="bucketName",\n                bucket_owner="bucketOwner",\n                output_format="outputFormat",\n                prefix="prefix"\n            )\n        ),\n        name="name",\n        source_parameters=pipes.CfnPipe.PipeSourceParametersProperty(\n            active_mq_broker_parameters=pipes.CfnPipe.PipeSourceActiveMQBrokerParametersProperty(\n                credentials=pipes.CfnPipe.MQBrokerAccessCredentialsProperty(\n                    basic_auth="basicAuth"\n                ),\n                queue_name="queueName",\n\n                # the properties below are optional\n                batch_size=123,\n                maximum_batching_window_in_seconds=123\n            ),\n            dynamo_db_stream_parameters=pipes.CfnPipe.PipeSourceDynamoDBStreamParametersProperty(\n                starting_position="startingPosition",\n\n                # the properties below are optional\n                batch_size=123,\n                dead_letter_config=pipes.CfnPipe.DeadLetterConfigProperty(\n                    arn="arn"\n                ),\n                maximum_batching_window_in_seconds=123,\n                maximum_record_age_in_seconds=123,\n                maximum_retry_attempts=123,\n                on_partial_batch_item_failure="onPartialBatchItemFailure",\n                parallelization_factor=123\n            ),\n            filter_criteria=pipes.CfnPipe.FilterCriteriaProperty(\n                filters=[pipes.CfnPipe.FilterProperty(\n                    pattern="pattern"\n                )]\n            ),\n            kinesis_stream_parameters=pipes.CfnPipe.PipeSourceKinesisStreamParametersProperty(\n                starting_position="startingPosition",\n\n                # the properties below are optional\n                batch_size=123,\n                dead_letter_config=pipes.CfnPipe.DeadLetterConfigProperty(\n                    arn="arn"\n                ),\n                maximum_batching_window_in_seconds=123,\n                maximum_record_age_in_seconds=123,\n                maximum_retry_attempts=123,\n                on_partial_batch_item_failure="onPartialBatchItemFailure",\n                parallelization_factor=123,\n                starting_position_timestamp="startingPositionTimestamp"\n            ),\n            managed_streaming_kafka_parameters=pipes.CfnPipe.PipeSourceManagedStreamingKafkaParametersProperty(\n                topic_name="topicName",\n\n                # the properties below are optional\n                batch_size=123,\n                consumer_group_id="consumerGroupId",\n                credentials=pipes.CfnPipe.MSKAccessCredentialsProperty(\n                    client_certificate_tls_auth="clientCertificateTlsAuth",\n                    sasl_scram512_auth="saslScram512Auth"\n                ),\n                maximum_batching_window_in_seconds=123,\n                starting_position="startingPosition"\n            ),\n            rabbit_mq_broker_parameters=pipes.CfnPipe.PipeSourceRabbitMQBrokerParametersProperty(\n                credentials=pipes.CfnPipe.MQBrokerAccessCredentialsProperty(\n                    basic_auth="basicAuth"\n                ),\n                queue_name="queueName",\n\n                # the properties below are optional\n                batch_size=123,\n                maximum_batching_window_in_seconds=123,\n                virtual_host="virtualHost"\n            ),\n            self_managed_kafka_parameters=pipes.CfnPipe.PipeSourceSelfManagedKafkaParametersProperty(\n                topic_name="topicName",\n\n                # the properties below are optional\n                additional_bootstrap_servers=["additionalBootstrapServers"],\n                batch_size=123,\n                consumer_group_id="consumerGroupId",\n                credentials=pipes.CfnPipe.SelfManagedKafkaAccessConfigurationCredentialsProperty(\n                    basic_auth="basicAuth",\n                    client_certificate_tls_auth="clientCertificateTlsAuth",\n                    sasl_scram256_auth="saslScram256Auth",\n                    sasl_scram512_auth="saslScram512Auth"\n                ),\n                maximum_batching_window_in_seconds=123,\n                server_root_ca_certificate="serverRootCaCertificate",\n                starting_position="startingPosition",\n                vpc=pipes.CfnPipe.SelfManagedKafkaAccessConfigurationVpcProperty(\n                    security_group=["securityGroup"],\n                    subnets=["subnets"]\n                )\n            ),\n            sqs_queue_parameters=pipes.CfnPipe.PipeSourceSqsQueueParametersProperty(\n                batch_size=123,\n                maximum_batching_window_in_seconds=123\n            )\n        ),\n        tags={\n            "tags_key": "tags"\n        },\n        target_parameters=pipes.CfnPipe.PipeTargetParametersProperty(\n            batch_job_parameters=pipes.CfnPipe.PipeTargetBatchJobParametersProperty(\n                job_definition="jobDefinition",\n                job_name="jobName",\n\n                # the properties below are optional\n                array_properties=pipes.CfnPipe.BatchArrayPropertiesProperty(\n                    size=123\n                ),\n                container_overrides=pipes.CfnPipe.BatchContainerOverridesProperty(\n                    command=["command"],\n                    environment=[pipes.CfnPipe.BatchEnvironmentVariableProperty(\n                        name="name",\n                        value="value"\n                    )],\n                    instance_type="instanceType",\n                    resource_requirements=[pipes.CfnPipe.BatchResourceRequirementProperty(\n                        type="type",\n                        value="value"\n                    )]\n                ),\n                depends_on=[pipes.CfnPipe.BatchJobDependencyProperty(\n                    job_id="jobId",\n                    type="type"\n                )],\n                parameters={\n                    "parameters_key": "parameters"\n                },\n                retry_strategy=pipes.CfnPipe.BatchRetryStrategyProperty(\n                    attempts=123\n                )\n            ),\n            cloud_watch_logs_parameters=pipes.CfnPipe.PipeTargetCloudWatchLogsParametersProperty(\n                log_stream_name="logStreamName",\n                timestamp="timestamp"\n            ),\n            ecs_task_parameters=pipes.CfnPipe.PipeTargetEcsTaskParametersProperty(\n                task_definition_arn="taskDefinitionArn",\n\n                # the properties below are optional\n                capacity_provider_strategy=[pipes.CfnPipe.CapacityProviderStrategyItemProperty(\n                    capacity_provider="capacityProvider",\n\n                    # the properties below are optional\n                    base=123,\n                    weight=123\n                )],\n                enable_ecs_managed_tags=False,\n                enable_execute_command=False,\n                group="group",\n                launch_type="launchType",\n                network_configuration=pipes.CfnPipe.NetworkConfigurationProperty(\n                    awsvpc_configuration=pipes.CfnPipe.AwsVpcConfigurationProperty(\n                        subnets=["subnets"],\n\n                        # the properties below are optional\n                        assign_public_ip="assignPublicIp",\n                        security_groups=["securityGroups"]\n                    )\n                ),\n                overrides=pipes.CfnPipe.EcsTaskOverrideProperty(\n                    container_overrides=[pipes.CfnPipe.EcsContainerOverrideProperty(\n                        command=["command"],\n                        cpu=123,\n                        environment=[pipes.CfnPipe.EcsEnvironmentVariableProperty(\n                            name="name",\n                            value="value"\n                        )],\n                        environment_files=[pipes.CfnPipe.EcsEnvironmentFileProperty(\n                            type="type",\n                            value="value"\n                        )],\n                        memory=123,\n                        memory_reservation=123,\n                        name="name",\n                        resource_requirements=[pipes.CfnPipe.EcsResourceRequirementProperty(\n                            type="type",\n                            value="value"\n                        )]\n                    )],\n                    cpu="cpu",\n                    ephemeral_storage=pipes.CfnPipe.EcsEphemeralStorageProperty(\n                        size_in_gi_b=123\n                    ),\n                    execution_role_arn="executionRoleArn",\n                    inference_accelerator_overrides=[pipes.CfnPipe.EcsInferenceAcceleratorOverrideProperty(\n                        device_name="deviceName",\n                        device_type="deviceType"\n                    )],\n                    memory="memory",\n                    task_role_arn="taskRoleArn"\n                ),\n                placement_constraints=[pipes.CfnPipe.PlacementConstraintProperty(\n                    expression="expression",\n                    type="type"\n                )],\n                placement_strategy=[pipes.CfnPipe.PlacementStrategyProperty(\n                    field="field",\n                    type="type"\n                )],\n                platform_version="platformVersion",\n                propagate_tags="propagateTags",\n                reference_id="referenceId",\n                tags=[CfnTag(\n                    key="key",\n                    value="value"\n                )],\n                task_count=123\n            ),\n            event_bridge_event_bus_parameters=pipes.CfnPipe.PipeTargetEventBridgeEventBusParametersProperty(\n                detail_type="detailType",\n                endpoint_id="endpointId",\n                resources=["resources"],\n                source="source",\n                time="time"\n            ),\n            http_parameters=pipes.CfnPipe.PipeTargetHttpParametersProperty(\n                header_parameters={\n                    "header_parameters_key": "headerParameters"\n                },\n                path_parameter_values=["pathParameterValues"],\n                query_string_parameters={\n                    "query_string_parameters_key": "queryStringParameters"\n                }\n            ),\n            input_template="inputTemplate",\n            kinesis_stream_parameters=pipes.CfnPipe.PipeTargetKinesisStreamParametersProperty(\n                partition_key="partitionKey"\n            ),\n            lambda_function_parameters=pipes.CfnPipe.PipeTargetLambdaFunctionParametersProperty(\n                invocation_type="invocationType"\n            ),\n            redshift_data_parameters=pipes.CfnPipe.PipeTargetRedshiftDataParametersProperty(\n                database="database",\n                sqls=["sqls"],\n\n                # the properties below are optional\n                db_user="dbUser",\n                secret_manager_arn="secretManagerArn",\n                statement_name="statementName",\n                with_event=False\n            ),\n            sage_maker_pipeline_parameters=pipes.CfnPipe.PipeTargetSageMakerPipelineParametersProperty(\n                pipeline_parameter_list=[pipes.CfnPipe.SageMakerPipelineParameterProperty(\n                    name="name",\n                    value="value"\n                )]\n            ),\n            sqs_queue_parameters=pipes.CfnPipe.PipeTargetSqsQueueParametersProperty(\n                message_deduplication_id="messageDeduplicationId",\n                message_group_id="messageGroupId"\n            ),\n            step_function_state_machine_parameters=pipes.CfnPipe.PipeTargetStateMachineParametersProperty(\n                invocation_type="invocationType"\n            ),\n            timestream_parameters=pipes.CfnPipe.PipeTargetTimestreamParametersProperty(\n                dimension_mappings=[pipes.CfnPipe.DimensionMappingProperty(\n                    dimension_name="dimensionName",\n                    dimension_value="dimensionValue",\n                    dimension_value_type="dimensionValueType"\n                )],\n                time_value="timeValue",\n                version_value="versionValue",\n\n                # the properties below are optional\n                epoch_time_unit="epochTimeUnit",\n                multi_measure_mappings=[pipes.CfnPipe.MultiMeasureMappingProperty(\n                    multi_measure_attribute_mappings=[pipes.CfnPipe.MultiMeasureAttributeMappingProperty(\n                        measure_value="measureValue",\n                        measure_value_type="measureValueType",\n                        multi_measure_attribute_name="multiMeasureAttributeName"\n                    )],\n                    multi_measure_name="multiMeasureName"\n                )],\n                single_measure_mappings=[pipes.CfnPipe.SingleMeasureMappingProperty(\n                    measure_name="measureName",\n                    measure_value="measureValue",\n                    measure_value_type="measureValueType"\n                )],\n                time_field_type="timeFieldType",\n                timestamp_format="timestampFormat"\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['role_arn', 'source', 'target', 'description', 'desired_state', 'enrichment', 'enrichment_parameters', 'log_configuration', 'name', 'source_parameters', 'tags', 'target_parameters']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_pipes.CfnPipeProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




class ModuleModel(pydantic.BaseModel):
    CfnPipe_AwsVpcConfigurationProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_AwsVpcConfigurationPropertyDef]] = pydantic.Field(None)
    CfnPipe_BatchArrayPropertiesProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_BatchArrayPropertiesPropertyDef]] = pydantic.Field(None)
    CfnPipe_BatchContainerOverridesProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_BatchContainerOverridesPropertyDef]] = pydantic.Field(None)
    CfnPipe_BatchEnvironmentVariableProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_BatchEnvironmentVariablePropertyDef]] = pydantic.Field(None)
    CfnPipe_BatchJobDependencyProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_BatchJobDependencyPropertyDef]] = pydantic.Field(None)
    CfnPipe_BatchResourceRequirementProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_BatchResourceRequirementPropertyDef]] = pydantic.Field(None)
    CfnPipe_BatchRetryStrategyProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_BatchRetryStrategyPropertyDef]] = pydantic.Field(None)
    CfnPipe_CapacityProviderStrategyItemProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_CapacityProviderStrategyItemPropertyDef]] = pydantic.Field(None)
    CfnPipe_CloudwatchLogsLogDestinationProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_CloudwatchLogsLogDestinationPropertyDef]] = pydantic.Field(None)
    CfnPipe_DeadLetterConfigProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_DeadLetterConfigPropertyDef]] = pydantic.Field(None)
    CfnPipe_DimensionMappingProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_DimensionMappingPropertyDef]] = pydantic.Field(None)
    CfnPipe_EcsContainerOverrideProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_EcsContainerOverridePropertyDef]] = pydantic.Field(None)
    CfnPipe_EcsEnvironmentFileProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_EcsEnvironmentFilePropertyDef]] = pydantic.Field(None)
    CfnPipe_EcsEnvironmentVariableProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_EcsEnvironmentVariablePropertyDef]] = pydantic.Field(None)
    CfnPipe_EcsEphemeralStorageProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_EcsEphemeralStoragePropertyDef]] = pydantic.Field(None)
    CfnPipe_EcsInferenceAcceleratorOverrideProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_EcsInferenceAcceleratorOverridePropertyDef]] = pydantic.Field(None)
    CfnPipe_EcsResourceRequirementProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_EcsResourceRequirementPropertyDef]] = pydantic.Field(None)
    CfnPipe_EcsTaskOverrideProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_EcsTaskOverridePropertyDef]] = pydantic.Field(None)
    CfnPipe_FilterCriteriaProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_FilterCriteriaPropertyDef]] = pydantic.Field(None)
    CfnPipe_FilterProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_FilterPropertyDef]] = pydantic.Field(None)
    CfnPipe_FirehoseLogDestinationProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_FirehoseLogDestinationPropertyDef]] = pydantic.Field(None)
    CfnPipe_MQBrokerAccessCredentialsProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_MQBrokerAccessCredentialsPropertyDef]] = pydantic.Field(None)
    CfnPipe_MSKAccessCredentialsProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_MSKAccessCredentialsPropertyDef]] = pydantic.Field(None)
    CfnPipe_MultiMeasureAttributeMappingProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_MultiMeasureAttributeMappingPropertyDef]] = pydantic.Field(None)
    CfnPipe_MultiMeasureMappingProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_MultiMeasureMappingPropertyDef]] = pydantic.Field(None)
    CfnPipe_NetworkConfigurationProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_NetworkConfigurationPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeEnrichmentHttpParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeEnrichmentHttpParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeEnrichmentParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeEnrichmentParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeLogConfigurationProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeLogConfigurationPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeSourceActiveMQBrokerParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeSourceActiveMQBrokerParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeSourceDynamoDBStreamParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeSourceDynamoDBStreamParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeSourceKinesisStreamParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeSourceKinesisStreamParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeSourceManagedStreamingKafkaParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeSourceManagedStreamingKafkaParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeSourceParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeSourceParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeSourceRabbitMQBrokerParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeSourceRabbitMQBrokerParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeSourceSelfManagedKafkaParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeSourceSelfManagedKafkaParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeSourceSqsQueueParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeSourceSqsQueueParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetBatchJobParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetBatchJobParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetCloudWatchLogsParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetCloudWatchLogsParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetEcsTaskParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetEcsTaskParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetEventBridgeEventBusParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetEventBridgeEventBusParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetHttpParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetHttpParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetKinesisStreamParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetKinesisStreamParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetLambdaFunctionParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetLambdaFunctionParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetRedshiftDataParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetRedshiftDataParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetSageMakerPipelineParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetSageMakerPipelineParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetSqsQueueParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetSqsQueueParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetStateMachineParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetStateMachineParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PipeTargetTimestreamParametersProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PipeTargetTimestreamParametersPropertyDef]] = pydantic.Field(None)
    CfnPipe_PlacementConstraintProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PlacementConstraintPropertyDef]] = pydantic.Field(None)
    CfnPipe_PlacementStrategyProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_PlacementStrategyPropertyDef]] = pydantic.Field(None)
    CfnPipe_S3LogDestinationProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_S3LogDestinationPropertyDef]] = pydantic.Field(None)
    CfnPipe_SageMakerPipelineParameterProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_SageMakerPipelineParameterPropertyDef]] = pydantic.Field(None)
    CfnPipe_SelfManagedKafkaAccessConfigurationCredentialsProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_SelfManagedKafkaAccessConfigurationCredentialsPropertyDef]] = pydantic.Field(None)
    CfnPipe_SelfManagedKafkaAccessConfigurationVpcProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_SelfManagedKafkaAccessConfigurationVpcPropertyDef]] = pydantic.Field(None)
    CfnPipe_SingleMeasureMappingProperty: typing.Optional[dict[str, models.aws_pipes.CfnPipe_SingleMeasureMappingPropertyDef]] = pydantic.Field(None)
    CfnPipe: typing.Optional[dict[str, models.aws_pipes.CfnPipeDef]] = pydantic.Field(None)
    CfnPipeProps: typing.Optional[dict[str, models.aws_pipes.CfnPipePropsDef]] = pydantic.Field(None)
    ...

import models
