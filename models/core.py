from __future__ import annotations
import typing
import aws_cdk

import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.Annotations
class AnnotationsDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['acknowledge_warning', 'add_deprecation', 'add_error', 'add_info', 'add_warning', 'add_warning_v2']
    _classmethod_names: typing.ClassVar[list[str]] = ['of']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Annotations'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[AnnotationsDefConfig] = pydantic.Field(None)


class AnnotationsDefConfig(pydantic.BaseModel):
    acknowledge_warning: typing.Optional[list[AnnotationsDefAcknowledgeWarningParams]] = pydantic.Field(None, description='Acknowledge a warning. When a warning is acknowledged for a scope all warnings that match the id will be ignored.\nThe acknowledgement will apply to all child scopes')
    add_deprecation: typing.Optional[list[AnnotationsDefAddDeprecationParams]] = pydantic.Field(None, description='Adds a deprecation warning for a specific API.\nDeprecations will be added only once per construct as a warning and will be\ndeduplicated based on the ``api``.\n\nIf the environment variable ``CDK_BLOCK_DEPRECATIONS`` is set, this method\nwill throw an error instead with the deprecation message.')
    add_error: typing.Optional[list[AnnotationsDefAddErrorParams]] = pydantic.Field(None, description='Adds an { "error":  } metadata entry to this construct.\nThe toolkit will fail deployment of any stack that has errors reported against it.')
    add_info: typing.Optional[list[AnnotationsDefAddInfoParams]] = pydantic.Field(None, description='Adds an info metadata entry to this construct.\nThe CLI will display the info message when apps are synthesized.')
    add_warning: typing.Optional[list[AnnotationsDefAddWarningParams]] = pydantic.Field(None, description='Adds a warning metadata entry to this construct. Prefer using ``addWarningV2``.\nThe CLI will display the warning when an app is synthesized, or fail if run\nin ``--strict`` mode.\n\nWarnings added by this call cannot be acknowledged. This will block users from\nrunning in ``--strict`` mode until the deal with the warning, which makes it\neffectively not very different from ``addError``. Prefer using ``addWarningV2`` instead.')
    add_warning_v2: typing.Optional[list[AnnotationsDefAddWarningV2Params]] = pydantic.Field(None, description='Adds an acknowledgeable warning metadata entry to this construct.\nThe CLI will display the warning when an app is synthesized, or fail if run\nin ``--strict`` mode.\n\nIf the warning is acknowledged using ``acknowledgeWarning()``, it will not be shown by\nthe CLI, and will not cause ``--strict`` mode to fail synthesis.')
    of: typing.Optional[list[AnnotationsDefOfParams]] = pydantic.Field(None, description='Returns the annotations API for a construct scope.')

class AnnotationsDefAcknowledgeWarningParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='- the id of the warning message to acknowledge.\n')
    message: typing.Optional[str] = pydantic.Field(None, description='optional message to explain the reason for acknowledgement.\n\nExample::\n\n    # my_construct: Construct\n\n    Annotations.of(my_construct).acknowledge_warning("SomeWarningId", "This warning can be ignored because...")\n')
    ...

class AnnotationsDefAddDeprecationParams(pydantic.BaseModel):
    api: str = pydantic.Field(..., description='The API being deprecated in the format ``module.Class.property`` (e.g. ``@aws-cdk/core.Construct.node``).\n')
    message: str = pydantic.Field(..., description='The deprecation message to display, with information about alternatives.')
    ...

class AnnotationsDefAddErrorParams(pydantic.BaseModel):
    message: str = pydantic.Field(..., description='The error message.')
    ...

class AnnotationsDefAddInfoParams(pydantic.BaseModel):
    message: str = pydantic.Field(..., description='The info message.')
    ...

class AnnotationsDefAddWarningParams(pydantic.BaseModel):
    message: str = pydantic.Field(..., description='The warning message.')
    ...

class AnnotationsDefAddWarningV2Params(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='the unique identifier for the warning. This can be used to acknowledge the warning\n')
    message: str = pydantic.Field(..., description='The warning message.\n\nExample::\n\n    # my_construct: Construct\n\n    Annotations.of(my_construct).add_warning_v2("my-library:Construct.someWarning", "Some message explaining the warning")\n')
    ...

class AnnotationsDefOfParams(pydantic.BaseModel):
    scope: models.AnyResource = pydantic.Field(..., description='The scope.')
    return_config: typing.Optional[list[models.core.AnnotationsDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.App
class AppDef(BaseClass):
    analytics_reporting: typing.Optional[bool] = pydantic.Field(None, description="Include runtime versioning information in the Stacks of this app. Default: Value of 'aws:cdk:version-reporting' context key\n")
    auto_synth: typing.Optional[bool] = pydantic.Field(None, description="Automatically call ``synth()`` before the program exits. If you set this, you don't have to call ``synth()`` explicitly. Note that this feature is only available for certain programming languages, and calling ``synth()`` is still recommended. Default: true if running via CDK CLI (``CDK_OUTDIR`` is set), ``false`` otherwise\n")
    context: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Additional context values for the application. Context set by the CLI or the ``context`` key in ``cdk.json`` has precedence. Context can be read from any construct using ``node.getContext(key)``. Default: - no additional context\n')
    default_stack_synthesizer: typing.Optional[typing.Union[models.BootstraplessSynthesizerDef, models.CliCredentialsStackSynthesizerDef, models.DefaultStackSynthesizerDef, models.LegacyStackSynthesizerDef]] = pydantic.Field(None, description='The stack synthesizer to use by default for all Stacks in the App. The Stack Synthesizer controls aspects of synthesis and deployment, like how assets are referenced and what IAM roles to use. For more information, see the README of the main CDK package. Default: - A ``DefaultStackSynthesizer`` with default settings\n')
    outdir: typing.Optional[str] = pydantic.Field(None, description="The output directory into which to emit synthesized artifacts. You should never need to set this value. By default, the value you pass to the CLI's ``--output`` flag will be used, and if you change it to a different directory the CLI will fail to pick up the generated Cloud Assembly. This property is intended for internal and testing use. Default: - If this value is *not* set, considers the environment variable ``CDK_OUTDIR``. If ``CDK_OUTDIR`` is not defined, uses a temp directory.\n")
    policy_validation_beta1: typing.Optional[typing.Sequence[models.UnsupportedResource]] = pydantic.Field(None, description='Validation plugins to run after synthesis. Default: - no validation plugins\n')
    post_cli_context: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Additional context values for the application. Context provided here has precedence over context set by: - The CLI via --context - The ``context`` key in ``cdk.json`` - The ``AppProps.context`` property This property is recommended over the ``AppProps.context`` property since you can make final decision over which context value to take in your app. Context can be read from any construct using ``node.getContext(key)``. Default: - no additional context\n')
    stack_traces: typing.Optional[bool] = pydantic.Field(None, description='Include construct creation stack trace in the ``aws:cdk:trace`` metadata key of all constructs. Default: true stack traces are included unless ``aws:cdk:disable-stack-trace`` is set in the context.\n')
    tree_metadata: typing.Optional[bool] = pydantic.Field(None, description='Include construct tree metadata as part of the Cloud Assembly. Default: true')
    _init_params: typing.ClassVar[list[str]] = ['analytics_reporting', 'auto_synth', 'context', 'default_stack_synthesizer', 'outdir', 'policy_validation_beta1', 'post_cli_context', 'stack_traces', 'tree_metadata']
    _method_names: typing.ClassVar[list[str]] = ['synth']
    _classmethod_names: typing.ClassVar[list[str]] = ['of']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.App'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[AppDefConfig] = pydantic.Field(None)


class AppDefConfig(pydantic.BaseModel):
    of: typing.Optional[list[AppDefOfParams]] = pydantic.Field(None, description='Return the stage this construct is contained with, if available.\nIf called\non a nested stage, returns its parent.')
    synth: typing.Optional[list[AppDefSynthParams]] = pydantic.Field(None, description='Synthesize this stage into a cloud assembly.\nOnce an assembly has been synthesized, it cannot be modified. Subsequent\ncalls will return the same assembly.')

class AppDefOfParams(pydantic.BaseModel):
    construct_: models.AnyResource = pydantic.Field(..., description='-', alias='construct')
    ...

class AppDefSynthParams(pydantic.BaseModel):
    force: typing.Optional[bool] = pydantic.Field(None, description='Force a re-synth, even if the stage has already been synthesized. This is used by tests to allow for incremental verification of the output. Do not use in production. Default: false\n')
    skip_validation: typing.Optional[bool] = pydantic.Field(None, description='Should we skip construct validation. Default: - false\n')
    validate_on_synthesis: typing.Optional[bool] = pydantic.Field(None, description='Whether the stack should be validated after synthesis to check for error metadata. Default: - false')
    return_config: typing.Optional[list[models.cx_api.CloudAssemblyDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.Arn
class ArnDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['extract_resource_name', 'format', 'split']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Arn'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[ArnDefConfig] = pydantic.Field(None)


class ArnDefConfig(pydantic.BaseModel):
    extract_resource_name: typing.Optional[list[ArnDefExtractResourceNameParams]] = pydantic.Field(None, description="Extract the full resource name from an ARN.\nNecessary for resource names (paths) that may contain the separator, like\n``arn:aws:iam::111111111111:role/path/to/role/name``.\n\nOnly works if we statically know the expected ``resourceType`` beforehand, since we're going\nto use that to split the string on ':/' (and take the right-hand side).\n\nWe can't extract the 'resourceType' from the ARN at hand, because CloudFormation Expressions\nonly allow literals in the 'separator' argument to ``{ Fn::Split }``, and so it can't be\n``{ Fn::Select: [5, { Fn::Split: [':', ARN] }}``.\n\nOnly necessary for ARN formats for which the type-name separator is ``/``.")
    format: typing.Optional[list[ArnDefFormatParams]] = pydantic.Field(None, description="Creates an ARN from components.\nIf ``partition``, ``region`` or ``account`` are not specified, the stack's\npartition, region and account will be used.\n\nIf any component is the empty string, an empty string will be inserted\ninto the generated ARN at the location that component corresponds to.\n\nThe ARN will be formatted as follows:\n\narn:{partition}:{service}:{region}:{account}:{resource}{sep}{resource-name}\n\nThe required ARN pieces that are omitted will be taken from the stack that\nthe 'scope' is attached to. If all ARN pieces are supplied, the supplied scope\ncan be 'undefined'.")
    split: typing.Optional[list[ArnDefSplitParams]] = pydantic.Field(None, description="Splits the provided ARN into its components.\nWorks both if 'arn' is a string like 'arn:aws:s3:::bucket',\nand a Token representing a dynamic CloudFormation expression\n(in which case the returned components will also be dynamic CloudFormation expressions,\nencoded as Tokens).")

class ArnDefExtractResourceNameParams(pydantic.BaseModel):
    arn: str = pydantic.Field(..., description='-\n')
    resource_type: str = pydantic.Field(..., description='-')
    ...

class ArnDefFormatParams(pydantic.BaseModel):
    components: typing.Union[models.ArnComponentsDef, dict[str, typing.Any]] = pydantic.Field(..., description='-\n')
    stack: typing.Optional[models.StackDef] = pydantic.Field(None, description='-')
    ...

class ArnDefSplitParams(pydantic.BaseModel):
    arn: str = pydantic.Field(..., description='the ARN to split into its components.\n')
    arn_format: aws_cdk.ArnFormat = pydantic.Field(..., description="the expected format of 'arn' - depends on what format the service 'arn' represents uses.")
    ...


#  autogenerated from aws_cdk.Aspects
class AspectsDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['add']
    _classmethod_names: typing.ClassVar[list[str]] = ['of']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Aspects'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[AspectsDefConfig] = pydantic.Field(None)


class AspectsDefConfig(pydantic.BaseModel):
    add: typing.Optional[list[AspectsDefAddParams]] = pydantic.Field(None, description='Adds an aspect to apply this scope before synthesis.')
    of: typing.Optional[list[AspectsDefOfParams]] = pydantic.Field(None, description='Returns the ``Aspects`` object associated with a construct scope.')

class AspectsDefAddParams(pydantic.BaseModel):
    aspect: typing.Union[models.RemoveTagDef, models.TagDef, models.aws_autoscaling.AutoScalingGroupRequireImdsv2AspectDef, models.aws_ec2.InstanceRequireImdsv2AspectDef, models.aws_ec2.LaunchTemplateRequireImdsv2AspectDef, models.aws_lambda.FunctionVersionUpgradeDef] = pydantic.Field(..., description='The aspect to add.')
    ...

class AspectsDefOfParams(pydantic.BaseModel):
    scope: models.AnyResource = pydantic.Field(..., description='The scope for which these aspects will apply.')
    return_config: typing.Optional[list[models.core.AspectsDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.AssetManifestBuilder
class AssetManifestBuilderDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['add_docker_image_asset', 'add_file_asset', 'default_add_docker_image_asset', 'default_add_file_asset', 'emit_manifest']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.AssetManifestBuilder'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[AssetManifestBuilderDefConfig] = pydantic.Field(None)


class AssetManifestBuilderDefConfig(pydantic.BaseModel):
    add_docker_image_asset: typing.Optional[list[AssetManifestBuilderDefAddDockerImageAssetParams]] = pydantic.Field(None, description='Add a docker asset source and destination to the manifest.\nsourceHash should be unique for every source.')
    add_file_asset: typing.Optional[list[AssetManifestBuilderDefAddFileAssetParams]] = pydantic.Field(None, description='Add a file asset source and destination to the manifest.\nsourceHash should be unique for every source.')
    default_add_docker_image_asset: typing.Optional[list[AssetManifestBuilderDefDefaultAddDockerImageAssetParams]] = pydantic.Field(None, description='Add a docker image asset to the manifest with default settings.\nDerive the region from the stack, use the asset hash as the key, and set the prefix.')
    default_add_file_asset: typing.Optional[list[AssetManifestBuilderDefDefaultAddFileAssetParams]] = pydantic.Field(None, description='Add a file asset to the manifest with default settings.\nDerive the region from the stack, use the asset hash as the key, copy the\nfile extension over, and set the prefix.')
    emit_manifest: typing.Optional[list[AssetManifestBuilderDefEmitManifestParams]] = pydantic.Field(None, description='Write the manifest to disk, and add it to the synthesis session.\nReturn the artifact id, which should be added to the ``additionalDependencies``\nfield of the stack artifact.')

class AssetManifestBuilderDefAddDockerImageAssetParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-\n')
    source_hash: str = pydantic.Field(..., description='-\n')
    source: typing.Union[models.cloud_assembly_schema.DockerImageSourceDef, dict[str, typing.Any]] = pydantic.Field(..., description='-\n')
    image_tag: str = pydantic.Field(..., description='Tag of the image to publish.\n')
    repository_name: str = pydantic.Field(..., description='Name of the ECR repository to publish to.\n')
    assume_role_arn: typing.Optional[str] = pydantic.Field(None, description='The role that needs to be assumed while publishing this asset. Default: - No role will be assumed\n')
    assume_role_external_id: typing.Optional[str] = pydantic.Field(None, description='The ExternalId that needs to be supplied while assuming this role. Default: - No ExternalId will be supplied\n')
    region: typing.Optional[str] = pydantic.Field(None, description='The region where this asset will need to be published. Default: - Current region')
    ...

class AssetManifestBuilderDefAddFileAssetParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-\n')
    source_hash: str = pydantic.Field(..., description='-\n')
    source: typing.Union[models.cloud_assembly_schema.FileSourceDef, dict[str, typing.Any]] = pydantic.Field(..., description='-\n')
    bucket_name: str = pydantic.Field(..., description='The name of the bucket.\n')
    object_key: str = pydantic.Field(..., description='The destination object key.\n')
    assume_role_arn: typing.Optional[str] = pydantic.Field(None, description='The role that needs to be assumed while publishing this asset. Default: - No role will be assumed\n')
    assume_role_external_id: typing.Optional[str] = pydantic.Field(None, description='The ExternalId that needs to be supplied while assuming this role. Default: - No ExternalId will be supplied\n')
    region: typing.Optional[str] = pydantic.Field(None, description='The region where this asset will need to be published. Default: - Current region')
    ...

class AssetManifestBuilderDefDefaultAddDockerImageAssetParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-\n')
    asset: typing.Union[models.DockerImageAssetSourceDef, dict[str, typing.Any]] = pydantic.Field(..., description='-\n')
    repository_name: str = pydantic.Field(..., description='Repository name where the docker image asset should be written.\n')
    docker_tag_prefix: typing.Optional[str] = pydantic.Field(None, description="Prefix to add to the asset hash to make the Docker image tag. Default: ''\n")
    role: typing.Union[models.RoleOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Role to use to perform the upload. Default: - No role')
    ...

class AssetManifestBuilderDefDefaultAddFileAssetParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-\n')
    asset: typing.Union[models.FileAssetSourceDef, dict[str, typing.Any]] = pydantic.Field(..., description='-\n')
    bucket_name: str = pydantic.Field(..., description='Bucket name where the file asset should be written.\n')
    bucket_prefix: typing.Optional[str] = pydantic.Field(None, description="Prefix to prepend to the asset hash. Default: ''\n")
    role: typing.Union[models.RoleOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Role to use for uploading. Default: - current role')
    ...

class AssetManifestBuilderDefEmitManifestParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-\n')
    session: models.UnsupportedResource = pydantic.Field(..., description='-\n')
    options: typing.Union[models.cloud_assembly_schema.AssetManifestOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='-\n')
    dependencies: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='-')
    ...


#  autogenerated from aws_cdk.Aws
class AwsDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Aws'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.BootstraplessSynthesizer
class BootstraplessSynthesizerDef(BaseClass):
    cloud_formation_execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The CFN execution Role ARN to use. Default: - No CloudFormation role (use CLI credentials)')
    deploy_role_arn: typing.Optional[str] = pydantic.Field(None, description='The deploy Role ARN to use. Default: - No deploy role (use CLI credentials)')
    _init_params: typing.ClassVar[list[str]] = ['cloud_formation_execution_role_arn', 'deploy_role_arn']
    _method_names: typing.ClassVar[list[str]] = ['add_docker_image_asset', 'add_file_asset', 'bind', 'reusable_bind', 'synthesize']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.BootstraplessSynthesizer'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[BootstraplessSynthesizerDefConfig] = pydantic.Field(None)


class BootstraplessSynthesizerDefConfig(pydantic.BaseModel):
    add_docker_image_asset: typing.Optional[list[BootstraplessSynthesizerDefAddDockerImageAssetParams]] = pydantic.Field(None, description='Register a Docker Image Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    add_file_asset: typing.Optional[list[BootstraplessSynthesizerDefAddFileAssetParams]] = pydantic.Field(None, description='Register a File Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    bind: typing.Optional[list[BootstraplessSynthesizerDefBindParams]] = pydantic.Field(None, description='Bind to the stack this environment is going to be used on.\nMust be called before any of the other methods are called.')
    reusable_bind: typing.Optional[list[BootstraplessSynthesizerDefReusableBindParams]] = pydantic.Field(None, description='Produce a bound Stack Synthesizer for the given stack.\nThis method may be called more than once on the same object.')
    synthesize: typing.Optional[list[BootstraplessSynthesizerDefSynthesizeParams]] = pydantic.Field(None, description='Synthesize the associated stack to the session.')

class BootstraplessSynthesizerDefAddDockerImageAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description='The hash of the contents of the docker build context. This hash is used throughout the system to identify this image and avoid duplicate work in case the source did not change. NOTE: this means that if you wish to update your docker image, you must make a modification to the source (e.g. add some metadata to your Dockerfile).\n')
    asset_name: typing.Optional[str] = pydantic.Field(None, description='Unique identifier of the docker image asset and its potential revisions. Required if using AppScopedStagingSynthesizer. Default: - no asset name\n')
    directory_name: typing.Optional[str] = pydantic.Field(None, description='The directory where the Dockerfile is stored, must be relative to the cloud assembly root. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    docker_build_args: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build args to pass to the ``docker build`` command. Since Docker build arguments are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build args are passed\n')
    docker_build_secrets: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build secrets to pass to the ``docker build`` command. Since Docker build secrets are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build secrets are passed\n')
    docker_build_ssh: typing.Optional[str] = pydantic.Field(None, description='SSH agent socket or keys to pass to the ``docker buildx`` command. Default: - no ssh arg is passed\n')
    docker_build_target: typing.Optional[str] = pydantic.Field(None, description='Docker target to build to. Only allowed when ``directoryName`` is specified. Default: - no target\n')
    docker_cache_from: typing.Optional[typing.Sequence[typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Cache from options to pass to the ``docker build`` command. Default: - no cache from args are passed\n')
    docker_cache_to: typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Cache to options to pass to the ``docker build`` command. Default: - no cache to args are passed\n')
    docker_file: typing.Optional[str] = pydantic.Field(None, description='Path to the Dockerfile (relative to the directory). Only allowed when ``directoryName`` is specified. Default: - no file\n')
    docker_outputs: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Outputs to pass to the ``docker build`` command. Default: - no build args are passed\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the name of a local Docker image on ``stdout``. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    network_mode: typing.Optional[str] = pydantic.Field(None, description='Networking mode for the RUN commands during build. *Requires Docker Engine API v1.25+*. Specify this property to build images on a specific networking mode. Default: - no networking mode specified\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Platform to build for. *Requires Docker Buildx*. Specify this property to build images on a specific platform. Default: - no platform specified (the current machine architecture will be used)')
    ...

class BootstraplessSynthesizerDefAddFileAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description="A hash on the content source. This hash is used to uniquely identify this asset throughout the system. If this value doesn't change, the asset will not be rebuilt or republished.\n")
    deploy_time: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the asset needs to exist beyond deployment time; i.e. are copied over to a different location and not needed afterwards. Setting this property to true has an impact on the lifecycle of the asset, because we will assume that it is safe to delete after the CloudFormation deployment succeeds. For example, Lambda Function assets are copied over to Lambda during deployment. Therefore, it is not necessary to store the asset in S3, so we consider those deployTime assets. Default: false\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the location of a ZIP file on ``stdout``. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    file_name: typing.Optional[str] = pydantic.Field(None, description='The path, relative to the root of the cloud assembly, in which this asset source resides. This can be a path to a file or a directory, depending on the packaging type. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    packaging: typing.Optional[aws_cdk.FileAssetPackaging] = pydantic.Field(None, description='Which type of packaging to perform. Default: - Required if ``fileName`` is specified.')
    ...

class BootstraplessSynthesizerDefBindParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-')
    ...

class BootstraplessSynthesizerDefReusableBindParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models._interface_methods.CoreIBoundStackSynthesizerDefConfig]] = pydantic.Field(None)
    ...

class BootstraplessSynthesizerDefSynthesizeParams(pydantic.BaseModel):
    session: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.CfnDynamicReference
class CfnDynamicReferenceDef(BaseClass):
    service: typing.Union[aws_cdk.CfnDynamicReferenceService, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['service', 'key']
    _method_names: typing.ClassVar[list[str]] = ['resolve']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnDynamicReference'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnDynamicReferenceDefConfig] = pydantic.Field(None)


class CfnDynamicReferenceDefConfig(pydantic.BaseModel):
    resolve: typing.Optional[list[CfnDynamicReferenceDefResolveParams]] = pydantic.Field(None, description="Produce the Token's value at resolution time.")

class CfnDynamicReferenceDefResolveParams(pydantic.BaseModel):
    _context: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.CfnElement
class CfnElementDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['override_logical_id']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnElement'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnElementDefConfig] = pydantic.Field(None)


class CfnElementDefConfig(pydantic.BaseModel):
    override_logical_id: typing.Optional[list[CfnElementDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')

class CfnElementDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...


#  autogenerated from aws_cdk.CfnRefElement
class CfnRefElementDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['override_logical_id']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnRefElement'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnRefElementDefConfig] = pydantic.Field(None)


class CfnRefElementDefConfig(pydantic.BaseModel):
    override_logical_id: typing.Optional[list[CfnRefElementDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')

class CfnRefElementDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...


#  autogenerated from aws_cdk.CliCredentialsStackSynthesizer
class CliCredentialsStackSynthesizerDef(BaseClass):
    bucket_prefix: typing.Optional[str] = pydantic.Field(None, description='bucketPrefix to use while storing S3 Assets. Default: - DefaultStackSynthesizer.DEFAULT_FILE_ASSET_PREFIX')
    docker_tag_prefix: typing.Optional[str] = pydantic.Field(None, description='A prefix to use while tagging and uploading Docker images to ECR. This does not add any separators - the source hash will be appended to this string directly. Default: - DefaultStackSynthesizer.DEFAULT_DOCKER_ASSET_PREFIX\n')
    file_assets_bucket_name: typing.Optional[str] = pydantic.Field(None, description="Name of the S3 bucket to hold file assets. You must supply this if you have given a non-standard name to the staging bucket. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_FILE_ASSETS_BUCKET_NAME\n")
    image_assets_repository_name: typing.Optional[str] = pydantic.Field(None, description="Name of the ECR repository to hold Docker Image assets. You must supply this if you have given a non-standard name to the ECR repository. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_IMAGE_ASSETS_REPOSITORY_NAME\n")
    qualifier: typing.Optional[str] = pydantic.Field(None, description="Qualifier to disambiguate multiple environments in the same account. You can use this and leave the other naming properties empty if you have deployed the bootstrap environment with standard names but only different qualifiers. Default: - Value of context key '@aws-cdk/core:bootstrapQualifier' if set, otherwise ``DefaultStackSynthesizer.DEFAULT_QUALIFIER``")
    _init_params: typing.ClassVar[list[str]] = ['bucket_prefix', 'docker_tag_prefix', 'file_assets_bucket_name', 'image_assets_repository_name', 'qualifier']
    _method_names: typing.ClassVar[list[str]] = ['add_docker_image_asset', 'add_file_asset', 'bind', 'reusable_bind', 'synthesize']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CliCredentialsStackSynthesizer'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CliCredentialsStackSynthesizerDefConfig] = pydantic.Field(None)


class CliCredentialsStackSynthesizerDefConfig(pydantic.BaseModel):
    add_docker_image_asset: typing.Optional[list[CliCredentialsStackSynthesizerDefAddDockerImageAssetParams]] = pydantic.Field(None, description='Register a Docker Image Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    add_file_asset: typing.Optional[list[CliCredentialsStackSynthesizerDefAddFileAssetParams]] = pydantic.Field(None, description='Register a File Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    bind: typing.Optional[list[CliCredentialsStackSynthesizerDefBindParams]] = pydantic.Field(None, description='Bind to the stack this environment is going to be used on.\nMust be called before any of the other methods are called.')
    reusable_bind: typing.Optional[list[CliCredentialsStackSynthesizerDefReusableBindParams]] = pydantic.Field(None, description='Produce a bound Stack Synthesizer for the given stack.\nThis method may be called more than once on the same object.')
    synthesize: typing.Optional[list[CliCredentialsStackSynthesizerDefSynthesizeParams]] = pydantic.Field(None, description='Synthesize the associated stack to the session.')

class CliCredentialsStackSynthesizerDefAddDockerImageAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description='The hash of the contents of the docker build context. This hash is used throughout the system to identify this image and avoid duplicate work in case the source did not change. NOTE: this means that if you wish to update your docker image, you must make a modification to the source (e.g. add some metadata to your Dockerfile).\n')
    asset_name: typing.Optional[str] = pydantic.Field(None, description='Unique identifier of the docker image asset and its potential revisions. Required if using AppScopedStagingSynthesizer. Default: - no asset name\n')
    directory_name: typing.Optional[str] = pydantic.Field(None, description='The directory where the Dockerfile is stored, must be relative to the cloud assembly root. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    docker_build_args: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build args to pass to the ``docker build`` command. Since Docker build arguments are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build args are passed\n')
    docker_build_secrets: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build secrets to pass to the ``docker build`` command. Since Docker build secrets are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build secrets are passed\n')
    docker_build_ssh: typing.Optional[str] = pydantic.Field(None, description='SSH agent socket or keys to pass to the ``docker buildx`` command. Default: - no ssh arg is passed\n')
    docker_build_target: typing.Optional[str] = pydantic.Field(None, description='Docker target to build to. Only allowed when ``directoryName`` is specified. Default: - no target\n')
    docker_cache_from: typing.Optional[typing.Sequence[typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Cache from options to pass to the ``docker build`` command. Default: - no cache from args are passed\n')
    docker_cache_to: typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Cache to options to pass to the ``docker build`` command. Default: - no cache to args are passed\n')
    docker_file: typing.Optional[str] = pydantic.Field(None, description='Path to the Dockerfile (relative to the directory). Only allowed when ``directoryName`` is specified. Default: - no file\n')
    docker_outputs: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Outputs to pass to the ``docker build`` command. Default: - no build args are passed\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the name of a local Docker image on ``stdout``. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    network_mode: typing.Optional[str] = pydantic.Field(None, description='Networking mode for the RUN commands during build. *Requires Docker Engine API v1.25+*. Specify this property to build images on a specific networking mode. Default: - no networking mode specified\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Platform to build for. *Requires Docker Buildx*. Specify this property to build images on a specific platform. Default: - no platform specified (the current machine architecture will be used)')
    ...

class CliCredentialsStackSynthesizerDefAddFileAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description="A hash on the content source. This hash is used to uniquely identify this asset throughout the system. If this value doesn't change, the asset will not be rebuilt or republished.\n")
    deploy_time: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the asset needs to exist beyond deployment time; i.e. are copied over to a different location and not needed afterwards. Setting this property to true has an impact on the lifecycle of the asset, because we will assume that it is safe to delete after the CloudFormation deployment succeeds. For example, Lambda Function assets are copied over to Lambda during deployment. Therefore, it is not necessary to store the asset in S3, so we consider those deployTime assets. Default: false\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the location of a ZIP file on ``stdout``. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    file_name: typing.Optional[str] = pydantic.Field(None, description='The path, relative to the root of the cloud assembly, in which this asset source resides. This can be a path to a file or a directory, depending on the packaging type. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    packaging: typing.Optional[aws_cdk.FileAssetPackaging] = pydantic.Field(None, description='Which type of packaging to perform. Default: - Required if ``fileName`` is specified.')
    ...

class CliCredentialsStackSynthesizerDefBindParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-')
    ...

class CliCredentialsStackSynthesizerDefReusableBindParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models._interface_methods.CoreIBoundStackSynthesizerDefConfig]] = pydantic.Field(None)
    ...

class CliCredentialsStackSynthesizerDefSynthesizeParams(pydantic.BaseModel):
    session: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.ContextProvider
class ContextProviderDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['get_key', 'get_value']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.ContextProvider'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[ContextProviderDefConfig] = pydantic.Field(None)


class ContextProviderDefConfig(pydantic.BaseModel):
    get_key: typing.Optional[list[ContextProviderDefGetKeyParams]] = pydantic.Field(None, description='')
    get_value: typing.Optional[list[ContextProviderDefGetValueParams]] = pydantic.Field(None, description='')

class ContextProviderDefGetKeyParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-')
    provider: str = pydantic.Field(..., description='The context provider to query.\n')
    include_environment: typing.Optional[bool] = pydantic.Field(None, description="Whether to include the stack's account and region automatically. Default: true\n")
    props: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Provider-specific properties.\n')
    ...

class ContextProviderDefGetValueParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-')
    dummy_value: typing.Any = pydantic.Field(..., description='The value to return if the context value was not found and a missing context is reported. This should be a dummy value that should preferably fail during deployment since it represents an invalid state.\n')
    provider: str = pydantic.Field(..., description='The context provider to query.\n')
    include_environment: typing.Optional[bool] = pydantic.Field(None, description="Whether to include the stack's account and region automatically. Default: true\n")
    props: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Provider-specific properties.')
    ...


#  autogenerated from aws_cdk.DefaultStackSynthesizer
class DefaultStackSynthesizerDef(BaseClass):
    bootstrap_stack_version_ssm_parameter: typing.Optional[str] = pydantic.Field(None, description='Bootstrap stack version SSM parameter. The placeholder ``${Qualifier}`` will be replaced with the value of qualifier. Default: DefaultStackSynthesizer.DEFAULT_BOOTSTRAP_STACK_VERSION_SSM_PARAMETER')
    bucket_prefix: typing.Optional[str] = pydantic.Field(None, description='bucketPrefix to use while storing S3 Assets. Default: - DefaultStackSynthesizer.DEFAULT_FILE_ASSET_PREFIX\n')
    cloud_formation_execution_role: typing.Optional[str] = pydantic.Field(None, description="The role CloudFormation will assume when deploying the Stack. You must supply this if you have given a non-standard name to the execution role. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_CLOUDFORMATION_ROLE_ARN\n")
    deploy_role_arn: typing.Optional[str] = pydantic.Field(None, description="The role to assume to initiate a deployment in this environment. You must supply this if you have given a non-standard name to the publishing role. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_DEPLOY_ROLE_ARN\n")
    deploy_role_external_id: typing.Optional[str] = pydantic.Field(None, description='External ID to use when assuming role for cloudformation deployments. Default: - No external ID\n')
    docker_tag_prefix: typing.Optional[str] = pydantic.Field(None, description='A prefix to use while tagging and uploading Docker images to ECR. This does not add any separators - the source hash will be appended to this string directly. Default: - DefaultStackSynthesizer.DEFAULT_DOCKER_ASSET_PREFIX\n')
    file_asset_publishing_external_id: typing.Optional[str] = pydantic.Field(None, description='External ID to use when assuming role for file asset publishing. Default: - No external ID\n')
    file_asset_publishing_role_arn: typing.Optional[str] = pydantic.Field(None, description="The role to use to publish file assets to the S3 bucket in this environment. You must supply this if you have given a non-standard name to the publishing role. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_FILE_ASSET_PUBLISHING_ROLE_ARN\n")
    file_assets_bucket_name: typing.Optional[str] = pydantic.Field(None, description="Name of the S3 bucket to hold file assets. You must supply this if you have given a non-standard name to the staging bucket. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_FILE_ASSETS_BUCKET_NAME\n")
    generate_bootstrap_version_rule: typing.Optional[bool] = pydantic.Field(None, description='Whether to add a Rule to the stack template verifying the bootstrap stack version. This generally should be left set to ``true``, unless you explicitly want to be able to deploy to an unbootstrapped environment. Default: true\n')
    image_asset_publishing_external_id: typing.Optional[str] = pydantic.Field(None, description='External ID to use when assuming role for image asset publishing. Default: - No external ID\n')
    image_asset_publishing_role_arn: typing.Optional[str] = pydantic.Field(None, description="The role to use to publish image assets to the ECR repository in this environment. You must supply this if you have given a non-standard name to the publishing role. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_IMAGE_ASSET_PUBLISHING_ROLE_ARN\n")
    image_assets_repository_name: typing.Optional[str] = pydantic.Field(None, description="Name of the ECR repository to hold Docker Image assets. You must supply this if you have given a non-standard name to the ECR repository. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_IMAGE_ASSETS_REPOSITORY_NAME\n")
    lookup_role_arn: typing.Optional[str] = pydantic.Field(None, description='The role to use to look up values from the target AWS account during synthesis. Default: - None\n')
    lookup_role_external_id: typing.Optional[str] = pydantic.Field(None, description='External ID to use when assuming lookup role. Default: - No external ID\n')
    qualifier: typing.Optional[str] = pydantic.Field(None, description="Qualifier to disambiguate multiple environments in the same account. You can use this and leave the other naming properties empty if you have deployed the bootstrap environment with standard names but only different qualifiers. Default: - Value of context key '@aws-cdk/core:bootstrapQualifier' if set, otherwise ``DefaultStackSynthesizer.DEFAULT_QUALIFIER``\n")
    use_lookup_role_for_stack_operations: typing.Optional[bool] = pydantic.Field(None, description='Use the bootstrapped lookup role for (read-only) stack operations. Use the lookup role when performing a ``cdk diff``. If set to ``false``, the ``deploy role`` credentials will be used to perform a ``cdk diff``. Requires bootstrap stack version 8. Default: true')
    _init_params: typing.ClassVar[list[str]] = ['bootstrap_stack_version_ssm_parameter', 'bucket_prefix', 'cloud_formation_execution_role', 'deploy_role_arn', 'deploy_role_external_id', 'docker_tag_prefix', 'file_asset_publishing_external_id', 'file_asset_publishing_role_arn', 'file_assets_bucket_name', 'generate_bootstrap_version_rule', 'image_asset_publishing_external_id', 'image_asset_publishing_role_arn', 'image_assets_repository_name', 'lookup_role_arn', 'lookup_role_external_id', 'qualifier', 'use_lookup_role_for_stack_operations']
    _method_names: typing.ClassVar[list[str]] = ['add_docker_image_asset', 'add_file_asset', 'bind', 'reusable_bind', 'synthesize']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DefaultStackSynthesizer'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[DefaultStackSynthesizerDefConfig] = pydantic.Field(None)


class DefaultStackSynthesizerDefConfig(pydantic.BaseModel):
    add_docker_image_asset: typing.Optional[list[DefaultStackSynthesizerDefAddDockerImageAssetParams]] = pydantic.Field(None, description='Register a Docker Image Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    add_file_asset: typing.Optional[list[DefaultStackSynthesizerDefAddFileAssetParams]] = pydantic.Field(None, description='Register a File Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    bind: typing.Optional[list[DefaultStackSynthesizerDefBindParams]] = pydantic.Field(None, description='Bind to the stack this environment is going to be used on.\nMust be called before any of the other methods are called.')
    reusable_bind: typing.Optional[list[DefaultStackSynthesizerDefReusableBindParams]] = pydantic.Field(None, description='Produce a bound Stack Synthesizer for the given stack.\nThis method may be called more than once on the same object.')
    synthesize: typing.Optional[list[DefaultStackSynthesizerDefSynthesizeParams]] = pydantic.Field(None, description='Synthesize the associated stack to the session.')

class DefaultStackSynthesizerDefAddDockerImageAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description='The hash of the contents of the docker build context. This hash is used throughout the system to identify this image and avoid duplicate work in case the source did not change. NOTE: this means that if you wish to update your docker image, you must make a modification to the source (e.g. add some metadata to your Dockerfile).\n')
    asset_name: typing.Optional[str] = pydantic.Field(None, description='Unique identifier of the docker image asset and its potential revisions. Required if using AppScopedStagingSynthesizer. Default: - no asset name\n')
    directory_name: typing.Optional[str] = pydantic.Field(None, description='The directory where the Dockerfile is stored, must be relative to the cloud assembly root. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    docker_build_args: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build args to pass to the ``docker build`` command. Since Docker build arguments are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build args are passed\n')
    docker_build_secrets: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build secrets to pass to the ``docker build`` command. Since Docker build secrets are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build secrets are passed\n')
    docker_build_ssh: typing.Optional[str] = pydantic.Field(None, description='SSH agent socket or keys to pass to the ``docker buildx`` command. Default: - no ssh arg is passed\n')
    docker_build_target: typing.Optional[str] = pydantic.Field(None, description='Docker target to build to. Only allowed when ``directoryName`` is specified. Default: - no target\n')
    docker_cache_from: typing.Optional[typing.Sequence[typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Cache from options to pass to the ``docker build`` command. Default: - no cache from args are passed\n')
    docker_cache_to: typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Cache to options to pass to the ``docker build`` command. Default: - no cache to args are passed\n')
    docker_file: typing.Optional[str] = pydantic.Field(None, description='Path to the Dockerfile (relative to the directory). Only allowed when ``directoryName`` is specified. Default: - no file\n')
    docker_outputs: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Outputs to pass to the ``docker build`` command. Default: - no build args are passed\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the name of a local Docker image on ``stdout``. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    network_mode: typing.Optional[str] = pydantic.Field(None, description='Networking mode for the RUN commands during build. *Requires Docker Engine API v1.25+*. Specify this property to build images on a specific networking mode. Default: - no networking mode specified\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Platform to build for. *Requires Docker Buildx*. Specify this property to build images on a specific platform. Default: - no platform specified (the current machine architecture will be used)')
    ...

class DefaultStackSynthesizerDefAddFileAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description="A hash on the content source. This hash is used to uniquely identify this asset throughout the system. If this value doesn't change, the asset will not be rebuilt or republished.\n")
    deploy_time: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the asset needs to exist beyond deployment time; i.e. are copied over to a different location and not needed afterwards. Setting this property to true has an impact on the lifecycle of the asset, because we will assume that it is safe to delete after the CloudFormation deployment succeeds. For example, Lambda Function assets are copied over to Lambda during deployment. Therefore, it is not necessary to store the asset in S3, so we consider those deployTime assets. Default: false\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the location of a ZIP file on ``stdout``. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    file_name: typing.Optional[str] = pydantic.Field(None, description='The path, relative to the root of the cloud assembly, in which this asset source resides. This can be a path to a file or a directory, depending on the packaging type. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    packaging: typing.Optional[aws_cdk.FileAssetPackaging] = pydantic.Field(None, description='Which type of packaging to perform. Default: - Required if ``fileName`` is specified.')
    ...

class DefaultStackSynthesizerDefBindParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-')
    ...

class DefaultStackSynthesizerDefReusableBindParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models._interface_methods.CoreIBoundStackSynthesizerDefConfig]] = pydantic.Field(None)
    ...

class DefaultStackSynthesizerDefSynthesizeParams(pydantic.BaseModel):
    session: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.DefaultTokenResolver
class DefaultTokenResolverDef(BaseClass):
    concat: typing.Union[_REQUIRED_INIT_PARAM, models.StringConcatDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['concat']
    _method_names: typing.ClassVar[list[str]] = ['resolve_list', 'resolve_string', 'resolve_token']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DefaultTokenResolver'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[DefaultTokenResolverDefConfig] = pydantic.Field(None)


class DefaultTokenResolverDefConfig(pydantic.BaseModel):
    resolve_list: typing.Optional[list[DefaultTokenResolverDefResolveListParams]] = pydantic.Field(None, description='Resolve a tokenized list.')
    resolve_string: typing.Optional[list[DefaultTokenResolverDefResolveStringParams]] = pydantic.Field(None, description='Resolve string fragments to Tokens.')
    resolve_token: typing.Optional[list[DefaultTokenResolverDefResolveTokenParams]] = pydantic.Field(None, description='Default Token resolution.\nResolve the Token, recurse into whatever it returns,\nthen finally post-process it.')

class DefaultTokenResolverDefResolveListParams(pydantic.BaseModel):
    xs: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    context: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...

class DefaultTokenResolverDefResolveStringParams(pydantic.BaseModel):
    fragments: models.TokenizedStringFragmentsDef = pydantic.Field(..., description='-\n')
    context: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...

class DefaultTokenResolverDefResolveTokenParams(pydantic.BaseModel):
    t: models.UnsupportedResource = pydantic.Field(..., description='-\n')
    context: models.UnsupportedResource = pydantic.Field(..., description='-\n')
    post_processor: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.DockerBuildSecret
class DockerBuildSecretDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['from_src']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DockerBuildSecret'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_src']
    ...


    from_src: typing.Optional[DockerBuildSecretDefFromSrcParams] = pydantic.Field(None, description='A Docker build secret from a file source.')

class DockerBuildSecretDefFromSrcParams(pydantic.BaseModel):
    src: str = pydantic.Field(..., description='The path to the source file, relative to the build directory.\n')
    ...


#  autogenerated from aws_cdk.DockerIgnoreStrategy
class DockerIgnoreStrategyDef(BaseClass):
    absolute_root_path: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    patterns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['absolute_root_path', 'patterns']
    _method_names: typing.ClassVar[list[str]] = ['add', 'ignores']
    _classmethod_names: typing.ClassVar[list[str]] = ['docker', 'from_copy_options', 'git', 'glob']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DockerIgnoreStrategy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_copy_options']
    ...


    from_copy_options: typing.Optional[DockerIgnoreStrategyDefFromCopyOptionsParams] = pydantic.Field(None, description='Creates an IgnoreStrategy based on the ``ignoreMode`` and ``exclude`` in a ``CopyOptions``.')
    resource_config: typing.Optional[DockerIgnoreStrategyDefConfig] = pydantic.Field(None)


class DockerIgnoreStrategyDefConfig(pydantic.BaseModel):
    add: typing.Optional[list[DockerIgnoreStrategyDefAddParams]] = pydantic.Field(None, description='Adds another pattern.')
    docker: typing.Optional[list[DockerIgnoreStrategyDefDockerParams]] = pydantic.Field(None, description='Ignores file paths based on the ```.dockerignore specification`` <https://docs.docker.com/engine/reference/builder/#dockerignore-file>`_.')
    git: typing.Optional[list[DockerIgnoreStrategyDefGitParams]] = pydantic.Field(None, description='Ignores file paths based on the ```.gitignore specification`` <https://git-scm.com/docs/gitignore>`_.')
    glob: typing.Optional[list[DockerIgnoreStrategyDefGlobParams]] = pydantic.Field(None, description='Ignores file paths based on simple glob patterns.')
    ignores: typing.Optional[list[DockerIgnoreStrategyDefIgnoresParams]] = pydantic.Field(None, description='Determines whether a given file path should be ignored or not.')

class DockerIgnoreStrategyDefAddParams(pydantic.BaseModel):
    pattern: str = pydantic.Field(..., description='-\n')
    ...

class DockerIgnoreStrategyDefDockerParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.DockerIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class DockerIgnoreStrategyDefFromCopyOptionsParams(pydantic.BaseModel):
    options: typing.Union[models.CopyOptionsDef, dict[str, typing.Any]] = pydantic.Field(..., description='the ``CopyOptions`` to create the ``IgnoreStrategy`` from.\n')
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    ...

class DockerIgnoreStrategyDefGitParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.GitIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class DockerIgnoreStrategyDefGlobParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.GlobIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class DockerIgnoreStrategyDefIgnoresParams(pydantic.BaseModel):
    absolute_file_path: str = pydantic.Field(..., description='absolute file path to be assessed against the pattern.\n')
    ...


#  autogenerated from aws_cdk.DockerImage
class DockerImageDef(BaseClass):
    image: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Docker image.')
    _image_hash: typing.Optional[str] = pydantic.Field(None, description='-')
    _init_params: typing.ClassVar[list[str]] = ['image', '_image_hash']
    _method_names: typing.ClassVar[list[str]] = ['cp', 'run']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_build', 'from_registry']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DockerImage'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_build', 'from_registry']
    ...


    from_build: typing.Optional[DockerImageDefFromBuildParams] = pydantic.Field(None, description='Builds a Docker image.')
    from_registry: typing.Optional[DockerImageDefFromRegistryParams] = pydantic.Field(None, description='Reference an image on DockerHub or another online registry.')
    resource_config: typing.Optional[DockerImageDefConfig] = pydantic.Field(None)


class DockerImageDefConfig(pydantic.BaseModel):
    cp: typing.Optional[list[DockerImageDefCpParams]] = pydantic.Field(None, description='Copies a file or directory out of the Docker image to the local filesystem.\nIf ``outputPath`` is omitted the destination path is a temporary directory.')
    run: typing.Optional[list[DockerImageDefRunParams]] = pydantic.Field(None, description='Runs a Docker image.')

class DockerImageDefCpParams(pydantic.BaseModel):
    image_path: str = pydantic.Field(..., description='the path in the Docker image.\n')
    output_path: typing.Optional[str] = pydantic.Field(None, description='the destination path for the copy operation.\n')
    ...

class DockerImageDefFromBuildParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path to the directory containing the Docker file.\n')
    build_args: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build args. Default: - no build args\n')
    cache_from: typing.Optional[typing.Sequence[typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Cache from options to pass to the ``docker build`` command. Default: - no cache from args are passed\n')
    cache_to: typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Cache to options to pass to the ``docker build`` command. Default: - no cache to args are passed\n')
    file: typing.Optional[str] = pydantic.Field(None, description='Name of the Dockerfile, must relative to the docker build path. Default: ``Dockerfile``\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Set platform if server is multi-platform capable. *Requires Docker Engine API v1.38+*. Example value: ``linux/amd64`` Default: - no platform specified\n')
    target_stage: typing.Optional[str] = pydantic.Field(None, description='Set build target for multi-stage container builds. Any stage defined afterwards will be ignored. Example value: ``build-env`` Default: - Build all stages defined in the Dockerfile')
    ...

class DockerImageDefFromRegistryParams(pydantic.BaseModel):
    image: str = pydantic.Field(..., description='the image name.')
    ...

class DockerImageDefRunParams(pydantic.BaseModel):
    command: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The command to run in the container. Default: - run the command defined in the image\n')
    entrypoint: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The entrypoint to run in the container. Default: - run the entrypoint defined in the image\n')
    environment: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='The environment variables to pass to the container. Default: - no environment variables.\n')
    network: typing.Optional[str] = pydantic.Field(None, description='Docker `Networking options <https://docs.docker.com/engine/reference/commandline/run/#connect-a-container-to-a-network---network>`_. Default: - no networking options\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Set platform if server is multi-platform capable. *Requires Docker Engine API v1.38+*. Example value: ``linux/amd64`` Default: - no platform specified\n')
    security_opt: typing.Optional[str] = pydantic.Field(None, description='`Security configuration <https://docs.docker.com/engine/reference/run/#security-configuration>`_ when running the docker container. Default: - no security options\n')
    user: typing.Optional[str] = pydantic.Field(None, description='The user to use when running the container. Default: - root or image default\n')
    volumes: typing.Optional[typing.Sequence[typing.Union[models.DockerVolumeDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Docker volumes to mount. Default: - no volumes are mounted\n')
    volumes_from: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Where to mount the specified volumes from. Default: - no containers are specified to mount volumes from\n')
    working_directory: typing.Optional[str] = pydantic.Field(None, description='Working directory inside the container. Default: - image default')
    ...


#  autogenerated from aws_cdk.Duration
class DurationDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['format_token_to_number', 'minus', 'plus', 'unit_label']
    _classmethod_names: typing.ClassVar[list[str]] = ['days', 'hours', 'millis', 'minutes', 'parse', 'seconds']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Duration'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[DurationDefConfig] = pydantic.Field(None)


class DurationDefConfig(pydantic.BaseModel):
    days: typing.Optional[list[DurationDefDaysParams]] = pydantic.Field(None, description='Create a Duration representing an amount of days.')
    format_token_to_number: typing.Optional[bool] = pydantic.Field(None, description='Returns stringified number of duration.')
    hours: typing.Optional[list[DurationDefHoursParams]] = pydantic.Field(None, description='Create a Duration representing an amount of hours.')
    millis: typing.Optional[list[DurationDefMillisParams]] = pydantic.Field(None, description='Create a Duration representing an amount of milliseconds.')
    minus: typing.Optional[list[DurationDefMinusParams]] = pydantic.Field(None, description='Substract two Durations together.')
    minutes: typing.Optional[list[DurationDefMinutesParams]] = pydantic.Field(None, description='Create a Duration representing an amount of minutes.')
    parse: typing.Optional[list[DurationDefParseParams]] = pydantic.Field(None, description='Parse a period formatted according to the ISO 8601 standard.')
    plus: typing.Optional[list[DurationDefPlusParams]] = pydantic.Field(None, description='Add two Durations together.')
    seconds: typing.Optional[list[DurationDefSecondsParams]] = pydantic.Field(None, description='Create a Duration representing an amount of seconds.')
    unit_label: typing.Optional[bool] = pydantic.Field(None, description='Returns unit of the duration.')

class DurationDefDaysParams(pydantic.BaseModel):
    amount: typing.Union[int, float] = pydantic.Field(..., description='the amount of Days the ``Duration`` will represent.\n')
    return_config: typing.Optional[list[models.core.DurationDefConfig]] = pydantic.Field(None)
    ...

class DurationDefHoursParams(pydantic.BaseModel):
    amount: typing.Union[int, float] = pydantic.Field(..., description='the amount of Hours the ``Duration`` will represent.\n')
    return_config: typing.Optional[list[models.core.DurationDefConfig]] = pydantic.Field(None)
    ...

class DurationDefMillisParams(pydantic.BaseModel):
    amount: typing.Union[int, float] = pydantic.Field(..., description='the amount of Milliseconds the ``Duration`` will represent.\n')
    return_config: typing.Optional[list[models.core.DurationDefConfig]] = pydantic.Field(None)
    ...

class DurationDefMinusParams(pydantic.BaseModel):
    rhs: models.DurationDef = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.core.DurationDefConfig]] = pydantic.Field(None)
    ...

class DurationDefMinutesParams(pydantic.BaseModel):
    amount: typing.Union[int, float] = pydantic.Field(..., description='the amount of Minutes the ``Duration`` will represent.\n')
    return_config: typing.Optional[list[models.core.DurationDefConfig]] = pydantic.Field(None)
    ...

class DurationDefParseParams(pydantic.BaseModel):
    duration: str = pydantic.Field(..., description='an ISO-formatted duration to be parsed.\n')
    return_config: typing.Optional[list[models.core.DurationDefConfig]] = pydantic.Field(None)
    ...

class DurationDefPlusParams(pydantic.BaseModel):
    rhs: models.DurationDef = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.core.DurationDefConfig]] = pydantic.Field(None)
    ...

class DurationDefSecondsParams(pydantic.BaseModel):
    amount: typing.Union[int, float] = pydantic.Field(..., description='the amount of Seconds the ``Duration`` will represent.\n')
    return_config: typing.Optional[list[models.core.DurationDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.Expiration
class ExpirationDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['after', 'at_date', 'at_timestamp', 'from_string']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Expiration'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_string']
    ...


    from_string: typing.Optional[ExpirationDefFromStringParams] = pydantic.Field(None, description='Expire at specified date, represented as a string.')
    resource_config: typing.Optional[ExpirationDefConfig] = pydantic.Field(None)


class ExpirationDefConfig(pydantic.BaseModel):
    after: typing.Optional[list[ExpirationDefAfterParams]] = pydantic.Field(None, description='Expire once the specified duration has passed since deployment time.')
    at_date: typing.Optional[list[ExpirationDefAtDateParams]] = pydantic.Field(None, description='Expire at the specified date.')
    at_timestamp: typing.Optional[list[ExpirationDefAtTimestampParams]] = pydantic.Field(None, description='Expire at the specified timestamp.')

class ExpirationDefAfterParams(pydantic.BaseModel):
    t: models.DurationDef = pydantic.Field(..., description='the duration to wait before expiring.')
    return_config: typing.Optional[list[models.core.ExpirationDefConfig]] = pydantic.Field(None)
    ...

class ExpirationDefAtDateParams(pydantic.BaseModel):
    d: datetime.datetime = pydantic.Field(..., description='date to expire at.')
    return_config: typing.Optional[list[models.core.ExpirationDefConfig]] = pydantic.Field(None)
    ...

class ExpirationDefAtTimestampParams(pydantic.BaseModel):
    t: typing.Union[int, float] = pydantic.Field(..., description='timestamp in unix milliseconds.')
    return_config: typing.Optional[list[models.core.ExpirationDefConfig]] = pydantic.Field(None)
    ...

class ExpirationDefFromStringParams(pydantic.BaseModel):
    s: str = pydantic.Field(..., description='the string that represents date to expire at.')
    ...


#  autogenerated from aws_cdk.FeatureFlags
class FeatureFlagsDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['of']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.FeatureFlags'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[FeatureFlagsDefConfig] = pydantic.Field(None)


class FeatureFlagsDefConfig(pydantic.BaseModel):
    of: typing.Optional[list[FeatureFlagsDefOfParams]] = pydantic.Field(None, description="Inspect feature flags on the construct node's context.")

class FeatureFlagsDefOfParams(pydantic.BaseModel):
    scope: models.AnyResource = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.core.FeatureFlagsDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.FileSystem
class FileSystemDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['copy_directory', 'fingerprint', 'mkdtemp']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.FileSystem'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[FileSystemDefConfig] = pydantic.Field(None)


class FileSystemDefConfig(pydantic.BaseModel):
    copy_directory: typing.Optional[list[FileSystemDefCopyDirectoryParams]] = pydantic.Field(None, description='Copies an entire directory structure.')
    fingerprint: typing.Optional[list[FileSystemDefFingerprintParams]] = pydantic.Field(None, description='Produces fingerprint based on the contents of a single file or an entire directory tree.\nLine endings are converted from CRLF to LF.\n\nThe fingerprint will also include:\n\n1. An extra string if defined in ``options.extra``.\n2. The symlink follow mode value.')
    mkdtemp: typing.Optional[list[FileSystemDefMkdtempParams]] = pydantic.Field(None, description='Creates a unique temporary directory in the **system temp directory**.')

class FileSystemDefCopyDirectoryParams(pydantic.BaseModel):
    src_dir: str = pydantic.Field(..., description='Source directory.\n')
    dest_dir: str = pydantic.Field(..., description='Destination directory.\n')
    options: typing.Union[models.CopyOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='options.\n')
    root_dir: typing.Optional[str] = pydantic.Field(None, description='Root directory to calculate exclusions from.')
    ...

class FileSystemDefFingerprintParams(pydantic.BaseModel):
    file_or_directory: str = pydantic.Field(..., description='The directory or file to fingerprint.\n')
    extra_hash: typing.Optional[str] = pydantic.Field(None, description='Extra information to encode into the fingerprint (e.g. build instructions and other inputs). Default: - hash is only based on source content\n')
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='File paths matching the patterns will be excluded. See ``ignoreMode`` to set the matching behavior. Has no effect on Assets bundled using the ``bundling`` property. Default: - nothing is excluded\n')
    follow: typing.Optional[aws_cdk.SymlinkFollowMode] = pydantic.Field(None, description='A strategy for how to handle symlinks. Default: SymlinkFollowMode.NEVER\n')
    ignore_mode: typing.Optional[aws_cdk.IgnoreMode] = pydantic.Field(None, description='The ignore behavior to use for ``exclude`` patterns. Default: IgnoreMode.GLOB')
    ...

class FileSystemDefMkdtempParams(pydantic.BaseModel):
    prefix: str = pydantic.Field(..., description='A prefix for the directory name. Six random characters will be generated and appended behind this prefix.')
    ...


#  autogenerated from aws_cdk.Fn
class FnDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['base64', 'cidr', 'condition_and', 'condition_contains', 'condition_each_member_equals', 'condition_each_member_in', 'condition_equals', 'condition_if', 'condition_not', 'condition_or', 'find_in_map', 'get_att', 'get_azs', 'import_list_value', 'import_value', 'join', 'len', 'parse_domain_name', 'ref', 'ref_all', 'select', 'split', 'sub', 'transform', 'value_of', 'value_of_all']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Fn'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['condition_and', 'condition_contains', 'condition_each_member_equals', 'condition_each_member_in', 'condition_equals', 'condition_if', 'condition_not', 'condition_or', 'get_att', 'transform']
    ...


    condition_and: typing.Optional[FnDefConditionAndParams] = pydantic.Field(None, description='Returns true if all the specified conditions evaluate to true, or returns false if any one of the conditions evaluates to false.\n``Fn::And`` acts as\nan AND operator. The minimum number of conditions that you can include is\n1.')
    condition_contains: typing.Optional[FnDefConditionContainsParams] = pydantic.Field(None, description='Returns true if a specified string matches at least one value in a list of strings.')
    condition_each_member_equals: typing.Optional[FnDefConditionEachMemberEqualsParams] = pydantic.Field(None, description='Returns true if a specified string matches all values in a list.')
    condition_each_member_in: typing.Optional[FnDefConditionEachMemberInParams] = pydantic.Field(None, description='Returns true if each member in a list of strings matches at least one value in a second list of strings.')
    condition_equals: typing.Optional[FnDefConditionEqualsParams] = pydantic.Field(None, description="Compares if two values are equal.\nReturns true if the two values are equal\nor false if they aren't.")
    condition_if: typing.Optional[FnDefConditionIfParams] = pydantic.Field(None, description='Returns one value if the specified condition evaluates to true and another value if the specified condition evaluates to false.\nCurrently, AWS\nCloudFormation supports the ``Fn::If`` intrinsic function in the metadata\nattribute, update policy attribute, and property values in the Resources\nsection and Outputs sections of a template. You can use the AWS::NoValue\npseudo parameter as a return value to remove the corresponding property.')
    condition_not: typing.Optional[FnDefConditionNotParams] = pydantic.Field(None, description='Returns true for a condition that evaluates to false or returns false for a condition that evaluates to true.\n``Fn::Not`` acts as a NOT operator.')
    condition_or: typing.Optional[FnDefConditionOrParams] = pydantic.Field(None, description='Returns true if any one of the specified conditions evaluate to true, or returns false if all of the conditions evaluates to false.\n``Fn::Or`` acts\nas an OR operator. The minimum number of conditions that you can include is\n1.')
    get_att: typing.Optional[FnDefGetAttParams] = pydantic.Field(None, description='The ``Fn::GetAtt`` intrinsic function returns the value of an attribute from a resource in the template.')
    transform: typing.Optional[FnDefTransformParams] = pydantic.Field(None, description='Creates a token representing the ``Fn::Transform`` expression.')
    resource_config: typing.Optional[FnDefConfig] = pydantic.Field(None)


class FnDefConfig(pydantic.BaseModel):
    base64: typing.Optional[list[FnDefBase64Params]] = pydantic.Field(None, description='The intrinsic function ``Fn::Base64`` returns the Base64 representation of the input string.\nThis function is typically used to pass encoded data to\nAmazon EC2 instances by way of the UserData property.')
    cidr: typing.Optional[list[FnDefCidrParams]] = pydantic.Field(None, description='The intrinsic function ``Fn::Cidr`` returns the specified Cidr address block.')
    find_in_map: typing.Optional[list[FnDefFindInMapParams]] = pydantic.Field(None, description='The intrinsic function ``Fn::FindInMap`` returns the value corresponding to keys in a two-level map that is declared in the Mappings section.\nWarning: do not use with lazy mappings as this function will not guarentee a lazy mapping to render in the template.\nPrefer to use ``CfnMapping.findInMap`` in general.')
    get_azs: typing.Optional[list[FnDefGetAzsParams]] = pydantic.Field(None, description="The intrinsic function ``Fn::GetAZs`` returns an array that lists Availability Zones for a specified region.\nBecause customers have access to\ndifferent Availability Zones, the intrinsic function ``Fn::GetAZs`` enables\ntemplate authors to write templates that adapt to the calling user's\naccess. That way you don't have to hard-code a full list of Availability\nZones for a specified region.")
    import_list_value: typing.Optional[list[FnDefImportListValueParams]] = pydantic.Field(None, description="Like ``Fn.importValue``, but import a list with a known length.\nIf you explicitly want a list with an unknown length, call ``Fn.split(',', Fn.importValue(exportName))``. See the documentation of ``Fn.split`` to read\nmore about the limitations of using lists of unknown length.\n\n``Fn.importListValue(exportName, assumedLength)`` is the same as\n``Fn.split(',', Fn.importValue(exportName), assumedLength)``,\nbut easier to read and impossible to forget to pass ``assumedLength``.")
    import_value: typing.Optional[list[FnDefImportValueParams]] = pydantic.Field(None, description='The intrinsic function ``Fn::ImportValue`` returns the value of an output exported by another stack.\nYou typically use this function to create\ncross-stack references. In the following example template snippets, Stack A\nexports VPC security group values and Stack B imports them.')
    join: typing.Optional[list[FnDefJoinParams]] = pydantic.Field(None, description='The intrinsic function ``Fn::Join`` appends a set of values into a single value, separated by the specified delimiter.\nIf a delimiter is the empty\nstring, the set of values are concatenated with no delimiter.')
    len: typing.Optional[list[FnDefLenParams]] = pydantic.Field(None, description='The intrinsic function ``Fn::Length`` returns the number of elements within an array or an intrinsic function that returns an array.')
    parse_domain_name: typing.Optional[list[FnDefParseDomainNameParams]] = pydantic.Field(None, description='Given an url, parse the domain name.')
    ref: typing.Optional[list[FnDefRefParams]] = pydantic.Field(None, description="The ``Ref`` intrinsic function returns the value of the specified parameter or resource.\nNote that it doesn't validate the logicalName, it mainly serves parameter/resource reference defined in a ``CfnInclude`` template.")
    ref_all: typing.Optional[list[FnDefRefAllParams]] = pydantic.Field(None, description='Returns all values for a specified parameter type.')
    select: typing.Optional[list[FnDefSelectParams]] = pydantic.Field(None, description='The intrinsic function ``Fn::Select`` returns a single object from a list of objects by index.')
    split: typing.Optional[list[FnDefSplitParams]] = pydantic.Field(None, description='Split a string token into a token list of string values.\nSpecify the location of splits with a delimiter such as \',\' (a comma).\nRenders to the ``Fn::Split`` intrinsic function.\n\n\nLists with unknown lengths (default)\n\nSince this function is used to work with deploy-time values, if ``assumedLength``\nis not given the CDK cannot know the length of the resulting list at synthesis time.\nThis brings the following restrictions:\n\n- You must use ``Fn.select(i, list)`` to pick elements out of the list (you must not use\n  ``list[i]``).\n- You cannot add elements to the list, remove elements from the list,\n  combine two such lists together, or take a slice of the list.\n- You cannot pass the list to constructs that do any of the above.\n\nThe only valid operation with such a tokenized list is to pass it unmodified to a\nCloudFormation Resource construct.\n\n\nLists with assumed lengths\n\nPass ``assumedLength`` if you know the length of the list that will be\nproduced by splitting. The actual list length at deploy time may be\n*longer* than the number you pass, but not *shorter*.\n\nThe returned list will look like::\n\n   [Fn.select(0, split), Fn.select(1, split), Fn.select(2, split), ...]\n\nThe restrictions from the section "Lists with unknown lengths" will now be lifted,\nat the expense of having to know and fix the length of the list.')
    sub: typing.Optional[list[FnDefSubParams]] = pydantic.Field(None, description="The intrinsic function ``Fn::Sub`` substitutes variables in an input string with values that you specify.\nIn your templates, you can use this function\nto construct commands or outputs that include values that aren't available\nuntil you create or update a stack.")
    value_of: typing.Optional[list[FnDefValueOfParams]] = pydantic.Field(None, description='Returns an attribute value or list of values for a specific parameter and attribute.')
    value_of_all: typing.Optional[list[FnDefValueOfAllParams]] = pydantic.Field(None, description='Returns a list of all attribute values for a given parameter type and attribute.')

class FnDefBase64Params(pydantic.BaseModel):
    data: str = pydantic.Field(..., description='The string value you want to convert to Base64.\n')
    ...

class FnDefCidrParams(pydantic.BaseModel):
    ip_block: str = pydantic.Field(..., description='The user-specified default Cidr address block.\n')
    count: typing.Union[int, float] = pydantic.Field(..., description="The number of subnets' Cidr block wanted. Count can be 1 to 256.\n")
    size_mask: typing.Optional[str] = pydantic.Field(None, description='The digit covered in the subnet.\n')
    ...

class FnDefConditionAndParams(pydantic.BaseModel):
    conditions: list[typing.Union[models.CfnConditionDef]] = pydantic.Field(...)
    ...

class FnDefConditionContainsParams(pydantic.BaseModel):
    list_of_strings: typing.Sequence[str] = pydantic.Field(..., description='A list of strings, such as "A", "B", "C".\n')
    value: str = pydantic.Field(..., description='A string, such as "A", that you want to compare against a list of strings.\n')
    ...

class FnDefConditionEachMemberEqualsParams(pydantic.BaseModel):
    list_of_strings: typing.Sequence[str] = pydantic.Field(..., description='A list of strings, such as "A", "B", "C".\n')
    value: str = pydantic.Field(..., description='A string, such as "A", that you want to compare against a list of strings.\n')
    ...

class FnDefConditionEachMemberInParams(pydantic.BaseModel):
    strings_to_check: typing.Sequence[str] = pydantic.Field(..., description='A list of strings, such as "A", "B", "C". AWS CloudFormation checks whether each member in the strings_to_check parameter is in the strings_to_match parameter.\n')
    strings_to_match: typing.Sequence[str] = pydantic.Field(..., description='A list of strings, such as "A", "B", "C". Each member in the strings_to_match parameter is compared against the members of the strings_to_check parameter.\n')
    ...

class FnDefConditionEqualsParams(pydantic.BaseModel):
    lhs: typing.Any = pydantic.Field(..., description='A value of any type that you want to compare.\n')
    rhs: typing.Any = pydantic.Field(..., description='A value of any type that you want to compare.\n')
    ...

class FnDefConditionIfParams(pydantic.BaseModel):
    condition_id: str = pydantic.Field(..., description="A reference to a condition in the Conditions section. Use the condition's name to reference it.\n")
    value_if_true: typing.Any = pydantic.Field(..., description='A value to be returned if the specified condition evaluates to true.\n')
    value_if_false: typing.Any = pydantic.Field(..., description='A value to be returned if the specified condition evaluates to false.\n')
    ...

class FnDefConditionNotParams(pydantic.BaseModel):
    condition: typing.Union[models.CfnConditionDef] = pydantic.Field(..., description='A condition such as ``Fn::Equals`` that evaluates to true or false.\n')
    ...

class FnDefConditionOrParams(pydantic.BaseModel):
    conditions: list[typing.Union[models.CfnConditionDef]] = pydantic.Field(...)
    ...

class FnDefFindInMapParams(pydantic.BaseModel):
    map_name: str = pydantic.Field(..., description='-\n')
    top_level_key: str = pydantic.Field(..., description='-\n')
    second_level_key: str = pydantic.Field(..., description='-\n')
    default_value: typing.Optional[str] = pydantic.Field(None, description='-\n')
    ...

class FnDefGetAttParams(pydantic.BaseModel):
    logical_name_of_resource: str = pydantic.Field(..., description='The logical name (also called logical ID) of the resource that contains the attribute that you want.\n')
    attribute_name: str = pydantic.Field(..., description="The name of the resource-specific attribute whose value you want. See the resource's reference page for details about the attributes available for that resource type.\n")
    ...

class FnDefGetAzsParams(pydantic.BaseModel):
    region: typing.Optional[str] = pydantic.Field(None, description='The name of the region for which you want to get the Availability Zones. You can use the AWS::Region pseudo parameter to specify the region in which the stack is created. Specifying an empty string is equivalent to specifying AWS::Region.\n')
    ...

class FnDefImportListValueParams(pydantic.BaseModel):
    shared_value_to_import: str = pydantic.Field(..., description='-\n')
    assumed_length: typing.Union[int, float] = pydantic.Field(..., description='-\n')
    delimiter: typing.Optional[str] = pydantic.Field(None, description='-')
    ...

class FnDefImportValueParams(pydantic.BaseModel):
    shared_value_to_import: str = pydantic.Field(..., description='The stack output value that you want to import.\n')
    ...

class FnDefJoinParams(pydantic.BaseModel):
    delimiter: str = pydantic.Field(..., description='The value you want to occur between fragments. The delimiter will occur between fragments only. It will not terminate the final value.\n')
    list_of_values: typing.Sequence[str] = pydantic.Field(..., description='The list of values you want combined.\n')
    ...

class FnDefLenParams(pydantic.BaseModel):
    array: typing.Any = pydantic.Field(..., description='The array you want to return the number of elements from.')
    ...

class FnDefParseDomainNameParams(pydantic.BaseModel):
    url: str = pydantic.Field(..., description='the url to parse.')
    ...

class FnDefRefParams(pydantic.BaseModel):
    logical_name: str = pydantic.Field(..., description='The logical name of a parameter/resource for which you want to retrieve its value.')
    ...

class FnDefRefAllParams(pydantic.BaseModel):
    parameter_type: str = pydantic.Field(..., description='An AWS-specific parameter type, such as AWS::EC2::SecurityGroup::Id or AWS::EC2::VPC::Id. For more information, see Parameters in the AWS CloudFormation User Guide.\n')
    ...

class FnDefSelectParams(pydantic.BaseModel):
    index: typing.Union[int, float] = pydantic.Field(..., description='The index of the object to retrieve. This must be a value from zero to N-1, where N represents the number of elements in the array.\n')
    array: typing.Sequence[str] = pydantic.Field(..., description='The list of objects to select from. This list must not be null, nor can it have null entries.\n')
    ...

class FnDefSplitParams(pydantic.BaseModel):
    delimiter: str = pydantic.Field(..., description='A string value that determines where the source string is divided.\n')
    source: str = pydantic.Field(..., description='The string value that you want to split.\n')
    assumed_length: typing.Union[int, float, None] = pydantic.Field(None, description='The length of the list that will be produced by splitting.\n')
    ...

class FnDefSubParams(pydantic.BaseModel):
    body: str = pydantic.Field(..., description="A string with variables that AWS CloudFormation substitutes with their associated values at runtime. Write variables as ${MyVarName}. Variables can be template parameter names, resource logical IDs, resource attributes, or a variable in a key-value map. If you specify only template parameter names, resource logical IDs, and resource attributes, don't specify a key-value map.\n")
    variables: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='The name of a variable that you included in the String parameter. The value that AWS CloudFormation substitutes for the associated variable name at runtime.\n')
    ...

class FnDefTransformParams(pydantic.BaseModel):
    macro_name: str = pydantic.Field(..., description='The name of the macro to perform the processing.\n')
    parameters: typing.Mapping[str, typing.Any] = pydantic.Field(..., description='The parameters to be passed to the macro.\n')
    ...

class FnDefValueOfParams(pydantic.BaseModel):
    parameter_or_logical_id: str = pydantic.Field(..., description='The name of a parameter for which you want to retrieve attribute values. The parameter must be declared in the Parameters section of the template.\n')
    attribute: str = pydantic.Field(..., description='The name of an attribute from which you want to retrieve a value.\n')
    ...

class FnDefValueOfAllParams(pydantic.BaseModel):
    parameter_type: str = pydantic.Field(..., description='An AWS-specific parameter type, such as AWS::EC2::SecurityGroup::Id or AWS::EC2::VPC::Id. For more information, see Parameters in the AWS CloudFormation User Guide.\n')
    attribute: str = pydantic.Field(..., description='The name of an attribute from which you want to retrieve a value. For more information about attributes, see Supported Attributes.\n')
    ...


#  autogenerated from aws_cdk.GitIgnoreStrategy
class GitIgnoreStrategyDef(BaseClass):
    absolute_root_path: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    patterns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['absolute_root_path', 'patterns']
    _method_names: typing.ClassVar[list[str]] = ['add', 'ignores']
    _classmethod_names: typing.ClassVar[list[str]] = ['docker', 'from_copy_options', 'git', 'glob']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.GitIgnoreStrategy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_copy_options']
    ...


    from_copy_options: typing.Optional[GitIgnoreStrategyDefFromCopyOptionsParams] = pydantic.Field(None, description='Creates an IgnoreStrategy based on the ``ignoreMode`` and ``exclude`` in a ``CopyOptions``.')
    resource_config: typing.Optional[GitIgnoreStrategyDefConfig] = pydantic.Field(None)


class GitIgnoreStrategyDefConfig(pydantic.BaseModel):
    add: typing.Optional[list[GitIgnoreStrategyDefAddParams]] = pydantic.Field(None, description='Adds another pattern.')
    docker: typing.Optional[list[GitIgnoreStrategyDefDockerParams]] = pydantic.Field(None, description='Ignores file paths based on the ```.dockerignore specification`` <https://docs.docker.com/engine/reference/builder/#dockerignore-file>`_.')
    git: typing.Optional[list[GitIgnoreStrategyDefGitParams]] = pydantic.Field(None, description='Ignores file paths based on the ```.gitignore specification`` <https://git-scm.com/docs/gitignore>`_.')
    glob: typing.Optional[list[GitIgnoreStrategyDefGlobParams]] = pydantic.Field(None, description='Ignores file paths based on simple glob patterns.')
    ignores: typing.Optional[list[GitIgnoreStrategyDefIgnoresParams]] = pydantic.Field(None, description='Determines whether a given file path should be ignored or not.')

class GitIgnoreStrategyDefAddParams(pydantic.BaseModel):
    pattern: str = pydantic.Field(..., description='-\n')
    ...

class GitIgnoreStrategyDefDockerParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.DockerIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class GitIgnoreStrategyDefFromCopyOptionsParams(pydantic.BaseModel):
    options: typing.Union[models.CopyOptionsDef, dict[str, typing.Any]] = pydantic.Field(..., description='the ``CopyOptions`` to create the ``IgnoreStrategy`` from.\n')
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    ...

class GitIgnoreStrategyDefGitParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.GitIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class GitIgnoreStrategyDefGlobParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.GlobIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class GitIgnoreStrategyDefIgnoresParams(pydantic.BaseModel):
    absolute_file_path: str = pydantic.Field(..., description='absolute file path to be assessed against the pattern.\n')
    ...


#  autogenerated from aws_cdk.GlobIgnoreStrategy
class GlobIgnoreStrategyDef(BaseClass):
    absolute_root_path: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    patterns: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['absolute_root_path', 'patterns']
    _method_names: typing.ClassVar[list[str]] = ['add', 'ignores']
    _classmethod_names: typing.ClassVar[list[str]] = ['docker', 'from_copy_options', 'git', 'glob']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.GlobIgnoreStrategy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_copy_options']
    ...


    from_copy_options: typing.Optional[GlobIgnoreStrategyDefFromCopyOptionsParams] = pydantic.Field(None, description='Creates an IgnoreStrategy based on the ``ignoreMode`` and ``exclude`` in a ``CopyOptions``.')
    resource_config: typing.Optional[GlobIgnoreStrategyDefConfig] = pydantic.Field(None)


class GlobIgnoreStrategyDefConfig(pydantic.BaseModel):
    add: typing.Optional[list[GlobIgnoreStrategyDefAddParams]] = pydantic.Field(None, description='Adds another pattern.')
    docker: typing.Optional[list[GlobIgnoreStrategyDefDockerParams]] = pydantic.Field(None, description='Ignores file paths based on the ```.dockerignore specification`` <https://docs.docker.com/engine/reference/builder/#dockerignore-file>`_.')
    git: typing.Optional[list[GlobIgnoreStrategyDefGitParams]] = pydantic.Field(None, description='Ignores file paths based on the ```.gitignore specification`` <https://git-scm.com/docs/gitignore>`_.')
    glob: typing.Optional[list[GlobIgnoreStrategyDefGlobParams]] = pydantic.Field(None, description='Ignores file paths based on simple glob patterns.')
    ignores: typing.Optional[list[GlobIgnoreStrategyDefIgnoresParams]] = pydantic.Field(None, description='Determines whether a given file path should be ignored or not.')

class GlobIgnoreStrategyDefAddParams(pydantic.BaseModel):
    pattern: str = pydantic.Field(..., description='-\n')
    ...

class GlobIgnoreStrategyDefDockerParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.DockerIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class GlobIgnoreStrategyDefFromCopyOptionsParams(pydantic.BaseModel):
    options: typing.Union[models.CopyOptionsDef, dict[str, typing.Any]] = pydantic.Field(..., description='the ``CopyOptions`` to create the ``IgnoreStrategy`` from.\n')
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    ...

class GlobIgnoreStrategyDefGitParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.GitIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class GlobIgnoreStrategyDefGlobParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.GlobIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class GlobIgnoreStrategyDefIgnoresParams(pydantic.BaseModel):
    absolute_file_path: str = pydantic.Field(..., description='absolute file path to be assessed against the pattern.\n')
    ...


#  autogenerated from aws_cdk.IgnoreStrategy
class IgnoreStrategyDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['add', 'ignores']
    _classmethod_names: typing.ClassVar[list[str]] = ['docker', 'from_copy_options', 'git', 'glob']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.IgnoreStrategy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_copy_options']
    ...


    from_copy_options: typing.Optional[IgnoreStrategyDefFromCopyOptionsParams] = pydantic.Field(None, description='Creates an IgnoreStrategy based on the ``ignoreMode`` and ``exclude`` in a ``CopyOptions``.')
    resource_config: typing.Optional[IgnoreStrategyDefConfig] = pydantic.Field(None)


class IgnoreStrategyDefConfig(pydantic.BaseModel):
    add: typing.Optional[list[IgnoreStrategyDefAddParams]] = pydantic.Field(None, description='Adds another pattern.')
    docker: typing.Optional[list[IgnoreStrategyDefDockerParams]] = pydantic.Field(None, description='Ignores file paths based on the ```.dockerignore specification`` <https://docs.docker.com/engine/reference/builder/#dockerignore-file>`_.')
    git: typing.Optional[list[IgnoreStrategyDefGitParams]] = pydantic.Field(None, description='Ignores file paths based on the ```.gitignore specification`` <https://git-scm.com/docs/gitignore>`_.')
    glob: typing.Optional[list[IgnoreStrategyDefGlobParams]] = pydantic.Field(None, description='Ignores file paths based on simple glob patterns.')
    ignores: typing.Optional[list[IgnoreStrategyDefIgnoresParams]] = pydantic.Field(None, description='Determines whether a given file path should be ignored or not.')

class IgnoreStrategyDefAddParams(pydantic.BaseModel):
    pattern: str = pydantic.Field(..., description='-\n')
    ...

class IgnoreStrategyDefDockerParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.DockerIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class IgnoreStrategyDefFromCopyOptionsParams(pydantic.BaseModel):
    options: typing.Union[models.CopyOptionsDef, dict[str, typing.Any]] = pydantic.Field(..., description='the ``CopyOptions`` to create the ``IgnoreStrategy`` from.\n')
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    ...

class IgnoreStrategyDefGitParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.GitIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class IgnoreStrategyDefGlobParams(pydantic.BaseModel):
    absolute_root_path: str = pydantic.Field(..., description='the absolute path to the root directory of the paths to be considered.\n')
    patterns: typing.Sequence[str] = pydantic.Field(..., description='-\n')
    return_config: typing.Optional[list[models.core.GlobIgnoreStrategyDefConfig]] = pydantic.Field(None)
    ...

class IgnoreStrategyDefIgnoresParams(pydantic.BaseModel):
    absolute_file_path: str = pydantic.Field(..., description='absolute file path to be assessed against the pattern.\n')
    ...


#  autogenerated from aws_cdk.Intrinsic
class IntrinsicDef(BaseClass):
    value: typing.Union[typing.Any, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    stack_trace: typing.Optional[bool] = pydantic.Field(None, description='Capture the stack trace of where this token is created. Default: true\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='Type that this token is expected to evaluate to. Default: ResolutionTypeHint.STRING')
    _init_params: typing.ClassVar[list[str]] = ['value', 'stack_trace', 'type_hint']
    _method_names: typing.ClassVar[list[str]] = ['resolve']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Intrinsic'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[IntrinsicDefConfig] = pydantic.Field(None)


class IntrinsicDefConfig(pydantic.BaseModel):
    resolve: typing.Optional[list[IntrinsicDefResolveParams]] = pydantic.Field(None, description="Produce the Token's value at resolution time.")

class IntrinsicDefResolveParams(pydantic.BaseModel):
    _context: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.JsonNull
class JsonNullDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['resolve']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.JsonNull'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[JsonNullDefConfig] = pydantic.Field(None)


class JsonNullDefConfig(pydantic.BaseModel):
    resolve: typing.Optional[list[JsonNullDefResolveParams]] = pydantic.Field(None, description="Produce the Token's value at resolution time.")

class JsonNullDefResolveParams(pydantic.BaseModel):
    _ctx: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.Lazy
class LazyDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['any', 'list', 'number', 'string', 'uncached_any', 'uncached_list', 'uncached_number', 'uncached_string']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Lazy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['any', 'uncached_any']
    ...


    any: typing.Optional[LazyDefAnyParams] = pydantic.Field(None, description='Defer the one-time calculation of an arbitrarily typed value to synthesis time.\nUse this if you want to render an object to a template whose actual value depends on\nsome state mutation that may happen after the construct has been created.\n\nThe inner function will only be invoked one time and cannot depend on\nresolution context.')
    uncached_any: typing.Optional[LazyDefUncachedAnyParams] = pydantic.Field(None, description="Defer the calculation of an untyped value to synthesis time.\nUse of this function is not recommended; unless you know you need it for sure, you\nprobably don't. Use ``Lazy.any()`` instead.\n\nThe inner function may be invoked multiple times during synthesis. You\nshould only use this method if the returned value depends on variables\nthat may change during the Aspect application phase of synthesis, or if\nthe value depends on the Stack the value is being used in. Both of these\ncases are rare, and only ever occur for AWS Construct Library authors.")
    resource_config: typing.Optional[LazyDefConfig] = pydantic.Field(None)


class LazyDefConfig(pydantic.BaseModel):
    list: typing.Optional[list[LazyDefListParams]] = pydantic.Field(None, description="Defer the one-time calculation of a list value to synthesis time.\nUse this if you want to render a list to a template whose actual value depends on\nsome state mutation that may happen after the construct has been created.\n\nIf you are simply looking to force a value to a ``string[]`` type and don't need\nthe calculation to be deferred, use ``Token.asList()`` instead.\n\nThe inner function will only be invoked once, and the resolved value\ncannot depend on the Stack the Token is used in.")
    number: typing.Optional[list[LazyDefNumberParams]] = pydantic.Field(None, description="Defer the one-time calculation of a number value to synthesis time.\nUse this if you want to render a number to a template whose actual value depends on\nsome state mutation that may happen after the construct has been created.\n\nIf you are simply looking to force a value to a ``number`` type and don't need\nthe calculation to be deferred, use ``Token.asNumber()`` instead.\n\nThe inner function will only be invoked once, and the resolved value\ncannot depend on the Stack the Token is used in.")
    string: typing.Optional[list[LazyDefStringParams]] = pydantic.Field(None, description="Defer the one-time calculation of a string value to synthesis time.\nUse this if you want to render a string to a template whose actual value depends on\nsome state mutation that may happen after the construct has been created.\n\nIf you are simply looking to force a value to a ``string`` type and don't need\nthe calculation to be deferred, use ``Token.asString()`` instead.\n\nThe inner function will only be invoked once, and the resolved value\ncannot depend on the Stack the Token is used in.")
    uncached_list: typing.Optional[list[LazyDefUncachedListParams]] = pydantic.Field(None, description="Defer the calculation of a list value to synthesis time.\nUse of this function is not recommended; unless you know you need it for sure, you\nprobably don't. Use ``Lazy.list()`` instead.\n\nThe inner function may be invoked multiple times during synthesis. You\nshould only use this method if the returned value depends on variables\nthat may change during the Aspect application phase of synthesis, or if\nthe value depends on the Stack the value is being used in. Both of these\ncases are rare, and only ever occur for AWS Construct Library authors.")
    uncached_number: typing.Optional[list[LazyDefUncachedNumberParams]] = pydantic.Field(None, description="Defer the calculation of a number value to synthesis time.\nUse of this function is not recommended; unless you know you need it for sure, you\nprobably don't. Use ``Lazy.number()`` instead.\n\nThe inner function may be invoked multiple times during synthesis. You\nshould only use this method if the returned value depends on variables\nthat may change during the Aspect application phase of synthesis, or if\nthe value depends on the Stack the value is being used in. Both of these\ncases are rare, and only ever occur for AWS Construct Library authors.")
    uncached_string: typing.Optional[list[LazyDefUncachedStringParams]] = pydantic.Field(None, description="Defer the calculation of a string value to synthesis time.\nUse of this function is not recommended; unless you know you need it for sure, you\nprobably don't. Use ``Lazy.string()`` instead.\n\nThe inner function may be invoked multiple times during synthesis. You\nshould only use this method if the returned value depends on variables\nthat may change during the Aspect application phase of synthesis, or if\nthe value depends on the Stack the value is being used in. Both of these\ncases are rare, and only ever occur for AWS Construct Library authors.")

class LazyDefAnyParams(pydantic.BaseModel):
    producer: models.UnsupportedResource = pydantic.Field(..., description='-\n')
    display_hint: typing.Optional[str] = pydantic.Field(None, description='Use the given name as a display hint. Default: - No hint\n')
    omit_empty_array: typing.Optional[bool] = pydantic.Field(None, description="If the produced value is an array and it is empty, return 'undefined' instead. Default: false")
    ...

class LazyDefListParams(pydantic.BaseModel):
    producer: models.UnsupportedResource = pydantic.Field(..., description='-\n')
    display_hint: typing.Optional[str] = pydantic.Field(None, description='Use the given name as a display hint. Default: - No hint\n')
    omit_empty: typing.Optional[bool] = pydantic.Field(None, description="If the produced list is empty, return 'undefined' instead. Default: false")
    ...

class LazyDefNumberParams(pydantic.BaseModel):
    producer: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...

class LazyDefStringParams(pydantic.BaseModel):
    producer: models.UnsupportedResource = pydantic.Field(..., description='-\n')
    display_hint: typing.Optional[str] = pydantic.Field(None, description='Use the given name as a display hint. Default: - No hint')
    ...

class LazyDefUncachedAnyParams(pydantic.BaseModel):
    producer: models.UnsupportedResource = pydantic.Field(..., description='-\n')
    display_hint: typing.Optional[str] = pydantic.Field(None, description='Use the given name as a display hint. Default: - No hint\n')
    omit_empty_array: typing.Optional[bool] = pydantic.Field(None, description="If the produced value is an array and it is empty, return 'undefined' instead. Default: false")
    ...

class LazyDefUncachedListParams(pydantic.BaseModel):
    producer: models.UnsupportedResource = pydantic.Field(..., description='-\n')
    display_hint: typing.Optional[str] = pydantic.Field(None, description='Use the given name as a display hint. Default: - No hint\n')
    omit_empty: typing.Optional[bool] = pydantic.Field(None, description="If the produced list is empty, return 'undefined' instead. Default: false")
    ...

class LazyDefUncachedNumberParams(pydantic.BaseModel):
    producer: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...

class LazyDefUncachedStringParams(pydantic.BaseModel):
    producer: models.UnsupportedResource = pydantic.Field(..., description='-\n')
    display_hint: typing.Optional[str] = pydantic.Field(None, description='Use the given name as a display hint. Default: - No hint')
    ...


#  autogenerated from aws_cdk.LegacyStackSynthesizer
class LegacyStackSynthesizerDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['add_docker_image_asset', 'add_file_asset', 'bind', 'reusable_bind', 'synthesize']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.LegacyStackSynthesizer'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[LegacyStackSynthesizerDefConfig] = pydantic.Field(None)


class LegacyStackSynthesizerDefConfig(pydantic.BaseModel):
    add_docker_image_asset: typing.Optional[list[LegacyStackSynthesizerDefAddDockerImageAssetParams]] = pydantic.Field(None, description='Register a Docker Image Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    add_file_asset: typing.Optional[list[LegacyStackSynthesizerDefAddFileAssetParams]] = pydantic.Field(None, description='Register a File Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    bind: typing.Optional[list[LegacyStackSynthesizerDefBindParams]] = pydantic.Field(None, description='Bind to the stack this environment is going to be used on.\nMust be called before any of the other methods are called.')
    reusable_bind: typing.Optional[list[LegacyStackSynthesizerDefReusableBindParams]] = pydantic.Field(None, description='Produce a bound Stack Synthesizer for the given stack.\nThis method may be called more than once on the same object.')
    synthesize: typing.Optional[list[LegacyStackSynthesizerDefSynthesizeParams]] = pydantic.Field(None, description='Synthesize the associated stack to the session.')

class LegacyStackSynthesizerDefAddDockerImageAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description='The hash of the contents of the docker build context. This hash is used throughout the system to identify this image and avoid duplicate work in case the source did not change. NOTE: this means that if you wish to update your docker image, you must make a modification to the source (e.g. add some metadata to your Dockerfile).\n')
    asset_name: typing.Optional[str] = pydantic.Field(None, description='Unique identifier of the docker image asset and its potential revisions. Required if using AppScopedStagingSynthesizer. Default: - no asset name\n')
    directory_name: typing.Optional[str] = pydantic.Field(None, description='The directory where the Dockerfile is stored, must be relative to the cloud assembly root. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    docker_build_args: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build args to pass to the ``docker build`` command. Since Docker build arguments are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build args are passed\n')
    docker_build_secrets: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build secrets to pass to the ``docker build`` command. Since Docker build secrets are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build secrets are passed\n')
    docker_build_ssh: typing.Optional[str] = pydantic.Field(None, description='SSH agent socket or keys to pass to the ``docker buildx`` command. Default: - no ssh arg is passed\n')
    docker_build_target: typing.Optional[str] = pydantic.Field(None, description='Docker target to build to. Only allowed when ``directoryName`` is specified. Default: - no target\n')
    docker_cache_from: typing.Optional[typing.Sequence[typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Cache from options to pass to the ``docker build`` command. Default: - no cache from args are passed\n')
    docker_cache_to: typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Cache to options to pass to the ``docker build`` command. Default: - no cache to args are passed\n')
    docker_file: typing.Optional[str] = pydantic.Field(None, description='Path to the Dockerfile (relative to the directory). Only allowed when ``directoryName`` is specified. Default: - no file\n')
    docker_outputs: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Outputs to pass to the ``docker build`` command. Default: - no build args are passed\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the name of a local Docker image on ``stdout``. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    network_mode: typing.Optional[str] = pydantic.Field(None, description='Networking mode for the RUN commands during build. *Requires Docker Engine API v1.25+*. Specify this property to build images on a specific networking mode. Default: - no networking mode specified\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Platform to build for. *Requires Docker Buildx*. Specify this property to build images on a specific platform. Default: - no platform specified (the current machine architecture will be used)')
    ...

class LegacyStackSynthesizerDefAddFileAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description="A hash on the content source. This hash is used to uniquely identify this asset throughout the system. If this value doesn't change, the asset will not be rebuilt or republished.\n")
    deploy_time: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the asset needs to exist beyond deployment time; i.e. are copied over to a different location and not needed afterwards. Setting this property to true has an impact on the lifecycle of the asset, because we will assume that it is safe to delete after the CloudFormation deployment succeeds. For example, Lambda Function assets are copied over to Lambda during deployment. Therefore, it is not necessary to store the asset in S3, so we consider those deployTime assets. Default: false\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the location of a ZIP file on ``stdout``. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    file_name: typing.Optional[str] = pydantic.Field(None, description='The path, relative to the root of the cloud assembly, in which this asset source resides. This can be a path to a file or a directory, depending on the packaging type. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    packaging: typing.Optional[aws_cdk.FileAssetPackaging] = pydantic.Field(None, description='Which type of packaging to perform. Default: - Required if ``fileName`` is specified.')
    ...

class LegacyStackSynthesizerDefBindParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-')
    ...

class LegacyStackSynthesizerDefReusableBindParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models._interface_methods.CoreIBoundStackSynthesizerDefConfig]] = pydantic.Field(None)
    ...

class LegacyStackSynthesizerDefSynthesizeParams(pydantic.BaseModel):
    session: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.Names
class NamesDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['node_unique_id', 'unique_id', 'unique_resource_name']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Names'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[NamesDefConfig] = pydantic.Field(None)


class NamesDefConfig(pydantic.BaseModel):
    node_unique_id: typing.Optional[list[NamesDefNodeUniqueIdParams]] = pydantic.Field(None, description='Returns a CloudFormation-compatible unique identifier for a construct based on its path.\nThe identifier includes a human readable portion rendered\nfrom the path components and a hash suffix.\n\nTODO (v2): replace with API to use ``constructs.Node``.')
    unique_id: typing.Optional[list[NamesDefUniqueIdParams]] = pydantic.Field(None, description='Returns a CloudFormation-compatible unique identifier for a construct based on its path.\nThe identifier includes a human readable portion rendered\nfrom the path components and a hash suffix. uniqueId is not unique if multiple\ncopies of the stack are deployed. Prefer using uniqueResourceName().')
    unique_resource_name: typing.Optional[list[NamesDefUniqueResourceNameParams]] = pydantic.Field(None, description='Returns a CloudFormation-compatible unique identifier for a construct based on its path.\nThis function finds the stackName of the parent stack (non-nested)\nto the construct, and the ids of the components in the construct path.\n\nThe user can define allowed special characters, a separator between the elements,\nand the maximum length of the resource name. The name includes a human readable portion rendered\nfrom the path components, with or without user defined separators, and a hash suffix.\nIf the resource name is longer than the maximum length, it is trimmed in the middle.')

class NamesDefNodeUniqueIdParams(pydantic.BaseModel):
    node: models.constructs.NodeDef = pydantic.Field(..., description='The construct node.\n')
    ...

class NamesDefUniqueIdParams(pydantic.BaseModel):
    construct_: models.AnyResource = pydantic.Field(..., description='The construct.\n', alias='construct')
    ...

class NamesDefUniqueResourceNameParams(pydantic.BaseModel):
    construct_: models.AnyResource = pydantic.Field(..., description='The construct.\n', alias='construct')
    allowed_special_characters: typing.Optional[str] = pydantic.Field(None, description='Non-alphanumeric characters allowed in the unique resource name. Default: - none\n')
    max_length: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum length of the unique resource name. Default: - 256\n')
    separator: typing.Optional[str] = pydantic.Field(None, description='The separator used between the path components. Default: - none\n')
    ...


#  autogenerated from aws_cdk.NestedStackSynthesizer
class NestedStackSynthesizerDef(BaseClass):
    parent_deployment: typing.Union[_REQUIRED_INIT_PARAM, models.BootstraplessSynthesizerDef, models.CliCredentialsStackSynthesizerDef, models.DefaultStackSynthesizerDef, models.LegacyStackSynthesizerDef, models.NestedStackSynthesizerDef, models.StackSynthesizerDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['parent_deployment']
    _method_names: typing.ClassVar[list[str]] = ['add_docker_image_asset', 'add_file_asset', 'bind', 'synthesize']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.NestedStackSynthesizer'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[NestedStackSynthesizerDefConfig] = pydantic.Field(None)


class NestedStackSynthesizerDefConfig(pydantic.BaseModel):
    add_docker_image_asset: typing.Optional[list[NestedStackSynthesizerDefAddDockerImageAssetParams]] = pydantic.Field(None, description='Register a Docker Image Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    add_file_asset: typing.Optional[list[NestedStackSynthesizerDefAddFileAssetParams]] = pydantic.Field(None, description='Register a File Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    bind: typing.Optional[list[NestedStackSynthesizerDefBindParams]] = pydantic.Field(None, description='Bind to the stack this environment is going to be used on.\nMust be called before any of the other methods are called.')
    synthesize: typing.Optional[list[NestedStackSynthesizerDefSynthesizeParams]] = pydantic.Field(None, description='Synthesize the associated stack to the session.')

class NestedStackSynthesizerDefAddDockerImageAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description='The hash of the contents of the docker build context. This hash is used throughout the system to identify this image and avoid duplicate work in case the source did not change. NOTE: this means that if you wish to update your docker image, you must make a modification to the source (e.g. add some metadata to your Dockerfile).\n')
    asset_name: typing.Optional[str] = pydantic.Field(None, description='Unique identifier of the docker image asset and its potential revisions. Required if using AppScopedStagingSynthesizer. Default: - no asset name\n')
    directory_name: typing.Optional[str] = pydantic.Field(None, description='The directory where the Dockerfile is stored, must be relative to the cloud assembly root. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    docker_build_args: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build args to pass to the ``docker build`` command. Since Docker build arguments are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build args are passed\n')
    docker_build_secrets: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build secrets to pass to the ``docker build`` command. Since Docker build secrets are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build secrets are passed\n')
    docker_build_ssh: typing.Optional[str] = pydantic.Field(None, description='SSH agent socket or keys to pass to the ``docker buildx`` command. Default: - no ssh arg is passed\n')
    docker_build_target: typing.Optional[str] = pydantic.Field(None, description='Docker target to build to. Only allowed when ``directoryName`` is specified. Default: - no target\n')
    docker_cache_from: typing.Optional[typing.Sequence[typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Cache from options to pass to the ``docker build`` command. Default: - no cache from args are passed\n')
    docker_cache_to: typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Cache to options to pass to the ``docker build`` command. Default: - no cache to args are passed\n')
    docker_file: typing.Optional[str] = pydantic.Field(None, description='Path to the Dockerfile (relative to the directory). Only allowed when ``directoryName`` is specified. Default: - no file\n')
    docker_outputs: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Outputs to pass to the ``docker build`` command. Default: - no build args are passed\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the name of a local Docker image on ``stdout``. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    network_mode: typing.Optional[str] = pydantic.Field(None, description='Networking mode for the RUN commands during build. *Requires Docker Engine API v1.25+*. Specify this property to build images on a specific networking mode. Default: - no networking mode specified\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Platform to build for. *Requires Docker Buildx*. Specify this property to build images on a specific platform. Default: - no platform specified (the current machine architecture will be used)')
    ...

class NestedStackSynthesizerDefAddFileAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description="A hash on the content source. This hash is used to uniquely identify this asset throughout the system. If this value doesn't change, the asset will not be rebuilt or republished.\n")
    deploy_time: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the asset needs to exist beyond deployment time; i.e. are copied over to a different location and not needed afterwards. Setting this property to true has an impact on the lifecycle of the asset, because we will assume that it is safe to delete after the CloudFormation deployment succeeds. For example, Lambda Function assets are copied over to Lambda during deployment. Therefore, it is not necessary to store the asset in S3, so we consider those deployTime assets. Default: false\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the location of a ZIP file on ``stdout``. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    file_name: typing.Optional[str] = pydantic.Field(None, description='The path, relative to the root of the cloud assembly, in which this asset source resides. This can be a path to a file or a directory, depending on the packaging type. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    packaging: typing.Optional[aws_cdk.FileAssetPackaging] = pydantic.Field(None, description='Which type of packaging to perform. Default: - Required if ``fileName`` is specified.')
    ...

class NestedStackSynthesizerDefBindParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-')
    ...

class NestedStackSynthesizerDefSynthesizeParams(pydantic.BaseModel):
    session: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.PermissionsBoundary
class PermissionsBoundaryDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['from_arn', 'from_name']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.PermissionsBoundary'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_arn', 'from_name']
    ...


    from_arn: typing.Optional[PermissionsBoundaryDefFromArnParams] = pydantic.Field(None, description="Apply a permissions boundary with the given ARN to all IAM Roles and Users created within a scope.\nThe arn can include placeholders for the partition, region, qualifier, and account\nThese placeholders will be replaced with the actual values if available. This requires\nthat the Stack has the environment specified, it does not work with environment\nagnostic stacks.\n\n- '${AWS::Partition}'\n- '${AWS::Region}'\n- '${AWS::AccountId}'\n- '${Qualifier}'")
    from_name: typing.Optional[PermissionsBoundaryDefFromNameParams] = pydantic.Field(None, description="Apply a permissions boundary with the given name to all IAM Roles and Users created within a scope.\nThe name can include placeholders for the partition, region, qualifier, and account\nThese placeholders will be replaced with the actual values if available. This requires\nthat the Stack has the environment specified, it does not work with environment\nagnostic stacks.\n\n- '${AWS::Partition}'\n- '${AWS::Region}'\n- '${AWS::AccountId}'\n- '${Qualifier}'")

class PermissionsBoundaryDefFromArnParams(pydantic.BaseModel):
    arn: str = pydantic.Field(..., description='the ARN of the permissions boundary policy.\n\nExample::\n\n    Stage(app, "ProdStage",\n        permissions_boundary=PermissionsBoundary.from_arn("arn:aws:iam::${AWS::AccountId}:policy/my-custom-permissions-boundary")\n    )\n')
    ...

class PermissionsBoundaryDefFromNameParams(pydantic.BaseModel):
    name: str = pydantic.Field(..., description='the name of the permissions boundary policy.\n\nExample::\n\n    Stage(app, "ProdStage",\n        permissions_boundary=PermissionsBoundary.from_name("my-custom-permissions-boundary")\n    )\n')
    ...


#  autogenerated from aws_cdk.PhysicalName
class PhysicalNameDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.PhysicalName'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.Reference
class ReferenceDef(BaseClass):
    value: typing.Union[typing.Any, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    target: typing.Union[models.AnyResource, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-\n')
    display_name: typing.Optional[str] = pydantic.Field(None, description='-\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='Type that the Intrinsic is expected to evaluate to.')
    _init_params: typing.ClassVar[list[str]] = ['value', 'target', 'display_name', 'type_hint']
    _method_names: typing.ClassVar[list[str]] = ['resolve']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Reference'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[ReferenceDefConfig] = pydantic.Field(None)


class ReferenceDefConfig(pydantic.BaseModel):
    resolve: typing.Optional[list[ReferenceDefResolveParams]] = pydantic.Field(None, description="Produce the Token's value at resolution time.")

class ReferenceDefResolveParams(pydantic.BaseModel):
    _context: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.RemoveTag
class RemoveTagDef(BaseClass):
    key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The string key for the tag.')
    apply_to_launched_instances: typing.Optional[bool] = pydantic.Field(None, description='Whether the tag should be applied to instances in an AutoScalingGroup. Default: true\n')
    exclude_resource_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of Resource Types that will not receive this tag. An empty array will allow this tag to be applied to all resources. A non-empty array will apply this tag only if the Resource type is not in this array. Default: []\n')
    include_resource_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of Resource Types that will receive this tag. An empty array will match any Resource. A non-empty array will apply this tag only to Resource types that are included in this array. Default: []\n')
    priority: typing.Union[int, float, None] = pydantic.Field(None, description='Priority of the tag operation. Higher or equal priority tags will take precedence. Setting priority will enable the user to control tags when they need to not follow the default precedence pattern of last applied and closest to the construct in the tree. Default: Default priorities: - 100 for ``SetTag`` - 200 for ``RemoveTag`` - 50 for tags added directly to CloudFormation resources')
    _init_params: typing.ClassVar[list[str]] = ['key', 'apply_to_launched_instances', 'exclude_resource_types', 'include_resource_types', 'priority']
    _method_names: typing.ClassVar[list[str]] = ['visit']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.RemoveTag'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[RemoveTagDefConfig] = pydantic.Field(None)


class RemoveTagDefConfig(pydantic.BaseModel):
    visit: typing.Optional[list[RemoveTagDefVisitParams]] = pydantic.Field(None, description='All aspects can visit an IConstruct.')

class RemoveTagDefVisitParams(pydantic.BaseModel):
    construct_: models.AnyResource = pydantic.Field(..., description='-', alias='construct')
    ...


#  autogenerated from aws_cdk.Resource
class ResourceDef(BaseClass):
    account: typing.Optional[str] = pydantic.Field(None, description='The AWS account ID this resource belongs to. Default: - the resource is in the same account as the stack it belongs to\n')
    environment_from_arn: typing.Optional[str] = pydantic.Field(None, description='ARN to deduce region and account from. The ARN is parsed and the account and region are taken from the ARN. This should be used for imported resources. Cannot be supplied together with either ``account`` or ``region``. Default: - take environment from ``account``, ``region`` parameters, or use Stack environment.\n')
    physical_name: typing.Optional[str] = pydantic.Field(None, description='The value passed in by users to the physical name prop of the resource. - ``undefined`` implies that a physical name will be allocated by CloudFormation during deployment. - a concrete value implies a specific physical name - ``PhysicalName.GENERATE_IF_NEEDED`` is a marker that indicates that a physical will only be generated by the CDK if it is needed for cross-environment references. Otherwise, it will be allocated by CloudFormation. Default: - The physical name will be allocated by CloudFormation at deployment time\n')
    region: typing.Optional[str] = pydantic.Field(None, description='The AWS region this resource belongs to. Default: - the resource is in the same region as the stack it belongs to')
    _init_params: typing.ClassVar[list[str]] = ['account', 'environment_from_arn', 'physical_name', 'region']
    _method_names: typing.ClassVar[list[str]] = ['apply_removal_policy']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Resource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[ResourceDefConfig] = pydantic.Field(None)


class ResourceDefConfig(pydantic.BaseModel):
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)

class ResourceDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.ScopedAws
class ScopedAwsDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.ScopedAws'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.SecretValue
class SecretValueDef(BaseClass):
    protected_value: typing.Union[typing.Any, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-\n')
    stack_trace: typing.Optional[bool] = pydantic.Field(None, description='Capture the stack trace of where this token is created. Default: true\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='Type that this token is expected to evaluate to. Default: ResolutionTypeHint.STRING')
    _init_params: typing.ClassVar[list[str]] = ['protected_value', 'stack_trace', 'type_hint']
    _method_names: typing.ClassVar[list[str]] = ['resolve', 'unsafe_unwrap']
    _classmethod_names: typing.ClassVar[list[str]] = ['cfn_dynamic_reference', 'cfn_parameter', 'plain_text', 'resource_attribute', 'secrets_manager', 'ssm_secure', 'unsafe_plain_text']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.SecretValue'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[SecretValueDefConfig] = pydantic.Field(None)


class SecretValueDefConfig(pydantic.BaseModel):
    cfn_dynamic_reference: typing.Optional[list[SecretValueDefCfnDynamicReferenceParams]] = pydantic.Field(None, description='Obtain the secret value through a CloudFormation dynamic reference.\nIf possible, use ``SecretValue.ssmSecure`` or ``SecretValue.secretsManager`` directly.')
    cfn_parameter: typing.Optional[list[SecretValueDefCfnParameterParams]] = pydantic.Field(None, description='Obtain the secret value through a CloudFormation parameter.\nGenerally, this is not a recommended approach. AWS Secrets Manager is the\nrecommended way to reference secrets.')
    plain_text: typing.Optional[list[SecretValueDefPlainTextParams]] = pydantic.Field(None, description='(deprecated) Construct a literal secret value for use with secret-aware constructs.\nDo not use this method for any secrets that you care about! The value\nwill be visible to anyone who has access to the CloudFormation template\n(via the AWS Console, SDKs, or CLI).\n\nThe only reasonable use case for using this method is when you are testing.')
    resolve: typing.Optional[list[SecretValueDefResolveParams]] = pydantic.Field(None, description='Resolve the secret.\nIf the feature flag is not set, resolve as normal. Otherwise, throw a descriptive\nerror that the usage guard is missing.')
    resource_attribute: typing.Optional[list[SecretValueDefResourceAttributeParams]] = pydantic.Field(None, description="Use a resource's output as secret value.")
    secrets_manager: typing.Optional[list[SecretValueDefSecretsManagerParams]] = pydantic.Field(None, description='Creates a ``SecretValue`` with a value which is dynamically loaded from AWS Secrets Manager.\nIf you rotate the value in the Secret, you must also change at least one property\non the resource where you are using the secret, to force CloudFormation to re-read the secret.')
    ssm_secure: typing.Optional[list[SecretValueDefSsmSecureParams]] = pydantic.Field(None, description='Use a secret value stored from a Systems Manager (SSM) parameter.\nThis secret source in only supported in a limited set of resources and\nproperties. `Click here for the list of supported\nproperties <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html#template-parameters-dynamic-patterns-resources>`_.')
    unsafe_plain_text: typing.Optional[list[SecretValueDefUnsafePlainTextParams]] = pydantic.Field(None, description='Construct a literal secret value for use with secret-aware constructs.\nDo not use this method for any secrets that you care about! The value\nwill be visible to anyone who has access to the CloudFormation template\n(via the AWS Console, SDKs, or CLI).\n\nThe primary use case for using this method is when you are testing.\n\nThe other use case where this is appropriate is when constructing a JSON secret.\nFor example, a JSON secret might have multiple fields where only some are actual\nsecret values.')
    unsafe_unwrap: typing.Optional[bool] = pydantic.Field(None, description="Disable usage protection on this secret.\nCall this to indicate that you want to use the secret value held by this\nobject in an unchecked way. If you don't call this method, using the secret\nvalue directly in a string context or as a property value somewhere will\nproduce an error.\n\nThis method has 'unsafe' in the name on purpose! Make sure that the\nconstruct property you are using the returned value in is does not end up\nin a place in your AWS infrastructure where it could be read by anyone\nunexpected.\n\nWhen in doubt, don't call this method and only pass the object to constructs that\naccept ``SecretValue`` parameters.")

class SecretValueDefCfnDynamicReferenceParams(pydantic.BaseModel):
    ref: models.CfnDynamicReferenceDef = pydantic.Field(..., description='The dynamic reference to use.')
    return_config: typing.Optional[list[models.core.SecretValueDefConfig]] = pydantic.Field(None)
    ...

class SecretValueDefCfnParameterParams(pydantic.BaseModel):
    param: models.CfnParameterDef = pydantic.Field(..., description='The CloudFormation parameter to use.')
    return_config: typing.Optional[list[models.core.SecretValueDefConfig]] = pydantic.Field(None)
    ...

class SecretValueDefPlainTextParams(pydantic.BaseModel):
    secret: str = pydantic.Field(..., description='-\n\n:deprecated: Use ``unsafePlainText()`` instead.\n\n:stability: deprecated\n')
    return_config: typing.Optional[list[models.core.SecretValueDefConfig]] = pydantic.Field(None)
    ...

class SecretValueDefResolveParams(pydantic.BaseModel):
    context: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...

class SecretValueDefResourceAttributeParams(pydantic.BaseModel):
    attr: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.core.SecretValueDefConfig]] = pydantic.Field(None)
    ...

class SecretValueDefSecretsManagerParams(pydantic.BaseModel):
    secret_id: str = pydantic.Field(..., description='The ID or ARN of the secret.\n')
    json_field: typing.Optional[str] = pydantic.Field(None, description='The key of a JSON field to retrieve. This can only be used if the secret stores a JSON object. Default: - returns all the content stored in the Secrets Manager secret.\n')
    version_id: typing.Optional[str] = pydantic.Field(None, description='Specifies the unique identifier of the version of the secret you want to use. Can specify at most one of ``versionId`` and ``versionStage``. Default: AWSCURRENT\n')
    version_stage: typing.Optional[str] = pydantic.Field(None, description='Specifies the secret version that you want to retrieve by the staging label attached to the version. Can specify at most one of ``versionId`` and ``versionStage``. Default: AWSCURRENT')
    return_config: typing.Optional[list[models.core.SecretValueDefConfig]] = pydantic.Field(None)
    ...

class SecretValueDefSsmSecureParams(pydantic.BaseModel):
    parameter_name: str = pydantic.Field(..., description='The name of the parameter in the Systems Manager Parameter Store. The parameter name is case-sensitive.\n')
    version: typing.Optional[str] = pydantic.Field(None, description="An integer that specifies the version of the parameter to use. If you don't specify the exact version, AWS CloudFormation uses the latest version of the parameter.")
    return_config: typing.Optional[list[models.core.SecretValueDefConfig]] = pydantic.Field(None)
    ...

class SecretValueDefUnsafePlainTextParams(pydantic.BaseModel):
    secret: str = pydantic.Field(..., description='-\n\nExample::\n\n    # secret: SecretValue\n\n    json_secret = {\n        "username": SecretValue.unsafe_plain_text("myUsername"),\n        "password": secret\n    }\n')
    return_config: typing.Optional[list[models.core.SecretValueDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.Size
class SizeDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['bytes', 'gibibytes', 'kibibytes', 'mebibytes', 'pebibytes', 'tebibytes']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Size'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[SizeDefConfig] = pydantic.Field(None)


class SizeDefConfig(pydantic.BaseModel):
    bytes: typing.Optional[list[SizeDefBytesParams]] = pydantic.Field(None, description='Create a Storage representing an amount bytes.')
    gibibytes: typing.Optional[list[SizeDefGibibytesParams]] = pydantic.Field(None, description='Create a Storage representing an amount gibibytes.\n1 GiB = 1024 MiB')
    kibibytes: typing.Optional[list[SizeDefKibibytesParams]] = pydantic.Field(None, description='Create a Storage representing an amount kibibytes.\n1 KiB = 1024 bytes')
    mebibytes: typing.Optional[list[SizeDefMebibytesParams]] = pydantic.Field(None, description='Create a Storage representing an amount mebibytes.\n1 MiB = 1024 KiB')
    pebibytes: typing.Optional[list[SizeDefPebibytesParams]] = pydantic.Field(None, description='Create a Storage representing an amount pebibytes.\n1 PiB = 1024 TiB')
    tebibytes: typing.Optional[list[SizeDefTebibytesParams]] = pydantic.Field(None, description='Create a Storage representing an amount tebibytes.\n1 TiB = 1024 GiB')

class SizeDefBytesParams(pydantic.BaseModel):
    amount: typing.Union[int, float] = pydantic.Field(..., description='the amount of bytes to be represented.\n')
    return_config: typing.Optional[list[models.core.SizeDefConfig]] = pydantic.Field(None)
    ...

class SizeDefGibibytesParams(pydantic.BaseModel):
    amount: typing.Union[int, float] = pydantic.Field(..., description='the amount of gibibytes to be represented.\n')
    return_config: typing.Optional[list[models.core.SizeDefConfig]] = pydantic.Field(None)
    ...

class SizeDefKibibytesParams(pydantic.BaseModel):
    amount: typing.Union[int, float] = pydantic.Field(..., description='the amount of kibibytes to be represented.\n')
    return_config: typing.Optional[list[models.core.SizeDefConfig]] = pydantic.Field(None)
    ...

class SizeDefMebibytesParams(pydantic.BaseModel):
    amount: typing.Union[int, float] = pydantic.Field(..., description='the amount of mebibytes to be represented.\n')
    return_config: typing.Optional[list[models.core.SizeDefConfig]] = pydantic.Field(None)
    ...

class SizeDefPebibytesParams(pydantic.BaseModel):
    amount: typing.Union[int, float] = pydantic.Field(..., description='the amount of pebibytes to be represented.\n')
    return_config: typing.Optional[list[models.core.SizeDefConfig]] = pydantic.Field(None)
    ...

class SizeDefTebibytesParams(pydantic.BaseModel):
    amount: typing.Union[int, float] = pydantic.Field(..., description='the amount of tebibytes to be represented.\n')
    return_config: typing.Optional[list[models.core.SizeDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.StackSynthesizer
class StackSynthesizerDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['add_docker_image_asset', 'add_file_asset', 'bind', 'synthesize']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.StackSynthesizer'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[StackSynthesizerDefConfig] = pydantic.Field(None)


class StackSynthesizerDefConfig(pydantic.BaseModel):
    add_docker_image_asset: typing.Optional[list[StackSynthesizerDefAddDockerImageAssetParams]] = pydantic.Field(None, description='Register a Docker Image Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    add_file_asset: typing.Optional[list[StackSynthesizerDefAddFileAssetParams]] = pydantic.Field(None, description='Register a File Asset.\nReturns the parameters that can be used to refer to the asset inside the template.\n\nThe synthesizer must rely on some out-of-band mechanism to make sure the given files\nare actually placed in the returned location before the deployment happens. This can\nbe by writing the instructions to the asset manifest (for use by the ``cdk-assets`` tool),\nby relying on the CLI to upload files (legacy behavior), or some other operator controlled\nmechanism.')
    bind: typing.Optional[list[StackSynthesizerDefBindParams]] = pydantic.Field(None, description='Bind to the stack this environment is going to be used on.\nMust be called before any of the other methods are called.')
    synthesize: typing.Optional[list[StackSynthesizerDefSynthesizeParams]] = pydantic.Field(None, description='Synthesize the associated stack to the session.')

class StackSynthesizerDefAddDockerImageAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description='The hash of the contents of the docker build context. This hash is used throughout the system to identify this image and avoid duplicate work in case the source did not change. NOTE: this means that if you wish to update your docker image, you must make a modification to the source (e.g. add some metadata to your Dockerfile).\n')
    asset_name: typing.Optional[str] = pydantic.Field(None, description='Unique identifier of the docker image asset and its potential revisions. Required if using AppScopedStagingSynthesizer. Default: - no asset name\n')
    directory_name: typing.Optional[str] = pydantic.Field(None, description='The directory where the Dockerfile is stored, must be relative to the cloud assembly root. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    docker_build_args: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build args to pass to the ``docker build`` command. Since Docker build arguments are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build args are passed\n')
    docker_build_secrets: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build secrets to pass to the ``docker build`` command. Since Docker build secrets are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build secrets are passed\n')
    docker_build_ssh: typing.Optional[str] = pydantic.Field(None, description='SSH agent socket or keys to pass to the ``docker buildx`` command. Default: - no ssh arg is passed\n')
    docker_build_target: typing.Optional[str] = pydantic.Field(None, description='Docker target to build to. Only allowed when ``directoryName`` is specified. Default: - no target\n')
    docker_cache_from: typing.Optional[typing.Sequence[typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Cache from options to pass to the ``docker build`` command. Default: - no cache from args are passed\n')
    docker_cache_to: typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Cache to options to pass to the ``docker build`` command. Default: - no cache to args are passed\n')
    docker_file: typing.Optional[str] = pydantic.Field(None, description='Path to the Dockerfile (relative to the directory). Only allowed when ``directoryName`` is specified. Default: - no file\n')
    docker_outputs: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Outputs to pass to the ``docker build`` command. Default: - no build args are passed\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the name of a local Docker image on ``stdout``. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    network_mode: typing.Optional[str] = pydantic.Field(None, description='Networking mode for the RUN commands during build. *Requires Docker Engine API v1.25+*. Specify this property to build images on a specific networking mode. Default: - no networking mode specified\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Platform to build for. *Requires Docker Buildx*. Specify this property to build images on a specific platform. Default: - no platform specified (the current machine architecture will be used)')
    ...

class StackSynthesizerDefAddFileAssetParams(pydantic.BaseModel):
    source_hash: str = pydantic.Field(..., description="A hash on the content source. This hash is used to uniquely identify this asset throughout the system. If this value doesn't change, the asset will not be rebuilt or republished.\n")
    deploy_time: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the asset needs to exist beyond deployment time; i.e. are copied over to a different location and not needed afterwards. Setting this property to true has an impact on the lifecycle of the asset, because we will assume that it is safe to delete after the CloudFormation deployment succeeds. For example, Lambda Function assets are copied over to Lambda during deployment. Therefore, it is not necessary to store the asset in S3, so we consider those deployTime assets. Default: false\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the location of a ZIP file on ``stdout``. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    file_name: typing.Optional[str] = pydantic.Field(None, description='The path, relative to the root of the cloud assembly, in which this asset source resides. This can be a path to a file or a directory, depending on the packaging type. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    packaging: typing.Optional[aws_cdk.FileAssetPackaging] = pydantic.Field(None, description='Which type of packaging to perform. Default: - Required if ``fileName`` is specified.')
    ...

class StackSynthesizerDefBindParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-')
    ...

class StackSynthesizerDefSynthesizeParams(pydantic.BaseModel):
    session: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.StringConcat
class StringConcatDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['join']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.StringConcat'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[StringConcatDefConfig] = pydantic.Field(None)


class StringConcatDefConfig(pydantic.BaseModel):
    join: typing.Optional[list[StringConcatDefJoinParams]] = pydantic.Field(None, description='Join the fragment on the left and on the right.')

class StringConcatDefJoinParams(pydantic.BaseModel):
    left: typing.Any = pydantic.Field(..., description='-\n')
    right: typing.Any = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.Tag
class TagDef(BaseClass):
    key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The string key for the tag.')
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-\n')
    apply_to_launched_instances: typing.Optional[bool] = pydantic.Field(None, description='Whether the tag should be applied to instances in an AutoScalingGroup. Default: true\n')
    exclude_resource_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of Resource Types that will not receive this tag. An empty array will allow this tag to be applied to all resources. A non-empty array will apply this tag only if the Resource type is not in this array. Default: []\n')
    include_resource_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of Resource Types that will receive this tag. An empty array will match any Resource. A non-empty array will apply this tag only to Resource types that are included in this array. Default: []\n')
    priority: typing.Union[int, float, None] = pydantic.Field(None, description='Priority of the tag operation. Higher or equal priority tags will take precedence. Setting priority will enable the user to control tags when they need to not follow the default precedence pattern of last applied and closest to the construct in the tree. Default: Default priorities: - 100 for ``SetTag`` - 200 for ``RemoveTag`` - 50 for tags added directly to CloudFormation resources')
    _init_params: typing.ClassVar[list[str]] = ['key', 'value', 'apply_to_launched_instances', 'exclude_resource_types', 'include_resource_types', 'priority']
    _method_names: typing.ClassVar[list[str]] = ['visit']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Tag'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[TagDefConfig] = pydantic.Field(None)


class TagDefConfig(pydantic.BaseModel):
    visit: typing.Optional[list[TagDefVisitParams]] = pydantic.Field(None, description='All aspects can visit an IConstruct.')

class TagDefVisitParams(pydantic.BaseModel):
    construct_: models.AnyResource = pydantic.Field(..., description='-', alias='construct')
    ...


#  autogenerated from aws_cdk.TagManager
class TagManagerDef(BaseClass):
    tag_type: typing.Union[aws_cdk.TagType, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    resource_type_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-\n')
    initial_tags: typing.Any = pydantic.Field(None, description='-\n')
    tag_property_name: typing.Optional[str] = pydantic.Field(None, description='The name of the property in CloudFormation for these tags. Normally this is ``tags``, but Cognito UserPool uses UserPoolTags Default: "tags"')
    _init_params: typing.ClassVar[list[str]] = ['tag_type', 'resource_type_name', 'initial_tags', 'tag_property_name']
    _method_names: typing.ClassVar[list[str]] = ['apply_tag_aspect_here', 'has_tags', 'remove_tag', 'render_tags', 'set_tag', 'tag_values']
    _classmethod_names: typing.ClassVar[list[str]] = ['of']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.TagManager'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[TagManagerDefConfig] = pydantic.Field(None)


class TagManagerDefConfig(pydantic.BaseModel):
    apply_tag_aspect_here: typing.Optional[list[TagManagerDefApplyTagAspectHereParams]] = pydantic.Field(None, description='Determine if the aspect applies here.\nLooks at the include and exclude resourceTypeName arrays to determine if\nthe aspect applies here')
    has_tags: typing.Optional[bool] = pydantic.Field(None, description='Returns true if there are any tags defined.')
    of: typing.Optional[list[TagManagerDefOfParams]] = pydantic.Field(None, description='Return the TagManager associated with the given construct, if any.')
    remove_tag: typing.Optional[list[TagManagerDefRemoveTagParams]] = pydantic.Field(None, description='Removes the specified tag from the array if it exists.')
    render_tags: typing.Optional[list[TagManagerDefRenderTagsParams]] = pydantic.Field(None, description='Renders tags into the proper format based on TagType.\nThis method will eagerly render the tags currently applied. In\nmost cases, you should be using ``tagManager.renderedTags`` instead,\nwhich will return a ``Lazy`` value that will resolve to the correct\ntags at synthesis time.')
    set_tag: typing.Optional[list[TagManagerDefSetTagParams]] = pydantic.Field(None, description='Adds the specified tag to the array of tags.')
    tag_values: typing.Optional[bool] = pydantic.Field(None, description='Render the tags in a readable format.')
    rendered_tags_config: typing.Optional[models._interface_methods.CoreIResolvableDefConfig] = pydantic.Field(None)

class TagManagerDefApplyTagAspectHereParams(pydantic.BaseModel):
    include: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='-\n')
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='-')
    ...

class TagManagerDefOfParams(pydantic.BaseModel):
    construct_: typing.Any = pydantic.Field(..., description='-', alias='construct')
    ...

class TagManagerDefRemoveTagParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='The tag to remove.\n')
    priority: typing.Union[int, float] = pydantic.Field(..., description='The priority of the remove operation.')
    ...

class TagManagerDefRenderTagsParams(pydantic.BaseModel):
    combine_with_tags: typing.Any = pydantic.Field(None, description='-')
    ...

class TagManagerDefSetTagParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-\n')
    priority: typing.Union[int, float, None] = pydantic.Field(None, description='-\n')
    apply_to_launched_instances: typing.Optional[bool] = pydantic.Field(None, description='-')
    ...


#  autogenerated from aws_cdk.Tags
class TagsDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['add', 'remove']
    _classmethod_names: typing.ClassVar[list[str]] = ['of']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Tags'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[TagsDefConfig] = pydantic.Field(None)


class TagsDefConfig(pydantic.BaseModel):
    add: typing.Optional[list[TagsDefAddParams]] = pydantic.Field(None, description='add tags to the node of a construct and all its the taggable children.')
    of: typing.Optional[list[TagsDefOfParams]] = pydantic.Field(None, description='Returns the tags API for this scope.')
    remove: typing.Optional[list[TagsDefRemoveParams]] = pydantic.Field(None, description='remove tags to the node of a construct and all its the taggable children.')

class TagsDefAddParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-\n')
    apply_to_launched_instances: typing.Optional[bool] = pydantic.Field(None, description='Whether the tag should be applied to instances in an AutoScalingGroup. Default: true\n')
    exclude_resource_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of Resource Types that will not receive this tag. An empty array will allow this tag to be applied to all resources. A non-empty array will apply this tag only if the Resource type is not in this array. Default: []\n')
    include_resource_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of Resource Types that will receive this tag. An empty array will match any Resource. A non-empty array will apply this tag only to Resource types that are included in this array. Default: []\n')
    priority: typing.Union[int, float, None] = pydantic.Field(None, description='Priority of the tag operation. Higher or equal priority tags will take precedence. Setting priority will enable the user to control tags when they need to not follow the default precedence pattern of last applied and closest to the construct in the tree. Default: Default priorities: - 100 for ``SetTag`` - 200 for ``RemoveTag`` - 50 for tags added directly to CloudFormation resources')
    ...

class TagsDefOfParams(pydantic.BaseModel):
    scope: models.AnyResource = pydantic.Field(..., description='The scope.')
    return_config: typing.Optional[list[models.core.TagsDefConfig]] = pydantic.Field(None)
    ...

class TagsDefRemoveParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    apply_to_launched_instances: typing.Optional[bool] = pydantic.Field(None, description='Whether the tag should be applied to instances in an AutoScalingGroup. Default: true\n')
    exclude_resource_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of Resource Types that will not receive this tag. An empty array will allow this tag to be applied to all resources. A non-empty array will apply this tag only if the Resource type is not in this array. Default: []\n')
    include_resource_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of Resource Types that will receive this tag. An empty array will match any Resource. A non-empty array will apply this tag only to Resource types that are included in this array. Default: []\n')
    priority: typing.Union[int, float, None] = pydantic.Field(None, description='Priority of the tag operation. Higher or equal priority tags will take precedence. Setting priority will enable the user to control tags when they need to not follow the default precedence pattern of last applied and closest to the construct in the tree. Default: Default priorities: - 100 for ``SetTag`` - 200 for ``RemoveTag`` - 50 for tags added directly to CloudFormation resources')
    ...


#  autogenerated from aws_cdk.TimeZone
class TimeZoneDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['of']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.TimeZone'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[TimeZoneDefConfig] = pydantic.Field(None)


class TimeZoneDefConfig(pydantic.BaseModel):
    of: typing.Optional[list[TimeZoneDefOfParams]] = pydantic.Field(None, description='Use this to add a timezone not in this class.')

class TimeZoneDefOfParams(pydantic.BaseModel):
    timezone_name: str = pydantic.Field(..., description='the name of the timezone.\n')
    return_config: typing.Optional[list[models.core.TimeZoneDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.Token
class TokenDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['compare_strings']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Token'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[TokenDefConfig] = pydantic.Field(None)


class TokenDefConfig(pydantic.BaseModel):
    compare_strings: typing.Optional[list[TokenDefCompareStringsParams]] = pydantic.Field(None, description='Compare two strings that might contain Tokens with each other.')

class TokenDefCompareStringsParams(pydantic.BaseModel):
    possible_token1: str = pydantic.Field(..., description='-\n')
    possible_token2: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.TokenComparison
class TokenComparisonDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.TokenComparison'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.Tokenization
class TokenizationDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['resolve', 'reverse', 'reverse_complete_string', 'reverse_list', 'reverse_number', 'reverse_string', 'stringify_number']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Tokenization'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[TokenizationDefConfig] = pydantic.Field(None)


class TokenizationDefConfig(pydantic.BaseModel):
    resolve: typing.Optional[list[TokenizationDefResolveParams]] = pydantic.Field(None, description='Resolves an object by evaluating all tokens and removing any undefined or empty objects or arrays.\nValues can only be primitives, arrays or tokens. Other objects (i.e. with methods) will be rejected.')
    reverse: typing.Optional[list[TokenizationDefReverseParams]] = pydantic.Field(None, description='Reverse any value into a Resolvable, if possible.\nIn case of a string, the string must not be a concatenation.')
    reverse_complete_string: typing.Optional[list[TokenizationDefReverseCompleteStringParams]] = pydantic.Field(None, description="Un-encode a string which is either a complete encoded token, or doesn't contain tokens at all.\nIt's illegal for the string to be a concatenation of an encoded token and something else.")
    reverse_list: typing.Optional[list[TokenizationDefReverseListParams]] = pydantic.Field(None, description='Un-encode a Tokenized value from a list.')
    reverse_number: typing.Optional[list[TokenizationDefReverseNumberParams]] = pydantic.Field(None, description='Un-encode a Tokenized value from a number.')
    reverse_string: typing.Optional[list[TokenizationDefReverseStringParams]] = pydantic.Field(None, description='Un-encode a string potentially containing encoded tokens.')
    stringify_number: typing.Optional[list[TokenizationDefStringifyNumberParams]] = pydantic.Field(None, description="Stringify a number directly or lazily if it's a Token.\nIf it is an object (i.e., { Ref: 'SomeLogicalId' }), return it as-is.")

class TokenizationDefResolveParams(pydantic.BaseModel):
    obj: typing.Any = pydantic.Field(..., description='The object to resolve.\n')
    resolver: typing.Union[models.DefaultTokenResolverDef] = pydantic.Field(..., description='The resolver to apply to any resolvable tokens found.\n')
    scope: models.AnyResource = pydantic.Field(..., description='The scope from which resolution is performed.\n')
    preparing: typing.Optional[bool] = pydantic.Field(None, description='Whether the resolution is being executed during the prepare phase or not. Default: false\n')
    remove_empty: typing.Optional[bool] = pydantic.Field(None, description='Whether to remove undefined elements from arrays and objects when resolving. Default: true')
    ...

class TokenizationDefReverseParams(pydantic.BaseModel):
    x: typing.Any = pydantic.Field(..., description='-\n')
    fail_concat: typing.Optional[bool] = pydantic.Field(None, description='Fail if the given string is a concatenation. If ``false``, just return ``undefined``. Default: true')
    ...

class TokenizationDefReverseCompleteStringParams(pydantic.BaseModel):
    s: str = pydantic.Field(..., description='-')
    ...

class TokenizationDefReverseListParams(pydantic.BaseModel):
    l: typing.Sequence[str] = pydantic.Field(..., description='-')
    ...

class TokenizationDefReverseNumberParams(pydantic.BaseModel):
    n: typing.Union[int, float] = pydantic.Field(..., description='-')
    ...

class TokenizationDefReverseStringParams(pydantic.BaseModel):
    s: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.core.TokenizedStringFragmentsDefConfig]] = pydantic.Field(None)
    ...

class TokenizationDefStringifyNumberParams(pydantic.BaseModel):
    x: typing.Union[int, float] = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.TokenizedStringFragments
class TokenizedStringFragmentsDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['add_intrinsic', 'add_literal', 'add_token', 'join', 'map_tokens']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.TokenizedStringFragments'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[TokenizedStringFragmentsDefConfig] = pydantic.Field(None)


class TokenizedStringFragmentsDefConfig(pydantic.BaseModel):
    add_intrinsic: typing.Optional[list[TokenizedStringFragmentsDefAddIntrinsicParams]] = pydantic.Field(None, description='')
    add_literal: typing.Optional[list[TokenizedStringFragmentsDefAddLiteralParams]] = pydantic.Field(None, description='')
    add_token: typing.Optional[list[TokenizedStringFragmentsDefAddTokenParams]] = pydantic.Field(None, description='')
    join: typing.Optional[list[TokenizedStringFragmentsDefJoinParams]] = pydantic.Field(None, description='Combine the string fragments using the given joiner.\nIf there are any')
    map_tokens: typing.Optional[list[TokenizedStringFragmentsDefMapTokensParams]] = pydantic.Field(None, description='Apply a transformation function to all tokens in the string.')

class TokenizedStringFragmentsDefAddIntrinsicParams(pydantic.BaseModel):
    value: typing.Any = pydantic.Field(..., description='-')
    ...

class TokenizedStringFragmentsDefAddLiteralParams(pydantic.BaseModel):
    lit: typing.Any = pydantic.Field(..., description='-')
    ...

class TokenizedStringFragmentsDefAddTokenParams(pydantic.BaseModel):
    token: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...

class TokenizedStringFragmentsDefJoinParams(pydantic.BaseModel):
    concat: typing.Union[models.StringConcatDef] = pydantic.Field(..., description='-')
    ...

class TokenizedStringFragmentsDefMapTokensParams(pydantic.BaseModel):
    mapper: models.UnsupportedResource = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.core.TokenizedStringFragmentsDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.TreeInspector
class TreeInspectorDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['add_attribute']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.TreeInspector'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[TreeInspectorDefConfig] = pydantic.Field(None)


class TreeInspectorDefConfig(pydantic.BaseModel):
    add_attribute: typing.Optional[list[TreeInspectorDefAddAttributeParams]] = pydantic.Field(None, description='Adds attribute to bag.\nKeys should be added by convention to prevent conflicts\ni.e. L1 constructs will contain attributes with keys prefixed with aws:cdk:cloudformation')

class TreeInspectorDefAddAttributeParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='- key for metadata.\n')
    value: typing.Any = pydantic.Field(..., description='- value of metadata.')
    ...


#  autogenerated from aws_cdk.ValidationResult
class ValidationResultDef(BaseClass):
    error_message: typing.Optional[str] = pydantic.Field(None, description='-')
    results: typing.Optional[models.ValidationResultsDef] = pydantic.Field(None, description='-')
    _init_params: typing.ClassVar[list[str]] = ['error_message', 'results']
    _method_names: typing.ClassVar[list[str]] = ['assert_success', 'error_tree', 'prefix']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.ValidationResult'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[ValidationResultDefConfig] = pydantic.Field(None)


class ValidationResultDefConfig(pydantic.BaseModel):
    assert_success: typing.Optional[bool] = pydantic.Field(None, description='Turn a failed validation into an exception.')
    error_tree: typing.Optional[bool] = pydantic.Field(None, description='Return a string rendering of the tree of validation failures.')
    prefix: typing.Optional[list[ValidationResultDefPrefixParams]] = pydantic.Field(None, description='Wrap this result with an error message, if it concerns an error.')

class ValidationResultDefPrefixParams(pydantic.BaseModel):
    message: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.core.ValidationResultDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.ValidationResults
class ValidationResultsDef(BaseClass):
    results: typing.Optional[typing.Sequence[models.ValidationResultDef]] = pydantic.Field(None, description='-')
    _init_params: typing.ClassVar[list[str]] = ['results']
    _method_names: typing.ClassVar[list[str]] = ['collect', 'error_tree_list', 'wrap']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.ValidationResults'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[ValidationResultsDefConfig] = pydantic.Field(None)


class ValidationResultsDefConfig(pydantic.BaseModel):
    collect: typing.Optional[list[ValidationResultsDefCollectParams]] = pydantic.Field(None, description='')
    error_tree_list: typing.Optional[bool] = pydantic.Field(None, description='')
    wrap: typing.Optional[list[ValidationResultsDefWrapParams]] = pydantic.Field(None, description='Wrap up all validation results into a single tree node.\nIf there are failures in the collection, add a message, otherwise\nreturn a success.')

class ValidationResultsDefCollectParams(pydantic.BaseModel):
    result: models.ValidationResultDef = pydantic.Field(..., description='-')
    ...

class ValidationResultsDefWrapParams(pydantic.BaseModel):
    message: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.core.ValidationResultDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.AssetStaging
class AssetStagingDef(BaseConstruct):
    source_path: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The source file or directory to copy from.\n')
    extra_hash: typing.Optional[str] = pydantic.Field(None, description='Extra information to encode into the fingerprint (e.g. build instructions and other inputs). Default: - hash is only based on source content\n')
    asset_hash: typing.Optional[str] = pydantic.Field(None, description='Specify a custom hash for this asset. If ``assetHashType`` is set it must be set to ``AssetHashType.CUSTOM``. For consistency, this custom hash will be SHA256 hashed and encoded as hex. The resulting hash will be the asset hash. NOTE: the hash is used in order to identify a specific revision of the asset, and used for optimizing and caching deployment activities related to this asset such as packaging, uploading to Amazon S3, etc. If you chose to customize the hash, you will need to make sure it is updated every time the asset changes, or otherwise it is possible that some deployments will not be invalidated. Default: - based on ``assetHashType``\n')
    asset_hash_type: typing.Optional[aws_cdk.AssetHashType] = pydantic.Field(None, description='Specifies the type of hash to calculate for this asset. If ``assetHash`` is configured, this option must be ``undefined`` or ``AssetHashType.CUSTOM``. Default: - the default is ``AssetHashType.SOURCE``, but if ``assetHash`` is explicitly specified this value defaults to ``AssetHashType.CUSTOM``.\n')
    bundling: typing.Union[models.BundlingOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Bundle the asset by executing a command in a Docker container or a custom bundling provider. The asset path will be mounted at ``/asset-input``. The Docker container is responsible for putting content at ``/asset-output``. The content at ``/asset-output`` will be zipped and used as the final asset. Default: - uploaded as-is to S3 if the asset is a regular file or a .zip file, archived into a .zip file and uploaded to S3 otherwise\n')
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='File paths matching the patterns will be excluded. See ``ignoreMode`` to set the matching behavior. Has no effect on Assets bundled using the ``bundling`` property. Default: - nothing is excluded\n')
    follow: typing.Optional[aws_cdk.SymlinkFollowMode] = pydantic.Field(None, description='A strategy for how to handle symlinks. Default: SymlinkFollowMode.NEVER\n')
    ignore_mode: typing.Optional[aws_cdk.IgnoreMode] = pydantic.Field(None, description='The ignore behavior to use for ``exclude`` patterns. Default: IgnoreMode.GLOB')
    _init_params: typing.ClassVar[list[str]] = ['source_path', 'extra_hash', 'asset_hash', 'asset_hash_type', 'bundling', 'exclude', 'follow', 'ignore_mode']
    _method_names: typing.ClassVar[list[str]] = ['relative_staged_path']
    _classmethod_names: typing.ClassVar[list[str]] = ['clear_asset_hash_cache']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.AssetStaging'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[AssetStagingDefConfig] = pydantic.Field(None)


class AssetStagingDefConfig(pydantic.BaseModel):
    clear_asset_hash_cache: typing.Optional[bool] = pydantic.Field(None, description='Clears the asset hash cache.')
    relative_staged_path: typing.Optional[list[AssetStagingDefRelativeStagedPathParams]] = pydantic.Field(None, description='Return the path to the staged asset, relative to the Cloud Assembly (manifest) directory of the given stack.\nOnly returns a relative path if the asset was staged, returns an absolute path if\nit was not staged.\n\nA bundled asset might end up in the outDir and still not count as\n"staged"; if asset staging is disabled we\'re technically expected to\nreference source directories, but we don\'t have a source directory for the\nbundled outputs (as the bundle output is written to a temporary\ndirectory). Nevertheless, we will still return an absolute path.\n\nA non-obvious directory layout may look like this::\n\n     CLOUD ASSEMBLY ROOT\n       +-- asset.12345abcdef/\n       +-- assembly-Stage\n             +-- MyStack.template.json\n             +-- MyStack.assets.json <- will contain { "path": "../asset.12345abcdef" }')

class AssetStagingDefRelativeStagedPathParams(pydantic.BaseModel):
    stack: models.StackDef = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.CustomResource
class CustomResourceDef(BaseConstruct):
    service_token: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The ARN of the provider which implements this custom resource type. You can implement a provider by listening to raw AWS CloudFormation events and specify the ARN of an SNS topic (``topic.topicArn``) or the ARN of an AWS Lambda function (``lambda.functionArn``) or use the CDK's custom `resource provider framework <https://docs.aws.amazon.com/cdk/api/latest/docs/custom-resources-readme.html>`_ which makes it easier to implement robust providers. Provider framework:: // use the provider framework from aws-cdk/custom-resources: const provider = new customresources.Provider(this, 'ResourceProvider', { onEventHandler, isCompleteHandler, // optional }); new CustomResource(this, 'MyResource', { serviceToken: provider.serviceToken, }); AWS Lambda function (not recommended to use AWS Lambda Functions directly, see the module README):: // invoke an AWS Lambda function when a lifecycle event occurs: new CustomResource(this, 'MyResource', { serviceToken: myFunction.functionArn, }); SNS topic (not recommended to use AWS Lambda Functions directly, see the module README):: // publish lifecycle events to an SNS topic: new CustomResource(this, 'MyResource', { serviceToken: myTopic.topicArn, });\n")
    pascal_case_properties: typing.Optional[bool] = pydantic.Field(None, description='Convert all property keys to pascal case. Default: false\n')
    properties: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Properties to pass to the Lambda. Default: - No properties.\n')
    removal_policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='The policy to apply when this resource is removed from the application. Default: cdk.RemovalPolicy.Destroy\n')
    resource_type: typing.Optional[str] = pydantic.Field(None, description='For custom resources, you can specify AWS::CloudFormation::CustomResource (the default) as the resource type, or you can specify your own resource type name. For example, you can use "Custom::MyCustomResourceTypeName". Custom resource type names must begin with "Custom::" and can include alphanumeric characters and the following characters: _@-. You can specify a custom resource type name up to a maximum length of 60 characters. You cannot change the type during an update. Using your own resource type names helps you quickly differentiate the types of custom resources in your stack. For example, if you had two custom resources that conduct two different ping tests, you could name their type as Custom::PingTester to make them easily identifiable as ping testers (instead of using AWS::CloudFormation::CustomResource). Default: - AWS::CloudFormation::CustomResource')
    _init_params: typing.ClassVar[list[str]] = ['service_token', 'pascal_case_properties', 'properties', 'removal_policy', 'resource_type']
    _method_names: typing.ClassVar[list[str]] = ['apply_removal_policy', 'get_att', 'get_att_string']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CustomResource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CustomResourceDefConfig] = pydantic.Field(None)


class CustomResourceDefConfig(pydantic.BaseModel):
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CustomResourceDefGetAttParams]] = pydantic.Field(None, description='Returns the value of an attribute of the custom resource of an arbitrary type.\nAttributes are returned from the custom resource provider through the\n``Data`` map where the key is the attribute name.')
    get_att_string: typing.Optional[list[CustomResourceDefGetAttStringParams]] = pydantic.Field(None, description='Returns the value of an attribute of the custom resource of type string.\nAttributes are returned from the custom resource provider through the\n``Data`` map where the key is the attribute name.')

class CustomResourceDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class CustomResourceDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='the name of the attribute.\n')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CustomResourceDefGetAttStringParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='the name of the attribute.\n')
    ...


#  autogenerated from aws_cdk.CustomResourceProvider
class CustomResourceProviderDef(BaseConstruct):
    code_directory: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="A local file system directory with the provider's code. The code will be bundled into a zip asset and wired to the provider's AWS Lambda function.\n")
    runtime: typing.Union[aws_cdk.CustomResourceProviderRuntime, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS Lambda runtime and version to use for the provider.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the function. Default: - No description.\n')
    environment: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Key-value pairs that are passed to Lambda as Environment. Default: - No environment variables.\n')
    memory_size: typing.Optional[models.SizeDef] = pydantic.Field(None, description="The amount of memory that your function has access to. Increasing the function's memory also increases its CPU allocation. Default: Size.mebibytes(128)\n")
    policy_statements: typing.Optional[typing.Sequence[typing.Any]] = pydantic.Field(None, description="A set of IAM policy statements to include in the inline policy of the provider's lambda function. **Please note**: these are direct IAM JSON policy blobs, *not* ``iam.PolicyStatement`` objects like you will see in the rest of the CDK. Default: - no additional inline policy\n")
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='AWS Lambda timeout for the provider. Default: Duration.minutes(15)\n')
    use_cfn_response_wrapper: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the cloudformation response wrapper (``nodejs-entrypoint.ts``) is used. If set to ``true``, ``nodejs-entrypoint.js`` is bundled in the same asset as the custom resource and set as the entrypoint. If set to ``false``, the custom resource provided is the entrypoint. Default: - ``true`` if ``inlineCode: false`` and ``false`` otherwise.')
    _init_params: typing.ClassVar[list[str]] = ['code_directory', 'runtime', 'description', 'environment', 'memory_size', 'policy_statements', 'timeout', 'use_cfn_response_wrapper']
    _method_names: typing.ClassVar[list[str]] = ['add_to_role_policy']
    _classmethod_names: typing.ClassVar[list[str]] = ['get_or_create', 'get_or_create_provider']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CustomResourceProvider'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CustomResourceProviderDefConfig] = pydantic.Field(None)


class CustomResourceProviderDefConfig(pydantic.BaseModel):
    add_to_role_policy: typing.Optional[list[CustomResourceProviderDefAddToRolePolicyParams]] = pydantic.Field(None, description="Add an IAM policy statement to the inline policy of the provider's lambda function's role.\n**Please note**: this is a direct IAM JSON policy blob, *not* a ``iam.PolicyStatement``\nobject like you will see in the rest of the CDK.")
    get_or_create: typing.Optional[list[CustomResourceProviderDefGetOrCreateParams]] = pydantic.Field(None, description='Returns a stack-level singleton ARN (service token) for the custom resource provider.')
    get_or_create_provider: typing.Optional[list[CustomResourceProviderDefGetOrCreateProviderParams]] = pydantic.Field(None, description='Returns a stack-level singleton for the custom resource provider.')

class CustomResourceProviderDefAddToRolePolicyParams(pydantic.BaseModel):
    statement: typing.Any = pydantic.Field(..., description='-\n\nExample::\n\n    # my_provider: CustomResourceProvider\n\n\n    my_provider.add_to_role_policy({\n        "Effect": "Allow",\n        "Action": "s3:GetObject",\n        "Resource": "*"\n    })\n')
    ...

class CustomResourceProviderDefGetOrCreateParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='Construct scope.\n')
    uniqueid: str = pydantic.Field(..., description='A globally unique id that will be used for the stack-level construct.\n')
    code_directory: str = pydantic.Field(..., description="A local file system directory with the provider's code. The code will be bundled into a zip asset and wired to the provider's AWS Lambda function.\n")
    runtime: aws_cdk.CustomResourceProviderRuntime = pydantic.Field(..., description='The AWS Lambda runtime and version to use for the provider.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the function. Default: - No description.\n')
    environment: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Key-value pairs that are passed to Lambda as Environment. Default: - No environment variables.\n')
    memory_size: typing.Optional[models.SizeDef] = pydantic.Field(None, description="The amount of memory that your function has access to. Increasing the function's memory also increases its CPU allocation. Default: Size.mebibytes(128)\n")
    policy_statements: typing.Optional[typing.Sequence[typing.Any]] = pydantic.Field(None, description="A set of IAM policy statements to include in the inline policy of the provider's lambda function. **Please note**: these are direct IAM JSON policy blobs, *not* ``iam.PolicyStatement`` objects like you will see in the rest of the CDK. Default: - no additional inline policy\n")
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='AWS Lambda timeout for the provider. Default: Duration.minutes(15)\n')
    use_cfn_response_wrapper: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the cloudformation response wrapper (``nodejs-entrypoint.ts``) is used. If set to ``true``, ``nodejs-entrypoint.js`` is bundled in the same asset as the custom resource and set as the entrypoint. If set to ``false``, the custom resource provided is the entrypoint. Default: - ``true`` if ``inlineCode: false`` and ``false`` otherwise.\n')
    ...

class CustomResourceProviderDefGetOrCreateProviderParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='Construct scope.\n')
    uniqueid: str = pydantic.Field(..., description='A globally unique id that will be used for the stack-level construct.\n')
    code_directory: str = pydantic.Field(..., description="A local file system directory with the provider's code. The code will be bundled into a zip asset and wired to the provider's AWS Lambda function.\n")
    runtime: aws_cdk.CustomResourceProviderRuntime = pydantic.Field(..., description='The AWS Lambda runtime and version to use for the provider.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the function. Default: - No description.\n')
    environment: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Key-value pairs that are passed to Lambda as Environment. Default: - No environment variables.\n')
    memory_size: typing.Optional[models.SizeDef] = pydantic.Field(None, description="The amount of memory that your function has access to. Increasing the function's memory also increases its CPU allocation. Default: Size.mebibytes(128)\n")
    policy_statements: typing.Optional[typing.Sequence[typing.Any]] = pydantic.Field(None, description="A set of IAM policy statements to include in the inline policy of the provider's lambda function. **Please note**: these are direct IAM JSON policy blobs, *not* ``iam.PolicyStatement`` objects like you will see in the rest of the CDK. Default: - no additional inline policy\n")
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='AWS Lambda timeout for the provider. Default: Duration.minutes(15)\n')
    use_cfn_response_wrapper: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the cloudformation response wrapper (``nodejs-entrypoint.ts``) is used. If set to ``true``, ``nodejs-entrypoint.js`` is bundled in the same asset as the custom resource and set as the entrypoint. If set to ``false``, the custom resource provided is the entrypoint. Default: - ``true`` if ``inlineCode: false`` and ``false`` otherwise.\n')
    return_config: typing.Optional[list[models.core.CustomResourceProviderDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.NestedStack
class NestedStackDef(BaseConstruct):
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the stack. Default: - No description.\n')
    notification_arns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The Simple Notification Service (SNS) topics to publish stack related events. Default: - notifications are not sent for this stack.\n')
    parameters: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='The set value pairs that represent the parameters passed to CloudFormation when this nested stack is created. Each parameter has a name corresponding to a parameter defined in the embedded template and a value representing the value that you want to set for the parameter. The nested stack construct will automatically synthesize parameters in order to bind references from the parent stack(s) into the nested stack. Default: - no user-defined parameters are passed to the nested stack\n')
    removal_policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='Policy to apply when the nested stack is removed. The default is ``Destroy``, because all Removal Policies of resources inside the Nested Stack should already have been set correctly. You normally should not need to set this value. Default: RemovalPolicy.DESTROY\n')
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The length of time that CloudFormation waits for the nested stack to reach the CREATE_COMPLETE state. When CloudFormation detects that the nested stack has reached the CREATE_COMPLETE state, it marks the nested stack resource as CREATE_COMPLETE in the parent stack and resumes creating the parent stack. If the timeout period expires before the nested stack reaches CREATE_COMPLETE, CloudFormation marks the nested stack as failed and rolls back both the nested stack and parent stack. Default: - no timeout')
    _init_params: typing.ClassVar[list[str]] = ['description', 'notification_arns', 'parameters', 'removal_policy', 'timeout']
    _method_names: typing.ClassVar[list[str]] = ['add_dependency', 'add_metadata', 'add_transform', 'export_string_list_value', 'export_value', 'format_arn', 'get_logical_id', 'regional_fact', 'rename_logical_id', 'report_missing_context_key', 'resolve', 'set_parameter', 'split_arn']
    _classmethod_names: typing.ClassVar[list[str]] = ['of']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.NestedStack'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[NestedStackDefConfig] = pydantic.Field(None)


class NestedStackDefConfig(pydantic.BaseModel):
    add_dependency: typing.Optional[list[NestedStackDefAddDependencyParams]] = pydantic.Field(None, description='Add a dependency between this stack and another stack.\nThis can be used to define dependencies between any two stacks within an\napp, and also supports nested stacks.')
    add_metadata: typing.Optional[list[NestedStackDefAddMetadataParams]] = pydantic.Field(None, description='Adds an arbitary key-value pair, with information you want to record about the stack.\nThese get translated to the Metadata section of the generated template.')
    add_transform: typing.Optional[list[NestedStackDefAddTransformParams]] = pydantic.Field(None, description='Add a Transform to this stack. A Transform is a macro that AWS CloudFormation uses to process your template.\nDuplicate values are removed when stack is synthesized.')
    export_string_list_value: typing.Optional[list[NestedStackDefExportStringListValueParams]] = pydantic.Field(None, description="Create a CloudFormation Export for a string list value.\nReturns a string list representing the corresponding ``Fn.importValue()``\nexpression for this Export. The export expression is automatically wrapped with an\n``Fn::Join`` and the import value with an ``Fn::Split``, since CloudFormation can only\nexport strings. You can control the name for the export by passing the ``name`` option.\n\nIf you don't supply a value for ``name``, the value you're exporting must be\na Resource attribute (for example: ``bucket.bucketName``) and it will be\ngiven the same name as the automatic cross-stack reference that would be created\nif you used the attribute in another Stack.\n\nOne of the uses for this method is to *remove* the relationship between\ntwo Stacks established by automatic cross-stack references. It will\ntemporarily ensure that the CloudFormation Export still exists while you\nremove the reference from the consuming stack. After that, you can remove\nthe resource and the manual export.\n\nSee ``exportValue`` for an example of this process.")
    export_value: typing.Optional[list[NestedStackDefExportValueParams]] = pydantic.Field(None, description="Create a CloudFormation Export for a string value.\nReturns a string representing the corresponding ``Fn.importValue()``\nexpression for this Export. You can control the name for the export by\npassing the ``name`` option.\n\nIf you don't supply a value for ``name``, the value you're exporting must be\na Resource attribute (for example: ``bucket.bucketName``) and it will be\ngiven the same name as the automatic cross-stack reference that would be created\nif you used the attribute in another Stack.\n\nOne of the uses for this method is to *remove* the relationship between\ntwo Stacks established by automatic cross-stack references. It will\ntemporarily ensure that the CloudFormation Export still exists while you\nremove the reference from the consuming stack. After that, you can remove\nthe resource and the manual export.\n\n\nExample\n\nHere is how the process works. Let's say there are two stacks,\n``producerStack`` and ``consumerStack``, and ``producerStack`` has a bucket\ncalled ``bucket``, which is referenced by ``consumerStack`` (perhaps because\nan AWS Lambda Function writes into it, or something like that).\n\nIt is not safe to remove ``producerStack.bucket`` because as the bucket is being\ndeleted, ``consumerStack`` might still be using it.\n\nInstead, the process takes two deployments:\n\n\nDeployment 1: break the relationship\n\n- Make sure ``consumerStack`` no longer references ``bucket.bucketName`` (maybe the consumer\n  stack now uses its own bucket, or it writes to an AWS DynamoDB table, or maybe you just\n  remove the Lambda Function altogether).\n- In the ``ProducerStack`` class, call ``this.exportValue(this.bucket.bucketName)``. This\n  will make sure the CloudFormation Export continues to exist while the relationship\n  between the two stacks is being broken.\n- Deploy (this will effectively only change the ``consumerStack``, but it's safe to deploy both).\n\n\n\nDeployment 2: remove the bucket resource\n\n- You are now free to remove the ``bucket`` resource from ``producerStack``.\n- Don't forget to remove the ``exportValue()`` call as well.\n- Deploy again (this time only the ``producerStack`` will be changed -- the bucket will be deleted).")
    format_arn: typing.Optional[list[NestedStackDefFormatArnParams]] = pydantic.Field(None, description="Creates an ARN from components.\nIf ``partition``, ``region`` or ``account`` are not specified, the stack's\npartition, region and account will be used.\n\nIf any component is the empty string, an empty string will be inserted\ninto the generated ARN at the location that component corresponds to.\n\nThe ARN will be formatted as follows:\n\narn:{partition}:{service}:{region}:{account}:{resource}{sep}{resource-name}\n\nThe required ARN pieces that are omitted will be taken from the stack that\nthe 'scope' is attached to. If all ARN pieces are supplied, the supplied scope\ncan be 'undefined'.")
    get_logical_id: typing.Optional[list[NestedStackDefGetLogicalIdParams]] = pydantic.Field(None, description='Allocates a stack-unique CloudFormation-compatible logical identity for a specific resource.\nThis method is called when a ``CfnElement`` is created and used to render the\ninitial logical identity of resources. Logical ID renames are applied at\nthis stage.\n\nThis method uses the protected method ``allocateLogicalId`` to render the\nlogical ID for an element. To modify the naming scheme, extend the ``Stack``\nclass and override this method.')
    of: typing.Optional[list[NestedStackDefOfParams]] = pydantic.Field(None, description='Looks up the first stack scope in which ``construct`` is defined.\nFails if there is no stack up the tree.')
    regional_fact: typing.Optional[list[NestedStackDefRegionalFactParams]] = pydantic.Field(None, description='Look up a fact value for the given fact for the region of this stack.\nWill return a definite value only if the region of the current stack is resolved.\nIf not, a lookup map will be added to the stack and the lookup will be done at\nCDK deployment time.\n\nWhat regions will be included in the lookup map is controlled by the\n``@aws-cdk/core:target-partitions`` context value: it must be set to a list\nof partitions, and only regions from the given partitions will be included.\nIf no such context key is set, all regions will be included.\n\nThis function is intended to be used by construct library authors. Application\nbuilders can rely on the abstractions offered by construct libraries and do\nnot have to worry about regional facts.\n\nIf ``defaultValue`` is not given, it is an error if the fact is unknown for\nthe given region.')
    rename_logical_id: typing.Optional[list[NestedStackDefRenameLogicalIdParams]] = pydantic.Field(None, description='Rename a generated logical identities.\nTo modify the naming scheme strategy, extend the ``Stack`` class and\noverride the ``allocateLogicalId`` method.')
    report_missing_context_key: typing.Optional[list[NestedStackDefReportMissingContextKeyParams]] = pydantic.Field(None, description='Indicate that a context key was expected.\nContains instructions which will be emitted into the cloud assembly on how\nthe key should be supplied.')
    resolve: typing.Optional[list[NestedStackDefResolveParams]] = pydantic.Field(None, description='Resolve a tokenized value in the context of the current stack.')
    set_parameter: typing.Optional[list[NestedStackDefSetParameterParams]] = pydantic.Field(None, description='Assign a value to one of the nested stack parameters.')
    split_arn: typing.Optional[list[NestedStackDefSplitArnParams]] = pydantic.Field(None, description="Splits the provided ARN into its components.\nWorks both if 'arn' is a string like 'arn:aws:s3:::bucket',\nand a Token representing a dynamic CloudFormation expression\n(in which case the returned components will also be dynamic CloudFormation expressions,\nencoded as Tokens).")
    synthesizer_config: typing.Optional[models._interface_methods.CoreIStackSynthesizerDefConfig] = pydantic.Field(None)

class NestedStackDefAddDependencyParams(pydantic.BaseModel):
    target: models.StackDef = pydantic.Field(..., description='-\n')
    reason: typing.Optional[str] = pydantic.Field(None, description='-')
    ...

class NestedStackDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n')
    ...

class NestedStackDefAddTransformParams(pydantic.BaseModel):
    transform: str = pydantic.Field(..., description='The transform to add.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/transform-section-structure.html\n\nExample::\n\n    # stack: Stack\n\n\n    stack.add_transform("AWS::Serverless-2016-10-31")\n')
    ...

class NestedStackDefExportStringListValueParams(pydantic.BaseModel):
    exported_value: typing.Any = pydantic.Field(..., description='-\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the export to create. Default: - A name is automatically chosen')
    ...

class NestedStackDefExportValueParams(pydantic.BaseModel):
    exported_value: typing.Any = pydantic.Field(..., description='-\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the export to create. Default: - A name is automatically chosen')
    ...

class NestedStackDefFormatArnParams(pydantic.BaseModel):
    resource: str = pydantic.Field(..., description='Resource type (e.g. "table", "autoScalingGroup", "certificate"). For some resource types, e.g. S3 buckets, this field defines the bucket name.\n')
    service: str = pydantic.Field(..., description="The service namespace that identifies the AWS product (for example, 's3', 'iam', 'codepipline').\n")
    account: typing.Optional[str] = pydantic.Field(None, description="The ID of the AWS account that owns the resource, without the hyphens. For example, 123456789012. Note that the ARNs for some resources don't require an account number, so this component might be omitted. Default: The account the stack is deployed to.\n")
    arn_format: typing.Optional[aws_cdk.ArnFormat] = pydantic.Field(None, description='The specific ARN format to use for this ARN value. Default: - uses value of ``sep`` as the separator for formatting, ``ArnFormat.SLASH_RESOURCE_NAME`` if that property was also not provided\n')
    partition: typing.Optional[str] = pydantic.Field(None, description='The partition that the resource is in. For standard AWS regions, the partition is aws. If you have resources in other partitions, the partition is aws-partitionname. For example, the partition for resources in the China (Beijing) region is aws-cn. Default: The AWS partition the stack is deployed to.\n')
    region: typing.Optional[str] = pydantic.Field(None, description='The region the resource resides in. Note that the ARNs for some resources do not require a region, so this component might be omitted. Default: The region the stack is deployed to.\n')
    resource_name: typing.Optional[str] = pydantic.Field(None, description='Resource name or path within the resource (i.e. S3 bucket object key) or a wildcard such as ``"*"``. This is service-dependent.')
    ...

class NestedStackDefGetLogicalIdParams(pydantic.BaseModel):
    element: models.CfnElementDef = pydantic.Field(..., description='The CloudFormation element for which a logical identity is needed.')
    ...

class NestedStackDefOfParams(pydantic.BaseModel):
    construct_: models.AnyResource = pydantic.Field(..., description='The construct to start the search from.', alias='construct')
    return_config: typing.Optional[list[models.core.StackDefConfig]] = pydantic.Field(None)
    ...

class NestedStackDefRegionalFactParams(pydantic.BaseModel):
    fact_name: str = pydantic.Field(..., description='-\n')
    default_value: typing.Optional[str] = pydantic.Field(None, description='-')
    ...

class NestedStackDefRenameLogicalIdParams(pydantic.BaseModel):
    old_id: str = pydantic.Field(..., description='-\n')
    new_id: str = pydantic.Field(..., description='-')
    ...

class NestedStackDefReportMissingContextKeyParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='The missing context key.\n')
    props: typing.Union[models.cloud_assembly_schema.AmiContextQueryDef, dict[str, typing.Any], models.cloud_assembly_schema.AvailabilityZonesContextQueryDef, models.cloud_assembly_schema.HostedZoneContextQueryDef, models.cloud_assembly_schema.SSMParameterContextQueryDef, models.cloud_assembly_schema.VpcContextQueryDef, models.cloud_assembly_schema.EndpointServiceAvailabilityZonesContextQueryDef, models.cloud_assembly_schema.LoadBalancerContextQueryDef, models.cloud_assembly_schema.LoadBalancerListenerContextQueryDef, models.cloud_assembly_schema.SecurityGroupContextQueryDef, models.cloud_assembly_schema.KeyContextQueryDef, models.cloud_assembly_schema.PluginContextQueryDef] = pydantic.Field(..., description='A set of provider-specific options.\n')
    provider: aws_cdk.cloud_assembly_schema.ContextProvider = pydantic.Field(..., description='The provider from which we expect this context key to be obtained.')
    ...

class NestedStackDefResolveParams(pydantic.BaseModel):
    obj: typing.Any = pydantic.Field(..., description='-')
    ...

class NestedStackDefSetParameterParams(pydantic.BaseModel):
    name: str = pydantic.Field(..., description='The parameter name (ID).\n')
    value: str = pydantic.Field(..., description='The value to assign.')
    ...

class NestedStackDefSplitArnParams(pydantic.BaseModel):
    arn: str = pydantic.Field(..., description='the ARN to split into its components.\n')
    arn_format: aws_cdk.ArnFormat = pydantic.Field(..., description="the expected format of 'arn' - depends on what format the service 'arn' represents uses.")
    ...


#  autogenerated from aws_cdk.Stack
class StackDef(BaseConstruct):
    analytics_reporting: typing.Optional[bool] = pydantic.Field(None, description="Include runtime versioning information in this Stack. Default: ``analyticsReporting`` setting of containing ``App``, or value of 'aws:cdk:version-reporting' context key\n")
    cross_region_references: typing.Optional[bool] = pydantic.Field(None, description='Enable this flag to allow native cross region stack references. Enabling this will create a CloudFormation custom resource in both the producing stack and consuming stack in order to perform the export/import This feature is currently experimental Default: false\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the stack. Default: - No description.\n')
    env: typing.Union[models.EnvironmentDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The AWS environment (account/region) where this stack will be deployed. Set the ``region``/``account`` fields of ``env`` to either a concrete value to select the indicated environment (recommended for production stacks), or to the values of environment variables ``CDK_DEFAULT_REGION``/``CDK_DEFAULT_ACCOUNT`` to let the target environment depend on the AWS credentials/configuration that the CDK CLI is executed under (recommended for development stacks). If the ``Stack`` is instantiated inside a ``Stage``, any undefined ``region``/``account`` fields from ``env`` will default to the same field on the encompassing ``Stage``, if configured there. If either ``region`` or ``account`` are not set nor inherited from ``Stage``, the Stack will be considered "*environment-agnostic*"". Environment-agnostic stacks can be deployed to any environment but may not be able to take advantage of all features of the CDK. For example, they will not be able to use environmental context lookups such as ``ec2.Vpc.fromLookup`` and will not automatically translate Service Principals to the right format based on the environment\'s AWS partition, and other such enhancements. Default: - The environment of the containing ``Stage`` if available, otherwise create the stack will be environment-agnostic.\n')
    permissions_boundary: typing.Optional[models.PermissionsBoundaryDef] = pydantic.Field(None, description='Options for applying a permissions boundary to all IAM Roles and Users created within this Stage. Default: - no permissions boundary is applied\n')
    stack_name: typing.Optional[str] = pydantic.Field(None, description='Name to deploy the stack with. Default: - Derived from construct path.\n')
    suppress_template_indentation: typing.Optional[bool] = pydantic.Field(None, description='Enable this flag to suppress indentation in generated CloudFormation templates. If not specified, the value of the ``@aws-cdk/core:suppressTemplateIndentation`` context key will be used. If that is not specified, then the default value ``false`` will be used. Default: - the value of ``@aws-cdk/core:suppressTemplateIndentation``, or ``false`` if that is not set.\n')
    synthesizer: typing.Optional[typing.Union[models.BootstraplessSynthesizerDef, models.CliCredentialsStackSynthesizerDef, models.DefaultStackSynthesizerDef, models.LegacyStackSynthesizerDef, models.NestedStackSynthesizerDef, models.StackSynthesizerDef]] = pydantic.Field(None, description='Synthesis method to use while deploying this stack. The Stack Synthesizer controls aspects of synthesis and deployment, like how assets are referenced and what IAM roles to use. For more information, see the README of the main CDK package. If not specified, the ``defaultStackSynthesizer`` from ``App`` will be used. If that is not specified, ``DefaultStackSynthesizer`` is used if ``@aws-cdk/core:newStyleStackSynthesis`` is set to ``true`` or the CDK major version is v2. In CDK v1 ``LegacyStackSynthesizer`` is the default if no other synthesizer is specified. Default: - The synthesizer specified on ``App``, or ``DefaultStackSynthesizer`` otherwise.\n')
    tags: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Stack tags that will be applied to all the taggable resources and the stack itself. Default: {}\n')
    termination_protection: typing.Optional[bool] = pydantic.Field(None, description='Whether to enable termination protection for this stack. Default: false')
    _init_params: typing.ClassVar[list[str]] = ['analytics_reporting', 'cross_region_references', 'description', 'env', 'permissions_boundary', 'stack_name', 'suppress_template_indentation', 'synthesizer', 'tags', 'termination_protection']
    _method_names: typing.ClassVar[list[str]] = ['add_dependency', 'add_metadata', 'add_transform', 'export_string_list_value', 'export_value', 'format_arn', 'get_logical_id', 'regional_fact', 'rename_logical_id', 'report_missing_context_key', 'resolve', 'split_arn']
    _classmethod_names: typing.ClassVar[list[str]] = ['of']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Stack'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[StackDefConfig] = pydantic.Field(None)


class StackDefConfig(pydantic.BaseModel):
    add_dependency: typing.Optional[list[StackDefAddDependencyParams]] = pydantic.Field(None, description='Add a dependency between this stack and another stack.\nThis can be used to define dependencies between any two stacks within an\napp, and also supports nested stacks.')
    add_metadata: typing.Optional[list[StackDefAddMetadataParams]] = pydantic.Field(None, description='Adds an arbitary key-value pair, with information you want to record about the stack.\nThese get translated to the Metadata section of the generated template.')
    add_transform: typing.Optional[list[StackDefAddTransformParams]] = pydantic.Field(None, description='Add a Transform to this stack. A Transform is a macro that AWS CloudFormation uses to process your template.\nDuplicate values are removed when stack is synthesized.')
    export_string_list_value: typing.Optional[list[StackDefExportStringListValueParams]] = pydantic.Field(None, description="Create a CloudFormation Export for a string list value.\nReturns a string list representing the corresponding ``Fn.importValue()``\nexpression for this Export. The export expression is automatically wrapped with an\n``Fn::Join`` and the import value with an ``Fn::Split``, since CloudFormation can only\nexport strings. You can control the name for the export by passing the ``name`` option.\n\nIf you don't supply a value for ``name``, the value you're exporting must be\na Resource attribute (for example: ``bucket.bucketName``) and it will be\ngiven the same name as the automatic cross-stack reference that would be created\nif you used the attribute in another Stack.\n\nOne of the uses for this method is to *remove* the relationship between\ntwo Stacks established by automatic cross-stack references. It will\ntemporarily ensure that the CloudFormation Export still exists while you\nremove the reference from the consuming stack. After that, you can remove\nthe resource and the manual export.\n\nSee ``exportValue`` for an example of this process.")
    export_value: typing.Optional[list[StackDefExportValueParams]] = pydantic.Field(None, description="Create a CloudFormation Export for a string value.\nReturns a string representing the corresponding ``Fn.importValue()``\nexpression for this Export. You can control the name for the export by\npassing the ``name`` option.\n\nIf you don't supply a value for ``name``, the value you're exporting must be\na Resource attribute (for example: ``bucket.bucketName``) and it will be\ngiven the same name as the automatic cross-stack reference that would be created\nif you used the attribute in another Stack.\n\nOne of the uses for this method is to *remove* the relationship between\ntwo Stacks established by automatic cross-stack references. It will\ntemporarily ensure that the CloudFormation Export still exists while you\nremove the reference from the consuming stack. After that, you can remove\nthe resource and the manual export.\n\n\nExample\n\nHere is how the process works. Let's say there are two stacks,\n``producerStack`` and ``consumerStack``, and ``producerStack`` has a bucket\ncalled ``bucket``, which is referenced by ``consumerStack`` (perhaps because\nan AWS Lambda Function writes into it, or something like that).\n\nIt is not safe to remove ``producerStack.bucket`` because as the bucket is being\ndeleted, ``consumerStack`` might still be using it.\n\nInstead, the process takes two deployments:\n\n\nDeployment 1: break the relationship\n\n- Make sure ``consumerStack`` no longer references ``bucket.bucketName`` (maybe the consumer\n  stack now uses its own bucket, or it writes to an AWS DynamoDB table, or maybe you just\n  remove the Lambda Function altogether).\n- In the ``ProducerStack`` class, call ``this.exportValue(this.bucket.bucketName)``. This\n  will make sure the CloudFormation Export continues to exist while the relationship\n  between the two stacks is being broken.\n- Deploy (this will effectively only change the ``consumerStack``, but it's safe to deploy both).\n\n\n\nDeployment 2: remove the bucket resource\n\n- You are now free to remove the ``bucket`` resource from ``producerStack``.\n- Don't forget to remove the ``exportValue()`` call as well.\n- Deploy again (this time only the ``producerStack`` will be changed -- the bucket will be deleted).")
    format_arn: typing.Optional[list[StackDefFormatArnParams]] = pydantic.Field(None, description="Creates an ARN from components.\nIf ``partition``, ``region`` or ``account`` are not specified, the stack's\npartition, region and account will be used.\n\nIf any component is the empty string, an empty string will be inserted\ninto the generated ARN at the location that component corresponds to.\n\nThe ARN will be formatted as follows:\n\narn:{partition}:{service}:{region}:{account}:{resource}{sep}{resource-name}\n\nThe required ARN pieces that are omitted will be taken from the stack that\nthe 'scope' is attached to. If all ARN pieces are supplied, the supplied scope\ncan be 'undefined'.")
    get_logical_id: typing.Optional[list[StackDefGetLogicalIdParams]] = pydantic.Field(None, description='Allocates a stack-unique CloudFormation-compatible logical identity for a specific resource.\nThis method is called when a ``CfnElement`` is created and used to render the\ninitial logical identity of resources. Logical ID renames are applied at\nthis stage.\n\nThis method uses the protected method ``allocateLogicalId`` to render the\nlogical ID for an element. To modify the naming scheme, extend the ``Stack``\nclass and override this method.')
    of: typing.Optional[list[StackDefOfParams]] = pydantic.Field(None, description='Looks up the first stack scope in which ``construct`` is defined.\nFails if there is no stack up the tree.')
    regional_fact: typing.Optional[list[StackDefRegionalFactParams]] = pydantic.Field(None, description='Look up a fact value for the given fact for the region of this stack.\nWill return a definite value only if the region of the current stack is resolved.\nIf not, a lookup map will be added to the stack and the lookup will be done at\nCDK deployment time.\n\nWhat regions will be included in the lookup map is controlled by the\n``@aws-cdk/core:target-partitions`` context value: it must be set to a list\nof partitions, and only regions from the given partitions will be included.\nIf no such context key is set, all regions will be included.\n\nThis function is intended to be used by construct library authors. Application\nbuilders can rely on the abstractions offered by construct libraries and do\nnot have to worry about regional facts.\n\nIf ``defaultValue`` is not given, it is an error if the fact is unknown for\nthe given region.')
    rename_logical_id: typing.Optional[list[StackDefRenameLogicalIdParams]] = pydantic.Field(None, description='Rename a generated logical identities.\nTo modify the naming scheme strategy, extend the ``Stack`` class and\noverride the ``allocateLogicalId`` method.')
    report_missing_context_key: typing.Optional[list[StackDefReportMissingContextKeyParams]] = pydantic.Field(None, description='Indicate that a context key was expected.\nContains instructions which will be emitted into the cloud assembly on how\nthe key should be supplied.')
    resolve: typing.Optional[list[StackDefResolveParams]] = pydantic.Field(None, description='Resolve a tokenized value in the context of the current stack.')
    split_arn: typing.Optional[list[StackDefSplitArnParams]] = pydantic.Field(None, description="Splits the provided ARN into its components.\nWorks both if 'arn' is a string like 'arn:aws:s3:::bucket',\nand a Token representing a dynamic CloudFormation expression\n(in which case the returned components will also be dynamic CloudFormation expressions,\nencoded as Tokens).")
    synthesizer_config: typing.Optional[models._interface_methods.CoreIStackSynthesizerDefConfig] = pydantic.Field(None)

class StackDefAddDependencyParams(pydantic.BaseModel):
    target: models.StackDef = pydantic.Field(..., description='-\n')
    reason: typing.Optional[str] = pydantic.Field(None, description='-')
    ...

class StackDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n')
    ...

class StackDefAddTransformParams(pydantic.BaseModel):
    transform: str = pydantic.Field(..., description='The transform to add.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/transform-section-structure.html\n\nExample::\n\n    # stack: Stack\n\n\n    stack.add_transform("AWS::Serverless-2016-10-31")\n')
    ...

class StackDefExportStringListValueParams(pydantic.BaseModel):
    exported_value: typing.Any = pydantic.Field(..., description='-\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the export to create. Default: - A name is automatically chosen')
    ...

class StackDefExportValueParams(pydantic.BaseModel):
    exported_value: typing.Any = pydantic.Field(..., description='-\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the export to create. Default: - A name is automatically chosen')
    ...

class StackDefFormatArnParams(pydantic.BaseModel):
    resource: str = pydantic.Field(..., description='Resource type (e.g. "table", "autoScalingGroup", "certificate"). For some resource types, e.g. S3 buckets, this field defines the bucket name.\n')
    service: str = pydantic.Field(..., description="The service namespace that identifies the AWS product (for example, 's3', 'iam', 'codepipline').\n")
    account: typing.Optional[str] = pydantic.Field(None, description="The ID of the AWS account that owns the resource, without the hyphens. For example, 123456789012. Note that the ARNs for some resources don't require an account number, so this component might be omitted. Default: The account the stack is deployed to.\n")
    arn_format: typing.Optional[aws_cdk.ArnFormat] = pydantic.Field(None, description='The specific ARN format to use for this ARN value. Default: - uses value of ``sep`` as the separator for formatting, ``ArnFormat.SLASH_RESOURCE_NAME`` if that property was also not provided\n')
    partition: typing.Optional[str] = pydantic.Field(None, description='The partition that the resource is in. For standard AWS regions, the partition is aws. If you have resources in other partitions, the partition is aws-partitionname. For example, the partition for resources in the China (Beijing) region is aws-cn. Default: The AWS partition the stack is deployed to.\n')
    region: typing.Optional[str] = pydantic.Field(None, description='The region the resource resides in. Note that the ARNs for some resources do not require a region, so this component might be omitted. Default: The region the stack is deployed to.\n')
    resource_name: typing.Optional[str] = pydantic.Field(None, description='Resource name or path within the resource (i.e. S3 bucket object key) or a wildcard such as ``"*"``. This is service-dependent.')
    ...

class StackDefGetLogicalIdParams(pydantic.BaseModel):
    element: models.CfnElementDef = pydantic.Field(..., description='The CloudFormation element for which a logical identity is needed.')
    ...

class StackDefOfParams(pydantic.BaseModel):
    construct_: models.AnyResource = pydantic.Field(..., description='The construct to start the search from.', alias='construct')
    return_config: typing.Optional[list[models.core.StackDefConfig]] = pydantic.Field(None)
    ...

class StackDefRegionalFactParams(pydantic.BaseModel):
    fact_name: str = pydantic.Field(..., description='-\n')
    default_value: typing.Optional[str] = pydantic.Field(None, description='-')
    ...

class StackDefRenameLogicalIdParams(pydantic.BaseModel):
    old_id: str = pydantic.Field(..., description='-\n')
    new_id: str = pydantic.Field(..., description='-')
    ...

class StackDefReportMissingContextKeyParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='The missing context key.\n')
    props: typing.Union[models.cloud_assembly_schema.AmiContextQueryDef, dict[str, typing.Any], models.cloud_assembly_schema.AvailabilityZonesContextQueryDef, models.cloud_assembly_schema.HostedZoneContextQueryDef, models.cloud_assembly_schema.SSMParameterContextQueryDef, models.cloud_assembly_schema.VpcContextQueryDef, models.cloud_assembly_schema.EndpointServiceAvailabilityZonesContextQueryDef, models.cloud_assembly_schema.LoadBalancerContextQueryDef, models.cloud_assembly_schema.LoadBalancerListenerContextQueryDef, models.cloud_assembly_schema.SecurityGroupContextQueryDef, models.cloud_assembly_schema.KeyContextQueryDef, models.cloud_assembly_schema.PluginContextQueryDef] = pydantic.Field(..., description='A set of provider-specific options.\n')
    provider: aws_cdk.cloud_assembly_schema.ContextProvider = pydantic.Field(..., description='The provider from which we expect this context key to be obtained.')
    ...

class StackDefResolveParams(pydantic.BaseModel):
    obj: typing.Any = pydantic.Field(..., description='-')
    ...

class StackDefSplitArnParams(pydantic.BaseModel):
    arn: str = pydantic.Field(..., description='the ARN to split into its components.\n')
    arn_format: aws_cdk.ArnFormat = pydantic.Field(..., description="the expected format of 'arn' - depends on what format the service 'arn' represents uses.")
    ...


#  autogenerated from aws_cdk.Stage
class StageDef(BaseConstruct):
    env: typing.Union[models.EnvironmentDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Default AWS environment (account/region) for ``Stack``s in this ``Stage``. Stacks defined inside this ``Stage`` with either ``region`` or ``account`` missing from its env will use the corresponding field given here. If either ``region`` or ``account``is is not configured for ``Stack`` (either on the ``Stack`` itself or on the containing ``Stage``), the Stack will be *environment-agnostic*. Environment-agnostic stacks can be deployed to any environment, may not be able to take advantage of all features of the CDK. For example, they will not be able to use environmental context lookups, will not automatically translate Service Principals to the right format based on the environment's AWS partition, and other such enhancements. Default: - The environments should be configured on the ``Stack``s.\n")
    outdir: typing.Optional[str] = pydantic.Field(None, description='The output directory into which to emit synthesized artifacts. Can only be specified if this stage is the root stage (the app). If this is specified and this stage is nested within another stage, an error will be thrown. Default: - for nested stages, outdir will be determined as a relative directory to the outdir of the app. For apps, if outdir is not specified, a temporary directory will be created.\n')
    permissions_boundary: typing.Optional[models.PermissionsBoundaryDef] = pydantic.Field(None, description='Options for applying a permissions boundary to all IAM Roles and Users created within this Stage. Default: - no permissions boundary is applied\n')
    policy_validation_beta1: typing.Optional[typing.Sequence[models.UnsupportedResource]] = pydantic.Field(None, description='Validation plugins to run during synthesis. If any plugin reports any violation, synthesis will be interrupted and the report displayed to the user. Default: - no validation plugins are used\n')
    stage_name: typing.Optional[str] = pydantic.Field(None, description='Name of this stage. Default: - Derived from the id.')
    _init_params: typing.ClassVar[list[str]] = ['env', 'outdir', 'permissions_boundary', 'policy_validation_beta1', 'stage_name']
    _method_names: typing.ClassVar[list[str]] = ['synth']
    _classmethod_names: typing.ClassVar[list[str]] = ['of']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Stage'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[StageDefConfig] = pydantic.Field(None)


class StageDefConfig(pydantic.BaseModel):
    of: typing.Optional[list[StageDefOfParams]] = pydantic.Field(None, description='Return the stage this construct is contained with, if available.\nIf called\non a nested stage, returns its parent.')
    synth: typing.Optional[list[StageDefSynthParams]] = pydantic.Field(None, description='Synthesize this stage into a cloud assembly.\nOnce an assembly has been synthesized, it cannot be modified. Subsequent\ncalls will return the same assembly.')

class StageDefOfParams(pydantic.BaseModel):
    construct_: models.AnyResource = pydantic.Field(..., description='-', alias='construct')
    ...

class StageDefSynthParams(pydantic.BaseModel):
    force: typing.Optional[bool] = pydantic.Field(None, description='Force a re-synth, even if the stage has already been synthesized. This is used by tests to allow for incremental verification of the output. Do not use in production. Default: false\n')
    skip_validation: typing.Optional[bool] = pydantic.Field(None, description='Should we skip construct validation. Default: - false\n')
    validate_on_synthesis: typing.Optional[bool] = pydantic.Field(None, description='Whether the stack should be validated after synthesis to check for error metadata. Default: - false')
    return_config: typing.Optional[list[models.cx_api.CloudAssemblyDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.AppProps
class AppPropsDef(BaseStruct):
    analytics_reporting: typing.Optional[bool] = pydantic.Field(None, description="Include runtime versioning information in the Stacks of this app. Default: Value of 'aws:cdk:version-reporting' context key\n")
    auto_synth: typing.Optional[bool] = pydantic.Field(None, description="Automatically call ``synth()`` before the program exits. If you set this, you don't have to call ``synth()`` explicitly. Note that this feature is only available for certain programming languages, and calling ``synth()`` is still recommended. Default: true if running via CDK CLI (``CDK_OUTDIR`` is set), ``false`` otherwise\n")
    context: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Additional context values for the application. Context set by the CLI or the ``context`` key in ``cdk.json`` has precedence. Context can be read from any construct using ``node.getContext(key)``. Default: - no additional context\n')
    default_stack_synthesizer: typing.Optional[typing.Union[models.BootstraplessSynthesizerDef, models.CliCredentialsStackSynthesizerDef, models.DefaultStackSynthesizerDef, models.LegacyStackSynthesizerDef]] = pydantic.Field(None, description='The stack synthesizer to use by default for all Stacks in the App. The Stack Synthesizer controls aspects of synthesis and deployment, like how assets are referenced and what IAM roles to use. For more information, see the README of the main CDK package. Default: - A ``DefaultStackSynthesizer`` with default settings\n')
    outdir: typing.Optional[str] = pydantic.Field(None, description="The output directory into which to emit synthesized artifacts. You should never need to set this value. By default, the value you pass to the CLI's ``--output`` flag will be used, and if you change it to a different directory the CLI will fail to pick up the generated Cloud Assembly. This property is intended for internal and testing use. Default: - If this value is *not* set, considers the environment variable ``CDK_OUTDIR``. If ``CDK_OUTDIR`` is not defined, uses a temp directory.\n")
    policy_validation_beta1: typing.Optional[typing.Sequence[models.UnsupportedResource]] = pydantic.Field(None, description='Validation plugins to run after synthesis. Default: - no validation plugins\n')
    post_cli_context: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Additional context values for the application. Context provided here has precedence over context set by: - The CLI via --context - The ``context`` key in ``cdk.json`` - The ``AppProps.context`` property This property is recommended over the ``AppProps.context`` property since you can make final decision over which context value to take in your app. Context can be read from any construct using ``node.getContext(key)``. Default: - no additional context\n')
    stack_traces: typing.Optional[bool] = pydantic.Field(None, description='Include construct creation stack trace in the ``aws:cdk:trace`` metadata key of all constructs. Default: true stack traces are included unless ``aws:cdk:disable-stack-trace`` is set in the context.\n')
    tree_metadata: typing.Optional[bool] = pydantic.Field(None, description='Include construct tree metadata as part of the Cloud Assembly. Default: true\n\n:exampleMetadata: infused\n\nExample::\n\n    app = App(\n        default_stack_synthesizer=AppStagingSynthesizer.default_resources(\n            app_id="my-app-id",\n            deployment_identities=DeploymentIdentities.cli_credentials()\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['analytics_reporting', 'auto_synth', 'context', 'default_stack_synthesizer', 'outdir', 'policy_validation_beta1', 'post_cli_context', 'stack_traces', 'tree_metadata']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.AppProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.ArnComponents
class ArnComponentsDef(BaseStruct):
    resource: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Resource type (e.g. "table", "autoScalingGroup", "certificate"). For some resource types, e.g. S3 buckets, this field defines the bucket name.')
    service: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The service namespace that identifies the AWS product (for example, 's3', 'iam', 'codepipline').\n")
    account: typing.Optional[str] = pydantic.Field(None, description="The ID of the AWS account that owns the resource, without the hyphens. For example, 123456789012. Note that the ARNs for some resources don't require an account number, so this component might be omitted. Default: The account the stack is deployed to.\n")
    arn_format: typing.Optional[aws_cdk.ArnFormat] = pydantic.Field(None, description='The specific ARN format to use for this ARN value. Default: - uses value of ``sep`` as the separator for formatting, ``ArnFormat.SLASH_RESOURCE_NAME`` if that property was also not provided\n')
    partition: typing.Optional[str] = pydantic.Field(None, description='The partition that the resource is in. For standard AWS regions, the partition is aws. If you have resources in other partitions, the partition is aws-partitionname. For example, the partition for resources in the China (Beijing) region is aws-cn. Default: The AWS partition the stack is deployed to.\n')
    region: typing.Optional[str] = pydantic.Field(None, description='The region the resource resides in. Note that the ARNs for some resources do not require a region, so this component might be omitted. Default: The region the stack is deployed to.\n')
    resource_name: typing.Optional[str] = pydantic.Field(None, description='Resource name or path within the resource (i.e. S3 bucket object key) or a wildcard such as ``"*"``. This is service-dependent.\n\n:exampleMetadata: infused\n\nExample::\n\n    sub_zone = route53.PublicHostedZone(self, "SubZone",\n        zone_name="sub.someexample.com"\n    )\n\n    # import the delegation role by constructing the roleArn\n    delegation_role_arn = Stack.of(self).format_arn(\n        region="",  # IAM is global in each partition\n        service="iam",\n        account="parent-account-id",\n        resource="role",\n        resource_name="MyDelegationRole"\n    )\n    delegation_role = iam.Role.from_role_arn(self, "DelegationRole", delegation_role_arn)\n\n    # create the record\n    route53.CrossAccountZoneDelegationRecord(self, "delegate",\n        delegated_zone=sub_zone,\n        parent_hosted_zone_name="someexample.com",  # or you can use parentHostedZoneId\n        delegation_role=delegation_role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['resource', 'service', 'account', 'arn_format', 'partition', 'region', 'resource_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.ArnComponents'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.AssetManifestDockerImageDestination
class AssetManifestDockerImageDestinationDef(BaseStruct):
    repository_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Repository name where the docker image asset should be written.\n')
    docker_tag_prefix: typing.Optional[str] = pydantic.Field(None, description="Prefix to add to the asset hash to make the Docker image tag. Default: ''\n")
    role: typing.Union[models.RoleOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Role to use to perform the upload. Default: - No role\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    asset_manifest_docker_image_destination = cdk.AssetManifestDockerImageDestination(\n        repository_name="repositoryName",\n\n        # the properties below are optional\n        docker_tag_prefix="dockerTagPrefix",\n        role=cdk.RoleOptions(\n            assume_role_arn="assumeRoleArn",\n\n            # the properties below are optional\n            assume_role_external_id="assumeRoleExternalId"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['repository_name', 'docker_tag_prefix', 'role']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.AssetManifestDockerImageDestination'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.AssetManifestFileDestination
class AssetManifestFileDestinationDef(BaseStruct):
    bucket_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Bucket name where the file asset should be written.\n')
    bucket_prefix: typing.Optional[str] = pydantic.Field(None, description="Prefix to prepend to the asset hash. Default: ''\n")
    role: typing.Union[models.RoleOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Role to use for uploading. Default: - current role\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    asset_manifest_file_destination = cdk.AssetManifestFileDestination(\n        bucket_name="bucketName",\n\n        # the properties below are optional\n        bucket_prefix="bucketPrefix",\n        role=cdk.RoleOptions(\n            assume_role_arn="assumeRoleArn",\n\n            # the properties below are optional\n            assume_role_external_id="assumeRoleExternalId"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket_name', 'bucket_prefix', 'role']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.AssetManifestFileDestination'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.AssetOptions
class AssetOptionsDef(BaseStruct):
    asset_hash: typing.Optional[str] = pydantic.Field(None, description='Specify a custom hash for this asset. If ``assetHashType`` is set it must be set to ``AssetHashType.CUSTOM``. For consistency, this custom hash will be SHA256 hashed and encoded as hex. The resulting hash will be the asset hash. NOTE: the hash is used in order to identify a specific revision of the asset, and used for optimizing and caching deployment activities related to this asset such as packaging, uploading to Amazon S3, etc. If you chose to customize the hash, you will need to make sure it is updated every time the asset changes, or otherwise it is possible that some deployments will not be invalidated. Default: - based on ``assetHashType``\n')
    asset_hash_type: typing.Optional[aws_cdk.AssetHashType] = pydantic.Field(None, description='Specifies the type of hash to calculate for this asset. If ``assetHash`` is configured, this option must be ``undefined`` or ``AssetHashType.CUSTOM``. Default: - the default is ``AssetHashType.SOURCE``, but if ``assetHash`` is explicitly specified this value defaults to ``AssetHashType.CUSTOM``.\n')
    bundling: typing.Union[models.BundlingOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Bundle the asset by executing a command in a Docker container or a custom bundling provider. The asset path will be mounted at ``/asset-input``. The Docker container is responsible for putting content at ``/asset-output``. The content at ``/asset-output`` will be zipped and used as the final asset. Default: - uploaded as-is to S3 if the asset is a regular file or a .zip file, archived into a .zip file and uploaded to S3 otherwise\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    # docker_image: cdk.DockerImage\n    # local_bundling: cdk.ILocalBundling\n\n    asset_options = cdk.AssetOptions(\n        asset_hash="assetHash",\n        asset_hash_type=cdk.AssetHashType.SOURCE,\n        bundling=cdk.BundlingOptions(\n            image=docker_image,\n\n            # the properties below are optional\n            bundling_file_access=cdk.BundlingFileAccess.VOLUME_COPY,\n            command=["command"],\n            entrypoint=["entrypoint"],\n            environment={\n                "environment_key": "environment"\n            },\n            local=local_bundling,\n            network="network",\n            output_type=cdk.BundlingOutput.ARCHIVED,\n            platform="platform",\n            security_opt="securityOpt",\n            user="user",\n            volumes=[cdk.DockerVolume(\n                container_path="containerPath",\n                host_path="hostPath",\n\n                # the properties below are optional\n                consistency=cdk.DockerVolumeConsistency.CONSISTENT\n            )],\n            volumes_from=["volumesFrom"],\n            working_directory="workingDirectory"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['asset_hash', 'asset_hash_type', 'bundling']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.AssetOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.AssetStagingProps
class AssetStagingPropsDef(BaseStruct):
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='File paths matching the patterns will be excluded. See ``ignoreMode`` to set the matching behavior. Has no effect on Assets bundled using the ``bundling`` property. Default: - nothing is excluded\n')
    follow: typing.Optional[aws_cdk.SymlinkFollowMode] = pydantic.Field(None, description='A strategy for how to handle symlinks. Default: SymlinkFollowMode.NEVER\n')
    ignore_mode: typing.Optional[aws_cdk.IgnoreMode] = pydantic.Field(None, description='The ignore behavior to use for ``exclude`` patterns. Default: IgnoreMode.GLOB\n')
    extra_hash: typing.Optional[str] = pydantic.Field(None, description='Extra information to encode into the fingerprint (e.g. build instructions and other inputs). Default: - hash is only based on source content\n')
    asset_hash: typing.Optional[str] = pydantic.Field(None, description='Specify a custom hash for this asset. If ``assetHashType`` is set it must be set to ``AssetHashType.CUSTOM``. For consistency, this custom hash will be SHA256 hashed and encoded as hex. The resulting hash will be the asset hash. NOTE: the hash is used in order to identify a specific revision of the asset, and used for optimizing and caching deployment activities related to this asset such as packaging, uploading to Amazon S3, etc. If you chose to customize the hash, you will need to make sure it is updated every time the asset changes, or otherwise it is possible that some deployments will not be invalidated. Default: - based on ``assetHashType``\n')
    asset_hash_type: typing.Optional[aws_cdk.AssetHashType] = pydantic.Field(None, description='Specifies the type of hash to calculate for this asset. If ``assetHash`` is configured, this option must be ``undefined`` or ``AssetHashType.CUSTOM``. Default: - the default is ``AssetHashType.SOURCE``, but if ``assetHash`` is explicitly specified this value defaults to ``AssetHashType.CUSTOM``.\n')
    bundling: typing.Union[models.BundlingOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Bundle the asset by executing a command in a Docker container or a custom bundling provider. The asset path will be mounted at ``/asset-input``. The Docker container is responsible for putting content at ``/asset-output``. The content at ``/asset-output`` will be zipped and used as the final asset. Default: - uploaded as-is to S3 if the asset is a regular file or a .zip file, archived into a .zip file and uploaded to S3 otherwise\n')
    source_path: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The source file or directory to copy from.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    # docker_image: cdk.DockerImage\n    # local_bundling: cdk.ILocalBundling\n\n    asset_staging_props = cdk.AssetStagingProps(\n        source_path="sourcePath",\n\n        # the properties below are optional\n        asset_hash="assetHash",\n        asset_hash_type=cdk.AssetHashType.SOURCE,\n        bundling=cdk.BundlingOptions(\n            image=docker_image,\n\n            # the properties below are optional\n            bundling_file_access=cdk.BundlingFileAccess.VOLUME_COPY,\n            command=["command"],\n            entrypoint=["entrypoint"],\n            environment={\n                "environment_key": "environment"\n            },\n            local=local_bundling,\n            network="network",\n            output_type=cdk.BundlingOutput.ARCHIVED,\n            platform="platform",\n            security_opt="securityOpt",\n            user="user",\n            volumes=[cdk.DockerVolume(\n                container_path="containerPath",\n                host_path="hostPath",\n\n                # the properties below are optional\n                consistency=cdk.DockerVolumeConsistency.CONSISTENT\n            )],\n            volumes_from=["volumesFrom"],\n            working_directory="workingDirectory"\n        ),\n        exclude=["exclude"],\n        extra_hash="extraHash",\n        follow=cdk.SymlinkFollowMode.NEVER,\n        ignore_mode=cdk.IgnoreMode.GLOB\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['exclude', 'follow', 'ignore_mode', 'extra_hash', 'asset_hash', 'asset_hash_type', 'bundling', 'source_path']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.AssetStagingProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.BootstraplessSynthesizerProps
class BootstraplessSynthesizerPropsDef(BaseStruct):
    cloud_formation_execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The CFN execution Role ARN to use. Default: - No CloudFormation role (use CLI credentials)\n')
    deploy_role_arn: typing.Optional[str] = pydantic.Field(None, description='The deploy Role ARN to use. Default: - No deploy role (use CLI credentials)\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    bootstrapless_synthesizer_props = cdk.BootstraplessSynthesizerProps(\n        cloud_formation_execution_role_arn="cloudFormationExecutionRoleArn",\n        deploy_role_arn="deployRoleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cloud_formation_execution_role_arn', 'deploy_role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.BootstraplessSynthesizerProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.BundlingOptions
class BundlingOptionsDef(BaseStruct):
    image: typing.Union[models.DockerImageDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Docker image where the command will run.\n')
    bundling_file_access: typing.Optional[aws_cdk.BundlingFileAccess] = pydantic.Field(None, description='The access mechanism used to make source files available to the bundling container and to return the bundling output back to the host. Default: - BundlingFileAccess.BIND_MOUNT\n')
    command: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="The command to run in the Docker container. Example value: ``['npm', 'install']`` Default: - run the command defined in the image\n")
    entrypoint: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="The entrypoint to run in the Docker container. Example value: ``['/bin/sh', '-c']`` Default: - run the entrypoint defined in the image\n")
    environment: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='The environment variables to pass to the Docker container. Default: - no environment variables.\n')
    local: typing.Optional[models.UnsupportedResource] = pydantic.Field(None, description='Local bundling provider. The provider implements a method ``tryBundle()`` which should return ``true`` if local bundling was performed. If ``false`` is returned, docker bundling will be done. Default: - bundling will only be performed in a Docker container\n')
    network: typing.Optional[str] = pydantic.Field(None, description='Docker `Networking options <https://docs.docker.com/engine/reference/commandline/run/#connect-a-container-to-a-network---network>`_. Default: - no networking options\n')
    output_type: typing.Optional[aws_cdk.BundlingOutput] = pydantic.Field(None, description='The type of output that this bundling operation is producing. Default: BundlingOutput.AUTO_DISCOVER\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Platform to build for. *Requires Docker Buildx*. Specify this property to build images on a specific platform. Default: - no platform specified (the current machine architecture will be used)\n')
    security_opt: typing.Optional[str] = pydantic.Field(None, description='`Security configuration <https://docs.docker.com/engine/reference/run/#security-configuration>`_ when running the docker container. Default: - no security options\n')
    user: typing.Optional[str] = pydantic.Field(None, description='The user to use when running the Docker container. user | user:group | uid | uid:gid | user:gid | uid:group Default: - uid:gid of the current user or 1000:1000 on Windows\n')
    volumes: typing.Optional[typing.Sequence[typing.Union[models.DockerVolumeDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Additional Docker volumes to mount. Default: - no additional volumes are mounted\n')
    volumes_from: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Where to mount the specified volumes from. Default: - no containers are specified to mount volumes from\n')
    working_directory: typing.Optional[str] = pydantic.Field(None, description='Working directory inside the Docker container. Default: /asset-input\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk as cdk\n\n\n    asset = Asset(self, "BundledAsset",\n        path="/path/to/asset",\n        bundling=cdk.BundlingOptions(\n            image=cdk.DockerImage.from_registry("alpine"),\n            command=["command-that-produces-an-archive.sh"],\n            output_type=cdk.BundlingOutput.NOT_ARCHIVED\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['image', 'bundling_file_access', 'command', 'entrypoint', 'environment', 'local', 'network', 'output_type', 'platform', 'security_opt', 'user', 'volumes', 'volumes_from', 'working_directory']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.BundlingOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CliCredentialsStackSynthesizerProps
class CliCredentialsStackSynthesizerPropsDef(BaseStruct):
    bucket_prefix: typing.Optional[str] = pydantic.Field(None, description='bucketPrefix to use while storing S3 Assets. Default: - DefaultStackSynthesizer.DEFAULT_FILE_ASSET_PREFIX\n')
    docker_tag_prefix: typing.Optional[str] = pydantic.Field(None, description='A prefix to use while tagging and uploading Docker images to ECR. This does not add any separators - the source hash will be appended to this string directly. Default: - DefaultStackSynthesizer.DEFAULT_DOCKER_ASSET_PREFIX\n')
    file_assets_bucket_name: typing.Optional[str] = pydantic.Field(None, description="Name of the S3 bucket to hold file assets. You must supply this if you have given a non-standard name to the staging bucket. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_FILE_ASSETS_BUCKET_NAME\n")
    image_assets_repository_name: typing.Optional[str] = pydantic.Field(None, description="Name of the ECR repository to hold Docker Image assets. You must supply this if you have given a non-standard name to the ECR repository. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_IMAGE_ASSETS_REPOSITORY_NAME\n")
    qualifier: typing.Optional[str] = pydantic.Field(None, description='Qualifier to disambiguate multiple environments in the same account. You can use this and leave the other naming properties empty if you have deployed the bootstrap environment with standard names but only different qualifiers. Default: - Value of context key \'@aws-cdk/core:bootstrapQualifier\' if set, otherwise ``DefaultStackSynthesizer.DEFAULT_QUALIFIER``\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cli_credentials_stack_synthesizer_props = cdk.CliCredentialsStackSynthesizerProps(\n        bucket_prefix="bucketPrefix",\n        docker_tag_prefix="dockerTagPrefix",\n        file_assets_bucket_name="fileAssetsBucketName",\n        image_assets_repository_name="imageAssetsRepositoryName",\n        qualifier="qualifier"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket_prefix', 'docker_tag_prefix', 'file_assets_bucket_name', 'image_assets_repository_name', 'qualifier']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CliCredentialsStackSynthesizerProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CopyOptions
class CopyOptionsDef(BaseStruct):
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='File paths matching the patterns will be excluded. See ``ignoreMode`` to set the matching behavior. Has no effect on Assets bundled using the ``bundling`` property. Default: - nothing is excluded\n')
    follow: typing.Optional[aws_cdk.SymlinkFollowMode] = pydantic.Field(None, description='A strategy for how to handle symlinks. Default: SymlinkFollowMode.NEVER\n')
    ignore_mode: typing.Optional[aws_cdk.IgnoreMode] = pydantic.Field(None, description='The ignore behavior to use for ``exclude`` patterns. Default: IgnoreMode.GLOB\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    copy_options = cdk.CopyOptions(\n        exclude=["exclude"],\n        follow=cdk.SymlinkFollowMode.NEVER,\n        ignore_mode=cdk.IgnoreMode.GLOB\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['exclude', 'follow', 'ignore_mode']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CopyOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CustomResourceProps
class CustomResourcePropsDef(BaseStruct):
    service_token: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The ARN of the provider which implements this custom resource type. You can implement a provider by listening to raw AWS CloudFormation events and specify the ARN of an SNS topic (``topic.topicArn``) or the ARN of an AWS Lambda function (``lambda.functionArn``) or use the CDK's custom `resource provider framework <https://docs.aws.amazon.com/cdk/api/latest/docs/custom-resources-readme.html>`_ which makes it easier to implement robust providers. Provider framework:: // use the provider framework from aws-cdk/custom-resources: const provider = new customresources.Provider(this, 'ResourceProvider', { onEventHandler, isCompleteHandler, // optional }); new CustomResource(this, 'MyResource', { serviceToken: provider.serviceToken, }); AWS Lambda function (not recommended to use AWS Lambda Functions directly, see the module README):: // invoke an AWS Lambda function when a lifecycle event occurs: new CustomResource(this, 'MyResource', { serviceToken: myFunction.functionArn, }); SNS topic (not recommended to use AWS Lambda Functions directly, see the module README):: // publish lifecycle events to an SNS topic: new CustomResource(this, 'MyResource', { serviceToken: myTopic.topicArn, });\n")
    pascal_case_properties: typing.Optional[bool] = pydantic.Field(None, description='Convert all property keys to pascal case. Default: false\n')
    properties: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Properties to pass to the Lambda. Default: - No properties.\n')
    removal_policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='The policy to apply when this resource is removed from the application. Default: cdk.RemovalPolicy.Destroy\n')
    resource_type: typing.Optional[str] = pydantic.Field(None, description='For custom resources, you can specify AWS::CloudFormation::CustomResource (the default) as the resource type, or you can specify your own resource type name. For example, you can use "Custom::MyCustomResourceTypeName". Custom resource type names must begin with "Custom::" and can include alphanumeric characters and the following characters: _@-. You can specify a custom resource type name up to a maximum length of 60 characters. You cannot change the type during an update. Using your own resource type names helps you quickly differentiate the types of custom resources in your stack. For example, if you had two custom resources that conduct two different ping tests, you could name their type as Custom::PingTester to make them easily identifiable as ping testers (instead of using AWS::CloudFormation::CustomResource). Default: - AWS::CloudFormation::CustomResource\n\n:exampleMetadata: infused\n\nExample::\n\n    service_token = CustomResourceProvider.get_or_create(self, "Custom::MyCustomResourceType",\n        code_directory=f"{__dirname}/my-handler",\n        runtime=CustomResourceProviderRuntime.NODEJS_18_X,\n        description="Lambda function created by the custom resource provider"\n    )\n\n    CustomResource(self, "MyResource",\n        resource_type="Custom::MyCustomResourceType",\n        service_token=service_token\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['service_token', 'pascal_case_properties', 'properties', 'removal_policy', 'resource_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CustomResourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CustomResourceProviderProps
class CustomResourceProviderPropsDef(BaseStruct):
    code_directory: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="A local file system directory with the provider's code. The code will be bundled into a zip asset and wired to the provider's AWS Lambda function.\n")
    runtime: typing.Union[aws_cdk.CustomResourceProviderRuntime, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS Lambda runtime and version to use for the provider.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the function. Default: - No description.\n')
    environment: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Key-value pairs that are passed to Lambda as Environment. Default: - No environment variables.\n')
    memory_size: typing.Optional[models.SizeDef] = pydantic.Field(None, description="The amount of memory that your function has access to. Increasing the function's memory also increases its CPU allocation. Default: Size.mebibytes(128)\n")
    policy_statements: typing.Optional[typing.Sequence[typing.Any]] = pydantic.Field(None, description="A set of IAM policy statements to include in the inline policy of the provider's lambda function. **Please note**: these are direct IAM JSON policy blobs, *not* ``iam.PolicyStatement`` objects like you will see in the rest of the CDK. Default: - no additional inline policy\n")
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='AWS Lambda timeout for the provider. Default: Duration.minutes(15)\n')
    use_cfn_response_wrapper: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the cloudformation response wrapper (``nodejs-entrypoint.ts``) is used. If set to ``true``, ``nodejs-entrypoint.js`` is bundled in the same asset as the custom resource and set as the entrypoint. If set to ``false``, the custom resource provided is the entrypoint. Default: - ``true`` if ``inlineCode: false`` and ``false`` otherwise.\n\n:exampleMetadata: infused\n\nExample::\n\n    provider = CustomResourceProvider.get_or_create_provider(self, "Custom::MyCustomResourceType",\n        code_directory=f"{__dirname}/my-handler",\n        runtime=CustomResourceProviderRuntime.NODEJS_18_X\n    )\n    provider.add_to_role_policy({\n        "Effect": "Allow",\n        "Action": "s3:GetObject",\n        "Resource": "*"\n    })\n')
    _init_params: typing.ClassVar[list[str]] = ['code_directory', 'runtime', 'description', 'environment', 'memory_size', 'policy_statements', 'timeout', 'use_cfn_response_wrapper']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CustomResourceProviderProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.DefaultStackSynthesizerProps
class DefaultStackSynthesizerPropsDef(BaseStruct):
    bootstrap_stack_version_ssm_parameter: typing.Optional[str] = pydantic.Field(None, description='Bootstrap stack version SSM parameter. The placeholder ``${Qualifier}`` will be replaced with the value of qualifier. Default: DefaultStackSynthesizer.DEFAULT_BOOTSTRAP_STACK_VERSION_SSM_PARAMETER\n')
    bucket_prefix: typing.Optional[str] = pydantic.Field(None, description='bucketPrefix to use while storing S3 Assets. Default: - DefaultStackSynthesizer.DEFAULT_FILE_ASSET_PREFIX\n')
    cloud_formation_execution_role: typing.Optional[str] = pydantic.Field(None, description="The role CloudFormation will assume when deploying the Stack. You must supply this if you have given a non-standard name to the execution role. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_CLOUDFORMATION_ROLE_ARN\n")
    deploy_role_arn: typing.Optional[str] = pydantic.Field(None, description="The role to assume to initiate a deployment in this environment. You must supply this if you have given a non-standard name to the publishing role. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_DEPLOY_ROLE_ARN\n")
    deploy_role_external_id: typing.Optional[str] = pydantic.Field(None, description='External ID to use when assuming role for cloudformation deployments. Default: - No external ID\n')
    docker_tag_prefix: typing.Optional[str] = pydantic.Field(None, description='A prefix to use while tagging and uploading Docker images to ECR. This does not add any separators - the source hash will be appended to this string directly. Default: - DefaultStackSynthesizer.DEFAULT_DOCKER_ASSET_PREFIX\n')
    file_asset_publishing_external_id: typing.Optional[str] = pydantic.Field(None, description='External ID to use when assuming role for file asset publishing. Default: - No external ID\n')
    file_asset_publishing_role_arn: typing.Optional[str] = pydantic.Field(None, description="The role to use to publish file assets to the S3 bucket in this environment. You must supply this if you have given a non-standard name to the publishing role. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_FILE_ASSET_PUBLISHING_ROLE_ARN\n")
    file_assets_bucket_name: typing.Optional[str] = pydantic.Field(None, description="Name of the S3 bucket to hold file assets. You must supply this if you have given a non-standard name to the staging bucket. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_FILE_ASSETS_BUCKET_NAME\n")
    generate_bootstrap_version_rule: typing.Optional[bool] = pydantic.Field(None, description='Whether to add a Rule to the stack template verifying the bootstrap stack version. This generally should be left set to ``true``, unless you explicitly want to be able to deploy to an unbootstrapped environment. Default: true\n')
    image_asset_publishing_external_id: typing.Optional[str] = pydantic.Field(None, description='External ID to use when assuming role for image asset publishing. Default: - No external ID\n')
    image_asset_publishing_role_arn: typing.Optional[str] = pydantic.Field(None, description="The role to use to publish image assets to the ECR repository in this environment. You must supply this if you have given a non-standard name to the publishing role. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_IMAGE_ASSET_PUBLISHING_ROLE_ARN\n")
    image_assets_repository_name: typing.Optional[str] = pydantic.Field(None, description="Name of the ECR repository to hold Docker Image assets. You must supply this if you have given a non-standard name to the ECR repository. The placeholders ``${Qualifier}``, ``${AWS::AccountId}`` and ``${AWS::Region}`` will be replaced with the values of qualifier and the stack's account and region, respectively. Default: DefaultStackSynthesizer.DEFAULT_IMAGE_ASSETS_REPOSITORY_NAME\n")
    lookup_role_arn: typing.Optional[str] = pydantic.Field(None, description='The role to use to look up values from the target AWS account during synthesis. Default: - None\n')
    lookup_role_external_id: typing.Optional[str] = pydantic.Field(None, description='External ID to use when assuming lookup role. Default: - No external ID\n')
    qualifier: typing.Optional[str] = pydantic.Field(None, description="Qualifier to disambiguate multiple environments in the same account. You can use this and leave the other naming properties empty if you have deployed the bootstrap environment with standard names but only different qualifiers. Default: - Value of context key '@aws-cdk/core:bootstrapQualifier' if set, otherwise ``DefaultStackSynthesizer.DEFAULT_QUALIFIER``\n")
    use_lookup_role_for_stack_operations: typing.Optional[bool] = pydantic.Field(None, description='Use the bootstrapped lookup role for (read-only) stack operations. Use the lookup role when performing a ``cdk diff``. If set to ``false``, the ``deploy role`` credentials will be used to perform a ``cdk diff``. Requires bootstrap stack version 8. Default: true\n\n:exampleMetadata: infused\n\nExample::\n\n    MyStack(app, "MyStack",\n        synthesizer=DefaultStackSynthesizer(\n            file_assets_bucket_name="my-orgs-asset-bucket"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bootstrap_stack_version_ssm_parameter', 'bucket_prefix', 'cloud_formation_execution_role', 'deploy_role_arn', 'deploy_role_external_id', 'docker_tag_prefix', 'file_asset_publishing_external_id', 'file_asset_publishing_role_arn', 'file_assets_bucket_name', 'generate_bootstrap_version_rule', 'image_asset_publishing_external_id', 'image_asset_publishing_role_arn', 'image_assets_repository_name', 'lookup_role_arn', 'lookup_role_external_id', 'qualifier', 'use_lookup_role_for_stack_operations']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DefaultStackSynthesizerProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.DockerBuildOptions
class DockerBuildOptionsDef(BaseStruct):
    build_args: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build args. Default: - no build args\n')
    cache_from: typing.Optional[typing.Sequence[typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Cache from options to pass to the ``docker build`` command. Default: - no cache from args are passed\n')
    cache_to: typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Cache to options to pass to the ``docker build`` command. Default: - no cache to args are passed\n')
    file: typing.Optional[str] = pydantic.Field(None, description='Name of the Dockerfile, must relative to the docker build path. Default: ``Dockerfile``\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Set platform if server is multi-platform capable. *Requires Docker Engine API v1.38+*. Example value: ``linux/amd64`` Default: - no platform specified\n')
    target_stage: typing.Optional[str] = pydantic.Field(None, description='Set build target for multi-stage container builds. Any stage defined afterwards will be ignored. Example value: ``build-env`` Default: - Build all stages defined in the Dockerfile\n\n:exampleMetadata: infused\n\nExample::\n\n    lambda_.Function(self, "Function",\n        code=lambda_.Code.from_asset("/path/to/handler",\n            bundling=BundlingOptions(\n                image=DockerImage.from_build("/path/to/dir/with/DockerFile",\n                    build_args={\n                        "ARG1": "value1"\n                    }\n                ),\n                command=["my", "cool", "command"]\n            )\n        ),\n        runtime=lambda_.Runtime.PYTHON_3_9,\n        handler="index.handler"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['build_args', 'cache_from', 'cache_to', 'file', 'platform', 'target_stage']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DockerBuildOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.DockerCacheOption
class DockerCacheOptionDef(BaseStruct):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of cache to use. Refer to https://docs.docker.com/build/cache/backends/ for full list of backends. Default: - unspecified\n')
    params: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Any parameters to pass into the docker cache backend configuration. Refer to https://docs.docker.com/build/cache/backends/ for cache backend configuration. Default: {} No options provided\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    docker_cache_option = cdk.DockerCacheOption(\n        type="type",\n\n        # the properties below are optional\n        params={\n            "params_key": "params"\n        }\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type', 'params']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DockerCacheOption'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.DockerImageAssetLocation
class DockerImageAssetLocationDef(BaseStruct):
    image_uri: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The URI of the image in Amazon ECR (including a tag).\n')
    repository_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the ECR repository.\n')
    image_tag: typing.Optional[str] = pydantic.Field(None, description='The tag of the image in Amazon ECR. Default: - the hash of the asset, or the ``dockerTagPrefix`` concatenated with the asset hash if a ``dockerTagPrefix`` is specified in the stack synthesizer\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    docker_image_asset_location = cdk.DockerImageAssetLocation(\n        image_uri="imageUri",\n        repository_name="repositoryName",\n\n        # the properties below are optional\n        image_tag="imageTag"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['image_uri', 'repository_name', 'image_tag']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DockerImageAssetLocation'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.DockerImageAssetSource
class DockerImageAssetSourceDef(BaseStruct):
    source_hash: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The hash of the contents of the docker build context. This hash is used throughout the system to identify this image and avoid duplicate work in case the source did not change. NOTE: this means that if you wish to update your docker image, you must make a modification to the source (e.g. add some metadata to your Dockerfile).')
    asset_name: typing.Optional[str] = pydantic.Field(None, description='Unique identifier of the docker image asset and its potential revisions. Required if using AppScopedStagingSynthesizer. Default: - no asset name\n')
    directory_name: typing.Optional[str] = pydantic.Field(None, description='The directory where the Dockerfile is stored, must be relative to the cloud assembly root. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    docker_build_args: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build args to pass to the ``docker build`` command. Since Docker build arguments are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build args are passed\n')
    docker_build_secrets: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Build secrets to pass to the ``docker build`` command. Since Docker build secrets are resolved before deployment, keys and values cannot refer to unresolved tokens (such as ``lambda.functionArn`` or ``queue.queueUrl``). Only allowed when ``directoryName`` is specified. Default: - no build secrets are passed\n')
    docker_build_ssh: typing.Optional[str] = pydantic.Field(None, description='SSH agent socket or keys to pass to the ``docker buildx`` command. Default: - no ssh arg is passed\n')
    docker_build_target: typing.Optional[str] = pydantic.Field(None, description='Docker target to build to. Only allowed when ``directoryName`` is specified. Default: - no target\n')
    docker_cache_from: typing.Optional[typing.Sequence[typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Cache from options to pass to the ``docker build`` command. Default: - no cache from args are passed\n')
    docker_cache_to: typing.Union[models.DockerCacheOptionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Cache to options to pass to the ``docker build`` command. Default: - no cache to args are passed\n')
    docker_file: typing.Optional[str] = pydantic.Field(None, description='Path to the Dockerfile (relative to the directory). Only allowed when ``directoryName`` is specified. Default: - no file\n')
    docker_outputs: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Outputs to pass to the ``docker build`` command. Default: - no build args are passed\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the name of a local Docker image on ``stdout``. Default: - Exactly one of ``directoryName`` and ``executable`` is required\n')
    network_mode: typing.Optional[str] = pydantic.Field(None, description='Networking mode for the RUN commands during build. *Requires Docker Engine API v1.25+*. Specify this property to build images on a specific networking mode. Default: - no networking mode specified\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Platform to build for. *Requires Docker Buildx*. Specify this property to build images on a specific platform. Default: - no platform specified (the current machine architecture will be used)\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    docker_image_asset_source = cdk.DockerImageAssetSource(\n        source_hash="sourceHash",\n\n        # the properties below are optional\n        asset_name="assetName",\n        directory_name="directoryName",\n        docker_build_args={\n            "docker_build_args_key": "dockerBuildArgs"\n        },\n        docker_build_secrets={\n            "docker_build_secrets_key": "dockerBuildSecrets"\n        },\n        docker_build_ssh="dockerBuildSsh",\n        docker_build_target="dockerBuildTarget",\n        docker_cache_from=[cdk.DockerCacheOption(\n            type="type",\n\n            # the properties below are optional\n            params={\n                "params_key": "params"\n            }\n        )],\n        docker_cache_to=cdk.DockerCacheOption(\n            type="type",\n\n            # the properties below are optional\n            params={\n                "params_key": "params"\n            }\n        ),\n        docker_file="dockerFile",\n        docker_outputs=["dockerOutputs"],\n        executable=["executable"],\n        network_mode="networkMode",\n        platform="platform"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['source_hash', 'asset_name', 'directory_name', 'docker_build_args', 'docker_build_secrets', 'docker_build_ssh', 'docker_build_target', 'docker_cache_from', 'docker_cache_to', 'docker_file', 'docker_outputs', 'executable', 'network_mode', 'platform']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DockerImageAssetSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.DockerRunOptions
class DockerRunOptionsDef(BaseStruct):
    command: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The command to run in the container. Default: - run the command defined in the image\n')
    entrypoint: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The entrypoint to run in the container. Default: - run the entrypoint defined in the image\n')
    environment: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='The environment variables to pass to the container. Default: - no environment variables.\n')
    network: typing.Optional[str] = pydantic.Field(None, description='Docker `Networking options <https://docs.docker.com/engine/reference/commandline/run/#connect-a-container-to-a-network---network>`_. Default: - no networking options\n')
    platform: typing.Optional[str] = pydantic.Field(None, description='Set platform if server is multi-platform capable. *Requires Docker Engine API v1.38+*. Example value: ``linux/amd64`` Default: - no platform specified\n')
    security_opt: typing.Optional[str] = pydantic.Field(None, description='`Security configuration <https://docs.docker.com/engine/reference/run/#security-configuration>`_ when running the docker container. Default: - no security options\n')
    user: typing.Optional[str] = pydantic.Field(None, description='The user to use when running the container. Default: - root or image default\n')
    volumes: typing.Optional[typing.Sequence[typing.Union[models.DockerVolumeDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Docker volumes to mount. Default: - no volumes are mounted\n')
    volumes_from: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Where to mount the specified volumes from. Default: - no containers are specified to mount volumes from\n')
    working_directory: typing.Optional[str] = pydantic.Field(None, description='Working directory inside the container. Default: - image default\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    docker_run_options = cdk.DockerRunOptions(\n        command=["command"],\n        entrypoint=["entrypoint"],\n        environment={\n            "environment_key": "environment"\n        },\n        network="network",\n        platform="platform",\n        security_opt="securityOpt",\n        user="user",\n        volumes=[cdk.DockerVolume(\n            container_path="containerPath",\n            host_path="hostPath",\n\n            # the properties below are optional\n            consistency=cdk.DockerVolumeConsistency.CONSISTENT\n        )],\n        volumes_from=["volumesFrom"],\n        working_directory="workingDirectory"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['command', 'entrypoint', 'environment', 'network', 'platform', 'security_opt', 'user', 'volumes', 'volumes_from', 'working_directory']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DockerRunOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.DockerVolume
class DockerVolumeDef(BaseStruct):
    container_path: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The path where the file or directory is mounted in the container.\n')
    host_path: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The path to the file or directory on the host machine.\n')
    consistency: typing.Optional[aws_cdk.DockerVolumeConsistency] = pydantic.Field(None, description='Mount consistency. Only applicable for macOS Default: DockerConsistency.DELEGATED\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    docker_volume = cdk.DockerVolume(\n        container_path="containerPath",\n        host_path="hostPath",\n\n        # the properties below are optional\n        consistency=cdk.DockerVolumeConsistency.CONSISTENT\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['container_path', 'host_path', 'consistency']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.DockerVolume'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.EncodingOptions
class EncodingOptionsDef(BaseStruct):
    display_hint: typing.Optional[str] = pydantic.Field(None, description='A hint for the Token\'s purpose when stringifying it.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    encoding_options = cdk.EncodingOptions(\n        display_hint="displayHint"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['display_hint']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.EncodingOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.Environment
class EnvironmentDef(BaseStruct):
    account: typing.Optional[str] = pydantic.Field(None, description='The AWS account ID for this environment. This can be either a concrete value such as ``585191031104`` or ``Aws.ACCOUNT_ID`` which indicates that account ID will only be determined during deployment (it will resolve to the CloudFormation intrinsic ``{"Ref":"AWS::AccountId"}``). Note that certain features, such as cross-stack references and environmental context providers require concrete region information and will cause this stack to emit synthesis errors. Default: Aws.ACCOUNT_ID which means that the stack will be account-agnostic.\n')
    region: typing.Optional[str] = pydantic.Field(None, description='The AWS region for this environment. This can be either a concrete value such as ``eu-west-2`` or ``Aws.REGION`` which indicates that account ID will only be determined during deployment (it will resolve to the CloudFormation intrinsic ``{"Ref":"AWS::Region"}``). Note that certain features, such as cross-stack references and environmental context providers require concrete region information and will cause this stack to emit synthesis errors. Default: Aws.REGION which means that the stack will be region-agnostic.\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk as cdk\n\n\n    app = cdk.App()\n    stack = cdk.Stack(app, "Stack", env=cdk.Environment(region="us-west-2"))\n\n    global_table = dynamodb.TableV2(stack, "GlobalTable",\n        partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING),\n        replicas=[dynamodb.ReplicaTableProps(region="us-east-1")]\n    )\n\n    global_table.add_replica(region="us-east-2", deletion_protection=True)\n')
    _init_params: typing.ClassVar[list[str]] = ['account', 'region']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.Environment'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.ExportValueOptions
class ExportValueOptionsDef(BaseStruct):
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the export to create. Default: - A name is automatically chosen\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    export_value_options = cdk.ExportValueOptions(\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.ExportValueOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.FileAssetLocation
class FileAssetLocationDef(BaseStruct):
    bucket_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the Amazon S3 bucket.\n')
    http_url: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The HTTP URL of this asset on Amazon S3. This value suitable for inclusion in a CloudFormation template, and may be an encoded token. Example value: ``https://s3-us-east-1.amazonaws.com/mybucket/myobject``\n')
    object_key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon S3 object key.\n')
    s3_object_url: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The S3 URL of this asset on Amazon S3. This value suitable for inclusion in a CloudFormation template, and may be an encoded token. Example value: ``s3://mybucket/myobject``\n')
    kms_key_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the KMS key used to encrypt the file asset bucket, if any. The CDK bootstrap stack comes with a key policy that does not require setting this property, so you only need to set this property if you have customized the bootstrap stack to require it. Default: - Asset bucket is not encrypted, or decryption permissions are defined by a Key Policy.\n')
    s3_object_url_with_placeholders: typing.Optional[str] = pydantic.Field(None, description='Like ``s3ObjectUrl``, but not suitable for CloudFormation consumption. If there are placeholders in the S3 URL, they will be returned un-replaced and un-evaluated. Default: - This feature cannot be used\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    file_asset_location = cdk.FileAssetLocation(\n        bucket_name="bucketName",\n        http_url="httpUrl",\n        object_key="objectKey",\n        s3_object_url="s3ObjectUrl",\n\n        # the properties below are optional\n        kms_key_arn="kmsKeyArn",\n        s3_object_url_with_placeholders="s3ObjectUrlWithPlaceholders"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket_name', 'http_url', 'object_key', 's3_object_url', 'kms_key_arn', 's3_object_url_with_placeholders']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.FileAssetLocation'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.FileAssetSource
class FileAssetSourceDef(BaseStruct):
    source_hash: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="A hash on the content source. This hash is used to uniquely identify this asset throughout the system. If this value doesn't change, the asset will not be rebuilt or republished.\n")
    deploy_time: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the asset needs to exist beyond deployment time; i.e. are copied over to a different location and not needed afterwards. Setting this property to true has an impact on the lifecycle of the asset, because we will assume that it is safe to delete after the CloudFormation deployment succeeds. For example, Lambda Function assets are copied over to Lambda during deployment. Therefore, it is not necessary to store the asset in S3, so we consider those deployTime assets. Default: false\n')
    executable: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An external command that will produce the packaged asset. The command should produce the location of a ZIP file on ``stdout``. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    file_name: typing.Optional[str] = pydantic.Field(None, description='The path, relative to the root of the cloud assembly, in which this asset source resides. This can be a path to a file or a directory, depending on the packaging type. Default: - Exactly one of ``fileName`` and ``executable`` is required\n')
    packaging: typing.Optional[aws_cdk.FileAssetPackaging] = pydantic.Field(None, description='Which type of packaging to perform. Default: - Required if ``fileName`` is specified.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    file_asset_source = cdk.FileAssetSource(\n        source_hash="sourceHash",\n\n        # the properties below are optional\n        deploy_time=False,\n        executable=["executable"],\n        file_name="fileName",\n        packaging=cdk.FileAssetPackaging.ZIP_DIRECTORY\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['source_hash', 'deploy_time', 'executable', 'file_name', 'packaging']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.FileAssetSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.FileCopyOptions
class FileCopyOptionsDef(BaseStruct):
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='File paths matching the patterns will be excluded. See ``ignoreMode`` to set the matching behavior. Has no effect on Assets bundled using the ``bundling`` property. Default: - nothing is excluded\n')
    follow_symlinks: typing.Optional[aws_cdk.SymlinkFollowMode] = pydantic.Field(None, description='A strategy for how to handle symlinks. Default: SymlinkFollowMode.NEVER\n')
    ignore_mode: typing.Optional[aws_cdk.IgnoreMode] = pydantic.Field(None, description='The ignore behavior to use for ``exclude`` patterns. Default: IgnoreMode.GLOB\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    file_copy_options = cdk.FileCopyOptions(\n        exclude=["exclude"],\n        follow_symlinks=cdk.SymlinkFollowMode.NEVER,\n        ignore_mode=cdk.IgnoreMode.GLOB\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['exclude', 'follow_symlinks', 'ignore_mode']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.FileCopyOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.FileFingerprintOptions
class FileFingerprintOptionsDef(BaseStruct):
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='File paths matching the patterns will be excluded. See ``ignoreMode`` to set the matching behavior. Has no effect on Assets bundled using the ``bundling`` property. Default: - nothing is excluded\n')
    follow_symlinks: typing.Optional[aws_cdk.SymlinkFollowMode] = pydantic.Field(None, description='A strategy for how to handle symlinks. Default: SymlinkFollowMode.NEVER\n')
    ignore_mode: typing.Optional[aws_cdk.IgnoreMode] = pydantic.Field(None, description='The ignore behavior to use for ``exclude`` patterns. Default: IgnoreMode.GLOB\n')
    extra_hash: typing.Optional[str] = pydantic.Field(None, description='Extra information to encode into the fingerprint (e.g. build instructions and other inputs). Default: - hash is only based on source content\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    file_fingerprint_options = cdk.FileFingerprintOptions(\n        exclude=["exclude"],\n        extra_hash="extraHash",\n        follow_symlinks=cdk.SymlinkFollowMode.NEVER,\n        ignore_mode=cdk.IgnoreMode.GLOB\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['exclude', 'follow_symlinks', 'ignore_mode', 'extra_hash']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.FileFingerprintOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.FingerprintOptions
class FingerprintOptionsDef(BaseStruct):
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='File paths matching the patterns will be excluded. See ``ignoreMode`` to set the matching behavior. Has no effect on Assets bundled using the ``bundling`` property. Default: - nothing is excluded\n')
    follow: typing.Optional[aws_cdk.SymlinkFollowMode] = pydantic.Field(None, description='A strategy for how to handle symlinks. Default: SymlinkFollowMode.NEVER\n')
    ignore_mode: typing.Optional[aws_cdk.IgnoreMode] = pydantic.Field(None, description='The ignore behavior to use for ``exclude`` patterns. Default: IgnoreMode.GLOB\n')
    extra_hash: typing.Optional[str] = pydantic.Field(None, description='Extra information to encode into the fingerprint (e.g. build instructions and other inputs). Default: - hash is only based on source content\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    fingerprint_options = cdk.FingerprintOptions(\n        exclude=["exclude"],\n        extra_hash="extraHash",\n        follow=cdk.SymlinkFollowMode.NEVER,\n        ignore_mode=cdk.IgnoreMode.GLOB\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['exclude', 'follow', 'ignore_mode', 'extra_hash']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.FingerprintOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.GetContextKeyOptions
class GetContextKeyOptionsDef(BaseStruct):
    provider: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The context provider to query.')
    include_environment: typing.Optional[bool] = pydantic.Field(None, description="Whether to include the stack's account and region automatically. Default: true\n")
    props: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Provider-specific properties.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    # props: Any\n\n    get_context_key_options = cdk.GetContextKeyOptions(\n        provider="provider",\n\n        # the properties below are optional\n        include_environment=False,\n        props={\n            "props_key": props\n        }\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['provider', 'include_environment', 'props']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.GetContextKeyOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.GetContextKeyResult
class GetContextKeyResultDef(BaseStruct):
    key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='')
    props: typing.Union[typing.Mapping[str, typing.Any], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='')
    _init_params: typing.ClassVar[list[str]] = ['key', 'props']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.GetContextKeyResult'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.GetContextValueOptions
class GetContextValueOptionsDef(BaseStruct):
    provider: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The context provider to query.')
    include_environment: typing.Optional[bool] = pydantic.Field(None, description="Whether to include the stack's account and region automatically. Default: true\n")
    props: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Provider-specific properties.\n')
    dummy_value: typing.Union[typing.Any, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The value to return if the context value was not found and a missing context is reported. This should be a dummy value that should preferably fail during deployment since it represents an invalid state.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    # dummy_value: Any\n    # props: Any\n\n    get_context_value_options = cdk.GetContextValueOptions(\n        dummy_value=dummy_value,\n        provider="provider",\n\n        # the properties below are optional\n        include_environment=False,\n        props={\n            "props_key": props\n        }\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['provider', 'include_environment', 'props', 'dummy_value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.GetContextValueOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.GetContextValueResult
class GetContextValueResultDef(BaseStruct):
    value: typing.Any = pydantic.Field(None, description='')
    _init_params: typing.ClassVar[list[str]] = ['value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.GetContextValueResult'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.IntrinsicProps
class IntrinsicPropsDef(BaseStruct):
    stack_trace: typing.Optional[bool] = pydantic.Field(None, description='Capture the stack trace of where this token is created. Default: true\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='Type that this token is expected to evaluate to. Default: ResolutionTypeHint.STRING\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    intrinsic_props = cdk.IntrinsicProps(\n        stack_trace=False,\n        type_hint=cdk.ResolutionTypeHint.STRING\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['stack_trace', 'type_hint']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.IntrinsicProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.LazyAnyValueOptions
class LazyAnyValueOptionsDef(BaseStruct):
    display_hint: typing.Optional[str] = pydantic.Field(None, description='Use the given name as a display hint. Default: - No hint\n')
    omit_empty_array: typing.Optional[bool] = pydantic.Field(None, description='If the produced value is an array and it is empty, return \'undefined\' instead. Default: false\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    lazy_any_value_options = cdk.LazyAnyValueOptions(\n        display_hint="displayHint",\n        omit_empty_array=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['display_hint', 'omit_empty_array']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.LazyAnyValueOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.LazyListValueOptions
class LazyListValueOptionsDef(BaseStruct):
    display_hint: typing.Optional[str] = pydantic.Field(None, description='Use the given name as a display hint. Default: - No hint\n')
    omit_empty: typing.Optional[bool] = pydantic.Field(None, description='If the produced list is empty, return \'undefined\' instead. Default: false\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    lazy_list_value_options = cdk.LazyListValueOptions(\n        display_hint="displayHint",\n        omit_empty=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['display_hint', 'omit_empty']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.LazyListValueOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.LazyStringValueOptions
class LazyStringValueOptionsDef(BaseStruct):
    display_hint: typing.Optional[str] = pydantic.Field(None, description='Use the given name as a display hint. Default: - No hint\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    lazy_string_value_options = cdk.LazyStringValueOptions(\n        display_hint="displayHint"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['display_hint']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.LazyStringValueOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.NestedStackProps
class NestedStackPropsDef(BaseStruct):
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the stack. Default: - No description.\n')
    notification_arns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The Simple Notification Service (SNS) topics to publish stack related events. Default: - notifications are not sent for this stack.\n')
    parameters: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='The set value pairs that represent the parameters passed to CloudFormation when this nested stack is created. Each parameter has a name corresponding to a parameter defined in the embedded template and a value representing the value that you want to set for the parameter. The nested stack construct will automatically synthesize parameters in order to bind references from the parent stack(s) into the nested stack. Default: - no user-defined parameters are passed to the nested stack\n')
    removal_policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='Policy to apply when the nested stack is removed. The default is ``Destroy``, because all Removal Policies of resources inside the Nested Stack should already have been set correctly. You normally should not need to set this value. Default: RemovalPolicy.DESTROY\n')
    timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The length of time that CloudFormation waits for the nested stack to reach the CREATE_COMPLETE state. When CloudFormation detects that the nested stack has reached the CREATE_COMPLETE state, it marks the nested stack resource as CREATE_COMPLETE in the parent stack and resumes creating the parent stack. If the timeout period expires before the nested stack reaches CREATE_COMPLETE, CloudFormation marks the nested stack as failed and rolls back both the nested stack and parent stack. Default: - no timeout\n\n:exampleMetadata: lit=aws-apigateway/test/integ.restapi-import.lit.ts infused\n\nExample::\n\n    from aws_cdk.aws_apigateway import IntegrationResponse, MethodResponse, IntegrationResponse, MethodResponse\n    from constructs import Construct\n    from aws_cdk import App, CfnOutput, NestedStack, NestedStackProps, Stack\n    from aws_cdk.aws_apigateway import Deployment, Method, MockIntegration, PassthroughBehavior, RestApi, Stage\n\n    #\n    # This file showcases how to split up a RestApi\'s Resources and Methods across nested stacks.\n    #\n    # The root stack \'RootStack\' first defines a RestApi.\n    # Two nested stacks BooksStack and PetsStack, create corresponding Resources \'/books\' and \'/pets\'.\n    # They are then deployed to a \'prod\' Stage via a third nested stack - DeployStack.\n    #\n    # To verify this worked, go to the APIGateway\n    #\n\n    class RootStack(Stack):\n        def __init__(self, scope):\n            super().__init__(scope, "integ-restapi-import-RootStack")\n\n            rest_api = RestApi(self, "RestApi",\n                cloud_watch_role=True,\n                deploy=False\n            )\n            rest_api.root.add_method("ANY")\n\n            pets_stack = PetsStack(self,\n                rest_api_id=rest_api.rest_api_id,\n                root_resource_id=rest_api.rest_api_root_resource_id\n            )\n            books_stack = BooksStack(self,\n                rest_api_id=rest_api.rest_api_id,\n                root_resource_id=rest_api.rest_api_root_resource_id\n            )\n            DeployStack(self,\n                rest_api_id=rest_api.rest_api_id,\n                methods=pets_stack.methods.concat(books_stack.methods)\n            )\n\n            CfnOutput(self, "PetsURL",\n                value=f"https://{restApi.restApiId}.execute-api.{this.region}.amazonaws.com/prod/pets"\n            )\n\n            CfnOutput(self, "BooksURL",\n                value=f"https://{restApi.restApiId}.execute-api.{this.region}.amazonaws.com/prod/books"\n            )\n\n    class PetsStack(NestedStack):\n\n        def __init__(self, scope, *, restApiId, rootResourceId, parameters=None, timeout=None, notificationArns=None, removalPolicy=None, description=None):\n            super().__init__(scope, "integ-restapi-import-PetsStack", restApiId=restApiId, rootResourceId=rootResourceId, parameters=parameters, timeout=timeout, notificationArns=notificationArns, removalPolicy=removalPolicy, description=description)\n\n            api = RestApi.from_rest_api_attributes(self, "RestApi",\n                rest_api_id=rest_api_id,\n                root_resource_id=root_resource_id\n            )\n\n            method = api.root.add_resource("pets").add_method("GET", MockIntegration(\n                integration_responses=[IntegrationResponse(\n                    status_code="200"\n                )],\n                passthrough_behavior=PassthroughBehavior.NEVER,\n                request_templates={\n                    "application/json": "{ "statusCode": 200 }"\n                }\n            ),\n                method_responses=[MethodResponse(status_code="200")]\n            )\n\n            self.methods.push(method)\n\n    class BooksStack(NestedStack):\n\n        def __init__(self, scope, *, restApiId, rootResourceId, parameters=None, timeout=None, notificationArns=None, removalPolicy=None, description=None):\n            super().__init__(scope, "integ-restapi-import-BooksStack", restApiId=restApiId, rootResourceId=rootResourceId, parameters=parameters, timeout=timeout, notificationArns=notificationArns, removalPolicy=removalPolicy, description=description)\n\n            api = RestApi.from_rest_api_attributes(self, "RestApi",\n                rest_api_id=rest_api_id,\n                root_resource_id=root_resource_id\n            )\n\n            method = api.root.add_resource("books").add_method("GET", MockIntegration(\n                integration_responses=[IntegrationResponse(\n                    status_code="200"\n                )],\n                passthrough_behavior=PassthroughBehavior.NEVER,\n                request_templates={\n                    "application/json": "{ "statusCode": 200 }"\n                }\n            ),\n                method_responses=[MethodResponse(status_code="200")]\n            )\n\n            self.methods.push(method)\n\n    class DeployStack(NestedStack):\n        def __init__(self, scope, *, restApiId, methods=None, parameters=None, timeout=None, notificationArns=None, removalPolicy=None, description=None):\n            super().__init__(scope, "integ-restapi-import-DeployStack", restApiId=restApiId, methods=methods, parameters=parameters, timeout=timeout, notificationArns=notificationArns, removalPolicy=removalPolicy, description=description)\n\n            deployment = Deployment(self, "Deployment",\n                api=RestApi.from_rest_api_id(self, "RestApi", rest_api_id)\n            )\n            if methods:\n                for method in methods:\n                    deployment.node.add_dependency(method)\n            Stage(self, "Stage", deployment=deployment)\n\n    RootStack(App())\n')
    _init_params: typing.ClassVar[list[str]] = ['description', 'notification_arns', 'parameters', 'removal_policy', 'timeout']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.NestedStackProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.PermissionsBoundaryBindOptions
class PermissionsBoundaryBindOptionsDef(BaseStruct):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.PermissionsBoundaryBindOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.PolicyValidationPluginReportBeta1
class PolicyValidationPluginReportBeta1Def(BaseStruct):
    success: typing.Union[bool, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Whether or not the report was successful.\n')
    violations: typing.Union[typing.Sequence[typing.Union[models.PolicyViolationBeta1Def, dict[str, typing.Any]]], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='List of violations in the report.\n')
    metadata: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Arbitrary information about the report. Default: - no metadata\n')
    plugin_version: typing.Optional[str] = pydantic.Field(None, description='The version of the plugin that created the report. Default: - no version\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    policy_validation_plugin_report_beta1 = cdk.PolicyValidationPluginReportBeta1(\n        success=False,\n        violations=[cdk.PolicyViolationBeta1(\n            description="description",\n            rule_name="ruleName",\n            violating_resources=[cdk.PolicyViolatingResourceBeta1(\n                locations=["locations"],\n                resource_logical_id="resourceLogicalId",\n                template_path="templatePath"\n            )],\n\n            # the properties below are optional\n            fix="fix",\n            rule_metadata={\n                "rule_metadata_key": "ruleMetadata"\n            },\n            severity="severity"\n        )],\n\n        # the properties below are optional\n        metadata={\n            "metadata_key": "metadata"\n        },\n        plugin_version="pluginVersion"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['success', 'violations', 'metadata', 'plugin_version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.PolicyValidationPluginReportBeta1'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.PolicyViolatingResourceBeta1
class PolicyViolatingResourceBeta1Def(BaseStruct):
    locations: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The locations in the CloudFormation template that pose the violations.\n')
    resource_logical_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The logical ID of the resource in the CloudFormation template.\n')
    template_path: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The path to the CloudFormation template that contains this resource.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    policy_violating_resource_beta1 = cdk.PolicyViolatingResourceBeta1(\n        locations=["locations"],\n        resource_logical_id="resourceLogicalId",\n        template_path="templatePath"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['locations', 'resource_logical_id', 'template_path']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.PolicyViolatingResourceBeta1'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.PolicyViolationBeta1
class PolicyViolationBeta1Def(BaseStruct):
    description: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The description of the violation.\n')
    rule_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the rule.\n')
    violating_resources: typing.Union[typing.Sequence[typing.Union[models.PolicyViolatingResourceBeta1Def, dict[str, typing.Any]]], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The resources violating this rule.\n')
    fix: typing.Optional[str] = pydantic.Field(None, description='How to fix the violation. Default: - no fix is provided\n')
    rule_metadata: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Additional metadata to include with the rule results. This can be used to provide additional information that is plugin specific. The data provided here will be rendered as is. Default: - no rule metadata\n')
    severity: typing.Optional[str] = pydantic.Field(None, description='The severity of the violation, only used for reporting purposes. This is useful for helping the user discriminate between warnings, errors, information, etc. Default: - no severity\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    policy_violation_beta1 = cdk.PolicyViolationBeta1(\n        description="description",\n        rule_name="ruleName",\n        violating_resources=[cdk.PolicyViolatingResourceBeta1(\n            locations=["locations"],\n            resource_logical_id="resourceLogicalId",\n            template_path="templatePath"\n        )],\n\n        # the properties below are optional\n        fix="fix",\n        rule_metadata={\n            "rule_metadata_key": "ruleMetadata"\n        },\n        severity="severity"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['description', 'rule_name', 'violating_resources', 'fix', 'rule_metadata', 'severity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.PolicyViolationBeta1'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.RemovalPolicyOptions
class RemovalPolicyOptionsDef(BaseStruct):
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    removal_policy_options = cdk.RemovalPolicyOptions(\n        apply_to_update_replace_policy=False,\n        default=cdk.RemovalPolicy.DESTROY\n    )\n")
    _init_params: typing.ClassVar[list[str]] = ['apply_to_update_replace_policy', 'default']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.RemovalPolicyOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.ResolveChangeContextOptions
class ResolveChangeContextOptionsDef(BaseStruct):
    allow_intrinsic_keys: typing.Optional[bool] = pydantic.Field(None, description="Change the 'allowIntrinsicKeys' option. Default: - Unchanged\n")
    remove_empty: typing.Optional[bool] = pydantic.Field(None, description='Whether to remove undefined elements from arrays and objects when resolving. Default: - Unchanged\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    resolve_change_context_options = cdk.ResolveChangeContextOptions(\n        allow_intrinsic_keys=False,\n        remove_empty=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['allow_intrinsic_keys', 'remove_empty']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.ResolveChangeContextOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.ResolveOptions
class ResolveOptionsDef(BaseStruct):
    resolver: typing.Union[_REQUIRED_INIT_PARAM, models.DefaultTokenResolverDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The resolver to apply to any resolvable tokens found.\n')
    preparing: typing.Optional[bool] = pydantic.Field(None, description='Whether the resolution is being executed during the prepare phase or not. Default: false\n')
    remove_empty: typing.Optional[bool] = pydantic.Field(None, description='Whether to remove undefined elements from arrays and objects when resolving. Default: true\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    import constructs as constructs\n\n    # construct: constructs.Construct\n    # token_resolver: cdk.ITokenResolver\n\n    resolve_options = cdk.ResolveOptions(\n        resolver=token_resolver,\n        scope=construct,\n\n        # the properties below are optional\n        preparing=False,\n        remove_empty=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['resolver', 'preparing', 'remove_empty']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.ResolveOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[ResolveOptionsDefConfig] = pydantic.Field(None)


class ResolveOptionsDefConfig(pydantic.BaseModel):
    resolver_config: typing.Optional[models._interface_methods.CoreITokenResolverDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.ResourceEnvironment
class ResourceEnvironmentDef(BaseStruct):
    account: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The AWS account ID that this resource belongs to. Since this can be a Token (for example, when the account is CloudFormation's AWS::AccountId intrinsic), make sure to use Token.compareStrings() instead of just comparing the values for equality.\n")
    region: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS region that this resource belongs to. Since this can be a Token (for example, when the region is CloudFormation\'s AWS::Region intrinsic), make sure to use Token.compareStrings() instead of just comparing the values for equality.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    resource_environment = cdk.ResourceEnvironment(\n        account="account",\n        region="region"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['account', 'region']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.ResourceEnvironment'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.ResourceProps
class ResourcePropsDef(BaseStruct):
    account: typing.Optional[str] = pydantic.Field(None, description='The AWS account ID this resource belongs to. Default: - the resource is in the same account as the stack it belongs to\n')
    environment_from_arn: typing.Optional[str] = pydantic.Field(None, description='ARN to deduce region and account from. The ARN is parsed and the account and region are taken from the ARN. This should be used for imported resources. Cannot be supplied together with either ``account`` or ``region``. Default: - take environment from ``account``, ``region`` parameters, or use Stack environment.\n')
    physical_name: typing.Optional[str] = pydantic.Field(None, description='The value passed in by users to the physical name prop of the resource. - ``undefined`` implies that a physical name will be allocated by CloudFormation during deployment. - a concrete value implies a specific physical name - ``PhysicalName.GENERATE_IF_NEEDED`` is a marker that indicates that a physical will only be generated by the CDK if it is needed for cross-environment references. Otherwise, it will be allocated by CloudFormation. Default: - The physical name will be allocated by CloudFormation at deployment time\n')
    region: typing.Optional[str] = pydantic.Field(None, description='The AWS region this resource belongs to. Default: - the resource is in the same region as the stack it belongs to\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    resource_props = cdk.ResourceProps(\n        account="account",\n        environment_from_arn="environmentFromArn",\n        physical_name="physicalName",\n        region="region"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['account', 'environment_from_arn', 'physical_name', 'region']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.ResourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.ReverseOptions
class ReverseOptionsDef(BaseStruct):
    fail_concat: typing.Optional[bool] = pydantic.Field(None, description='Fail if the given string is a concatenation. If ``false``, just return ``undefined``. Default: true\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    reverse_options = cdk.ReverseOptions(\n        fail_concat=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['fail_concat']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.ReverseOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.RoleOptions
class RoleOptionsDef(BaseStruct):
    assume_role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='ARN of the role to assume.\n')
    assume_role_external_id: typing.Optional[str] = pydantic.Field(None, description='External ID to use when assuming the role. Default: - No external ID\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    role_options = cdk.RoleOptions(\n        assume_role_arn="assumeRoleArn",\n\n        # the properties below are optional\n        assume_role_external_id="assumeRoleExternalId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['assume_role_arn', 'assume_role_external_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.RoleOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.SecretsManagerSecretOptions
class SecretsManagerSecretOptionsDef(BaseStruct):
    json_field: typing.Optional[str] = pydantic.Field(None, description='The key of a JSON field to retrieve. This can only be used if the secret stores a JSON object. Default: - returns all the content stored in the Secrets Manager secret.\n')
    version_id: typing.Optional[str] = pydantic.Field(None, description='Specifies the unique identifier of the version of the secret you want to use. Can specify at most one of ``versionId`` and ``versionStage``. Default: AWSCURRENT\n')
    version_stage: typing.Optional[str] = pydantic.Field(None, description='Specifies the secret version that you want to retrieve by the staging label attached to the version. Can specify at most one of ``versionId`` and ``versionStage``. Default: AWSCURRENT\n\n:exampleMetadata: infused\n\nExample::\n\n    codebuild.BitBucketSourceCredentials(self, "CodeBuildBitBucketCreds",\n        username=SecretValue.secrets_manager("my-bitbucket-creds", json_field="username"),\n        password=SecretValue.secrets_manager("my-bitbucket-creds", json_field="password")\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['json_field', 'version_id', 'version_stage']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.SecretsManagerSecretOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.SizeConversionOptions
class SizeConversionOptionsDef(BaseStruct):
    rounding: typing.Optional[aws_cdk.SizeRoundingBehavior] = pydantic.Field(None, description='How conversions should behave when it encounters a non-integer result. Default: SizeRoundingBehavior.FAIL\n\n:exampleMetadata: infused\n\nExample::\n\n    Size.mebibytes(2).to_kibibytes() # yields 2048\n    Size.kibibytes(2050).to_mebibytes(rounding=SizeRoundingBehavior.FLOOR)\n')
    _init_params: typing.ClassVar[list[str]] = ['rounding']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.SizeConversionOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.StackProps
class StackPropsDef(BaseStruct):
    analytics_reporting: typing.Optional[bool] = pydantic.Field(None, description="Include runtime versioning information in this Stack. Default: ``analyticsReporting`` setting of containing ``App``, or value of 'aws:cdk:version-reporting' context key")
    cross_region_references: typing.Optional[bool] = pydantic.Field(None, description='Enable this flag to allow native cross region stack references. Enabling this will create a CloudFormation custom resource in both the producing stack and consuming stack in order to perform the export/import This feature is currently experimental Default: false\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the stack. Default: - No description.\n')
    env: typing.Union[models.EnvironmentDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The AWS environment (account/region) where this stack will be deployed. Set the ``region``/``account`` fields of ``env`` to either a concrete value to select the indicated environment (recommended for production stacks), or to the values of environment variables ``CDK_DEFAULT_REGION``/``CDK_DEFAULT_ACCOUNT`` to let the target environment depend on the AWS credentials/configuration that the CDK CLI is executed under (recommended for development stacks). If the ``Stack`` is instantiated inside a ``Stage``, any undefined ``region``/``account`` fields from ``env`` will default to the same field on the encompassing ``Stage``, if configured there. If either ``region`` or ``account`` are not set nor inherited from ``Stage``, the Stack will be considered "*environment-agnostic*"". Environment-agnostic stacks can be deployed to any environment but may not be able to take advantage of all features of the CDK. For example, they will not be able to use environmental context lookups such as ``ec2.Vpc.fromLookup`` and will not automatically translate Service Principals to the right format based on the environment\'s AWS partition, and other such enhancements. Default: - The environment of the containing ``Stage`` if available, otherwise create the stack will be environment-agnostic.\n')
    permissions_boundary: typing.Optional[models.PermissionsBoundaryDef] = pydantic.Field(None, description='Options for applying a permissions boundary to all IAM Roles and Users created within this Stage. Default: - no permissions boundary is applied\n')
    stack_name: typing.Optional[str] = pydantic.Field(None, description='Name to deploy the stack with. Default: - Derived from construct path.\n')
    suppress_template_indentation: typing.Optional[bool] = pydantic.Field(None, description='Enable this flag to suppress indentation in generated CloudFormation templates. If not specified, the value of the ``@aws-cdk/core:suppressTemplateIndentation`` context key will be used. If that is not specified, then the default value ``false`` will be used. Default: - the value of ``@aws-cdk/core:suppressTemplateIndentation``, or ``false`` if that is not set.\n')
    synthesizer: typing.Optional[typing.Union[models.BootstraplessSynthesizerDef, models.CliCredentialsStackSynthesizerDef, models.DefaultStackSynthesizerDef, models.LegacyStackSynthesizerDef, models.NestedStackSynthesizerDef, models.StackSynthesizerDef]] = pydantic.Field(None, description='Synthesis method to use while deploying this stack. The Stack Synthesizer controls aspects of synthesis and deployment, like how assets are referenced and what IAM roles to use. For more information, see the README of the main CDK package. If not specified, the ``defaultStackSynthesizer`` from ``App`` will be used. If that is not specified, ``DefaultStackSynthesizer`` is used if ``@aws-cdk/core:newStyleStackSynthesis`` is set to ``true`` or the CDK major version is v2. In CDK v1 ``LegacyStackSynthesizer`` is the default if no other synthesizer is specified. Default: - The synthesizer specified on ``App``, or ``DefaultStackSynthesizer`` otherwise.\n')
    tags: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Stack tags that will be applied to all the taggable resources and the stack itself. Default: {}\n')
    termination_protection: typing.Optional[bool] = pydantic.Field(None, description='Whether to enable termination protection for this stack. Default: false\n\n:exampleMetadata: infused\n\nExample::\n\n    stack1 = Stack(app, "Stack1",\n        env=Environment(\n            region="us-east-1"\n        ),\n        cross_region_references=True\n    )\n    cert = acm.Certificate(stack1, "Cert",\n        domain_name="*.example.com",\n        validation=acm.CertificateValidation.from_dns(route53.PublicHostedZone.from_hosted_zone_id(stack1, "Zone", "Z0329774B51CGXTDQV3X"))\n    )\n\n    stack2 = Stack(app, "Stack2",\n        env=Environment(\n            region="us-east-2"\n        ),\n        cross_region_references=True\n    )\n    cloudfront.Distribution(stack2, "Distribution",\n        default_behavior=cloudfront.BehaviorOptions(\n            origin=origins.HttpOrigin("example.com")\n        ),\n        domain_names=["dev.example.com"],\n        certificate=cert\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['analytics_reporting', 'cross_region_references', 'description', 'env', 'permissions_boundary', 'stack_name', 'suppress_template_indentation', 'synthesizer', 'tags', 'termination_protection']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.StackProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.StageProps
class StagePropsDef(BaseStruct):
    env: typing.Union[models.EnvironmentDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Default AWS environment (account/region) for ``Stack``s in this ``Stage``. Stacks defined inside this ``Stage`` with either ``region`` or ``account`` missing from its env will use the corresponding field given here. If either ``region`` or ``account``is is not configured for ``Stack`` (either on the ``Stack`` itself or on the containing ``Stage``), the Stack will be *environment-agnostic*. Environment-agnostic stacks can be deployed to any environment, may not be able to take advantage of all features of the CDK. For example, they will not be able to use environmental context lookups, will not automatically translate Service Principals to the right format based on the environment's AWS partition, and other such enhancements. Default: - The environments should be configured on the ``Stack``s.\n")
    outdir: typing.Optional[str] = pydantic.Field(None, description='The output directory into which to emit synthesized artifacts. Can only be specified if this stage is the root stage (the app). If this is specified and this stage is nested within another stage, an error will be thrown. Default: - for nested stages, outdir will be determined as a relative directory to the outdir of the app. For apps, if outdir is not specified, a temporary directory will be created.\n')
    permissions_boundary: typing.Optional[models.PermissionsBoundaryDef] = pydantic.Field(None, description='Options for applying a permissions boundary to all IAM Roles and Users created within this Stage. Default: - no permissions boundary is applied\n')
    policy_validation_beta1: typing.Optional[typing.Sequence[models.UnsupportedResource]] = pydantic.Field(None, description='Validation plugins to run during synthesis. If any plugin reports any violation, synthesis will be interrupted and the report displayed to the user. Default: - no validation plugins are used\n')
    stage_name: typing.Optional[str] = pydantic.Field(None, description='Name of this stage. Default: - Derived from the id.\n\n:exampleMetadata: infused\n\nExample::\n\n    # app: App\n\n\n    Stage(app, "DevStage")\n\n    Stage(app, "BetaStage",\n        permissions_boundary=PermissionsBoundary.from_name("beta-permissions-boundary")\n    )\n\n    Stage(app, "GammaStage",\n        permissions_boundary=PermissionsBoundary.from_name("prod-permissions-boundary")\n    )\n\n    Stage(app, "ProdStage",\n        permissions_boundary=PermissionsBoundary.from_name("prod-permissions-boundary")\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['env', 'outdir', 'permissions_boundary', 'policy_validation_beta1', 'stage_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.StageProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.StageSynthesisOptions
class StageSynthesisOptionsDef(BaseStruct):
    force: typing.Optional[bool] = pydantic.Field(None, description='Force a re-synth, even if the stage has already been synthesized. This is used by tests to allow for incremental verification of the output. Do not use in production. Default: false\n')
    skip_validation: typing.Optional[bool] = pydantic.Field(None, description='Should we skip construct validation. Default: - false\n')
    validate_on_synthesis: typing.Optional[bool] = pydantic.Field(None, description='Whether the stack should be validated after synthesis to check for error metadata. Default: - false\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    stage_synthesis_options = cdk.StageSynthesisOptions(\n        force=False,\n        skip_validation=False,\n        validate_on_synthesis=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['force', 'skip_validation', 'validate_on_synthesis']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.StageSynthesisOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.SynthesizeStackArtifactOptions
class SynthesizeStackArtifactOptionsDef(BaseStruct):
    additional_dependencies: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Identifiers of additional dependencies. Default: - No additional dependencies\n')
    assume_role_arn: typing.Optional[str] = pydantic.Field(None, description='The role that needs to be assumed to deploy the stack. Default: - No role is assumed (current credentials are used)\n')
    assume_role_external_id: typing.Optional[str] = pydantic.Field(None, description='The externalID to use with the assumeRoleArn. Default: - No externalID is used\n')
    bootstrap_stack_version_ssm_parameter: typing.Optional[str] = pydantic.Field(None, description="SSM parameter where the bootstrap stack version number can be found. Only used if ``requiresBootstrapStackVersion`` is set. - If this value is not set, the bootstrap stack name must be known at deployment time so the stack version can be looked up from the stack outputs. - If this value is set, the bootstrap stack can have any name because we won't need to look it up. Default: - Bootstrap stack version number looked up\n")
    cloud_formation_execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The role that is passed to CloudFormation to execute the change set. Default: - No role is passed (currently assumed role/credentials are used)\n')
    lookup_role: typing.Union[models.cloud_assembly_schema.BootstrapRoleDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The role to use to look up values from the target AWS account. Default: - None\n')
    parameters: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Values for CloudFormation stack parameters that should be passed when the stack is deployed. Default: - No parameters\n')
    requires_bootstrap_stack_version: typing.Union[int, float, None] = pydantic.Field(None, description='Version of bootstrap stack required to deploy this stack. Default: - No bootstrap stack required\n')
    stack_template_asset_object_url: typing.Optional[str] = pydantic.Field(None, description='If the stack template has already been included in the asset manifest, its asset URL. Default: - Not uploaded yet, upload just before deploying\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    synthesize_stack_artifact_options = cdk.SynthesizeStackArtifactOptions(\n        additional_dependencies=["additionalDependencies"],\n        assume_role_arn="assumeRoleArn",\n        assume_role_external_id="assumeRoleExternalId",\n        bootstrap_stack_version_ssm_parameter="bootstrapStackVersionSsmParameter",\n        cloud_formation_execution_role_arn="cloudFormationExecutionRoleArn",\n        lookup_role=cdk.cloud_assembly_schema.BootstrapRole(\n            arn="arn",\n\n            # the properties below are optional\n            assume_role_external_id="assumeRoleExternalId",\n            bootstrap_stack_version_ssm_parameter="bootstrapStackVersionSsmParameter",\n            requires_bootstrap_stack_version=123\n        ),\n        parameters={\n            "parameters_key": "parameters"\n        },\n        requires_bootstrap_stack_version=123,\n        stack_template_asset_object_url="stackTemplateAssetObjectUrl"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['additional_dependencies', 'assume_role_arn', 'assume_role_external_id', 'bootstrap_stack_version_ssm_parameter', 'cloud_formation_execution_role_arn', 'lookup_role', 'parameters', 'requires_bootstrap_stack_version', 'stack_template_asset_object_url']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.SynthesizeStackArtifactOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.TagManagerOptions
class TagManagerOptionsDef(BaseStruct):
    tag_property_name: typing.Optional[str] = pydantic.Field(None, description='The name of the property in CloudFormation for these tags. Normally this is ``tags``, but Cognito UserPool uses UserPoolTags Default: "tags"\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    tag_manager_options = cdk.TagManagerOptions(\n        tag_property_name="tagPropertyName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['tag_property_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.TagManagerOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.TagProps
class TagPropsDef(BaseStruct):
    apply_to_launched_instances: typing.Optional[bool] = pydantic.Field(None, description='Whether the tag should be applied to instances in an AutoScalingGroup. Default: true\n')
    exclude_resource_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of Resource Types that will not receive this tag. An empty array will allow this tag to be applied to all resources. A non-empty array will apply this tag only if the Resource type is not in this array. Default: []\n')
    include_resource_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of Resource Types that will receive this tag. An empty array will match any Resource. A non-empty array will apply this tag only to Resource types that are included in this array. Default: []\n')
    priority: typing.Union[int, float, None] = pydantic.Field(None, description='Priority of the tag operation. Higher or equal priority tags will take precedence. Setting priority will enable the user to control tags when they need to not follow the default precedence pattern of last applied and closest to the construct in the tree. Default: Default priorities: - 100 for ``SetTag`` - 200 for ``RemoveTag`` - 50 for tags added directly to CloudFormation resources\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    tag_props = cdk.TagProps(\n        apply_to_launched_instances=False,\n        exclude_resource_types=["excludeResourceTypes"],\n        include_resource_types=["includeResourceTypes"],\n        priority=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['apply_to_launched_instances', 'exclude_resource_types', 'include_resource_types', 'priority']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.TagProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.TimeConversionOptions
class TimeConversionOptionsDef(BaseStruct):
    integral: typing.Optional[bool] = pydantic.Field(None, description='If ``true``, conversions into a larger time unit (e.g. ``Seconds`` to ``Minutes``) will fail if the result is not an integer. Default: true\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    time_conversion_options = cdk.TimeConversionOptions(\n        integral=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['integral']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.TimeConversionOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.UniqueResourceNameOptions
class UniqueResourceNameOptionsDef(BaseStruct):
    allowed_special_characters: typing.Optional[str] = pydantic.Field(None, description='Non-alphanumeric characters allowed in the unique resource name. Default: - none\n')
    max_length: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum length of the unique resource name. Default: - 256\n')
    separator: typing.Optional[str] = pydantic.Field(None, description='The separator used between the path components. Default: - none\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    unique_resource_name_options = cdk.UniqueResourceNameOptions(\n        allowed_special_characters="allowedSpecialCharacters",\n        max_length=123,\n        separator="separator"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['allowed_special_characters', 'max_length', 'separator']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.UniqueResourceNameOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.ArnFormat
# skipping emum

#  autogenerated from aws_cdk.AssetHashType
# skipping emum

#  autogenerated from aws_cdk.BundlingFileAccess
# skipping emum

#  autogenerated from aws_cdk.BundlingOutput
# skipping emum

#  autogenerated from aws_cdk.CfnCapabilities
# skipping emum

#  autogenerated from aws_cdk.CfnDeletionPolicy
# skipping emum

#  autogenerated from aws_cdk.CfnDynamicReferenceService
# skipping emum

#  autogenerated from aws_cdk.CfnTrafficRoutingType
# skipping emum

#  autogenerated from aws_cdk.CustomResourceProviderRuntime
# skipping emum

#  autogenerated from aws_cdk.DockerVolumeConsistency
# skipping emum

#  autogenerated from aws_cdk.FileAssetPackaging
# skipping emum

#  autogenerated from aws_cdk.IgnoreMode
# skipping emum

#  autogenerated from aws_cdk.PolicyValidationReportStatusBeta1
# skipping emum

#  autogenerated from aws_cdk.RemovalPolicy
# skipping emum

#  autogenerated from aws_cdk.ResolutionTypeHint
# skipping emum

#  autogenerated from aws_cdk.SizeRoundingBehavior
# skipping emum

#  autogenerated from aws_cdk.SymlinkFollowMode
# skipping emum

#  autogenerated from aws_cdk.TagType
# skipping emum

#  autogenerated from aws_cdk.IAnyProducer
#  skipping Interface

#  autogenerated from aws_cdk.IAspect
#  skipping Interface

#  autogenerated from aws_cdk.IAsset
#  skipping Interface

#  autogenerated from aws_cdk.IBoundStackSynthesizer
#  skipping Interface

#  autogenerated from aws_cdk.ICfnConditionExpression
#  skipping Interface

#  autogenerated from aws_cdk.ICfnResourceOptions
#  skipping Interface

#  autogenerated from aws_cdk.ICfnRuleConditionExpression
#  skipping Interface

#  autogenerated from aws_cdk.IFragmentConcatenator
#  skipping Interface

#  autogenerated from aws_cdk.IInspectable
#  skipping Interface

#  autogenerated from aws_cdk.IListProducer
#  skipping Interface

#  autogenerated from aws_cdk.ILocalBundling
#  skipping Interface

#  autogenerated from aws_cdk.INumberProducer
#  skipping Interface

#  autogenerated from aws_cdk.IPolicyValidationContextBeta1
#  skipping Interface

#  autogenerated from aws_cdk.IPolicyValidationPluginBeta1
#  skipping Interface

#  autogenerated from aws_cdk.IPostProcessor
#  skipping Interface

#  autogenerated from aws_cdk.IResolvable
#  skipping Interface

#  autogenerated from aws_cdk.IResolveContext
#  skipping Interface

#  autogenerated from aws_cdk.IResource
#  skipping Interface

#  autogenerated from aws_cdk.IReusableStackSynthesizer
#  skipping Interface

#  autogenerated from aws_cdk.IStableAnyProducer
#  skipping Interface

#  autogenerated from aws_cdk.IStableListProducer
#  skipping Interface

#  autogenerated from aws_cdk.IStableNumberProducer
#  skipping Interface

#  autogenerated from aws_cdk.IStableStringProducer
#  skipping Interface

#  autogenerated from aws_cdk.IStackSynthesizer
#  skipping Interface

#  autogenerated from aws_cdk.IStringProducer
#  skipping Interface

#  autogenerated from aws_cdk.ISynthesisSession
#  skipping Interface

#  autogenerated from aws_cdk.ITaggable
#  skipping Interface

#  autogenerated from aws_cdk.ITaggableV2
#  skipping Interface

#  autogenerated from aws_cdk.ITemplateOptions
#  skipping Interface

#  autogenerated from aws_cdk.ITokenMapper
#  skipping Interface

#  autogenerated from aws_cdk.ITokenResolver
#  skipping Interface

#  autogenerated from aws_cdk.CfnCodeDeployBlueGreenHook
class CfnCodeDeployBlueGreenHookDef(BaseCfnResource):
    applications: typing.Union[typing.Sequence[typing.Union[models.CfnCodeDeployBlueGreenApplicationDef, dict[str, typing.Any]]], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Properties of the Amazon ECS applications being deployed.\n')
    service_role: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The IAM Role for CloudFormation to use to perform blue-green deployments.\n')
    additional_options: typing.Union[models.CfnCodeDeployBlueGreenAdditionalOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Additional options for the blue/green deployment. Default: - no additional options\n')
    lifecycle_event_hooks: typing.Union[models.CfnCodeDeployBlueGreenLifecycleEventHooksDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Use lifecycle event hooks to specify a Lambda function that CodeDeploy can call to validate a deployment. You can use the same function or a different one for deployment lifecycle events. Following completion of the validation tests, the Lambda ``CfnCodeDeployBlueGreenLifecycleEventHooks.afterAllowTraffic`` function calls back CodeDeploy and delivers a result of 'Succeeded' or 'Failed'. Default: - no lifecycle event hooks\n")
    traffic_routing_config: typing.Union[models.CfnTrafficRoutingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Traffic routing configuration settings. Default: - time-based canary traffic shifting, with a 15% step percentage and a five minute bake time')
    _init_params: typing.ClassVar[list[str]] = ['applications', 'service_role', 'additional_options', 'lifecycle_event_hooks', 'traffic_routing_config']
    _method_names: typing.ClassVar[list[str]] = ['override_logical_id']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCodeDeployBlueGreenHook'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnCodeDeployBlueGreenHookDefConfig] = pydantic.Field(None)


class CfnCodeDeployBlueGreenHookDefConfig(pydantic.BaseModel):
    override_logical_id: typing.Optional[list[CfnCodeDeployBlueGreenHookDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')

class CfnCodeDeployBlueGreenHookDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...


#  autogenerated from aws_cdk.CfnCondition
class CfnConditionDef(BaseCfnResource):
    expression: typing.Optional[typing.Union[models.CfnConditionDef]] = pydantic.Field(None, description='The expression that the condition will evaluate. Default: - None.')
    _init_params: typing.ClassVar[list[str]] = ['expression']
    _method_names: typing.ClassVar[list[str]] = ['override_logical_id', 'resolve']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCondition'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnConditionDefConfig] = pydantic.Field(None)


class CfnConditionDefConfig(pydantic.BaseModel):
    override_logical_id: typing.Optional[list[CfnConditionDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    resolve: typing.Optional[list[CfnConditionDefResolveParams]] = pydantic.Field(None, description='Synthesizes the condition.')

class CfnConditionDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnConditionDefResolveParams(pydantic.BaseModel):
    _context: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.CfnCustomResource
class CfnCustomResourceDef(BaseCfnResource):
    service_token: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description=".. epigraph:: Only one property is defined by AWS for a custom resource: ``ServiceToken`` . All other properties are defined by the service provider. The service token that was given to the template developer by the service provider to access the service, such as an Amazon SNS topic ARN or Lambda function ARN. The service token must be from the same Region in which you are creating the stack. Updates aren't supported.")
    _init_params: typing.ClassVar[list[str]] = ['service_token']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCustomResource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnCustomResourceDefConfig] = pydantic.Field(None)


class CfnCustomResourceDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnCustomResourceDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnCustomResourceDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnCustomResourceDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnCustomResourceDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnCustomResourceDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnCustomResourceDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnCustomResourceDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnCustomResourceDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnCustomResourceDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnCustomResourceDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnCustomResourceDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnCustomResourceDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnCustomResourceDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnCustomResourceDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnCustomResourceDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnCustomResourceDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnCustomResourceDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnCustomResourceDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnCustomResourceDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnCustomResourceDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnCustomResourceDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnCustomResourceDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnCustomResourceDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnCustomResourceDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnCustomResourceDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnCustomResourceDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnCustomResourceDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnHook
class CfnHookDef(BaseCfnResource):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of the hook (for example, "AWS::CodeDeploy::BlueGreen").\n')
    properties: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='The properties of the hook. Default: - no properties')
    _init_params: typing.ClassVar[list[str]] = ['type', 'properties']
    _method_names: typing.ClassVar[list[str]] = ['override_logical_id']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnHook'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnHookDefConfig] = pydantic.Field(None)


class CfnHookDefConfig(pydantic.BaseModel):
    override_logical_id: typing.Optional[list[CfnHookDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')

class CfnHookDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...


#  autogenerated from aws_cdk.CfnHookDefaultVersion
class CfnHookDefaultVersionDef(BaseCfnResource):
    type_name: typing.Optional[str] = pydantic.Field(None, description='The name of the hook. You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .\n')
    type_version_arn: typing.Optional[str] = pydantic.Field(None, description='The version ID of the type configuration. You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .\n')
    version_id: typing.Optional[str] = pydantic.Field(None, description='The version ID of the type specified. You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .')
    _init_params: typing.ClassVar[list[str]] = ['type_name', 'type_version_arn', 'version_id']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnHookDefaultVersion'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnHookDefaultVersionDefConfig] = pydantic.Field(None)


class CfnHookDefaultVersionDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnHookDefaultVersionDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnHookDefaultVersionDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnHookDefaultVersionDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnHookDefaultVersionDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnHookDefaultVersionDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnHookDefaultVersionDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnHookDefaultVersionDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnHookDefaultVersionDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnHookDefaultVersionDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnHookDefaultVersionDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnHookDefaultVersionDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnHookDefaultVersionDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnHookDefaultVersionDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnHookDefaultVersionDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnHookDefaultVersionDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnHookDefaultVersionDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnHookDefaultVersionDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnHookDefaultVersionDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnHookDefaultVersionDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnHookDefaultVersionDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnHookDefaultVersionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnHookDefaultVersionDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnHookDefaultVersionDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnHookDefaultVersionDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnHookDefaultVersionDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnHookDefaultVersionDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnHookDefaultVersionDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnHookTypeConfig
class CfnHookTypeConfigDef(BaseCfnResource):
    configuration: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the activated hook type configuration, in this AWS account and AWS Region . You must specify either ``TypeName`` and ``Configuration`` or ``TypeARN`` and ``Configuration`` .\n')
    configuration_alias: typing.Optional[str] = pydantic.Field(None, description='Specifies the activated hook type configuration, in this AWS account and AWS Region . Defaults to ``default`` alias. Hook types currently support default configuration alias. Default: - "default"\n')
    type_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Number (ARN) for the hook to set ``Configuration`` for. You must specify either ``TypeName`` and ``Configuration`` or ``TypeARN`` and ``Configuration`` .\n')
    type_name: typing.Optional[str] = pydantic.Field(None, description='The unique name for your hook. Specifies a three-part namespace for your hook, with a recommended pattern of ``Organization::Service::Hook`` . You must specify either ``TypeName`` and ``Configuration`` or ``TypeARN`` and ``Configuration`` .')
    _init_params: typing.ClassVar[list[str]] = ['configuration', 'configuration_alias', 'type_arn', 'type_name']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnHookTypeConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnHookTypeConfigDefConfig] = pydantic.Field(None)


class CfnHookTypeConfigDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnHookTypeConfigDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnHookTypeConfigDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnHookTypeConfigDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnHookTypeConfigDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnHookTypeConfigDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnHookTypeConfigDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnHookTypeConfigDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnHookTypeConfigDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnHookTypeConfigDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnHookTypeConfigDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnHookTypeConfigDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnHookTypeConfigDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnHookTypeConfigDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnHookTypeConfigDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnHookTypeConfigDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnHookTypeConfigDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnHookTypeConfigDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnHookTypeConfigDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnHookTypeConfigDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnHookTypeConfigDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnHookTypeConfigDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnHookTypeConfigDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnHookTypeConfigDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnHookTypeConfigDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnHookTypeConfigDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnHookTypeConfigDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnHookTypeConfigDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnHookVersion
class CfnHookVersionDef(BaseCfnResource):
    schema_handler_package: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="A URL to the Amazon S3 bucket containing the hook project package that contains the necessary files for the hook you want to register. For information on generating a schema handler package for the resource you want to register, see `submit <https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/resource-type-cli-submit.html>`_ in the *CloudFormation CLI User Guide for Extension Development* . .. epigraph:: The user registering the resource must be able to access the package in the S3 bucket. That's, the user must have `GetObject <https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html>`_ permissions for the schema handler package. For more information, see `Actions, Resources, and Condition Keys for Amazon S3 <https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html>`_ in the *AWS Identity and Access Management User Guide* .\n")
    type_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The unique name for your hook. Specifies a three-part namespace for your hook, with a recommended pattern of ``Organization::Service::Hook`` . .. epigraph:: The following organization namespaces are reserved and can't be used in your hook type names: - ``Alexa`` - ``AMZN`` - ``Amazon`` - ``ASK`` - ``AWS`` - ``Custom`` - ``Dev``\n")
    execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the task execution role that grants the hook permission.\n')
    logging_config: typing.Union[models.UnsupportedResource, models.CfnHookVersion_LoggingConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Contains logging configuration information for an extension.')
    _init_params: typing.ClassVar[list[str]] = ['schema_handler_package', 'type_name', 'execution_role_arn', 'logging_config']
    _method_names: typing.ClassVar[list[str]] = ['LoggingConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnHookVersion'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnHookVersionDefConfig] = pydantic.Field(None)


class CfnHookVersionDefConfig(pydantic.BaseModel):
    LoggingConfigProperty: typing.Optional[list[CfnHookVersionDefLoggingconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnHookVersionDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnHookVersionDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnHookVersionDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnHookVersionDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnHookVersionDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnHookVersionDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnHookVersionDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnHookVersionDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnHookVersionDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnHookVersionDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnHookVersionDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnHookVersionDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnHookVersionDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    attr_is_default_version_config: typing.Optional[models._interface_methods.CoreIResolvableDefConfig] = pydantic.Field(None)

class CfnHookVersionDefLoggingconfigpropertyParams(pydantic.BaseModel):
    log_group_name: typing.Optional[str] = pydantic.Field(None, description='')
    log_role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnHookVersionDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnHookVersionDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnHookVersionDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnHookVersionDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnHookVersionDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnHookVersionDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnHookVersionDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnHookVersionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnHookVersionDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnHookVersionDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnHookVersionDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnHookVersionDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnHookVersionDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnHookVersionDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnJson
class CfnJsonDef(BaseCfnResource):
    value: typing.Union[typing.Any, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The value to resolve. Can be any JavaScript object, including tokens and references in keys or values.')
    _init_params: typing.ClassVar[list[str]] = ['value']
    _method_names: typing.ClassVar[list[str]] = ['resolve']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnJson'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnJsonDefConfig] = pydantic.Field(None)


class CfnJsonDefConfig(pydantic.BaseModel):
    resolve: typing.Optional[list[CfnJsonDefResolveParams]] = pydantic.Field(None, description="Produce the Token's value at resolution time.")
    value_config: typing.Optional[models.core.ReferenceDefConfig] = pydantic.Field(None)

class CfnJsonDefResolveParams(pydantic.BaseModel):
    _context: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.CfnMacro
class CfnMacroDef(BaseCfnResource):
    function_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the underlying AWS Lambda function that you want AWS CloudFormation to invoke when the macro is run.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the macro. The name of the macro must be unique across all macros in the account.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the macro.\n')
    log_group_name: typing.Optional[str] = pydantic.Field(None, description="The CloudWatch Logs group to which AWS CloudFormation sends error logging information when invoking the macro's underlying AWS Lambda function.\n")
    log_role_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the role AWS CloudFormation should assume when sending log entries to CloudWatch Logs .')
    _init_params: typing.ClassVar[list[str]] = ['function_name', 'name', 'description', 'log_group_name', 'log_role_arn']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnMacro'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnMacroDefConfig] = pydantic.Field(None)


class CfnMacroDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnMacroDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnMacroDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnMacroDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnMacroDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnMacroDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnMacroDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnMacroDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnMacroDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnMacroDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnMacroDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnMacroDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnMacroDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnMacroDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnMacroDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnMacroDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnMacroDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnMacroDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnMacroDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnMacroDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnMacroDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnMacroDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnMacroDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnMacroDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnMacroDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnMacroDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnMacroDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnMacroDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnMapping
class CfnMappingDef(BaseCfnResource):
    lazy: typing.Optional[bool] = pydantic.Field(None, description='')
    mapping: typing.Optional[typing.Mapping[str, typing.Mapping[str, typing.Any]]] = pydantic.Field(None, description='Mapping of key to a set of corresponding set of named values. The key identifies a map of name-value pairs and must be unique within the mapping. For example, if you want to set values based on a region, you can create a mapping that uses the region name as a key and contains the values you want to specify for each specific region. Default: - No mapping.')
    _init_params: typing.ClassVar[list[str]] = ['lazy', 'mapping']
    _method_names: typing.ClassVar[list[str]] = ['find_in_map', 'override_logical_id', 'set_value']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnMapping'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnMappingDefConfig] = pydantic.Field(None)


class CfnMappingDefConfig(pydantic.BaseModel):
    find_in_map: typing.Optional[list[CfnMappingDefFindInMapParams]] = pydantic.Field(None, description='')
    override_logical_id: typing.Optional[list[CfnMappingDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    set_value: typing.Optional[list[CfnMappingDefSetValueParams]] = pydantic.Field(None, description='Sets a value in the map based on the two keys.')

class CfnMappingDefFindInMapParams(pydantic.BaseModel):
    key1: str = pydantic.Field(..., description='-')
    key2: str = pydantic.Field(..., description='-\n')
    default_value: typing.Optional[str] = pydantic.Field(None, description='-\n')
    ...

class CfnMappingDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnMappingDefSetValueParams(pydantic.BaseModel):
    key1: str = pydantic.Field(..., description='-\n')
    key2: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.CfnModuleDefaultVersion
class CfnModuleDefaultVersionDef(BaseCfnResource):
    arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the module version to set as the default version. Conditional: You must specify either ``Arn`` , or ``ModuleName`` and ``VersionId`` .\n')
    module_name: typing.Optional[str] = pydantic.Field(None, description='The name of the module. Conditional: You must specify either ``Arn`` , or ``ModuleName`` and ``VersionId`` .\n')
    version_id: typing.Optional[str] = pydantic.Field(None, description='The ID for the specific version of the module. Conditional: You must specify either ``Arn`` , or ``ModuleName`` and ``VersionId`` .')
    _init_params: typing.ClassVar[list[str]] = ['arn', 'module_name', 'version_id']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnModuleDefaultVersion'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnModuleDefaultVersionDefConfig] = pydantic.Field(None)


class CfnModuleDefaultVersionDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnModuleDefaultVersionDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnModuleDefaultVersionDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnModuleDefaultVersionDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnModuleDefaultVersionDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnModuleDefaultVersionDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnModuleDefaultVersionDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnModuleDefaultVersionDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnModuleDefaultVersionDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnModuleDefaultVersionDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnModuleDefaultVersionDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnModuleDefaultVersionDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnModuleDefaultVersionDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnModuleDefaultVersionDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnModuleDefaultVersionDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnModuleDefaultVersionDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnModuleDefaultVersionDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnModuleDefaultVersionDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnModuleDefaultVersionDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnModuleDefaultVersionDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnModuleDefaultVersionDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnModuleDefaultVersionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnModuleDefaultVersionDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnModuleDefaultVersionDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnModuleDefaultVersionDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnModuleDefaultVersionDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnModuleDefaultVersionDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnModuleDefaultVersionDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnModuleVersion
class CfnModuleVersionDef(BaseCfnResource):
    module_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the module being registered.\n')
    module_package: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="A URL to the S3 bucket containing the package that contains the template fragment and schema files for the module version to register. .. epigraph:: The user registering the module version must be able to access the module package in the S3 bucket. That's, the user needs to have `GetObject <https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html>`_ permissions for the package. For more information, see `Actions, Resources, and Condition Keys for Amazon S3 <https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html>`_ in the *AWS Identity and Access Management User Guide* .")
    _init_params: typing.ClassVar[list[str]] = ['module_name', 'module_package']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnModuleVersion'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnModuleVersionDefConfig] = pydantic.Field(None)


class CfnModuleVersionDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnModuleVersionDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnModuleVersionDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnModuleVersionDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnModuleVersionDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnModuleVersionDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnModuleVersionDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnModuleVersionDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnModuleVersionDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnModuleVersionDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnModuleVersionDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnModuleVersionDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnModuleVersionDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnModuleVersionDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    attr_is_default_version_config: typing.Optional[models._interface_methods.CoreIResolvableDefConfig] = pydantic.Field(None)

class CfnModuleVersionDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnModuleVersionDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnModuleVersionDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnModuleVersionDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnModuleVersionDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnModuleVersionDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnModuleVersionDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnModuleVersionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnModuleVersionDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnModuleVersionDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnModuleVersionDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnModuleVersionDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnModuleVersionDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnModuleVersionDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnOutput
class CfnOutputDef(BaseCfnResource):
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The value of the property returned by the aws cloudformation describe-stacks command. The value of an output can include literals, parameter references, pseudo-parameters, a mapping value, or intrinsic functions.\n')
    condition: typing.Optional[models.CfnConditionDef] = pydantic.Field(None, description='A condition to associate with this output value. If the condition evaluates to ``false``, this output value will not be included in the stack. Default: - No condition is associated with the output.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A String type that describes the output value. The description can be a maximum of 4 K in length. Default: - No description.\n')
    export_name: typing.Optional[str] = pydantic.Field(None, description='The name used to export the value of this output across stacks. To import the value from another stack, use ``Fn.importValue(exportName)``. Default: - the output is not exported')
    _init_params: typing.ClassVar[list[str]] = ['value', 'condition', 'description', 'export_name']
    _method_names: typing.ClassVar[list[str]] = ['override_logical_id']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnOutput'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnOutputDefConfig] = pydantic.Field(None)


class CfnOutputDefConfig(pydantic.BaseModel):
    override_logical_id: typing.Optional[list[CfnOutputDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')

class CfnOutputDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...


#  autogenerated from aws_cdk.CfnParameter
class CfnParameterDef(BaseCfnResource):
    allowed_pattern: typing.Optional[str] = pydantic.Field(None, description='A regular expression that represents the patterns to allow for String types. Default: - No constraints on patterns allowed for parameter.\n')
    allowed_values: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array containing the list of values allowed for the parameter. Default: - No constraints on values allowed for parameter.\n')
    constraint_description: typing.Optional[str] = pydantic.Field(None, description='A string that explains a constraint when the constraint is violated. For example, without a constraint description, a parameter that has an allowed pattern of [A-Za-z0-9]+ displays the following error message when the user specifies an invalid value: Default: - No description with customized error message when user specifies invalid values.\n')
    default: typing.Any = pydantic.Field(None, description='A value of the appropriate type for the template to use if no value is specified when a stack is created. If you define constraints for the parameter, you must specify a value that adheres to those constraints. Default: - No default value for parameter.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A string of up to 4000 characters that describes the parameter. Default: - No description for the parameter.\n')
    max_length: typing.Union[int, float, None] = pydantic.Field(None, description='An integer value that determines the largest number of characters you want to allow for String types. Default: - None.\n')
    max_value: typing.Union[int, float, None] = pydantic.Field(None, description='A numeric value that determines the largest numeric value you want to allow for Number types. Default: - None.\n')
    min_length: typing.Union[int, float, None] = pydantic.Field(None, description='An integer value that determines the smallest number of characters you want to allow for String types. Default: - None.\n')
    min_value: typing.Union[int, float, None] = pydantic.Field(None, description='A numeric value that determines the smallest numeric value you want to allow for Number types. Default: - None.\n')
    no_echo: typing.Optional[bool] = pydantic.Field(None, description='Whether to mask the parameter value when anyone makes a call that describes the stack. If you set the value to ``true``, the parameter value is masked with asterisks (``*****``). Default: - Parameter values are not masked.\n')
    type: typing.Optional[str] = pydantic.Field(None, description='The data type for the parameter (DataType). Default: String')
    _init_params: typing.ClassVar[list[str]] = ['allowed_pattern', 'allowed_values', 'constraint_description', 'default', 'description', 'max_length', 'max_value', 'min_length', 'min_value', 'no_echo', 'type']
    _method_names: typing.ClassVar[list[str]] = ['override_logical_id', 'resolve']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnParameter'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnParameterDefConfig] = pydantic.Field(None)


class CfnParameterDefConfig(pydantic.BaseModel):
    override_logical_id: typing.Optional[list[CfnParameterDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    resolve: typing.Optional[list[CfnParameterDefResolveParams]] = pydantic.Field(None, description='')

class CfnParameterDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnParameterDefResolveParams(pydantic.BaseModel):
    _context: models.UnsupportedResource = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.CfnPublicTypeVersion
class CfnPublicTypeVersionDef(BaseCfnResource):
    arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Number (ARN) of the extension. Conditional: You must specify ``Arn`` , or ``TypeName`` and ``Type`` .\n')
    log_delivery_bucket: typing.Optional[str] = pydantic.Field(None, description='The S3 bucket to which CloudFormation delivers the contract test execution logs. CloudFormation delivers the logs by the time contract testing has completed and the extension has been assigned a test type status of ``PASSED`` or ``FAILED`` . The user initiating the stack operation must be able to access items in the specified S3 bucket. Specifically, the user needs the following permissions: - GetObject - PutObject For more information, see `Actions, Resources, and Condition Keys for Amazon S3 <https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazons3.html>`_ in the *AWS Identity and Access Management User Guide* .\n')
    public_version_number: typing.Optional[str] = pydantic.Field(None, description="The version number to assign to this version of the extension. Use the following format, and adhere to semantic versioning when assigning a version number to your extension: ``MAJOR.MINOR.PATCH`` For more information, see `Semantic Versioning 2.0.0 <https://docs.aws.amazon.com/https://semver.org/>`_ . If you don't specify a version number, CloudFormation increments the version number by one minor version release. You cannot specify a version number the first time you publish a type. AWS CloudFormation automatically sets the first version number to be ``1.0.0`` .\n")
    type: typing.Optional[str] = pydantic.Field(None, description='The type of the extension to test. Conditional: You must specify ``Arn`` , or ``TypeName`` and ``Type`` .\n')
    type_name: typing.Optional[str] = pydantic.Field(None, description='The name of the extension to test. Conditional: You must specify ``Arn`` , or ``TypeName`` and ``Type`` .')
    _init_params: typing.ClassVar[list[str]] = ['arn', 'log_delivery_bucket', 'public_version_number', 'type', 'type_name']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnPublicTypeVersion'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnPublicTypeVersionDefConfig] = pydantic.Field(None)


class CfnPublicTypeVersionDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnPublicTypeVersionDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnPublicTypeVersionDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnPublicTypeVersionDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnPublicTypeVersionDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnPublicTypeVersionDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnPublicTypeVersionDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnPublicTypeVersionDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnPublicTypeVersionDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnPublicTypeVersionDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnPublicTypeVersionDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnPublicTypeVersionDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnPublicTypeVersionDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnPublicTypeVersionDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnPublicTypeVersionDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnPublicTypeVersionDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnPublicTypeVersionDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnPublicTypeVersionDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnPublicTypeVersionDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnPublicTypeVersionDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnPublicTypeVersionDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnPublicTypeVersionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnPublicTypeVersionDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnPublicTypeVersionDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnPublicTypeVersionDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnPublicTypeVersionDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnPublicTypeVersionDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnPublicTypeVersionDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnPublisher
class CfnPublisherDef(BaseCfnResource):
    accept_terms_and_conditions: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Whether you accept the `Terms and Conditions <https://docs.aws.amazon.com/https://cloudformation-registry-documents.s3.amazonaws.com/Terms_and_Conditions_for_AWS_CloudFormation_Registry_Publishers.pdf>`_ for publishing extensions in the CloudFormation registry. You must accept the terms and conditions in order to register to publish public extensions to the CloudFormation registry. The default is ``false`` .\n')
    connection_arn: typing.Optional[str] = pydantic.Field(None, description='If you are using a Bitbucket or GitHub account for identity verification, the Amazon Resource Name (ARN) for your connection to that account. For more information, see `Registering your account to publish CloudFormation extensions <https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/publish-extension.html#publish-extension-prereqs>`_ in the *CloudFormation CLI User Guide* .')
    _init_params: typing.ClassVar[list[str]] = ['accept_terms_and_conditions', 'connection_arn']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnPublisher'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnPublisherDefConfig] = pydantic.Field(None)


class CfnPublisherDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnPublisherDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnPublisherDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnPublisherDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnPublisherDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnPublisherDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnPublisherDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnPublisherDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnPublisherDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnPublisherDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnPublisherDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnPublisherDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnPublisherDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnPublisherDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnPublisherDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnPublisherDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnPublisherDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnPublisherDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnPublisherDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnPublisherDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnPublisherDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnPublisherDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnPublisherDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnPublisherDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnPublisherDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnPublisherDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnPublisherDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnPublisherDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnResource
class CfnResourceDef(BaseCfnResource):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='CloudFormation resource type (e.g. ``AWS::S3::Bucket``).\n')
    properties: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Resource properties. Default: - No resource properties.')
    _init_params: typing.ClassVar[list[str]] = ['type', 'properties']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnResource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnResourceDefConfig] = pydantic.Field(None)


class CfnResourceDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnResourceDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnResourceDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnResourceDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnResourceDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnResourceDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnResourceDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnResourceDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnResourceDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnResourceDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnResourceDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnResourceDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnResourceDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnResourceDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnResourceDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnResourceDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnResourceDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnResourceDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnResourceDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnResourceDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnResourceDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnResourceDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnResourceDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnResourceDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnResourceDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnResourceDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnResourceDefaultVersion
class CfnResourceDefaultVersionDef(BaseCfnResource):
    type_name: typing.Optional[str] = pydantic.Field(None, description='The name of the resource. Conditional: You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .\n')
    type_version_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the resource version. Conditional: You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .\n')
    version_id: typing.Optional[str] = pydantic.Field(None, description="The ID of a specific version of the resource. The version ID is the value at the end of the Amazon Resource Name (ARN) assigned to the resource version when it's registered. Conditional: You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .")
    _init_params: typing.ClassVar[list[str]] = ['type_name', 'type_version_arn', 'version_id']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnResourceDefaultVersion'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnResourceDefaultVersionDefConfig] = pydantic.Field(None)


class CfnResourceDefaultVersionDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnResourceDefaultVersionDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnResourceDefaultVersionDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnResourceDefaultVersionDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnResourceDefaultVersionDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnResourceDefaultVersionDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnResourceDefaultVersionDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnResourceDefaultVersionDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnResourceDefaultVersionDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnResourceDefaultVersionDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnResourceDefaultVersionDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnResourceDefaultVersionDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnResourceDefaultVersionDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnResourceDefaultVersionDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnResourceDefaultVersionDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnResourceDefaultVersionDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnResourceDefaultVersionDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnResourceDefaultVersionDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnResourceDefaultVersionDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnResourceDefaultVersionDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnResourceDefaultVersionDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnResourceDefaultVersionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnResourceDefaultVersionDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnResourceDefaultVersionDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnResourceDefaultVersionDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnResourceDefaultVersionDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnResourceDefaultVersionDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnResourceDefaultVersionDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnResourceVersion
class CfnResourceVersionDef(BaseCfnResource):
    schema_handler_package: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A URL to the S3 bucket containing the resource project package that contains the necessary files for the resource you want to register. For information on generating a schema handler package for the resource you want to register, see `submit <https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/resource-type-cli-submit.html>`_ in the *CloudFormation CLI User Guide* . .. epigraph:: The user registering the resource must be able to access the package in the S3 bucket. That is, the user needs to have `GetObject <https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html>`_ permissions for the schema handler package. For more information, see `Actions, Resources, and Condition Keys for Amazon S3 <https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html>`_ in the *AWS Identity and Access Management User Guide* .\n')
    type_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The name of the resource being registered. We recommend that resource names adhere to the following pattern: *company_or_organization* :: *service* :: *type* . .. epigraph:: The following organization namespaces are reserved and can't be used in your resource names: - ``Alexa`` - ``AMZN`` - ``Amazon`` - ``AWS`` - ``Custom`` - ``Dev``\n")
    execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the IAM role for CloudFormation to assume when invoking the resource. If your resource calls AWS APIs in any of its handlers, you must create an *`IAM execution role <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html>`_* that includes the necessary permissions to call those AWS APIs, and provision that execution role in your account. When CloudFormation needs to invoke the resource type handler, CloudFormation assumes this execution role to create a temporary session token, which it then passes to the resource type handler, thereby supplying your resource type with the appropriate credentials.\n')
    logging_config: typing.Union[models.UnsupportedResource, models.CfnResourceVersion_LoggingConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Logging configuration information for a resource.')
    _init_params: typing.ClassVar[list[str]] = ['schema_handler_package', 'type_name', 'execution_role_arn', 'logging_config']
    _method_names: typing.ClassVar[list[str]] = ['LoggingConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnResourceVersion'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnResourceVersionDefConfig] = pydantic.Field(None)


class CfnResourceVersionDefConfig(pydantic.BaseModel):
    LoggingConfigProperty: typing.Optional[list[CfnResourceVersionDefLoggingconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnResourceVersionDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnResourceVersionDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnResourceVersionDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnResourceVersionDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnResourceVersionDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnResourceVersionDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnResourceVersionDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnResourceVersionDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnResourceVersionDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnResourceVersionDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnResourceVersionDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnResourceVersionDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnResourceVersionDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    attr_is_default_version_config: typing.Optional[models._interface_methods.CoreIResolvableDefConfig] = pydantic.Field(None)

class CfnResourceVersionDefLoggingconfigpropertyParams(pydantic.BaseModel):
    log_group_name: typing.Optional[str] = pydantic.Field(None, description='')
    log_role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnResourceVersionDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnResourceVersionDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnResourceVersionDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnResourceVersionDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnResourceVersionDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnResourceVersionDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnResourceVersionDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnResourceVersionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnResourceVersionDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnResourceVersionDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnResourceVersionDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnResourceVersionDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnResourceVersionDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnResourceVersionDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnRule
class CfnRuleDef(BaseCfnResource):
    assertions: typing.Optional[typing.Sequence[typing.Union[models.CfnRuleAssertionDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Assertions which define the rule. Default: - No assertions for the rule.\n')
    rule_condition: typing.Optional[typing.Union[models.CfnConditionDef]] = pydantic.Field(None, description="If the rule condition evaluates to false, the rule doesn't take effect. If the function in the rule condition evaluates to true, expressions in each assert are evaluated and applied. Default: - Rule's assertions will always take effect.")
    _init_params: typing.ClassVar[list[str]] = ['assertions', 'rule_condition']
    _method_names: typing.ClassVar[list[str]] = ['add_assertion', 'override_logical_id']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnRule'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnRuleDefConfig] = pydantic.Field(None)


class CfnRuleDefConfig(pydantic.BaseModel):
    add_assertion: typing.Optional[list[CfnRuleDefAddAssertionParams]] = pydantic.Field(None, description='Adds an assertion to the rule.')
    override_logical_id: typing.Optional[list[CfnRuleDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')

class CfnRuleDefAddAssertionParams(pydantic.BaseModel):
    condition: typing.Union[models.CfnConditionDef] = pydantic.Field(..., description='The expression to evaluation.\n')
    description: str = pydantic.Field(..., description='The description of the assertion.')
    ...

class CfnRuleDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...


#  autogenerated from aws_cdk.CfnStack
class CfnStackDef(BaseCfnResource):
    template_url: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Location of file containing the template body. The URL must point to a template (max size: 460,800 bytes) that's located in an Amazon S3 bucket. For more information, see `Template anatomy <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html>`_ . Whether an update causes interruptions depends on the resources that are being updated. An update never causes a nested stack to be replaced.\n")
    notification_arns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The Amazon Simple Notification Service (Amazon SNS) topic ARNs to publish stack related events. You can find your Amazon SNS topic ARNs using the Amazon SNS console or your Command Line Interface (CLI).\n')
    parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description="The set value pairs that represent the parameters passed to CloudFormation when this nested stack is created. Each parameter has a name corresponding to a parameter defined in the embedded template and a value representing the value that you want to set for the parameter. .. epigraph:: If you use the ``Ref`` function to pass a parameter value to a nested stack, comma-delimited list parameters must be of type ``String`` . In other words, you can't pass values that are of type ``CommaDelimitedList`` to nested stacks. Conditional. Required if the nested stack requires input parameters. Whether an update causes interruptions depends on the resources that are being updated. An update never causes a nested stack to be replaced.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs to associate with this stack. AWS CloudFormation also propagates these tags to the resources created in the stack. A maximum number of 50 tags can be specified.\n')
    timeout_in_minutes: typing.Union[int, float, None] = pydantic.Field(None, description="The length of time, in minutes, that CloudFormation waits for the nested stack to reach the ``CREATE_COMPLETE`` state. The default is no timeout. When CloudFormation detects that the nested stack has reached the ``CREATE_COMPLETE`` state, it marks the nested stack resource as ``CREATE_COMPLETE`` in the parent stack and resumes creating the parent stack. If the timeout period expires before the nested stack reaches ``CREATE_COMPLETE`` , CloudFormation marks the nested stack as failed and rolls back both the nested stack and parent stack. Updates aren't supported.")
    _init_params: typing.ClassVar[list[str]] = ['template_url', 'notification_arns', 'parameters', 'tags', 'timeout_in_minutes']
    _method_names: typing.ClassVar[list[str]] = ['OutputProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnStack'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnStackDefConfig] = pydantic.Field(None)


class CfnStackDefConfig(pydantic.BaseModel):
    OutputProperty: typing.Optional[list[CfnStackDefOutputpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnStackDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnStackDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnStackDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnStackDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnStackDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnStackDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnStackDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnStackDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnStackDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnStackDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnStackDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnStackDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnStackDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    attr_outputs_config: typing.Optional[models._interface_methods.CoreIResolvableDefConfig] = pydantic.Field(None)
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnStackDefOutputpropertyParams(pydantic.BaseModel):
    description: typing.Optional[str] = pydantic.Field(None, description='')
    export_name: typing.Optional[str] = pydantic.Field(None, description='')
    output_key: typing.Optional[str] = pydantic.Field(None, description='')
    output_value: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnStackDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnStackDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnStackDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnStackDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnStackDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnStackDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnStackDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnStackDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnStackDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnStackDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnStackDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnStackDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnStackDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnStackDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnStackSet
class CfnStackSetDef(BaseCfnResource):
    permission_model: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Describes how the IAM roles required for stack set operations are created. - With ``SELF_MANAGED`` permissions, you must create the administrator and execution roles required to deploy to target accounts. For more information, see `Grant Self-Managed Stack Set Permissions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-prereqs-self-managed.html>`_ . - With ``SERVICE_MANAGED`` permissions, StackSets automatically creates the IAM roles required to deploy to accounts managed by AWS Organizations .\n')
    stack_set_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name to associate with the stack set. The name must be unique in the Region where you create your stack set. *Maximum* : ``128`` *Pattern* : ``^[a-zA-Z][a-zA-Z0-9-]{0,127}$`` .. epigraph:: The ``StackSetName`` property is required.\n')
    administration_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Number (ARN) of the IAM role to use to create this stack set. Specify an IAM role only if you are using customized administrator roles to control which users or groups can manage specific stack sets within the same administrator account. Use customized administrator roles to control which users or groups can manage specific stack sets within the same administrator account. For more information, see `Prerequisites: Granting Permissions for Stack Set Operations <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-prereqs.html>`_ in the *AWS CloudFormation User Guide* . *Minimum* : ``20`` *Maximum* : ``2048``\n')
    auto_deployment: typing.Union[models.UnsupportedResource, models.CfnStackSet_AutoDeploymentPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='[ ``Service-managed`` permissions] Describes whether StackSets automatically deploys to AWS Organizations accounts that are added to a target organization or organizational unit (OU).\n')
    call_as: typing.Optional[str] = pydantic.Field(None, description="[Service-managed permissions] Specifies whether you are acting as an account administrator in the organization's management account or as a delegated administrator in a member account. By default, ``SELF`` is specified. Use ``SELF`` for stack sets with self-managed permissions. - To create a stack set with service-managed permissions while signed in to the management account, specify ``SELF`` . - To create a stack set with service-managed permissions while signed in to a delegated administrator account, specify ``DELEGATED_ADMIN`` . Your AWS account must be registered as a delegated admin in the management account. For more information, see `Register a delegated administrator <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-orgs-delegated-admin.html>`_ in the *AWS CloudFormation User Guide* . Stack sets with service-managed permissions are created in the management account, including stack sets that are created by delegated administrators. *Valid Values* : ``SELF`` | ``DELEGATED_ADMIN``\n")
    capabilities: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The capabilities that are allowed in the stack set. Some stack set templates might include resources that can affect permissions in your AWS account for example, by creating new AWS Identity and Access Management ( IAM ) users. For more information, see `Acknowledging IAM Resources in AWS CloudFormation Templates <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-iam-template.html#capabilities>`_ .\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the stack set. *Minimum* : ``1`` *Maximum* : ``1024``\n')
    execution_role_name: typing.Optional[str] = pydantic.Field(None, description="The name of the IAM execution role to use to create the stack set. If you don't specify an execution role, AWS CloudFormation uses the ``AWSCloudFormationStackSetExecutionRole`` role for the stack set operation. *Minimum* : ``1`` *Maximum* : ``64`` *Pattern* : ``[a-zA-Z_0-9+=,.@-]+``\n")
    managed_execution: typing.Any = pydantic.Field(None, description="Describes whether StackSets performs non-conflicting operations concurrently and queues conflicting operations. When active, StackSets performs non-conflicting operations concurrently and queues conflicting operations. After conflicting operations finish, StackSets starts queued operations in request order. .. epigraph:: If there are already running or queued operations, StackSets queues all incoming operations even if they are non-conflicting. You can't modify your stack set's execution configuration while there are running or queued operations for that stack set. When inactive (default), StackSets performs one operation at a time in request order.\n")
    operation_preferences: typing.Union[models.UnsupportedResource, models.CfnStackSet_OperationPreferencesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The user-specified preferences for how AWS CloudFormation performs a stack set operation.\n')
    parameters: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.CfnStackSet_ParameterPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The input parameters for the stack set template.\n')
    stack_instances_group: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.CfnStackSet_StackInstancesPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A group of stack instances with parameters in some specific accounts and Regions.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The key-value pairs to associate with this stack set and the stacks created from it. AWS CloudFormation also propagates these tags to supported resources that are created in the stacks. A maximum number of 50 tags can be specified.\n')
    template_body: typing.Optional[str] = pydantic.Field(None, description="The structure that contains the template body, with a minimum length of 1 byte and a maximum length of 51,200 bytes. You must include either ``TemplateURL`` or ``TemplateBody`` in a StackSet, but you can't use both. Dynamic references in the ``TemplateBody`` may not work correctly in all cases. It's recommended to pass templates containing dynamic references through ``TemplateUrl`` instead. *Minimum* : ``1`` *Maximum* : ``51200``\n")
    template_url: typing.Optional[str] = pydantic.Field(None, description="Location of file containing the template body. The URL must point to a template that's located in an Amazon S3 bucket or a Systems Manager document. For more information, go to `Template Anatomy <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html>`_ in the AWS CloudFormation User Guide. Conditional: You must specify only one of the following parameters: ``TemplateBody`` , ``TemplateURL`` .")
    _init_params: typing.ClassVar[list[str]] = ['permission_model', 'stack_set_name', 'administration_role_arn', 'auto_deployment', 'call_as', 'capabilities', 'description', 'execution_role_name', 'managed_execution', 'operation_preferences', 'parameters', 'stack_instances_group', 'tags', 'template_body', 'template_url']
    _method_names: typing.ClassVar[list[str]] = ['AutoDeploymentProperty', 'DeploymentTargetsProperty', 'ManagedExecutionProperty', 'OperationPreferencesProperty', 'ParameterProperty', 'StackInstancesProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnStackSet'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnStackSetDefConfig] = pydantic.Field(None)


class CfnStackSetDefConfig(pydantic.BaseModel):
    AutoDeploymentProperty: typing.Optional[list[CfnStackSetDefAutodeploymentpropertyParams]] = pydantic.Field(None, description='')
    DeploymentTargetsProperty: typing.Optional[list[CfnStackSetDefDeploymenttargetspropertyParams]] = pydantic.Field(None, description='')
    ManagedExecutionProperty: typing.Optional[list[CfnStackSetDefManagedexecutionpropertyParams]] = pydantic.Field(None, description='')
    OperationPreferencesProperty: typing.Optional[list[CfnStackSetDefOperationpreferencespropertyParams]] = pydantic.Field(None, description='')
    ParameterProperty: typing.Optional[list[CfnStackSetDefParameterpropertyParams]] = pydantic.Field(None, description='')
    StackInstancesProperty: typing.Optional[list[CfnStackSetDefStackinstancespropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnStackSetDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnStackSetDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnStackSetDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnStackSetDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnStackSetDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnStackSetDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnStackSetDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnStackSetDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnStackSetDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnStackSetDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnStackSetDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnStackSetDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnStackSetDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnStackSetDefAutodeploymentpropertyParams(pydantic.BaseModel):
    enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    retain_stacks_on_account_removal: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnStackSetDefDeploymenttargetspropertyParams(pydantic.BaseModel):
    account_filter_type: typing.Optional[str] = pydantic.Field(None, description='')
    accounts: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    accounts_url: typing.Optional[str] = pydantic.Field(None, description='')
    organizational_unit_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnStackSetDefManagedexecutionpropertyParams(pydantic.BaseModel):
    active: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnStackSetDefOperationpreferencespropertyParams(pydantic.BaseModel):
    failure_tolerance_count: typing.Union[int, float, None] = pydantic.Field(None, description='')
    failure_tolerance_percentage: typing.Union[int, float, None] = pydantic.Field(None, description='')
    max_concurrent_count: typing.Union[int, float, None] = pydantic.Field(None, description='')
    max_concurrent_percentage: typing.Union[int, float, None] = pydantic.Field(None, description='')
    region_concurrency_type: typing.Optional[str] = pydantic.Field(None, description='')
    region_order: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnStackSetDefParameterpropertyParams(pydantic.BaseModel):
    parameter_key: str = pydantic.Field(..., description='')
    parameter_value: str = pydantic.Field(..., description='')
    ...

class CfnStackSetDefStackinstancespropertyParams(pydantic.BaseModel):
    deployment_targets: typing.Union[models.UnsupportedResource, models.CfnStackSet_DeploymentTargetsPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    regions: typing.Sequence[str] = pydantic.Field(..., description='')
    parameter_overrides: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.CfnStackSet_ParameterPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnStackSetDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnStackSetDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnStackSetDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnStackSetDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnStackSetDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnStackSetDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnStackSetDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnStackSetDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnStackSetDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnStackSetDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnStackSetDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnStackSetDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnStackSetDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnStackSetDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnTypeActivation
class CfnTypeActivationDef(BaseCfnResource):
    auto_update: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to automatically update the extension in this account and Region when a new *minor* version is published by the extension publisher. Major versions released by the publisher must be manually updated. The default is ``true`` .\n')
    execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The name of the IAM execution role to use to activate the extension.\n')
    logging_config: typing.Union[models.UnsupportedResource, models.CfnTypeActivation_LoggingConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies logging configuration information for an extension.\n')
    major_version: typing.Optional[str] = pydantic.Field(None, description='The major version of this extension you want to activate, if multiple major versions are available. The default is the latest major version. CloudFormation uses the latest available *minor* version of the major version selected. You can specify ``MajorVersion`` or ``VersionBump`` , but not both.\n')
    public_type_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Number (ARN) of the public extension. Conditional: You must specify ``PublicTypeArn`` , or ``TypeName`` , ``Type`` , and ``PublisherId`` .\n')
    publisher_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the extension publisher. Conditional: You must specify ``PublicTypeArn`` , or ``TypeName`` , ``Type`` , and ``PublisherId`` .\n')
    type: typing.Optional[str] = pydantic.Field(None, description='The extension type. Conditional: You must specify ``PublicTypeArn`` , or ``TypeName`` , ``Type`` , and ``PublisherId`` .\n')
    type_name: typing.Optional[str] = pydantic.Field(None, description='The name of the extension. Conditional: You must specify ``PublicTypeArn`` , or ``TypeName`` , ``Type`` , and ``PublisherId`` .\n')
    type_name_alias: typing.Optional[str] = pydantic.Field(None, description='An alias to assign to the public extension, in this account and Region. If you specify an alias for the extension, CloudFormation treats the alias as the extension type name within this account and Region. You must use the alias to refer to the extension in your templates, API calls, and CloudFormation console. An extension alias must be unique within a given account and Region. You can activate the same public resource multiple times in the same account and Region, using different type name aliases.\n')
    version_bump: typing.Optional[str] = pydantic.Field(None, description='Manually updates a previously-activated type to a new major or minor version, if available. You can also use this parameter to update the value of ``AutoUpdate`` . - ``MAJOR`` : CloudFormation updates the extension to the newest major version, if one is available. - ``MINOR`` : CloudFormation updates the extension to the newest minor version, if one is available.')
    _init_params: typing.ClassVar[list[str]] = ['auto_update', 'execution_role_arn', 'logging_config', 'major_version', 'public_type_arn', 'publisher_id', 'type', 'type_name', 'type_name_alias', 'version_bump']
    _method_names: typing.ClassVar[list[str]] = ['LoggingConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnTypeActivation'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnTypeActivationDefConfig] = pydantic.Field(None)


class CfnTypeActivationDefConfig(pydantic.BaseModel):
    LoggingConfigProperty: typing.Optional[list[CfnTypeActivationDefLoggingconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnTypeActivationDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnTypeActivationDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnTypeActivationDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnTypeActivationDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnTypeActivationDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnTypeActivationDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnTypeActivationDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnTypeActivationDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnTypeActivationDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnTypeActivationDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnTypeActivationDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnTypeActivationDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnTypeActivationDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnTypeActivationDefLoggingconfigpropertyParams(pydantic.BaseModel):
    log_group_name: typing.Optional[str] = pydantic.Field(None, description='')
    log_role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTypeActivationDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnTypeActivationDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnTypeActivationDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnTypeActivationDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnTypeActivationDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnTypeActivationDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnTypeActivationDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnTypeActivationDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnTypeActivationDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnTypeActivationDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnTypeActivationDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnTypeActivationDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnTypeActivationDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnTypeActivationDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnWaitCondition
class CfnWaitConditionDef(BaseCfnResource):
    count: typing.Union[int, float, None] = pydantic.Field(None, description="The number of success signals that CloudFormation must receive before it continues the stack creation process. When the wait condition receives the requisite number of success signals, CloudFormation resumes the creation of the stack. If the wait condition doesn't receive the specified number of success signals before the Timeout period expires, CloudFormation assumes that the wait condition has failed and rolls the stack back. Updates aren't supported.\n")
    handle: typing.Optional[str] = pydantic.Field(None, description="A reference to the wait condition handle used to signal this wait condition. Use the ``Ref`` intrinsic function to specify an ```AWS::CloudFormation::WaitConditionHandle`` <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-waitconditionhandle.html>`_ resource. Anytime you add a ``WaitCondition`` resource during a stack update, you must associate the wait condition with a new WaitConditionHandle resource. Don't reuse an old wait condition handle that has already been defined in the template. If you reuse a wait condition handle, the wait condition might evaluate old signals from a previous create or update stack command. Updates aren't supported.\n")
    timeout: typing.Optional[str] = pydantic.Field(None, description="The length of time (in seconds) to wait for the number of signals that the ``Count`` property specifies. ``Timeout`` is a minimum-bound property, meaning the timeout occurs no sooner than the time you specify, but can occur shortly thereafter. The maximum time that can be specified for this property is 12 hours (43200 seconds). Updates aren't supported.")
    _init_params: typing.ClassVar[list[str]] = ['count', 'handle', 'timeout']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnWaitCondition'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnWaitConditionDefConfig] = pydantic.Field(None)


class CfnWaitConditionDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnWaitConditionDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnWaitConditionDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnWaitConditionDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnWaitConditionDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnWaitConditionDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnWaitConditionDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnWaitConditionDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnWaitConditionDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnWaitConditionDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnWaitConditionDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnWaitConditionDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnWaitConditionDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnWaitConditionDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    attr_data_config: typing.Optional[models._interface_methods.CoreIResolvableDefConfig] = pydantic.Field(None)

class CfnWaitConditionDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnWaitConditionDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnWaitConditionDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnWaitConditionDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnWaitConditionDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnWaitConditionDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnWaitConditionDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnWaitConditionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnWaitConditionDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnWaitConditionDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnWaitConditionDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnWaitConditionDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnWaitConditionDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnWaitConditionDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnWaitConditionHandle
class CfnWaitConditionHandleDef(BaseCfnResource):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnWaitConditionHandle'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnWaitConditionHandleDefConfig] = pydantic.Field(None)


class CfnWaitConditionHandleDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnWaitConditionHandleDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnWaitConditionHandleDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnWaitConditionHandleDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnWaitConditionHandleDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnWaitConditionHandleDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnWaitConditionHandleDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnWaitConditionHandleDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnWaitConditionHandleDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnWaitConditionHandleDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnWaitConditionHandleDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnWaitConditionHandleDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnWaitConditionHandleDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnWaitConditionHandleDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnWaitConditionHandleDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnWaitConditionHandleDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnWaitConditionHandleDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnWaitConditionHandleDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnWaitConditionHandleDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnWaitConditionHandleDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnWaitConditionHandleDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnWaitConditionHandleDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnWaitConditionHandleDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnWaitConditionHandleDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnWaitConditionHandleDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnWaitConditionHandleDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnWaitConditionHandleDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnWaitConditionHandleDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.CfnAutoScalingReplacingUpdate
class CfnAutoScalingReplacingUpdateDef(BaseCfnProperty):
    will_replace: typing.Optional[bool] = pydantic.Field(None, description='')
    _init_params: typing.ClassVar[list[str]] = ['will_replace']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnAutoScalingReplacingUpdate'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnAutoScalingRollingUpdate
class CfnAutoScalingRollingUpdateDef(BaseCfnProperty):
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='Specifies the maximum number of instances that AWS CloudFormation updates.\n')
    min_instances_in_service: typing.Union[int, float, None] = pydantic.Field(None, description='Specifies the minimum number of instances that must be in service within the Auto Scaling group while AWS CloudFormation updates old instances.\n')
    min_successful_instances_percent: typing.Union[int, float, None] = pydantic.Field(None, description="Specifies the percentage of instances in an Auto Scaling rolling update that must signal success for an update to succeed. You can specify a value from 0 to 100. AWS CloudFormation rounds to the nearest tenth of a percent. For example, if you update five instances with a minimum successful percentage of 50, three instances must signal success. If an instance doesn't send a signal within the time specified in the PauseTime property, AWS CloudFormation assumes that the instance wasn't updated. If you specify this property, you must also enable the WaitOnResourceSignals and PauseTime properties.\n")
    pause_time: typing.Optional[str] = pydantic.Field(None, description='The amount of time that AWS CloudFormation pauses after making a change to a batch of instances to give those instances time to start software applications. For example, you might need to specify PauseTime when scaling up the number of instances in an Auto Scaling group. If you enable the WaitOnResourceSignals property, PauseTime is the amount of time that AWS CloudFormation should wait for the Auto Scaling group to receive the required number of valid signals from added or replaced instances. If the PauseTime is exceeded before the Auto Scaling group receives the required number of signals, the update fails. For best results, specify a time period that gives your applications sufficient time to get started. If the update needs to be rolled back, a short PauseTime can cause the rollback to fail. Specify PauseTime in the ISO8601 duration format (in the format PT#H#M#S, where each # is the number of hours, minutes, and seconds, respectively). The maximum PauseTime is one hour (PT1H).\n')
    suspend_processes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="Specifies the Auto Scaling processes to suspend during a stack update. Suspending processes prevents Auto Scaling from interfering with a stack update. For example, you can suspend alarming so that Auto Scaling doesn't execute scaling policies associated with an alarm. For valid values, see the ScalingProcesses.member.N parameter for the SuspendProcesses action in the Auto Scaling API Reference.\n")
    wait_on_resource_signals: typing.Optional[bool] = pydantic.Field(None, description='Specifies whether the Auto Scaling group waits on signals from new instances during an update. Use this property to ensure that instances have completed installing and configuring applications before the Auto Scaling group update proceeds. AWS CloudFormation suspends the update of an Auto Scaling group after new EC2 instances are launched into the group. AWS CloudFormation must receive a signal from each new instance within the specified PauseTime before continuing the update. To signal the Auto Scaling group, use the cfn-signal helper script or SignalResource API. To have instances wait for an Elastic Load Balancing health check before they signal success, add a health-check verification by using the cfn-init helper script. For an example, see the verify_instance_health command in the Auto Scaling rolling updates sample template.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_auto_scaling_rolling_update = cdk.CfnAutoScalingRollingUpdate(\n        max_batch_size=123,\n        min_instances_in_service=123,\n        min_successful_instances_percent=123,\n        pause_time="pauseTime",\n        suspend_processes=["suspendProcesses"],\n        wait_on_resource_signals=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_batch_size', 'min_instances_in_service', 'min_successful_instances_percent', 'pause_time', 'suspend_processes', 'wait_on_resource_signals']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnAutoScalingRollingUpdate'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnAutoScalingScheduledAction
class CfnAutoScalingScheduledActionDef(BaseCfnProperty):
    ignore_unmodified_group_size_properties: typing.Optional[bool] = pydantic.Field(None, description='')
    _init_params: typing.ClassVar[list[str]] = ['ignore_unmodified_group_size_properties']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnAutoScalingScheduledAction'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnCodeDeployBlueGreenAdditionalOptions
class CfnCodeDeployBlueGreenAdditionalOptionsDef(BaseCfnProperty):
    termination_wait_time_in_minutes: typing.Union[int, float, None] = pydantic.Field(None, description='Specifies time to wait, in minutes, before terminating the blue resources. Default: - 5 minutes\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_code_deploy_blue_green_additional_options = cdk.CfnCodeDeployBlueGreenAdditionalOptions(\n        termination_wait_time_in_minutes=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['termination_wait_time_in_minutes']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCodeDeployBlueGreenAdditionalOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnCodeDeployBlueGreenApplication
class CfnCodeDeployBlueGreenApplicationDef(BaseCfnProperty):
    ecs_attributes: typing.Union[_REQUIRED_INIT_PARAM, models.CfnCodeDeployBlueGreenEcsAttributesDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The detailed attributes of the deployed target.\n')
    target: typing.Union[_REQUIRED_INIT_PARAM, models.CfnCodeDeployBlueGreenApplicationTargetDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The target that is being deployed.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_code_deploy_blue_green_application = cdk.CfnCodeDeployBlueGreenApplication(\n        ecs_attributes=cdk.CfnCodeDeployBlueGreenEcsAttributes(\n            task_definitions=["taskDefinitions"],\n            task_sets=["taskSets"],\n            traffic_routing=cdk.CfnTrafficRouting(\n                prod_traffic_route=cdk.CfnTrafficRoute(\n                    logical_id="logicalId",\n                    type="type"\n                ),\n                target_groups=["targetGroups"],\n                test_traffic_route=cdk.CfnTrafficRoute(\n                    logical_id="logicalId",\n                    type="type"\n                )\n            )\n        ),\n        target=cdk.CfnCodeDeployBlueGreenApplicationTarget(\n            logical_id="logicalId",\n            type="type"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['ecs_attributes', 'target']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCodeDeployBlueGreenApplication'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnCodeDeployBlueGreenApplicationTarget
class CfnCodeDeployBlueGreenApplicationTargetDef(BaseCfnProperty):
    logical_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The logical id of the target resource.\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The resource type of the target being deployed. Right now, the only allowed value is \'AWS::ECS::Service\'.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_code_deploy_blue_green_application_target = cdk.CfnCodeDeployBlueGreenApplicationTarget(\n        logical_id="logicalId",\n        type="type"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['logical_id', 'type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCodeDeployBlueGreenApplicationTarget'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnCodeDeployBlueGreenEcsAttributes
class CfnCodeDeployBlueGreenEcsAttributesDef(BaseCfnProperty):
    task_definitions: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The logical IDs of the blue and green, respectively, AWS::ECS::TaskDefinition task definitions.\n')
    task_sets: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The logical IDs of the blue and green, respectively, AWS::ECS::TaskSet task sets.\n')
    traffic_routing: typing.Union[_REQUIRED_INIT_PARAM, models.CfnTrafficRoutingDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The traffic routing configuration.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_code_deploy_blue_green_ecs_attributes = cdk.CfnCodeDeployBlueGreenEcsAttributes(\n        task_definitions=["taskDefinitions"],\n        task_sets=["taskSets"],\n        traffic_routing=cdk.CfnTrafficRouting(\n            prod_traffic_route=cdk.CfnTrafficRoute(\n                logical_id="logicalId",\n                type="type"\n            ),\n            target_groups=["targetGroups"],\n            test_traffic_route=cdk.CfnTrafficRoute(\n                logical_id="logicalId",\n                type="type"\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['task_definitions', 'task_sets', 'traffic_routing']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCodeDeployBlueGreenEcsAttributes'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnCodeDeployBlueGreenHookProps
class CfnCodeDeployBlueGreenHookPropsDef(BaseCfnProperty):
    applications: typing.Union[typing.Sequence[typing.Union[models.CfnCodeDeployBlueGreenApplicationDef, dict[str, typing.Any]]], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Properties of the Amazon ECS applications being deployed.\n')
    service_role: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The IAM Role for CloudFormation to use to perform blue-green deployments.\n')
    additional_options: typing.Union[models.CfnCodeDeployBlueGreenAdditionalOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Additional options for the blue/green deployment. Default: - no additional options\n')
    lifecycle_event_hooks: typing.Union[models.CfnCodeDeployBlueGreenLifecycleEventHooksDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Use lifecycle event hooks to specify a Lambda function that CodeDeploy can call to validate a deployment. You can use the same function or a different one for deployment lifecycle events. Following completion of the validation tests, the Lambda ``CfnCodeDeployBlueGreenLifecycleEventHooks.afterAllowTraffic`` function calls back CodeDeploy and delivers a result of 'Succeeded' or 'Failed'. Default: - no lifecycle event hooks\n")
    traffic_routing_config: typing.Union[models.CfnTrafficRoutingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Traffic routing configuration settings. Default: - time-based canary traffic shifting, with a 15% step percentage and a five minute bake time\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_code_deploy_blue_green_hook_props = cdk.CfnCodeDeployBlueGreenHookProps(\n        applications=[cdk.CfnCodeDeployBlueGreenApplication(\n            ecs_attributes=cdk.CfnCodeDeployBlueGreenEcsAttributes(\n                task_definitions=["taskDefinitions"],\n                task_sets=["taskSets"],\n                traffic_routing=cdk.CfnTrafficRouting(\n                    prod_traffic_route=cdk.CfnTrafficRoute(\n                        logical_id="logicalId",\n                        type="type"\n                    ),\n                    target_groups=["targetGroups"],\n                    test_traffic_route=cdk.CfnTrafficRoute(\n                        logical_id="logicalId",\n                        type="type"\n                    )\n                )\n            ),\n            target=cdk.CfnCodeDeployBlueGreenApplicationTarget(\n                logical_id="logicalId",\n                type="type"\n            )\n        )],\n        service_role="serviceRole",\n\n        # the properties below are optional\n        additional_options=cdk.CfnCodeDeployBlueGreenAdditionalOptions(\n            termination_wait_time_in_minutes=123\n        ),\n        lifecycle_event_hooks=cdk.CfnCodeDeployBlueGreenLifecycleEventHooks(\n            after_allow_test_traffic="afterAllowTestTraffic",\n            after_allow_traffic="afterAllowTraffic",\n            after_install="afterInstall",\n            before_allow_traffic="beforeAllowTraffic",\n            before_install="beforeInstall"\n        ),\n        traffic_routing_config=cdk.CfnTrafficRoutingConfig(\n            type=cdk.CfnTrafficRoutingType.ALL_AT_ONCE,\n\n            # the properties below are optional\n            time_based_canary=cdk.CfnTrafficRoutingTimeBasedCanary(\n                bake_time_mins=123,\n                step_percentage=123\n            ),\n            time_based_linear=cdk.CfnTrafficRoutingTimeBasedLinear(\n                bake_time_mins=123,\n                step_percentage=123\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['applications', 'service_role', 'additional_options', 'lifecycle_event_hooks', 'traffic_routing_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCodeDeployBlueGreenHookProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnCodeDeployBlueGreenLifecycleEventHooks
class CfnCodeDeployBlueGreenLifecycleEventHooksDef(BaseCfnProperty):
    after_allow_test_traffic: typing.Optional[str] = pydantic.Field(None, description='Function to use to run tasks after the test listener serves traffic to the replacement task set. Default: - none\n')
    after_allow_traffic: typing.Optional[str] = pydantic.Field(None, description='Function to use to run tasks after the second target group serves traffic to the replacement task set. Default: - none\n')
    after_install: typing.Optional[str] = pydantic.Field(None, description='Function to use to run tasks after the replacement task set is created and one of the target groups is associated with it. Default: - none\n')
    before_allow_traffic: typing.Optional[str] = pydantic.Field(None, description='Function to use to run tasks after the second target group is associated with the replacement task set, but before traffic is shifted to the replacement task set. Default: - none\n')
    before_install: typing.Optional[str] = pydantic.Field(None, description='Function to use to run tasks before the replacement task set is created. Default: - none\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_code_deploy_blue_green_lifecycle_event_hooks = cdk.CfnCodeDeployBlueGreenLifecycleEventHooks(\n        after_allow_test_traffic="afterAllowTestTraffic",\n        after_allow_traffic="afterAllowTraffic",\n        after_install="afterInstall",\n        before_allow_traffic="beforeAllowTraffic",\n        before_install="beforeInstall"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['after_allow_test_traffic', 'after_allow_traffic', 'after_install', 'before_allow_traffic', 'before_install']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCodeDeployBlueGreenLifecycleEventHooks'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnCodeDeployLambdaAliasUpdate
class CfnCodeDeployLambdaAliasUpdateDef(BaseCfnProperty):
    application_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the AWS CodeDeploy application.\n')
    deployment_group_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the AWS CodeDeploy deployment group. This is where the traffic-shifting policy is set.\n')
    after_allow_traffic_hook: typing.Optional[str] = pydantic.Field(None, description='The name of the Lambda function to run after traffic routing completes.\n')
    before_allow_traffic_hook: typing.Optional[str] = pydantic.Field(None, description='The name of the Lambda function to run before traffic routing starts.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_code_deploy_lambda_alias_update = cdk.CfnCodeDeployLambdaAliasUpdate(\n        application_name="applicationName",\n        deployment_group_name="deploymentGroupName",\n\n        # the properties below are optional\n        after_allow_traffic_hook="afterAllowTrafficHook",\n        before_allow_traffic_hook="beforeAllowTrafficHook"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['application_name', 'deployment_group_name', 'after_allow_traffic_hook', 'before_allow_traffic_hook']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCodeDeployLambdaAliasUpdate'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnConditionProps
class CfnConditionPropsDef(BaseCfnProperty):
    expression: typing.Optional[typing.Union[models.CfnConditionDef]] = pydantic.Field(None, description='The expression that the condition will evaluate. Default: - None.')
    _init_params: typing.ClassVar[list[str]] = ['expression']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnConditionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnCreationPolicy
class CfnCreationPolicyDef(BaseCfnProperty):
    auto_scaling_creation_policy: typing.Union[models.CfnResourceAutoScalingCreationPolicyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='For an Auto Scaling group replacement update, specifies how many instances must signal success for the update to succeed.\n')
    resource_signal: typing.Union[models.CfnResourceSignalDef, dict[str, typing.Any], None] = pydantic.Field(None, description='When AWS CloudFormation creates the associated resource, configures the number of required success signals and the length of time that AWS CloudFormation waits for those signals.\n')
    start_fleet: typing.Optional[bool] = pydantic.Field(None, description='For an AppStream Fleet creation, specifies that the fleet is started after creation.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_creation_policy = cdk.CfnCreationPolicy(\n        auto_scaling_creation_policy=cdk.CfnResourceAutoScalingCreationPolicy(\n            min_successful_instances_percent=123\n        ),\n        resource_signal=cdk.CfnResourceSignal(\n            count=123,\n            timeout="timeout"\n        ),\n        start_fleet=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_creation_policy', 'resource_signal', 'start_fleet']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCreationPolicy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnCustomResourceProps
class CfnCustomResourcePropsDef(BaseCfnProperty):
    service_token: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='.. epigraph:: Only one property is defined by AWS for a custom resource: ``ServiceToken`` . All other properties are defined by the service provider. The service token that was given to the template developer by the service provider to access the service, such as an Amazon SNS topic ARN or Lambda function ARN. The service token must be from the same Region in which you are creating the stack. Updates aren\'t supported.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-customresource.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_custom_resource_props = cdk.CfnCustomResourceProps(\n        service_token="serviceToken"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['service_token']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnCustomResourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnDynamicReferenceProps
class CfnDynamicReferencePropsDef(BaseCfnProperty):
    reference_key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The reference key of the dynamic reference.\n')
    service: typing.Union[aws_cdk.CfnDynamicReferenceService, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The service to retrieve the dynamic reference from.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_dynamic_reference_props = cdk.CfnDynamicReferenceProps(\n        reference_key="referenceKey",\n        service=cdk.CfnDynamicReferenceService.SSM\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['reference_key', 'service']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnDynamicReferenceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnHookDefaultVersionProps
class CfnHookDefaultVersionPropsDef(BaseCfnProperty):
    type_name: typing.Optional[str] = pydantic.Field(None, description='The name of the hook. You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .\n')
    type_version_arn: typing.Optional[str] = pydantic.Field(None, description='The version ID of the type configuration. You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .\n')
    version_id: typing.Optional[str] = pydantic.Field(None, description='The version ID of the type specified. You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-hookdefaultversion.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_hook_default_version_props = cdk.CfnHookDefaultVersionProps(\n        type_name="typeName",\n        type_version_arn="typeVersionArn",\n        version_id="versionId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type_name', 'type_version_arn', 'version_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnHookDefaultVersionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnHookProps
class CfnHookPropsDef(BaseCfnProperty):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of the hook (for example, "AWS::CodeDeploy::BlueGreen").\n')
    properties: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='The properties of the hook. Default: - no properties\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    # properties: Any\n\n    cfn_hook_props = cdk.CfnHookProps(\n        type="type",\n\n        # the properties below are optional\n        properties={\n            "properties_key": properties\n        }\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type', 'properties']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnHookProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnHookTypeConfigProps
class CfnHookTypeConfigPropsDef(BaseCfnProperty):
    configuration: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the activated hook type configuration, in this AWS account and AWS Region . You must specify either ``TypeName`` and ``Configuration`` or ``TypeARN`` and ``Configuration`` .\n')
    configuration_alias: typing.Optional[str] = pydantic.Field(None, description='Specifies the activated hook type configuration, in this AWS account and AWS Region . Defaults to ``default`` alias. Hook types currently support default configuration alias. Default: - "default"\n')
    type_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Number (ARN) for the hook to set ``Configuration`` for. You must specify either ``TypeName`` and ``Configuration`` or ``TypeARN`` and ``Configuration`` .\n')
    type_name: typing.Optional[str] = pydantic.Field(None, description='The unique name for your hook. Specifies a three-part namespace for your hook, with a recommended pattern of ``Organization::Service::Hook`` . You must specify either ``TypeName`` and ``Configuration`` or ``TypeARN`` and ``Configuration`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-hooktypeconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_hook_type_config_props = cdk.CfnHookTypeConfigProps(\n        configuration="configuration",\n\n        # the properties below are optional\n        configuration_alias="configurationAlias",\n        type_arn="typeArn",\n        type_name="typeName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['configuration', 'configuration_alias', 'type_arn', 'type_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnHookTypeConfigProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnHookVersion.LoggingConfigProperty
class CfnHookVersion_LoggingConfigPropertyDef(BaseCfnProperty):
    log_group_name: typing.Optional[str] = pydantic.Field(None, description="The Amazon CloudWatch Logs group to which CloudFormation sends error logging information when invoking the extension's handlers.\n")
    log_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the role that CloudFormation should assume when sending log entries to CloudWatch Logs.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cloudformation-hookversion-loggingconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    logging_config_property = cdk.CfnHookVersion.LoggingConfigProperty(\n        log_group_name="logGroupName",\n        log_role_arn="logRoleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['log_group_name', 'log_role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnHookVersion.LoggingConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnHookVersionProps
class CfnHookVersionPropsDef(BaseCfnProperty):
    schema_handler_package: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="A URL to the Amazon S3 bucket containing the hook project package that contains the necessary files for the hook you want to register. For information on generating a schema handler package for the resource you want to register, see `submit <https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/resource-type-cli-submit.html>`_ in the *CloudFormation CLI User Guide for Extension Development* . .. epigraph:: The user registering the resource must be able to access the package in the S3 bucket. That's, the user must have `GetObject <https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html>`_ permissions for the schema handler package. For more information, see `Actions, Resources, and Condition Keys for Amazon S3 <https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html>`_ in the *AWS Identity and Access Management User Guide* .\n")
    type_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The unique name for your hook. Specifies a three-part namespace for your hook, with a recommended pattern of ``Organization::Service::Hook`` . .. epigraph:: The following organization namespaces are reserved and can't be used in your hook type names: - ``Alexa`` - ``AMZN`` - ``Amazon`` - ``ASK`` - ``AWS`` - ``Custom`` - ``Dev``\n")
    execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the task execution role that grants the hook permission.\n')
    logging_config: typing.Union[models.UnsupportedResource, models.CfnHookVersion_LoggingConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Contains logging configuration information for an extension.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-hookversion.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_hook_version_props = cdk.CfnHookVersionProps(\n        schema_handler_package="schemaHandlerPackage",\n        type_name="typeName",\n\n        # the properties below are optional\n        execution_role_arn="executionRoleArn",\n        logging_config=cdk.CfnHookVersion.LoggingConfigProperty(\n            log_group_name="logGroupName",\n            log_role_arn="logRoleArn"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['schema_handler_package', 'type_name', 'execution_role_arn', 'logging_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnHookVersionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnJsonProps
class CfnJsonPropsDef(BaseCfnProperty):
    value: typing.Union[typing.Any, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The value to resolve. Can be any JavaScript object, including tokens and references in keys or values.')
    _init_params: typing.ClassVar[list[str]] = ['value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnJsonProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnMacroProps
class CfnMacroPropsDef(BaseCfnProperty):
    function_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the underlying AWS Lambda function that you want AWS CloudFormation to invoke when the macro is run.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the macro. The name of the macro must be unique across all macros in the account.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the macro.\n')
    log_group_name: typing.Optional[str] = pydantic.Field(None, description="The CloudWatch Logs group to which AWS CloudFormation sends error logging information when invoking the macro's underlying AWS Lambda function.\n")
    log_role_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the role AWS CloudFormation should assume when sending log entries to CloudWatch Logs .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-macro.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_macro_props = cdk.CfnMacroProps(\n        function_name="functionName",\n        name="name",\n\n        # the properties below are optional\n        description="description",\n        log_group_name="logGroupName",\n        log_role_arn="logRoleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['function_name', 'name', 'description', 'log_group_name', 'log_role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnMacroProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnMappingProps
class CfnMappingPropsDef(BaseCfnProperty):
    lazy: typing.Optional[bool] = pydantic.Field(None, description='')
    mapping: typing.Optional[typing.Mapping[str, typing.Mapping[str, typing.Any]]] = pydantic.Field(None, description='Mapping of key to a set of corresponding set of named values. The key identifies a map of name-value pairs and must be unique within the mapping. For example, if you want to set values based on a region, you can create a mapping that uses the region name as a key and contains the values you want to specify for each specific region. Default: - No mapping.\n\n:exampleMetadata: infused\n\nExample::\n\n    region_table = CfnMapping(self, "RegionTable",\n        mapping={\n            "us-east-1": {\n                "region_name": "US East (N. Virginia)"\n            },\n            "us-east-2": {\n                "region_name": "US East (Ohio)"\n            }\n        }\n    )\n\n    region_table.find_in_map(Aws.REGION, "regionName")\n')
    _init_params: typing.ClassVar[list[str]] = ['lazy', 'mapping']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnMappingProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnModuleDefaultVersionProps
class CfnModuleDefaultVersionPropsDef(BaseCfnProperty):
    arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the module version to set as the default version. Conditional: You must specify either ``Arn`` , or ``ModuleName`` and ``VersionId`` .\n')
    module_name: typing.Optional[str] = pydantic.Field(None, description='The name of the module. Conditional: You must specify either ``Arn`` , or ``ModuleName`` and ``VersionId`` .\n')
    version_id: typing.Optional[str] = pydantic.Field(None, description='The ID for the specific version of the module. Conditional: You must specify either ``Arn`` , or ``ModuleName`` and ``VersionId`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-moduledefaultversion.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_module_default_version_props = cdk.CfnModuleDefaultVersionProps(\n        arn="arn",\n        module_name="moduleName",\n        version_id="versionId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['arn', 'module_name', 'version_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnModuleDefaultVersionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnModuleVersionProps
class CfnModuleVersionPropsDef(BaseCfnProperty):
    module_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the module being registered.\n')
    module_package: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A URL to the S3 bucket containing the package that contains the template fragment and schema files for the module version to register. .. epigraph:: The user registering the module version must be able to access the module package in the S3 bucket. That\'s, the user needs to have `GetObject <https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html>`_ permissions for the package. For more information, see `Actions, Resources, and Condition Keys for Amazon S3 <https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html>`_ in the *AWS Identity and Access Management User Guide* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-moduleversion.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_module_version_props = cdk.CfnModuleVersionProps(\n        module_name="moduleName",\n        module_package="modulePackage"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['module_name', 'module_package']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnModuleVersionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnOutputProps
class CfnOutputPropsDef(BaseCfnProperty):
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The value of the property returned by the aws cloudformation describe-stacks command. The value of an output can include literals, parameter references, pseudo-parameters, a mapping value, or intrinsic functions.')
    condition: typing.Optional[models.CfnConditionDef] = pydantic.Field(None, description='A condition to associate with this output value. If the condition evaluates to ``false``, this output value will not be included in the stack. Default: - No condition is associated with the output.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A String type that describes the output value. The description can be a maximum of 4 K in length. Default: - No description.\n')
    export_name: typing.Optional[str] = pydantic.Field(None, description='The name used to export the value of this output across stacks. To import the value from another stack, use ``Fn.importValue(exportName)``. Default: - the output is not exported\n\n:exampleMetadata: infused\n\nExample::\n\n    # cluster: eks.Cluster\n\n    # add service account\n    service_account = cluster.add_service_account("MyServiceAccount")\n\n    bucket = s3.Bucket(self, "Bucket")\n    bucket.grant_read_write(service_account)\n\n    mypod = cluster.add_manifest("mypod", {\n        "api_version": "v1",\n        "kind": "Pod",\n        "metadata": {"name": "mypod"},\n        "spec": {\n            "service_account_name": service_account.service_account_name,\n            "containers": [{\n                "name": "hello",\n                "image": "paulbouwer/hello-kubernetes:1.5",\n                "ports": [{"container_port": 8080}]\n            }\n            ]\n        }\n    })\n\n    # create the resource after the service account.\n    mypod.node.add_dependency(service_account)\n\n    # print the IAM role arn for this service account\n    CfnOutput(self, "ServiceAccountIamRole", value=service_account.role.role_arn)\n')
    _init_params: typing.ClassVar[list[str]] = ['value', 'condition', 'description', 'export_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnOutputProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnParameterProps
class CfnParameterPropsDef(BaseCfnProperty):
    allowed_pattern: typing.Optional[str] = pydantic.Field(None, description='A regular expression that represents the patterns to allow for String types. Default: - No constraints on patterns allowed for parameter.')
    allowed_values: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array containing the list of values allowed for the parameter. Default: - No constraints on values allowed for parameter.\n')
    constraint_description: typing.Optional[str] = pydantic.Field(None, description='A string that explains a constraint when the constraint is violated. For example, without a constraint description, a parameter that has an allowed pattern of [A-Za-z0-9]+ displays the following error message when the user specifies an invalid value: Default: - No description with customized error message when user specifies invalid values.\n')
    default: typing.Any = pydantic.Field(None, description='A value of the appropriate type for the template to use if no value is specified when a stack is created. If you define constraints for the parameter, you must specify a value that adheres to those constraints. Default: - No default value for parameter.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A string of up to 4000 characters that describes the parameter. Default: - No description for the parameter.\n')
    max_length: typing.Union[int, float, None] = pydantic.Field(None, description='An integer value that determines the largest number of characters you want to allow for String types. Default: - None.\n')
    max_value: typing.Union[int, float, None] = pydantic.Field(None, description='A numeric value that determines the largest numeric value you want to allow for Number types. Default: - None.\n')
    min_length: typing.Union[int, float, None] = pydantic.Field(None, description='An integer value that determines the smallest number of characters you want to allow for String types. Default: - None.\n')
    min_value: typing.Union[int, float, None] = pydantic.Field(None, description='A numeric value that determines the smallest numeric value you want to allow for Number types. Default: - None.\n')
    no_echo: typing.Optional[bool] = pydantic.Field(None, description='Whether to mask the parameter value when anyone makes a call that describes the stack. If you set the value to ``true``, the parameter value is masked with asterisks (``*****``). Default: - Parameter values are not masked.\n')
    type: typing.Optional[str] = pydantic.Field(None, description='The data type for the parameter (DataType). Default: String\n\n:exampleMetadata: infused\n\nExample::\n\n    CfnParameter(self, "MyParameter",\n        type="Number",\n        default=1337\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['allowed_pattern', 'allowed_values', 'constraint_description', 'default', 'description', 'max_length', 'max_value', 'min_length', 'min_value', 'no_echo', 'type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnParameterProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnPublicTypeVersionProps
class CfnPublicTypeVersionPropsDef(BaseCfnProperty):
    arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Number (ARN) of the extension. Conditional: You must specify ``Arn`` , or ``TypeName`` and ``Type`` .\n')
    log_delivery_bucket: typing.Optional[str] = pydantic.Field(None, description='The S3 bucket to which CloudFormation delivers the contract test execution logs. CloudFormation delivers the logs by the time contract testing has completed and the extension has been assigned a test type status of ``PASSED`` or ``FAILED`` . The user initiating the stack operation must be able to access items in the specified S3 bucket. Specifically, the user needs the following permissions: - GetObject - PutObject For more information, see `Actions, Resources, and Condition Keys for Amazon S3 <https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazons3.html>`_ in the *AWS Identity and Access Management User Guide* .\n')
    public_version_number: typing.Optional[str] = pydantic.Field(None, description="The version number to assign to this version of the extension. Use the following format, and adhere to semantic versioning when assigning a version number to your extension: ``MAJOR.MINOR.PATCH`` For more information, see `Semantic Versioning 2.0.0 <https://docs.aws.amazon.com/https://semver.org/>`_ . If you don't specify a version number, CloudFormation increments the version number by one minor version release. You cannot specify a version number the first time you publish a type. AWS CloudFormation automatically sets the first version number to be ``1.0.0`` .\n")
    type: typing.Optional[str] = pydantic.Field(None, description='The type of the extension to test. Conditional: You must specify ``Arn`` , or ``TypeName`` and ``Type`` .\n')
    type_name: typing.Optional[str] = pydantic.Field(None, description='The name of the extension to test. Conditional: You must specify ``Arn`` , or ``TypeName`` and ``Type`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-publictypeversion.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_public_type_version_props = cdk.CfnPublicTypeVersionProps(\n        arn="arn",\n        log_delivery_bucket="logDeliveryBucket",\n        public_version_number="publicVersionNumber",\n        type="type",\n        type_name="typeName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['arn', 'log_delivery_bucket', 'public_version_number', 'type', 'type_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnPublicTypeVersionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnPublisherProps
class CfnPublisherPropsDef(BaseCfnProperty):
    accept_terms_and_conditions: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Whether you accept the `Terms and Conditions <https://docs.aws.amazon.com/https://cloudformation-registry-documents.s3.amazonaws.com/Terms_and_Conditions_for_AWS_CloudFormation_Registry_Publishers.pdf>`_ for publishing extensions in the CloudFormation registry. You must accept the terms and conditions in order to register to publish public extensions to the CloudFormation registry. The default is ``false`` .\n')
    connection_arn: typing.Optional[str] = pydantic.Field(None, description='If you are using a Bitbucket or GitHub account for identity verification, the Amazon Resource Name (ARN) for your connection to that account. For more information, see `Registering your account to publish CloudFormation extensions <https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/publish-extension.html#publish-extension-prereqs>`_ in the *CloudFormation CLI User Guide* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-publisher.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_publisher_props = cdk.CfnPublisherProps(\n        accept_terms_and_conditions=False,\n\n        # the properties below are optional\n        connection_arn="connectionArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['accept_terms_and_conditions', 'connection_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnPublisherProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnResourceAutoScalingCreationPolicy
class CfnResourceAutoScalingCreationPolicyDef(BaseCfnProperty):
    min_successful_instances_percent: typing.Union[int, float, None] = pydantic.Field(None, description="Specifies the percentage of instances in an Auto Scaling replacement update that must signal success for the update to succeed. You can specify a value from 0 to 100. AWS CloudFormation rounds to the nearest tenth of a percent. For example, if you update five instances with a minimum successful percentage of 50, three instances must signal success. If an instance doesn't send a signal within the time specified by the Timeout property, AWS CloudFormation assumes that the instance wasn't created.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_resource_auto_scaling_creation_policy = cdk.CfnResourceAutoScalingCreationPolicy(\n        min_successful_instances_percent=123\n    )\n")
    _init_params: typing.ClassVar[list[str]] = ['min_successful_instances_percent']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnResourceAutoScalingCreationPolicy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnResourceDefaultVersionProps
class CfnResourceDefaultVersionPropsDef(BaseCfnProperty):
    type_name: typing.Optional[str] = pydantic.Field(None, description='The name of the resource. Conditional: You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .\n')
    type_version_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the resource version. Conditional: You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .\n')
    version_id: typing.Optional[str] = pydantic.Field(None, description='The ID of a specific version of the resource. The version ID is the value at the end of the Amazon Resource Name (ARN) assigned to the resource version when it\'s registered. Conditional: You must specify either ``TypeVersionArn`` , or ``TypeName`` and ``VersionId`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-resourcedefaultversion.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_resource_default_version_props = cdk.CfnResourceDefaultVersionProps(\n        type_name="typeName",\n        type_version_arn="typeVersionArn",\n        version_id="versionId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type_name', 'type_version_arn', 'version_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnResourceDefaultVersionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnResourceProps
class CfnResourcePropsDef(BaseCfnProperty):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='CloudFormation resource type (e.g. ``AWS::S3::Bucket``).')
    properties: typing.Optional[typing.Mapping[str, typing.Any]] = pydantic.Field(None, description='Resource properties. Default: - No resource properties.\n\n:exampleMetadata: infused\n\nExample::\n\n    @jsii.implements(ITaggable)\n    class MyConstruct(Resource):\n\n        def __init__(self, scope, id):\n            super().__init__(scope, id)\n\n            CfnResource(self, "Resource",\n                type="Whatever::The::Type",\n                properties={\n                    # ...\n                    "Tags": self.tags.rendered_tags\n                }\n            )\n')
    _init_params: typing.ClassVar[list[str]] = ['type', 'properties']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnResourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnResourceSignal
class CfnResourceSignalDef(BaseCfnProperty):
    count: typing.Union[int, float, None] = pydantic.Field(None, description="The number of success signals AWS CloudFormation must receive before it sets the resource status as CREATE_COMPLETE. If the resource receives a failure signal or doesn't receive the specified number of signals before the timeout period expires, the resource creation fails and AWS CloudFormation rolls the stack back.\n")
    timeout: typing.Optional[str] = pydantic.Field(None, description='The length of time that AWS CloudFormation waits for the number of signals that was specified in the Count property. The timeout period starts after AWS CloudFormation starts creating the resource, and the timeout expires no sooner than the time you specify but can occur shortly thereafter. The maximum time that you can specify is 12 hours.\n\n:exampleMetadata: infused\n\nExample::\n\n    # resource: CfnResource\n\n\n    resource.cfn_options.creation_policy = CfnCreationPolicy(\n        resource_signal=CfnResourceSignal(\n            count=3,\n            timeout="PR15M"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['count', 'timeout']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnResourceSignal'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnResourceVersion.LoggingConfigProperty
class CfnResourceVersion_LoggingConfigPropertyDef(BaseCfnProperty):
    log_group_name: typing.Optional[str] = pydantic.Field(None, description="The Amazon CloudWatch logs group to which CloudFormation sends error logging information when invoking the type's handlers.\n")
    log_role_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the role that CloudFormation should assume when sending log entries to CloudWatch logs.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cloudformation-resourceversion-loggingconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    logging_config_property = cdk.CfnResourceVersion.LoggingConfigProperty(\n        log_group_name="logGroupName",\n        log_role_arn="logRoleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['log_group_name', 'log_role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnResourceVersion.LoggingConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnResourceVersionProps
class CfnResourceVersionPropsDef(BaseCfnProperty):
    schema_handler_package: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A URL to the S3 bucket containing the resource project package that contains the necessary files for the resource you want to register. For information on generating a schema handler package for the resource you want to register, see `submit <https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/resource-type-cli-submit.html>`_ in the *CloudFormation CLI User Guide* . .. epigraph:: The user registering the resource must be able to access the package in the S3 bucket. That is, the user needs to have `GetObject <https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html>`_ permissions for the schema handler package. For more information, see `Actions, Resources, and Condition Keys for Amazon S3 <https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html>`_ in the *AWS Identity and Access Management User Guide* .\n')
    type_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The name of the resource being registered. We recommend that resource names adhere to the following pattern: *company_or_organization* :: *service* :: *type* . .. epigraph:: The following organization namespaces are reserved and can't be used in your resource names: - ``Alexa`` - ``AMZN`` - ``Amazon`` - ``AWS`` - ``Custom`` - ``Dev``\n")
    execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the IAM role for CloudFormation to assume when invoking the resource. If your resource calls AWS APIs in any of its handlers, you must create an *`IAM execution role <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html>`_* that includes the necessary permissions to call those AWS APIs, and provision that execution role in your account. When CloudFormation needs to invoke the resource type handler, CloudFormation assumes this execution role to create a temporary session token, which it then passes to the resource type handler, thereby supplying your resource type with the appropriate credentials.\n')
    logging_config: typing.Union[models.UnsupportedResource, models.CfnResourceVersion_LoggingConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Logging configuration information for a resource.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-resourceversion.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_resource_version_props = cdk.CfnResourceVersionProps(\n        schema_handler_package="schemaHandlerPackage",\n        type_name="typeName",\n\n        # the properties below are optional\n        execution_role_arn="executionRoleArn",\n        logging_config=cdk.CfnResourceVersion.LoggingConfigProperty(\n            log_group_name="logGroupName",\n            log_role_arn="logRoleArn"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['schema_handler_package', 'type_name', 'execution_role_arn', 'logging_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnResourceVersionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnRuleAssertion
class CfnRuleAssertionDef(BaseCfnProperty):
    assert_: typing.Union[_REQUIRED_INIT_PARAM, models.CfnConditionDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The assertion.\n')
    assert_description: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The assertion description.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    # cfn_condition_expression: cdk.ICfnConditionExpression\n\n    cfn_rule_assertion = cdk.CfnRuleAssertion(\n        assert=cfn_condition_expression,\n        assert_description="assertDescription"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['assert_', 'assert_description']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnRuleAssertion'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnRuleProps
class CfnRulePropsDef(BaseCfnProperty):
    assertions: typing.Optional[typing.Sequence[typing.Union[models.CfnRuleAssertionDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Assertions which define the rule. Default: - No assertions for the rule.\n')
    rule_condition: typing.Optional[typing.Union[models.CfnConditionDef]] = pydantic.Field(None, description='If the rule condition evaluates to false, the rule doesn\'t take effect. If the function in the rule condition evaluates to true, expressions in each assert are evaluated and applied. Default: - Rule\'s assertions will always take effect.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    # cfn_condition_expression: cdk.ICfnConditionExpression\n\n    cfn_rule_props = cdk.CfnRuleProps(\n        assertions=[cdk.CfnRuleAssertion(\n            assert=cfn_condition_expression,\n            assert_description="assertDescription"\n        )],\n        rule_condition=cfn_condition_expression\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['assertions', 'rule_condition']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnRuleProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnStack.OutputProperty
class CfnStack_OutputPropertyDef(BaseCfnProperty):
    description: typing.Optional[str] = pydantic.Field(None, description='User defined description associated with the output.\n')
    export_name: typing.Optional[str] = pydantic.Field(None, description='The name of the export associated with the output.\n')
    output_key: typing.Optional[str] = pydantic.Field(None, description='The key associated with the output.\n')
    output_value: typing.Optional[str] = pydantic.Field(None, description='The value associated with the output.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cloudformation-stack-output.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    output_property = cdk.CfnStack.OutputProperty(\n        description="description",\n        export_name="exportName",\n        output_key="outputKey",\n        output_value="outputValue"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['description', 'export_name', 'output_key', 'output_value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnStack.OutputProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnStackProps
class CfnStackPropsDef(BaseCfnProperty):
    template_url: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Location of file containing the template body. The URL must point to a template (max size: 460,800 bytes) that's located in an Amazon S3 bucket. For more information, see `Template anatomy <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html>`_ . Whether an update causes interruptions depends on the resources that are being updated. An update never causes a nested stack to be replaced.\n")
    notification_arns: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The Amazon Simple Notification Service (Amazon SNS) topic ARNs to publish stack related events. You can find your Amazon SNS topic ARNs using the Amazon SNS console or your Command Line Interface (CLI).\n')
    parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description="The set value pairs that represent the parameters passed to CloudFormation when this nested stack is created. Each parameter has a name corresponding to a parameter defined in the embedded template and a value representing the value that you want to set for the parameter. .. epigraph:: If you use the ``Ref`` function to pass a parameter value to a nested stack, comma-delimited list parameters must be of type ``String`` . In other words, you can't pass values that are of type ``CommaDelimitedList`` to nested stacks. Conditional. Required if the nested stack requires input parameters. Whether an update causes interruptions depends on the resources that are being updated. An update never causes a nested stack to be replaced.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs to associate with this stack. AWS CloudFormation also propagates these tags to the resources created in the stack. A maximum number of 50 tags can be specified.\n')
    timeout_in_minutes: typing.Union[int, float, None] = pydantic.Field(None, description='The length of time, in minutes, that CloudFormation waits for the nested stack to reach the ``CREATE_COMPLETE`` state. The default is no timeout. When CloudFormation detects that the nested stack has reached the ``CREATE_COMPLETE`` state, it marks the nested stack resource as ``CREATE_COMPLETE`` in the parent stack and resumes creating the parent stack. If the timeout period expires before the nested stack reaches ``CREATE_COMPLETE`` , CloudFormation marks the nested stack as failed and rolls back both the nested stack and parent stack. Updates aren\'t supported.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-stack.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_stack_props = cdk.CfnStackProps(\n        template_url="templateUrl",\n\n        # the properties below are optional\n        notification_arns=["notificationArns"],\n        parameters={\n            "parameters_key": "parameters"\n        },\n        tags=[cdk.CfnTag(\n            key="key",\n            value="value"\n        )],\n        timeout_in_minutes=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['template_url', 'notification_arns', 'parameters', 'tags', 'timeout_in_minutes']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnStackProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnStackSet.AutoDeploymentProperty
class CfnStackSet_AutoDeploymentPropertyDef(BaseCfnProperty):
    enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='If set to ``true`` , StackSets automatically deploys additional stack instances to AWS Organizations accounts that are added to a target organization or organizational unit (OU) in the specified Regions. If an account is removed from a target organization or OU, StackSets deletes stack instances from the account in the specified Regions.\n')
    retain_stacks_on_account_removal: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='If set to ``true`` , stack resources are retained when an account is removed from a target organization or OU. If set to ``false`` , stack resources are deleted. Specify only if ``Enabled`` is set to ``True`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cloudformation-stackset-autodeployment.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    auto_deployment_property = cdk.CfnStackSet.AutoDeploymentProperty(\n        enabled=False,\n        retain_stacks_on_account_removal=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['enabled', 'retain_stacks_on_account_removal']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnStackSet.AutoDeploymentProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnStackSet.DeploymentTargetsProperty
class CfnStackSet_DeploymentTargetsPropertyDef(BaseCfnProperty):
    account_filter_type: typing.Optional[str] = pydantic.Field(None, description='Limit deployment targets to individual accounts or include additional accounts with provided OUs. The following is a list of possible values for the ``AccountFilterType`` operation. - ``INTERSECTION`` : StackSets deploys to the accounts specified in ``Accounts`` parameter. - ``DIFFERENCE`` : StackSets excludes the accounts specified in ``Accounts`` parameter. This enables user to avoid certain accounts within an OU such as suspended accounts. - ``UNION`` : StackSets includes additional accounts deployment targets. This is the default value if ``AccountFilterType`` is not provided. This enables user to update an entire OU and individual accounts from a different OU in one request, which used to be two separate requests. - ``NONE`` : Deploys to all the accounts in specified organizational units (OU).\n')
    accounts: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The names of one or more AWS accounts for which you want to deploy stack set updates. *Pattern* : ``^[0-9]{12}$``\n')
    accounts_url: typing.Optional[str] = pydantic.Field(None, description='Returns the value of the ``AccountsUrl`` property.\n')
    organizational_unit_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The organization root ID or organizational unit (OU) IDs to which StackSets deploys. *Pattern* : ``^(ou-[a-z0-9]{4,32}-[a-z0-9]{8,32}|r-[a-z0-9]{4,32})$``\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cloudformation-stackset-deploymenttargets.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    deployment_targets_property = cdk.CfnStackSet.DeploymentTargetsProperty(\n        account_filter_type="accountFilterType",\n        accounts=["accounts"],\n        accounts_url="accountsUrl",\n        organizational_unit_ids=["organizationalUnitIds"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['account_filter_type', 'accounts', 'accounts_url', 'organizational_unit_ids']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnStackSet.DeploymentTargetsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnStackSet.ManagedExecutionProperty
class CfnStackSet_ManagedExecutionPropertyDef(BaseCfnProperty):
    active: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="When ``true`` , StackSets performs non-conflicting operations concurrently and queues conflicting operations. After conflicting operations finish, StackSets starts queued operations in request order. .. epigraph:: If there are already running or queued operations, StackSets queues all incoming operations even if they are non-conflicting. You can't modify your stack set's execution configuration while there are running or queued operations for that stack set. When ``false`` (default), StackSets performs one operation at a time in request order.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cloudformation-stackset-managedexecution.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    managed_execution_property = cdk.CfnStackSet.ManagedExecutionProperty(\n        active=False\n    )\n")
    _init_params: typing.ClassVar[list[str]] = ['active']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnStackSet.ManagedExecutionProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnStackSet.OperationPreferencesProperty
class CfnStackSet_OperationPreferencesPropertyDef(BaseCfnProperty):
    failure_tolerance_count: typing.Union[int, float, None] = pydantic.Field(None, description="The number of accounts, per Region, for which this operation can fail before AWS CloudFormation stops the operation in that Region. If the operation is stopped in a Region, AWS CloudFormation doesn't attempt the operation in any subsequent Regions. Conditional: You must specify either ``FailureToleranceCount`` or ``FailureTolerancePercentage`` (but not both).\n")
    failure_tolerance_percentage: typing.Union[int, float, None] = pydantic.Field(None, description="The percentage of accounts, per Region, for which this stack operation can fail before AWS CloudFormation stops the operation in that Region. If the operation is stopped in a Region, AWS CloudFormation doesn't attempt the operation in any subsequent Regions. When calculating the number of accounts based on the specified percentage, AWS CloudFormation rounds *down* to the next whole number. Conditional: You must specify either ``FailureToleranceCount`` or ``FailureTolerancePercentage`` , but not both.\n")
    max_concurrent_count: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of accounts in which to perform this operation at one time. This is dependent on the value of ``FailureToleranceCount`` . ``MaxConcurrentCount`` is at most one more than the ``FailureToleranceCount`` . Note that this setting lets you specify the *maximum* for operations. For large deployments, under certain circumstances the actual number of accounts acted upon concurrently may be lower due to service throttling. Conditional: You must specify either ``MaxConcurrentCount`` or ``MaxConcurrentPercentage`` , but not both.\n')
    max_concurrent_percentage: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum percentage of accounts in which to perform this operation at one time. When calculating the number of accounts based on the specified percentage, AWS CloudFormation rounds down to the next whole number. This is true except in cases where rounding down would result is zero. In this case, CloudFormation sets the number as one instead. Note that this setting lets you specify the *maximum* for operations. For large deployments, under certain circumstances the actual number of accounts acted upon concurrently may be lower due to service throttling. Conditional: You must specify either ``MaxConcurrentCount`` or ``MaxConcurrentPercentage`` , but not both.\n')
    region_concurrency_type: typing.Optional[str] = pydantic.Field(None, description='The concurrency type of deploying StackSets operations in Regions, could be in parallel or one Region at a time.\n')
    region_order: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The order of the Regions where you want to perform the stack operation.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cloudformation-stackset-operationpreferences.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    operation_preferences_property = cdk.CfnStackSet.OperationPreferencesProperty(\n        failure_tolerance_count=123,\n        failure_tolerance_percentage=123,\n        max_concurrent_count=123,\n        max_concurrent_percentage=123,\n        region_concurrency_type="regionConcurrencyType",\n        region_order=["regionOrder"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['failure_tolerance_count', 'failure_tolerance_percentage', 'max_concurrent_count', 'max_concurrent_percentage', 'region_concurrency_type', 'region_order']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnStackSet.OperationPreferencesProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnStackSet.ParameterProperty
class CfnStackSet_ParameterPropertyDef(BaseCfnProperty):
    parameter_key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The key associated with the parameter. If you don't specify a key and value for a particular parameter, AWS CloudFormation uses the default value that's specified in your template.\n")
    parameter_value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The input value associated with the parameter.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cloudformation-stackset-parameter.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    parameter_property = cdk.CfnStackSet.ParameterProperty(\n        parameter_key="parameterKey",\n        parameter_value="parameterValue"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['parameter_key', 'parameter_value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnStackSet.ParameterProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnStackSet.StackInstancesProperty
class CfnStackSet_StackInstancesPropertyDef(BaseCfnProperty):
    deployment_targets: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.CfnStackSet_DeploymentTargetsPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS ``OrganizationalUnitIds`` or ``Accounts`` for which to create stack instances in the specified Regions.\n')
    regions: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The names of one or more Regions where you want to create stack instances using the specified AWS accounts .\n')
    parameter_overrides: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.CfnStackSet_ParameterPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A list of stack set parameters whose values you want to override in the selected stack instances.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cloudformation-stackset-stackinstances.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    stack_instances_property = cdk.CfnStackSet.StackInstancesProperty(\n        deployment_targets=cdk.CfnStackSet.DeploymentTargetsProperty(\n            account_filter_type="accountFilterType",\n            accounts=["accounts"],\n            accounts_url="accountsUrl",\n            organizational_unit_ids=["organizationalUnitIds"]\n        ),\n        regions=["regions"],\n\n        # the properties below are optional\n        parameter_overrides=[cdk.CfnStackSet.ParameterProperty(\n            parameter_key="parameterKey",\n            parameter_value="parameterValue"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['deployment_targets', 'regions', 'parameter_overrides']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnStackSet.StackInstancesProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnStackSetProps
class CfnStackSetPropsDef(BaseCfnProperty):
    permission_model: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Describes how the IAM roles required for stack set operations are created. - With ``SELF_MANAGED`` permissions, you must create the administrator and execution roles required to deploy to target accounts. For more information, see `Grant Self-Managed Stack Set Permissions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-prereqs-self-managed.html>`_ . - With ``SERVICE_MANAGED`` permissions, StackSets automatically creates the IAM roles required to deploy to accounts managed by AWS Organizations .\n')
    stack_set_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name to associate with the stack set. The name must be unique in the Region where you create your stack set. *Maximum* : ``128`` *Pattern* : ``^[a-zA-Z][a-zA-Z0-9-]{0,127}$`` .. epigraph:: The ``StackSetName`` property is required.\n')
    administration_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Number (ARN) of the IAM role to use to create this stack set. Specify an IAM role only if you are using customized administrator roles to control which users or groups can manage specific stack sets within the same administrator account. Use customized administrator roles to control which users or groups can manage specific stack sets within the same administrator account. For more information, see `Prerequisites: Granting Permissions for Stack Set Operations <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-prereqs.html>`_ in the *AWS CloudFormation User Guide* . *Minimum* : ``20`` *Maximum* : ``2048``\n')
    auto_deployment: typing.Union[models.UnsupportedResource, models.CfnStackSet_AutoDeploymentPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='[ ``Service-managed`` permissions] Describes whether StackSets automatically deploys to AWS Organizations accounts that are added to a target organization or organizational unit (OU).\n')
    call_as: typing.Optional[str] = pydantic.Field(None, description="[Service-managed permissions] Specifies whether you are acting as an account administrator in the organization's management account or as a delegated administrator in a member account. By default, ``SELF`` is specified. Use ``SELF`` for stack sets with self-managed permissions. - To create a stack set with service-managed permissions while signed in to the management account, specify ``SELF`` . - To create a stack set with service-managed permissions while signed in to a delegated administrator account, specify ``DELEGATED_ADMIN`` . Your AWS account must be registered as a delegated admin in the management account. For more information, see `Register a delegated administrator <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-orgs-delegated-admin.html>`_ in the *AWS CloudFormation User Guide* . Stack sets with service-managed permissions are created in the management account, including stack sets that are created by delegated administrators. *Valid Values* : ``SELF`` | ``DELEGATED_ADMIN``\n")
    capabilities: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The capabilities that are allowed in the stack set. Some stack set templates might include resources that can affect permissions in your AWS account for example, by creating new AWS Identity and Access Management ( IAM ) users. For more information, see `Acknowledging IAM Resources in AWS CloudFormation Templates <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-iam-template.html#capabilities>`_ .\n')
    description: typing.Optional[str] = pydantic.Field(None, description='A description of the stack set. *Minimum* : ``1`` *Maximum* : ``1024``\n')
    execution_role_name: typing.Optional[str] = pydantic.Field(None, description="The name of the IAM execution role to use to create the stack set. If you don't specify an execution role, AWS CloudFormation uses the ``AWSCloudFormationStackSetExecutionRole`` role for the stack set operation. *Minimum* : ``1`` *Maximum* : ``64`` *Pattern* : ``[a-zA-Z_0-9+=,.@-]+``\n")
    managed_execution: typing.Any = pydantic.Field(None, description="Describes whether StackSets performs non-conflicting operations concurrently and queues conflicting operations. When active, StackSets performs non-conflicting operations concurrently and queues conflicting operations. After conflicting operations finish, StackSets starts queued operations in request order. .. epigraph:: If there are already running or queued operations, StackSets queues all incoming operations even if they are non-conflicting. You can't modify your stack set's execution configuration while there are running or queued operations for that stack set. When inactive (default), StackSets performs one operation at a time in request order.\n")
    operation_preferences: typing.Union[models.UnsupportedResource, models.CfnStackSet_OperationPreferencesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The user-specified preferences for how AWS CloudFormation performs a stack set operation.\n')
    parameters: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.CfnStackSet_ParameterPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The input parameters for the stack set template.\n')
    stack_instances_group: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.CfnStackSet_StackInstancesPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A group of stack instances with parameters in some specific accounts and Regions.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='The key-value pairs to associate with this stack set and the stacks created from it. AWS CloudFormation also propagates these tags to supported resources that are created in the stacks. A maximum number of 50 tags can be specified.\n')
    template_body: typing.Optional[str] = pydantic.Field(None, description="The structure that contains the template body, with a minimum length of 1 byte and a maximum length of 51,200 bytes. You must include either ``TemplateURL`` or ``TemplateBody`` in a StackSet, but you can't use both. Dynamic references in the ``TemplateBody`` may not work correctly in all cases. It's recommended to pass templates containing dynamic references through ``TemplateUrl`` instead. *Minimum* : ``1`` *Maximum* : ``51200``\n")
    template_url: typing.Optional[str] = pydantic.Field(None, description='Location of file containing the template body. The URL must point to a template that\'s located in an Amazon S3 bucket or a Systems Manager document. For more information, go to `Template Anatomy <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html>`_ in the AWS CloudFormation User Guide. Conditional: You must specify only one of the following parameters: ``TemplateBody`` , ``TemplateURL`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-stackset.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    # managed_execution: Any\n\n    cfn_stack_set_props = cdk.CfnStackSetProps(\n        permission_model="permissionModel",\n        stack_set_name="stackSetName",\n\n        # the properties below are optional\n        administration_role_arn="administrationRoleArn",\n        auto_deployment=cdk.CfnStackSet.AutoDeploymentProperty(\n            enabled=False,\n            retain_stacks_on_account_removal=False\n        ),\n        call_as="callAs",\n        capabilities=["capabilities"],\n        description="description",\n        execution_role_name="executionRoleName",\n        managed_execution=managed_execution,\n        operation_preferences=cdk.CfnStackSet.OperationPreferencesProperty(\n            failure_tolerance_count=123,\n            failure_tolerance_percentage=123,\n            max_concurrent_count=123,\n            max_concurrent_percentage=123,\n            region_concurrency_type="regionConcurrencyType",\n            region_order=["regionOrder"]\n        ),\n        parameters=[cdk.CfnStackSet.ParameterProperty(\n            parameter_key="parameterKey",\n            parameter_value="parameterValue"\n        )],\n        stack_instances_group=[cdk.CfnStackSet.StackInstancesProperty(\n            deployment_targets=cdk.CfnStackSet.DeploymentTargetsProperty(\n                account_filter_type="accountFilterType",\n                accounts=["accounts"],\n                accounts_url="accountsUrl",\n                organizational_unit_ids=["organizationalUnitIds"]\n            ),\n            regions=["regions"],\n\n            # the properties below are optional\n            parameter_overrides=[cdk.CfnStackSet.ParameterProperty(\n                parameter_key="parameterKey",\n                parameter_value="parameterValue"\n            )]\n        )],\n        tags=[cdk.CfnTag(\n            key="key",\n            value="value"\n        )],\n        template_body="templateBody",\n        template_url="templateUrl"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['permission_model', 'stack_set_name', 'administration_role_arn', 'auto_deployment', 'call_as', 'capabilities', 'description', 'execution_role_name', 'managed_execution', 'operation_preferences', 'parameters', 'stack_instances_group', 'tags', 'template_body', 'template_url']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnStackSetProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnTag
class CfnTagDef(BaseCfnProperty):
    key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='')
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='')
    _init_params: typing.ClassVar[list[str]] = ['key', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnTag'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnTrafficRoute
class CfnTrafficRouteDef(BaseCfnProperty):
    logical_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The logical id of the target resource.\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The resource type of the route. Today, the only allowed value is \'AWS::ElasticLoadBalancingV2::Listener\'.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_traffic_route = cdk.CfnTrafficRoute(\n        logical_id="logicalId",\n        type="type"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['logical_id', 'type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnTrafficRoute'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnTrafficRouting
class CfnTrafficRoutingDef(BaseCfnProperty):
    prod_traffic_route: typing.Union[_REQUIRED_INIT_PARAM, models.CfnTrafficRouteDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The listener to be used by your load balancer to direct traffic to your target groups.\n')
    target_groups: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The logical IDs of the blue and green, respectively, AWS::ElasticLoadBalancingV2::TargetGroup target groups.\n')
    test_traffic_route: typing.Union[_REQUIRED_INIT_PARAM, models.CfnTrafficRouteDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The listener to be used by your load balancer to direct traffic to your target groups.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_traffic_routing = cdk.CfnTrafficRouting(\n        prod_traffic_route=cdk.CfnTrafficRoute(\n            logical_id="logicalId",\n            type="type"\n        ),\n        target_groups=["targetGroups"],\n        test_traffic_route=cdk.CfnTrafficRoute(\n            logical_id="logicalId",\n            type="type"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['prod_traffic_route', 'target_groups', 'test_traffic_route']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnTrafficRouting'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnTrafficRoutingConfig
class CfnTrafficRoutingConfigDef(BaseCfnProperty):
    type: typing.Union[aws_cdk.CfnTrafficRoutingType, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of traffic shifting used by the blue-green deployment configuration.\n')
    time_based_canary: typing.Union[models.CfnTrafficRoutingTimeBasedCanaryDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration for traffic routing when ``type`` is ``CfnTrafficRoutingType.TIME_BASED_CANARY``. Default: - none\n')
    time_based_linear: typing.Union[models.CfnTrafficRoutingTimeBasedLinearDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The configuration for traffic routing when ``type`` is ``CfnTrafficRoutingType.TIME_BASED_LINEAR``. Default: - none\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_traffic_routing_config = cdk.CfnTrafficRoutingConfig(\n        type=cdk.CfnTrafficRoutingType.ALL_AT_ONCE,\n\n        # the properties below are optional\n        time_based_canary=cdk.CfnTrafficRoutingTimeBasedCanary(\n            bake_time_mins=123,\n            step_percentage=123\n        ),\n        time_based_linear=cdk.CfnTrafficRoutingTimeBasedLinear(\n            bake_time_mins=123,\n            step_percentage=123\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type', 'time_based_canary', 'time_based_linear']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnTrafficRoutingConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnTrafficRoutingTimeBasedCanary
class CfnTrafficRoutingTimeBasedCanaryDef(BaseCfnProperty):
    bake_time_mins: typing.Union[int, float, None] = pydantic.Field(None, description='The number of minutes between the first and second traffic shifts of a time-based canary deployment. Default: 5\n')
    step_percentage: typing.Union[int, float, None] = pydantic.Field(None, description='The percentage of traffic to shift in the first increment of a time-based canary deployment. The step percentage must be 14% or greater. Default: 15\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_traffic_routing_time_based_canary = cdk.CfnTrafficRoutingTimeBasedCanary(\n        bake_time_mins=123,\n        step_percentage=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bake_time_mins', 'step_percentage']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnTrafficRoutingTimeBasedCanary'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnTrafficRoutingTimeBasedLinear
class CfnTrafficRoutingTimeBasedLinearDef(BaseCfnProperty):
    bake_time_mins: typing.Union[int, float, None] = pydantic.Field(None, description='The number of minutes between the first and second traffic shifts of a time-based linear deployment. Default: 5\n')
    step_percentage: typing.Union[int, float, None] = pydantic.Field(None, description='The percentage of traffic that is shifted at the start of each increment of a time-based linear deployment. The step percentage must be 14% or greater. Default: 15\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_traffic_routing_time_based_linear = cdk.CfnTrafficRoutingTimeBasedLinear(\n        bake_time_mins=123,\n        step_percentage=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bake_time_mins', 'step_percentage']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnTrafficRoutingTimeBasedLinear'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnTypeActivation.LoggingConfigProperty
class CfnTypeActivation_LoggingConfigPropertyDef(BaseCfnProperty):
    log_group_name: typing.Optional[str] = pydantic.Field(None, description="The Amazon CloudWatch Logs group to which CloudFormation sends error logging information when invoking the extension's handlers.\n")
    log_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the role that CloudFormation should assume when sending log entries to CloudWatch Logs.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cloudformation-typeactivation-loggingconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    logging_config_property = cdk.CfnTypeActivation.LoggingConfigProperty(\n        log_group_name="logGroupName",\n        log_role_arn="logRoleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['log_group_name', 'log_role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnTypeActivation.LoggingConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnTypeActivationProps
class CfnTypeActivationPropsDef(BaseCfnProperty):
    auto_update: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to automatically update the extension in this account and Region when a new *minor* version is published by the extension publisher. Major versions released by the publisher must be manually updated. The default is ``true`` .\n')
    execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The name of the IAM execution role to use to activate the extension.\n')
    logging_config: typing.Union[models.UnsupportedResource, models.CfnTypeActivation_LoggingConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies logging configuration information for an extension.\n')
    major_version: typing.Optional[str] = pydantic.Field(None, description='The major version of this extension you want to activate, if multiple major versions are available. The default is the latest major version. CloudFormation uses the latest available *minor* version of the major version selected. You can specify ``MajorVersion`` or ``VersionBump`` , but not both.\n')
    public_type_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Number (ARN) of the public extension. Conditional: You must specify ``PublicTypeArn`` , or ``TypeName`` , ``Type`` , and ``PublisherId`` .\n')
    publisher_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the extension publisher. Conditional: You must specify ``PublicTypeArn`` , or ``TypeName`` , ``Type`` , and ``PublisherId`` .\n')
    type: typing.Optional[str] = pydantic.Field(None, description='The extension type. Conditional: You must specify ``PublicTypeArn`` , or ``TypeName`` , ``Type`` , and ``PublisherId`` .\n')
    type_name: typing.Optional[str] = pydantic.Field(None, description='The name of the extension. Conditional: You must specify ``PublicTypeArn`` , or ``TypeName`` , ``Type`` , and ``PublisherId`` .\n')
    type_name_alias: typing.Optional[str] = pydantic.Field(None, description='An alias to assign to the public extension, in this account and Region. If you specify an alias for the extension, CloudFormation treats the alias as the extension type name within this account and Region. You must use the alias to refer to the extension in your templates, API calls, and CloudFormation console. An extension alias must be unique within a given account and Region. You can activate the same public resource multiple times in the same account and Region, using different type name aliases.\n')
    version_bump: typing.Optional[str] = pydantic.Field(None, description='Manually updates a previously-activated type to a new major or minor version, if available. You can also use this parameter to update the value of ``AutoUpdate`` . - ``MAJOR`` : CloudFormation updates the extension to the newest major version, if one is available. - ``MINOR`` : CloudFormation updates the extension to the newest minor version, if one is available.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-typeactivation.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_type_activation_props = cdk.CfnTypeActivationProps(\n        auto_update=False,\n        execution_role_arn="executionRoleArn",\n        logging_config=cdk.CfnTypeActivation.LoggingConfigProperty(\n            log_group_name="logGroupName",\n            log_role_arn="logRoleArn"\n        ),\n        major_version="majorVersion",\n        public_type_arn="publicTypeArn",\n        publisher_id="publisherId",\n        type="type",\n        type_name="typeName",\n        type_name_alias="typeNameAlias",\n        version_bump="versionBump"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['auto_update', 'execution_role_arn', 'logging_config', 'major_version', 'public_type_arn', 'publisher_id', 'type', 'type_name', 'type_name_alias', 'version_bump']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnTypeActivationProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnUpdatePolicy
class CfnUpdatePolicyDef(BaseCfnProperty):
    auto_scaling_replacing_update: typing.Union[models.CfnAutoScalingReplacingUpdateDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies whether an Auto Scaling group and the instances it contains are replaced during an update. During replacement, AWS CloudFormation retains the old group until it finishes creating the new one. If the update fails, AWS CloudFormation can roll back to the old Auto Scaling group and delete the new Auto Scaling group.\n')
    auto_scaling_rolling_update: typing.Union[models.CfnAutoScalingRollingUpdateDef, dict[str, typing.Any], None] = pydantic.Field(None, description='To specify how AWS CloudFormation handles rolling updates for an Auto Scaling group, use the AutoScalingRollingUpdate policy. Rolling updates enable you to specify whether AWS CloudFormation updates instances that are in an Auto Scaling group in batches or all at once.\n')
    auto_scaling_scheduled_action: typing.Union[models.CfnAutoScalingScheduledActionDef, dict[str, typing.Any], None] = pydantic.Field(None, description='To specify how AWS CloudFormation handles updates for the MinSize, MaxSize, and DesiredCapacity properties when the AWS::AutoScaling::AutoScalingGroup resource has an associated scheduled action, use the AutoScalingScheduledAction policy.\n')
    code_deploy_lambda_alias_update: typing.Union[models.CfnCodeDeployLambdaAliasUpdateDef, dict[str, typing.Any], None] = pydantic.Field(None, description='To perform an AWS CodeDeploy deployment when the version changes on an AWS::Lambda::Alias resource, use the CodeDeployLambdaAliasUpdate update policy.\n')
    enable_version_upgrade: typing.Optional[bool] = pydantic.Field(None, description='To upgrade an Amazon ES domain to a new version of Elasticsearch rather than replacing the entire AWS::Elasticsearch::Domain resource, use the EnableVersionUpgrade update policy.\n')
    use_online_resharding: typing.Optional[bool] = pydantic.Field(None, description='To modify a replication group\'s shards by adding or removing shards, rather than replacing the entire AWS::ElastiCache::ReplicationGroup resource, use the UseOnlineResharding update policy.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_update_policy = cdk.CfnUpdatePolicy(\n        auto_scaling_replacing_update=cdk.CfnAutoScalingReplacingUpdate(\n            will_replace=False\n        ),\n        auto_scaling_rolling_update=cdk.CfnAutoScalingRollingUpdate(\n            max_batch_size=123,\n            min_instances_in_service=123,\n            min_successful_instances_percent=123,\n            pause_time="pauseTime",\n            suspend_processes=["suspendProcesses"],\n            wait_on_resource_signals=False\n        ),\n        auto_scaling_scheduled_action=cdk.CfnAutoScalingScheduledAction(\n            ignore_unmodified_group_size_properties=False\n        ),\n        code_deploy_lambda_alias_update=cdk.CfnCodeDeployLambdaAliasUpdate(\n            application_name="applicationName",\n            deployment_group_name="deploymentGroupName",\n\n            # the properties below are optional\n            after_allow_traffic_hook="afterAllowTrafficHook",\n            before_allow_traffic_hook="beforeAllowTrafficHook"\n        ),\n        enable_version_upgrade=False,\n        use_online_resharding=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['auto_scaling_replacing_update', 'auto_scaling_rolling_update', 'auto_scaling_scheduled_action', 'code_deploy_lambda_alias_update', 'enable_version_upgrade', 'use_online_resharding']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnUpdatePolicy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnWaitConditionHandleProps
class CfnWaitConditionHandlePropsDef(BaseCfnProperty):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnWaitConditionHandleProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.CfnWaitConditionProps
class CfnWaitConditionPropsDef(BaseCfnProperty):
    count: typing.Union[int, float, None] = pydantic.Field(None, description="The number of success signals that CloudFormation must receive before it continues the stack creation process. When the wait condition receives the requisite number of success signals, CloudFormation resumes the creation of the stack. If the wait condition doesn't receive the specified number of success signals before the Timeout period expires, CloudFormation assumes that the wait condition has failed and rolls the stack back. Updates aren't supported.\n")
    handle: typing.Optional[str] = pydantic.Field(None, description="A reference to the wait condition handle used to signal this wait condition. Use the ``Ref`` intrinsic function to specify an ```AWS::CloudFormation::WaitConditionHandle`` <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-waitconditionhandle.html>`_ resource. Anytime you add a ``WaitCondition`` resource during a stack update, you must associate the wait condition with a new WaitConditionHandle resource. Don't reuse an old wait condition handle that has already been defined in the template. If you reuse a wait condition handle, the wait condition might evaluate old signals from a previous create or update stack command. Updates aren't supported.\n")
    timeout: typing.Optional[str] = pydantic.Field(None, description='The length of time (in seconds) to wait for the number of signals that the ``Count`` property specifies. ``Timeout`` is a minimum-bound property, meaning the timeout occurs no sooner than the time you specify, but can occur shortly thereafter. The maximum time that can be specified for this property is 12 hours (43200 seconds). Updates aren\'t supported.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-waitcondition.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n\n    cfn_wait_condition_props = cdk.CfnWaitConditionProps(\n        count=123,\n        handle="handle",\n        timeout="timeout"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['count', 'handle', 'timeout']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.CfnWaitConditionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




import models

class ModuleModel(pydantic.BaseModel):
    Annotations: typing.Optional[dict[str, AnnotationsDef]] = pydantic.Field(None)
    App: typing.Optional[dict[str, AppDef]] = pydantic.Field(None)
    Arn: typing.Optional[dict[str, ArnDef]] = pydantic.Field(None)
    Aspects: typing.Optional[dict[str, AspectsDef]] = pydantic.Field(None)
    AssetManifestBuilder: typing.Optional[dict[str, AssetManifestBuilderDef]] = pydantic.Field(None)
    Aws: typing.Optional[dict[str, AwsDef]] = pydantic.Field(None)
    BootstraplessSynthesizer: typing.Optional[dict[str, BootstraplessSynthesizerDef]] = pydantic.Field(None)
    CfnDynamicReference: typing.Optional[dict[str, CfnDynamicReferenceDef]] = pydantic.Field(None)
    CfnElement: typing.Optional[dict[str, CfnElementDef]] = pydantic.Field(None)
    CfnRefElement: typing.Optional[dict[str, CfnRefElementDef]] = pydantic.Field(None)
    CliCredentialsStackSynthesizer: typing.Optional[dict[str, CliCredentialsStackSynthesizerDef]] = pydantic.Field(None)
    ContextProvider: typing.Optional[dict[str, ContextProviderDef]] = pydantic.Field(None)
    DefaultStackSynthesizer: typing.Optional[dict[str, DefaultStackSynthesizerDef]] = pydantic.Field(None)
    DefaultTokenResolver: typing.Optional[dict[str, DefaultTokenResolverDef]] = pydantic.Field(None)
    DockerBuildSecret: typing.Optional[dict[str, DockerBuildSecretDef]] = pydantic.Field(None)
    DockerIgnoreStrategy: typing.Optional[dict[str, DockerIgnoreStrategyDef]] = pydantic.Field(None)
    DockerImage: typing.Optional[dict[str, DockerImageDef]] = pydantic.Field(None)
    Duration: typing.Optional[dict[str, DurationDef]] = pydantic.Field(None)
    Expiration: typing.Optional[dict[str, ExpirationDef]] = pydantic.Field(None)
    FeatureFlags: typing.Optional[dict[str, FeatureFlagsDef]] = pydantic.Field(None)
    FileSystem: typing.Optional[dict[str, FileSystemDef]] = pydantic.Field(None)
    Fn: typing.Optional[dict[str, FnDef]] = pydantic.Field(None)
    GitIgnoreStrategy: typing.Optional[dict[str, GitIgnoreStrategyDef]] = pydantic.Field(None)
    GlobIgnoreStrategy: typing.Optional[dict[str, GlobIgnoreStrategyDef]] = pydantic.Field(None)
    IgnoreStrategy: typing.Optional[dict[str, IgnoreStrategyDef]] = pydantic.Field(None)
    Intrinsic: typing.Optional[dict[str, IntrinsicDef]] = pydantic.Field(None)
    JsonNull: typing.Optional[dict[str, JsonNullDef]] = pydantic.Field(None)
    Lazy: typing.Optional[dict[str, LazyDef]] = pydantic.Field(None)
    LegacyStackSynthesizer: typing.Optional[dict[str, LegacyStackSynthesizerDef]] = pydantic.Field(None)
    Names: typing.Optional[dict[str, NamesDef]] = pydantic.Field(None)
    NestedStackSynthesizer: typing.Optional[dict[str, NestedStackSynthesizerDef]] = pydantic.Field(None)
    PermissionsBoundary: typing.Optional[dict[str, PermissionsBoundaryDef]] = pydantic.Field(None)
    PhysicalName: typing.Optional[dict[str, PhysicalNameDef]] = pydantic.Field(None)
    Reference: typing.Optional[dict[str, ReferenceDef]] = pydantic.Field(None)
    RemoveTag: typing.Optional[dict[str, RemoveTagDef]] = pydantic.Field(None)
    Resource: typing.Optional[dict[str, ResourceDef]] = pydantic.Field(None)
    ScopedAws: typing.Optional[dict[str, ScopedAwsDef]] = pydantic.Field(None)
    SecretValue: typing.Optional[dict[str, SecretValueDef]] = pydantic.Field(None)
    Size: typing.Optional[dict[str, SizeDef]] = pydantic.Field(None)
    StackSynthesizer: typing.Optional[dict[str, StackSynthesizerDef]] = pydantic.Field(None)
    StringConcat: typing.Optional[dict[str, StringConcatDef]] = pydantic.Field(None)
    Tag: typing.Optional[dict[str, TagDef]] = pydantic.Field(None)
    TagManager: typing.Optional[dict[str, TagManagerDef]] = pydantic.Field(None)
    Tags: typing.Optional[dict[str, TagsDef]] = pydantic.Field(None)
    TimeZone: typing.Optional[dict[str, TimeZoneDef]] = pydantic.Field(None)
    Token: typing.Optional[dict[str, TokenDef]] = pydantic.Field(None)
    TokenComparison: typing.Optional[dict[str, TokenComparisonDef]] = pydantic.Field(None)
    Tokenization: typing.Optional[dict[str, TokenizationDef]] = pydantic.Field(None)
    TokenizedStringFragments: typing.Optional[dict[str, TokenizedStringFragmentsDef]] = pydantic.Field(None)
    TreeInspector: typing.Optional[dict[str, TreeInspectorDef]] = pydantic.Field(None)
    ValidationResult: typing.Optional[dict[str, ValidationResultDef]] = pydantic.Field(None)
    ValidationResults: typing.Optional[dict[str, ValidationResultsDef]] = pydantic.Field(None)
    AssetStaging: typing.Optional[dict[str, AssetStagingDef]] = pydantic.Field(None)
    CustomResource: typing.Optional[dict[str, CustomResourceDef]] = pydantic.Field(None)
    CustomResourceProvider: typing.Optional[dict[str, CustomResourceProviderDef]] = pydantic.Field(None)
    NestedStack: typing.Optional[dict[str, NestedStackDef]] = pydantic.Field(None)
    Stack: typing.Optional[dict[str, StackDef]] = pydantic.Field(None)
    Stage: typing.Optional[dict[str, StageDef]] = pydantic.Field(None)
    AppProps: typing.Optional[dict[str, AppPropsDef]] = pydantic.Field(None)
    ArnComponents: typing.Optional[dict[str, ArnComponentsDef]] = pydantic.Field(None)
    AssetManifestDockerImageDestination: typing.Optional[dict[str, AssetManifestDockerImageDestinationDef]] = pydantic.Field(None)
    AssetManifestFileDestination: typing.Optional[dict[str, AssetManifestFileDestinationDef]] = pydantic.Field(None)
    AssetOptions: typing.Optional[dict[str, AssetOptionsDef]] = pydantic.Field(None)
    AssetStagingProps: typing.Optional[dict[str, AssetStagingPropsDef]] = pydantic.Field(None)
    BootstraplessSynthesizerProps: typing.Optional[dict[str, BootstraplessSynthesizerPropsDef]] = pydantic.Field(None)
    BundlingOptions: typing.Optional[dict[str, BundlingOptionsDef]] = pydantic.Field(None)
    CliCredentialsStackSynthesizerProps: typing.Optional[dict[str, CliCredentialsStackSynthesizerPropsDef]] = pydantic.Field(None)
    CopyOptions: typing.Optional[dict[str, CopyOptionsDef]] = pydantic.Field(None)
    CustomResourceProps: typing.Optional[dict[str, CustomResourcePropsDef]] = pydantic.Field(None)
    CustomResourceProviderProps: typing.Optional[dict[str, CustomResourceProviderPropsDef]] = pydantic.Field(None)
    DefaultStackSynthesizerProps: typing.Optional[dict[str, DefaultStackSynthesizerPropsDef]] = pydantic.Field(None)
    DockerBuildOptions: typing.Optional[dict[str, DockerBuildOptionsDef]] = pydantic.Field(None)
    DockerCacheOption: typing.Optional[dict[str, DockerCacheOptionDef]] = pydantic.Field(None)
    DockerImageAssetLocation: typing.Optional[dict[str, DockerImageAssetLocationDef]] = pydantic.Field(None)
    DockerImageAssetSource: typing.Optional[dict[str, DockerImageAssetSourceDef]] = pydantic.Field(None)
    DockerRunOptions: typing.Optional[dict[str, DockerRunOptionsDef]] = pydantic.Field(None)
    DockerVolume: typing.Optional[dict[str, DockerVolumeDef]] = pydantic.Field(None)
    EncodingOptions: typing.Optional[dict[str, EncodingOptionsDef]] = pydantic.Field(None)
    Environment: typing.Optional[dict[str, EnvironmentDef]] = pydantic.Field(None)
    ExportValueOptions: typing.Optional[dict[str, ExportValueOptionsDef]] = pydantic.Field(None)
    FileAssetLocation: typing.Optional[dict[str, FileAssetLocationDef]] = pydantic.Field(None)
    FileAssetSource: typing.Optional[dict[str, FileAssetSourceDef]] = pydantic.Field(None)
    FileCopyOptions: typing.Optional[dict[str, FileCopyOptionsDef]] = pydantic.Field(None)
    FileFingerprintOptions: typing.Optional[dict[str, FileFingerprintOptionsDef]] = pydantic.Field(None)
    FingerprintOptions: typing.Optional[dict[str, FingerprintOptionsDef]] = pydantic.Field(None)
    GetContextKeyOptions: typing.Optional[dict[str, GetContextKeyOptionsDef]] = pydantic.Field(None)
    GetContextKeyResult: typing.Optional[dict[str, GetContextKeyResultDef]] = pydantic.Field(None)
    GetContextValueOptions: typing.Optional[dict[str, GetContextValueOptionsDef]] = pydantic.Field(None)
    GetContextValueResult: typing.Optional[dict[str, GetContextValueResultDef]] = pydantic.Field(None)
    IntrinsicProps: typing.Optional[dict[str, IntrinsicPropsDef]] = pydantic.Field(None)
    LazyAnyValueOptions: typing.Optional[dict[str, LazyAnyValueOptionsDef]] = pydantic.Field(None)
    LazyListValueOptions: typing.Optional[dict[str, LazyListValueOptionsDef]] = pydantic.Field(None)
    LazyStringValueOptions: typing.Optional[dict[str, LazyStringValueOptionsDef]] = pydantic.Field(None)
    NestedStackProps: typing.Optional[dict[str, NestedStackPropsDef]] = pydantic.Field(None)
    PermissionsBoundaryBindOptions: typing.Optional[dict[str, PermissionsBoundaryBindOptionsDef]] = pydantic.Field(None)
    PolicyValidationPluginReportBeta1: typing.Optional[dict[str, PolicyValidationPluginReportBeta1Def]] = pydantic.Field(None)
    PolicyViolatingResourceBeta1: typing.Optional[dict[str, PolicyViolatingResourceBeta1Def]] = pydantic.Field(None)
    PolicyViolationBeta1: typing.Optional[dict[str, PolicyViolationBeta1Def]] = pydantic.Field(None)
    RemovalPolicyOptions: typing.Optional[dict[str, RemovalPolicyOptionsDef]] = pydantic.Field(None)
    ResolveChangeContextOptions: typing.Optional[dict[str, ResolveChangeContextOptionsDef]] = pydantic.Field(None)
    ResolveOptions: typing.Optional[dict[str, ResolveOptionsDef]] = pydantic.Field(None)
    ResourceEnvironment: typing.Optional[dict[str, ResourceEnvironmentDef]] = pydantic.Field(None)
    ResourceProps: typing.Optional[dict[str, ResourcePropsDef]] = pydantic.Field(None)
    ReverseOptions: typing.Optional[dict[str, ReverseOptionsDef]] = pydantic.Field(None)
    RoleOptions: typing.Optional[dict[str, RoleOptionsDef]] = pydantic.Field(None)
    SecretsManagerSecretOptions: typing.Optional[dict[str, SecretsManagerSecretOptionsDef]] = pydantic.Field(None)
    SizeConversionOptions: typing.Optional[dict[str, SizeConversionOptionsDef]] = pydantic.Field(None)
    StackProps: typing.Optional[dict[str, StackPropsDef]] = pydantic.Field(None)
    StageProps: typing.Optional[dict[str, StagePropsDef]] = pydantic.Field(None)
    StageSynthesisOptions: typing.Optional[dict[str, StageSynthesisOptionsDef]] = pydantic.Field(None)
    SynthesizeStackArtifactOptions: typing.Optional[dict[str, SynthesizeStackArtifactOptionsDef]] = pydantic.Field(None)
    TagManagerOptions: typing.Optional[dict[str, TagManagerOptionsDef]] = pydantic.Field(None)
    TagProps: typing.Optional[dict[str, TagPropsDef]] = pydantic.Field(None)
    TimeConversionOptions: typing.Optional[dict[str, TimeConversionOptionsDef]] = pydantic.Field(None)
    UniqueResourceNameOptions: typing.Optional[dict[str, UniqueResourceNameOptionsDef]] = pydantic.Field(None)
    CfnCodeDeployBlueGreenHook: typing.Optional[dict[str, CfnCodeDeployBlueGreenHookDef]] = pydantic.Field(None)
    CfnCondition: typing.Optional[dict[str, CfnConditionDef]] = pydantic.Field(None)
    CfnCustomResource: typing.Optional[dict[str, CfnCustomResourceDef]] = pydantic.Field(None)
    CfnHook: typing.Optional[dict[str, CfnHookDef]] = pydantic.Field(None)
    CfnHookDefaultVersion: typing.Optional[dict[str, CfnHookDefaultVersionDef]] = pydantic.Field(None)
    CfnHookTypeConfig: typing.Optional[dict[str, CfnHookTypeConfigDef]] = pydantic.Field(None)
    CfnHookVersion: typing.Optional[dict[str, CfnHookVersionDef]] = pydantic.Field(None)
    CfnJson: typing.Optional[dict[str, CfnJsonDef]] = pydantic.Field(None)
    CfnMacro: typing.Optional[dict[str, CfnMacroDef]] = pydantic.Field(None)
    CfnMapping: typing.Optional[dict[str, CfnMappingDef]] = pydantic.Field(None)
    CfnModuleDefaultVersion: typing.Optional[dict[str, CfnModuleDefaultVersionDef]] = pydantic.Field(None)
    CfnModuleVersion: typing.Optional[dict[str, CfnModuleVersionDef]] = pydantic.Field(None)
    CfnOutput: typing.Optional[dict[str, CfnOutputDef]] = pydantic.Field(None)
    CfnParameter: typing.Optional[dict[str, CfnParameterDef]] = pydantic.Field(None)
    CfnPublicTypeVersion: typing.Optional[dict[str, CfnPublicTypeVersionDef]] = pydantic.Field(None)
    CfnPublisher: typing.Optional[dict[str, CfnPublisherDef]] = pydantic.Field(None)
    CfnResource: typing.Optional[dict[str, CfnResourceDef]] = pydantic.Field(None)
    CfnResourceDefaultVersion: typing.Optional[dict[str, CfnResourceDefaultVersionDef]] = pydantic.Field(None)
    CfnResourceVersion: typing.Optional[dict[str, CfnResourceVersionDef]] = pydantic.Field(None)
    CfnRule: typing.Optional[dict[str, CfnRuleDef]] = pydantic.Field(None)
    CfnStack: typing.Optional[dict[str, CfnStackDef]] = pydantic.Field(None)
    CfnStackSet: typing.Optional[dict[str, CfnStackSetDef]] = pydantic.Field(None)
    CfnTypeActivation: typing.Optional[dict[str, CfnTypeActivationDef]] = pydantic.Field(None)
    CfnWaitCondition: typing.Optional[dict[str, CfnWaitConditionDef]] = pydantic.Field(None)
    CfnWaitConditionHandle: typing.Optional[dict[str, CfnWaitConditionHandleDef]] = pydantic.Field(None)
    CfnAutoScalingReplacingUpdate: typing.Optional[dict[str, CfnAutoScalingReplacingUpdateDef]] = pydantic.Field(None)
    CfnAutoScalingRollingUpdate: typing.Optional[dict[str, CfnAutoScalingRollingUpdateDef]] = pydantic.Field(None)
    CfnAutoScalingScheduledAction: typing.Optional[dict[str, CfnAutoScalingScheduledActionDef]] = pydantic.Field(None)
    CfnCodeDeployBlueGreenAdditionalOptions: typing.Optional[dict[str, CfnCodeDeployBlueGreenAdditionalOptionsDef]] = pydantic.Field(None)
    CfnCodeDeployBlueGreenApplication: typing.Optional[dict[str, CfnCodeDeployBlueGreenApplicationDef]] = pydantic.Field(None)
    CfnCodeDeployBlueGreenApplicationTarget: typing.Optional[dict[str, CfnCodeDeployBlueGreenApplicationTargetDef]] = pydantic.Field(None)
    CfnCodeDeployBlueGreenEcsAttributes: typing.Optional[dict[str, CfnCodeDeployBlueGreenEcsAttributesDef]] = pydantic.Field(None)
    CfnCodeDeployBlueGreenHookProps: typing.Optional[dict[str, CfnCodeDeployBlueGreenHookPropsDef]] = pydantic.Field(None)
    CfnCodeDeployBlueGreenLifecycleEventHooks: typing.Optional[dict[str, CfnCodeDeployBlueGreenLifecycleEventHooksDef]] = pydantic.Field(None)
    CfnCodeDeployLambdaAliasUpdate: typing.Optional[dict[str, CfnCodeDeployLambdaAliasUpdateDef]] = pydantic.Field(None)
    CfnConditionProps: typing.Optional[dict[str, CfnConditionPropsDef]] = pydantic.Field(None)
    CfnCreationPolicy: typing.Optional[dict[str, CfnCreationPolicyDef]] = pydantic.Field(None)
    CfnCustomResourceProps: typing.Optional[dict[str, CfnCustomResourcePropsDef]] = pydantic.Field(None)
    CfnDynamicReferenceProps: typing.Optional[dict[str, CfnDynamicReferencePropsDef]] = pydantic.Field(None)
    CfnHookDefaultVersionProps: typing.Optional[dict[str, CfnHookDefaultVersionPropsDef]] = pydantic.Field(None)
    CfnHookProps: typing.Optional[dict[str, CfnHookPropsDef]] = pydantic.Field(None)
    CfnHookTypeConfigProps: typing.Optional[dict[str, CfnHookTypeConfigPropsDef]] = pydantic.Field(None)
    CfnHookVersion_LoggingConfigProperty: typing.Optional[dict[str, CfnHookVersion_LoggingConfigPropertyDef]] = pydantic.Field(None)
    CfnHookVersionProps: typing.Optional[dict[str, CfnHookVersionPropsDef]] = pydantic.Field(None)
    CfnJsonProps: typing.Optional[dict[str, CfnJsonPropsDef]] = pydantic.Field(None)
    CfnMacroProps: typing.Optional[dict[str, CfnMacroPropsDef]] = pydantic.Field(None)
    CfnMappingProps: typing.Optional[dict[str, CfnMappingPropsDef]] = pydantic.Field(None)
    CfnModuleDefaultVersionProps: typing.Optional[dict[str, CfnModuleDefaultVersionPropsDef]] = pydantic.Field(None)
    CfnModuleVersionProps: typing.Optional[dict[str, CfnModuleVersionPropsDef]] = pydantic.Field(None)
    CfnOutputProps: typing.Optional[dict[str, CfnOutputPropsDef]] = pydantic.Field(None)
    CfnParameterProps: typing.Optional[dict[str, CfnParameterPropsDef]] = pydantic.Field(None)
    CfnPublicTypeVersionProps: typing.Optional[dict[str, CfnPublicTypeVersionPropsDef]] = pydantic.Field(None)
    CfnPublisherProps: typing.Optional[dict[str, CfnPublisherPropsDef]] = pydantic.Field(None)
    CfnResourceAutoScalingCreationPolicy: typing.Optional[dict[str, CfnResourceAutoScalingCreationPolicyDef]] = pydantic.Field(None)
    CfnResourceDefaultVersionProps: typing.Optional[dict[str, CfnResourceDefaultVersionPropsDef]] = pydantic.Field(None)
    CfnResourceProps: typing.Optional[dict[str, CfnResourcePropsDef]] = pydantic.Field(None)
    CfnResourceSignal: typing.Optional[dict[str, CfnResourceSignalDef]] = pydantic.Field(None)
    CfnResourceVersion_LoggingConfigProperty: typing.Optional[dict[str, CfnResourceVersion_LoggingConfigPropertyDef]] = pydantic.Field(None)
    CfnResourceVersionProps: typing.Optional[dict[str, CfnResourceVersionPropsDef]] = pydantic.Field(None)
    CfnRuleAssertion: typing.Optional[dict[str, CfnRuleAssertionDef]] = pydantic.Field(None)
    CfnRuleProps: typing.Optional[dict[str, CfnRulePropsDef]] = pydantic.Field(None)
    CfnStack_OutputProperty: typing.Optional[dict[str, CfnStack_OutputPropertyDef]] = pydantic.Field(None)
    CfnStackProps: typing.Optional[dict[str, CfnStackPropsDef]] = pydantic.Field(None)
    CfnStackSet_AutoDeploymentProperty: typing.Optional[dict[str, CfnStackSet_AutoDeploymentPropertyDef]] = pydantic.Field(None)
    CfnStackSet_DeploymentTargetsProperty: typing.Optional[dict[str, CfnStackSet_DeploymentTargetsPropertyDef]] = pydantic.Field(None)
    CfnStackSet_ManagedExecutionProperty: typing.Optional[dict[str, CfnStackSet_ManagedExecutionPropertyDef]] = pydantic.Field(None)
    CfnStackSet_OperationPreferencesProperty: typing.Optional[dict[str, CfnStackSet_OperationPreferencesPropertyDef]] = pydantic.Field(None)
    CfnStackSet_ParameterProperty: typing.Optional[dict[str, CfnStackSet_ParameterPropertyDef]] = pydantic.Field(None)
    CfnStackSet_StackInstancesProperty: typing.Optional[dict[str, CfnStackSet_StackInstancesPropertyDef]] = pydantic.Field(None)
    CfnStackSetProps: typing.Optional[dict[str, CfnStackSetPropsDef]] = pydantic.Field(None)
    CfnTag: typing.Optional[dict[str, CfnTagDef]] = pydantic.Field(None)
    CfnTrafficRoute: typing.Optional[dict[str, CfnTrafficRouteDef]] = pydantic.Field(None)
    CfnTrafficRouting: typing.Optional[dict[str, CfnTrafficRoutingDef]] = pydantic.Field(None)
    CfnTrafficRoutingConfig: typing.Optional[dict[str, CfnTrafficRoutingConfigDef]] = pydantic.Field(None)
    CfnTrafficRoutingTimeBasedCanary: typing.Optional[dict[str, CfnTrafficRoutingTimeBasedCanaryDef]] = pydantic.Field(None)
    CfnTrafficRoutingTimeBasedLinear: typing.Optional[dict[str, CfnTrafficRoutingTimeBasedLinearDef]] = pydantic.Field(None)
    CfnTypeActivation_LoggingConfigProperty: typing.Optional[dict[str, CfnTypeActivation_LoggingConfigPropertyDef]] = pydantic.Field(None)
    CfnTypeActivationProps: typing.Optional[dict[str, CfnTypeActivationPropsDef]] = pydantic.Field(None)
    CfnUpdatePolicy: typing.Optional[dict[str, CfnUpdatePolicyDef]] = pydantic.Field(None)
    CfnWaitConditionHandleProps: typing.Optional[dict[str, CfnWaitConditionHandlePropsDef]] = pydantic.Field(None)
    CfnWaitConditionProps: typing.Optional[dict[str, CfnWaitConditionPropsDef]] = pydantic.Field(None)
    ...
