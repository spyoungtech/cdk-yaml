from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_appsync.AssetCode
class AssetCodeDef(BaseClass):
    path: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The path to the asset file.')
    deploy_time: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the asset needs to exist beyond deployment time; i.e. are copied over to a different location and not needed afterwards. Setting this property to true has an impact on the lifecycle of the asset, because we will assume that it is safe to delete after the CloudFormation deployment succeeds. For example, Lambda Function assets are copied over to Lambda during deployment. Therefore, it is not necessary to store the asset in S3, so we consider those deployTime assets. Default: false\n')
    readers: typing.Optional[typing.Sequence[models.AnyResource]] = pydantic.Field(None, description='A list of principals that should be able to read this asset from S3. You can use ``asset.grantRead(principal)`` to grant read permissions later. Default: - No principals that can read file asset.\n')
    asset_hash: typing.Optional[str] = pydantic.Field(None, description='Specify a custom hash for this asset. If ``assetHashType`` is set it must be set to ``AssetHashType.CUSTOM``. For consistency, this custom hash will be SHA256 hashed and encoded as hex. The resulting hash will be the asset hash. NOTE: the hash is used in order to identify a specific revision of the asset, and used for optimizing and caching deployment activities related to this asset such as packaging, uploading to Amazon S3, etc. If you chose to customize the hash, you will need to make sure it is updated every time the asset changes, or otherwise it is possible that some deployments will not be invalidated. Default: - based on ``assetHashType``\n')
    asset_hash_type: typing.Optional[aws_cdk.AssetHashType] = pydantic.Field(None, description='Specifies the type of hash to calculate for this asset. If ``assetHash`` is configured, this option must be ``undefined`` or ``AssetHashType.CUSTOM``. Default: - the default is ``AssetHashType.SOURCE``, but if ``assetHash`` is explicitly specified this value defaults to ``AssetHashType.CUSTOM``.\n')
    bundling: typing.Union[models.BundlingOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Bundle the asset by executing a command in a Docker container or a custom bundling provider. The asset path will be mounted at ``/asset-input``. The Docker container is responsible for putting content at ``/asset-output``. The content at ``/asset-output`` will be zipped and used as the final asset. Default: - uploaded as-is to S3 if the asset is a regular file or a .zip file, archived into a .zip file and uploaded to S3 otherwise\n')
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='File paths matching the patterns will be excluded. See ``ignoreMode`` to set the matching behavior. Has no effect on Assets bundled using the ``bundling`` property. Default: - nothing is excluded\n')
    follow_symlinks: typing.Optional[aws_cdk.SymlinkFollowMode] = pydantic.Field(None, description='A strategy for how to handle symlinks. Default: SymlinkFollowMode.NEVER\n')
    ignore_mode: typing.Optional[aws_cdk.IgnoreMode] = pydantic.Field(None, description='The ignore behavior to use for ``exclude`` patterns. Default: IgnoreMode.GLOB')
    _init_params: typing.ClassVar[list[str]] = ['path', 'deploy_time', 'readers', 'asset_hash', 'asset_hash_type', 'bundling', 'exclude', 'follow_symlinks', 'ignore_mode']
    _method_names: typing.ClassVar[list[str]] = ['bind']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_asset', 'from_inline']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.AssetCode'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_asset', 'from_inline']
    ...


    from_asset: typing.Optional[models.aws_appsync.AssetCodeDefFromAssetParams] = pydantic.Field(None, description='Loads the function code from a local disk path.')
    from_inline: typing.Optional[models.aws_appsync.AssetCodeDefFromInlineParams] = pydantic.Field(None, description='Inline code for AppSync function.')
    resource_config: typing.Optional[models.aws_appsync.AssetCodeDefConfig] = pydantic.Field(None)


class AssetCodeDefConfig(pydantic.BaseModel):
    bind: typing.Optional[list[models.aws_appsync.AssetCodeDefBindParams]] = pydantic.Field(None, description='Bind source code to an AppSync Function or resolver.')

class AssetCodeDefBindParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-')
    ...

class AssetCodeDefFromAssetParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path to the source code file.\n')
    deploy_time: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the asset needs to exist beyond deployment time; i.e. are copied over to a different location and not needed afterwards. Setting this property to true has an impact on the lifecycle of the asset, because we will assume that it is safe to delete after the CloudFormation deployment succeeds. For example, Lambda Function assets are copied over to Lambda during deployment. Therefore, it is not necessary to store the asset in S3, so we consider those deployTime assets. Default: false\n')
    readers: typing.Optional[typing.Sequence[models.AnyResource]] = pydantic.Field(None, description='A list of principals that should be able to read this asset from S3. You can use ``asset.grantRead(principal)`` to grant read permissions later. Default: - No principals that can read file asset.\n')
    asset_hash: typing.Optional[str] = pydantic.Field(None, description='Specify a custom hash for this asset. If ``assetHashType`` is set it must be set to ``AssetHashType.CUSTOM``. For consistency, this custom hash will be SHA256 hashed and encoded as hex. The resulting hash will be the asset hash. NOTE: the hash is used in order to identify a specific revision of the asset, and used for optimizing and caching deployment activities related to this asset such as packaging, uploading to Amazon S3, etc. If you chose to customize the hash, you will need to make sure it is updated every time the asset changes, or otherwise it is possible that some deployments will not be invalidated. Default: - based on ``assetHashType``\n')
    asset_hash_type: typing.Optional[aws_cdk.AssetHashType] = pydantic.Field(None, description='Specifies the type of hash to calculate for this asset. If ``assetHash`` is configured, this option must be ``undefined`` or ``AssetHashType.CUSTOM``. Default: - the default is ``AssetHashType.SOURCE``, but if ``assetHash`` is explicitly specified this value defaults to ``AssetHashType.CUSTOM``.\n')
    bundling: typing.Union[models.BundlingOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Bundle the asset by executing a command in a Docker container or a custom bundling provider. The asset path will be mounted at ``/asset-input``. The Docker container is responsible for putting content at ``/asset-output``. The content at ``/asset-output`` will be zipped and used as the final asset. Default: - uploaded as-is to S3 if the asset is a regular file or a .zip file, archived into a .zip file and uploaded to S3 otherwise\n')
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='File paths matching the patterns will be excluded. See ``ignoreMode`` to set the matching behavior. Has no effect on Assets bundled using the ``bundling`` property. Default: - nothing is excluded\n')
    follow_symlinks: typing.Optional[aws_cdk.SymlinkFollowMode] = pydantic.Field(None, description='A strategy for how to handle symlinks. Default: SymlinkFollowMode.NEVER\n')
    ignore_mode: typing.Optional[aws_cdk.IgnoreMode] = pydantic.Field(None, description='The ignore behavior to use for ``exclude`` patterns. Default: IgnoreMode.GLOB')
    ...

class AssetCodeDefFromInlineParams(pydantic.BaseModel):
    code: str = pydantic.Field(..., description='The actual handler code (limited to 4KiB).\n')
    ...


#  autogenerated from aws_cdk.aws_appsync.Assign
class AssignDef(BaseClass):
    attr: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    arg: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['attr', 'arg']
    _method_names: typing.ClassVar[list[str]] = ['put_in_map', 'render_as_assignment']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.Assign'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.AssignDefConfig] = pydantic.Field(None)


class AssignDefConfig(pydantic.BaseModel):
    put_in_map: typing.Optional[list[models.aws_appsync.AssignDefPutInMapParams]] = pydantic.Field(None, description='Renders the assignment as a map element.')
    render_as_assignment: typing.Optional[bool] = pydantic.Field(None, description='Renders the assignment as a VTL string.')

class AssignDefPutInMapParams(pydantic.BaseModel):
    map: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_appsync.AttributeValues
class AttributeValuesDef(BaseClass):
    container: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    assignments: typing.Optional[typing.Sequence[models.aws_appsync.AssignDef]] = pydantic.Field(None, description='-')
    _init_params: typing.ClassVar[list[str]] = ['container', 'assignments']
    _method_names: typing.ClassVar[list[str]] = ['attribute', 'render_template', 'render_variables']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.AttributeValues'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.AttributeValuesDefConfig] = pydantic.Field(None)


class AttributeValuesDefConfig(pydantic.BaseModel):
    attribute: typing.Optional[list[models.aws_appsync.AttributeValuesDefAttributeParams]] = pydantic.Field(None, description='Allows assigning a value to the specified attribute.')
    render_template: typing.Optional[bool] = pydantic.Field(None, description='Renders the attribute value assingments to a VTL string.')
    render_variables: typing.Optional[bool] = pydantic.Field(None, description='Renders the variables required for ``renderTemplate``.')

class AttributeValuesDefAttributeParams(pydantic.BaseModel):
    attr: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_appsync.AttributeValuesStep
class AttributeValuesStepDef(BaseClass):
    attr: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    container: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-\n')
    assignments: typing.Union[typing.Sequence[models.aws_appsync.AssignDef], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['attr', 'container', 'assignments']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.AttributeValuesStep'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.BackedDataSource
class BackedDataSourceDef(BaseClass):
    props: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.BackedDataSourcePropsDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='-\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='the type of the AppSync datasource.\n')
    dynamo_db_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_DynamoDBConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for DynamoDB Datasource. Default: - No config\n')
    elasticsearch_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_ElasticsearchConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='(deprecated) configuration for Elasticsearch data source. Default: - No config\n')
    event_bridge_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_EventBridgeConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for EventBridge Datasource. Default: - No config\n')
    http_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_HttpConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for HTTP Datasource. Default: - No config\n')
    lambda_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_LambdaConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for Lambda Datasource. Default: - No config\n')
    open_search_service_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_OpenSearchServiceConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for OpenSearch data source. Default: - No config\n')
    relational_database_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_RelationalDatabaseConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for RDS Datasource. Default: - No config')
    _init_params: typing.ClassVar[list[str]] = ['props', 'type', 'dynamo_db_config', 'elasticsearch_config', 'event_bridge_config', 'http_config', 'lambda_config', 'open_search_service_config', 'relational_database_config']
    _method_names: typing.ClassVar[list[str]] = ['create_function', 'create_resolver']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.BackedDataSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.BackedDataSourceDefConfig] = pydantic.Field(None)


class BackedDataSourceDefConfig(pydantic.BaseModel):
    create_function: typing.Optional[list[models.aws_appsync.BackedDataSourceDefCreateFunctionParams]] = pydantic.Field(None, description='creates a new appsync function for this datasource and API using the given properties.')
    create_resolver: typing.Optional[list[models.aws_appsync.BackedDataSourceDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')
    grant_principal_config: typing.Optional[models._interface_methods.AwsIamIPrincipalDefConfig] = pydantic.Field(None)

class BackedDataSourceDefCreateFunctionParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    name: str = pydantic.Field(..., description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    return_config: typing.Optional[list[models.aws_appsync.AppsyncFunctionDefConfig]] = pydantic.Field(None)
    ...

class BackedDataSourceDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...


#  autogenerated from aws_cdk.aws_appsync.BaseDataSource
class BaseDataSourceDef(BaseClass):
    props: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.BackedDataSourcePropsDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='-\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='the type of the AppSync datasource.\n')
    dynamo_db_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_DynamoDBConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for DynamoDB Datasource. Default: - No config\n')
    elasticsearch_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_ElasticsearchConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='(deprecated) configuration for Elasticsearch data source. Default: - No config\n')
    event_bridge_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_EventBridgeConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for EventBridge Datasource. Default: - No config\n')
    http_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_HttpConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for HTTP Datasource. Default: - No config\n')
    lambda_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_LambdaConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for Lambda Datasource. Default: - No config\n')
    open_search_service_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_OpenSearchServiceConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for OpenSearch data source. Default: - No config\n')
    relational_database_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_RelationalDatabaseConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for RDS Datasource. Default: - No config')
    _init_params: typing.ClassVar[list[str]] = ['props', 'type', 'dynamo_db_config', 'elasticsearch_config', 'event_bridge_config', 'http_config', 'lambda_config', 'open_search_service_config', 'relational_database_config']
    _method_names: typing.ClassVar[list[str]] = ['create_function', 'create_resolver']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.BaseDataSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.BaseDataSourceDefConfig] = pydantic.Field(None)


class BaseDataSourceDefConfig(pydantic.BaseModel):
    create_function: typing.Optional[list[models.aws_appsync.BaseDataSourceDefCreateFunctionParams]] = pydantic.Field(None, description='creates a new appsync function for this datasource and API using the given properties.')
    create_resolver: typing.Optional[list[models.aws_appsync.BaseDataSourceDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')

class BaseDataSourceDefCreateFunctionParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    name: str = pydantic.Field(..., description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    return_config: typing.Optional[list[models.aws_appsync.AppsyncFunctionDefConfig]] = pydantic.Field(None)
    ...

class BaseDataSourceDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...


#  autogenerated from aws_cdk.aws_appsync.Code
class CodeDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['bind']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_asset', 'from_inline']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.Code'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_asset', 'from_inline']
    ...


    from_asset: typing.Optional[models.aws_appsync.CodeDefFromAssetParams] = pydantic.Field(None, description='Loads the function code from a local disk path.')
    from_inline: typing.Optional[models.aws_appsync.CodeDefFromInlineParams] = pydantic.Field(None, description='Inline code for AppSync function.')
    resource_config: typing.Optional[models.aws_appsync.CodeDefConfig] = pydantic.Field(None)


class CodeDefConfig(pydantic.BaseModel):
    bind: typing.Optional[list[models.aws_appsync.CodeDefBindParams]] = pydantic.Field(None, description='Bind source code to an AppSync Function or resolver.')

class CodeDefBindParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-')
    ...

class CodeDefFromAssetParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path to the source code file.\n')
    deploy_time: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the asset needs to exist beyond deployment time; i.e. are copied over to a different location and not needed afterwards. Setting this property to true has an impact on the lifecycle of the asset, because we will assume that it is safe to delete after the CloudFormation deployment succeeds. For example, Lambda Function assets are copied over to Lambda during deployment. Therefore, it is not necessary to store the asset in S3, so we consider those deployTime assets. Default: false\n')
    readers: typing.Optional[typing.Sequence[models.AnyResource]] = pydantic.Field(None, description='A list of principals that should be able to read this asset from S3. You can use ``asset.grantRead(principal)`` to grant read permissions later. Default: - No principals that can read file asset.\n')
    asset_hash: typing.Optional[str] = pydantic.Field(None, description='Specify a custom hash for this asset. If ``assetHashType`` is set it must be set to ``AssetHashType.CUSTOM``. For consistency, this custom hash will be SHA256 hashed and encoded as hex. The resulting hash will be the asset hash. NOTE: the hash is used in order to identify a specific revision of the asset, and used for optimizing and caching deployment activities related to this asset such as packaging, uploading to Amazon S3, etc. If you chose to customize the hash, you will need to make sure it is updated every time the asset changes, or otherwise it is possible that some deployments will not be invalidated. Default: - based on ``assetHashType``\n')
    asset_hash_type: typing.Optional[aws_cdk.AssetHashType] = pydantic.Field(None, description='Specifies the type of hash to calculate for this asset. If ``assetHash`` is configured, this option must be ``undefined`` or ``AssetHashType.CUSTOM``. Default: - the default is ``AssetHashType.SOURCE``, but if ``assetHash`` is explicitly specified this value defaults to ``AssetHashType.CUSTOM``.\n')
    bundling: typing.Union[models.BundlingOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Bundle the asset by executing a command in a Docker container or a custom bundling provider. The asset path will be mounted at ``/asset-input``. The Docker container is responsible for putting content at ``/asset-output``. The content at ``/asset-output`` will be zipped and used as the final asset. Default: - uploaded as-is to S3 if the asset is a regular file or a .zip file, archived into a .zip file and uploaded to S3 otherwise\n')
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='File paths matching the patterns will be excluded. See ``ignoreMode`` to set the matching behavior. Has no effect on Assets bundled using the ``bundling`` property. Default: - nothing is excluded\n')
    follow_symlinks: typing.Optional[aws_cdk.SymlinkFollowMode] = pydantic.Field(None, description='A strategy for how to handle symlinks. Default: SymlinkFollowMode.NEVER\n')
    ignore_mode: typing.Optional[aws_cdk.IgnoreMode] = pydantic.Field(None, description='The ignore behavior to use for ``exclude`` patterns. Default: IgnoreMode.GLOB')
    ...

class CodeDefFromInlineParams(pydantic.BaseModel):
    code: str = pydantic.Field(..., description='The actual handler code (limited to 4KiB).\n')
    ...


#  autogenerated from aws_cdk.aws_appsync.Definition
class DefinitionDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['from_file', 'from_schema', 'from_source_apis']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.Definition'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_file', 'from_schema', 'from_source_apis']
    ...


    from_file: typing.Optional[models.aws_appsync.DefinitionDefFromFileParams] = pydantic.Field(None, description='Schema from file, allows schema definition through schema.graphql file.')
    from_schema: typing.Optional[models.aws_appsync.DefinitionDefFromSchemaParams] = pydantic.Field(None, description='Schema from schema object.')
    from_source_apis: typing.Optional[models.aws_appsync.DefinitionDefFromSourceApisParams] = pydantic.Field(None, description='Schema from existing AppSync APIs - used for creating a AppSync Merged API.')

class DefinitionDefFromFileParams(pydantic.BaseModel):
    file_path: str = pydantic.Field(..., description='the file path of the schema file.\n')
    ...

class DefinitionDefFromSchemaParams(pydantic.BaseModel):
    schema_: typing.Union[models.aws_appsync.SchemaFileDef] = pydantic.Field(..., description='SchemaFile.fromAsset(filePath: string) allows schema definition through schema.graphql file.\n', alias='schema')
    ...

class DefinitionDefFromSourceApisParams(pydantic.BaseModel):
    source_apis: typing.Sequence[typing.Union[models.aws_appsync.SourceApiDef, dict[str, typing.Any]]] = pydantic.Field(..., description='Definition of source APIs associated with this Merged API.\n')
    merged_api_execution_role: typing.Optional[models.aws_iam.RoleDef] = pydantic.Field(None, description='IAM Role used to validate access to source APIs at runtime and to update the merged API endpoint with the source API changes. Default: - An IAM Role with acccess to source schemas will be created\n')
    ...


#  autogenerated from aws_cdk.aws_appsync.FunctionRuntime
class FunctionRuntimeDef(BaseClass):
    family: typing.Union[aws_cdk.aws_appsync.FunctionRuntimeFamily, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    version: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['family', 'version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.FunctionRuntime'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.GraphqlApiBase
class GraphqlApiBaseDef(BaseClass):
    account: typing.Optional[str] = pydantic.Field(None, description='The AWS account ID this resource belongs to. Default: - the resource is in the same account as the stack it belongs to\n')
    environment_from_arn: typing.Optional[str] = pydantic.Field(None, description='ARN to deduce region and account from. The ARN is parsed and the account and region are taken from the ARN. This should be used for imported resources. Cannot be supplied together with either ``account`` or ``region``. Default: - take environment from ``account``, ``region`` parameters, or use Stack environment.\n')
    physical_name: typing.Optional[str] = pydantic.Field(None, description='The value passed in by users to the physical name prop of the resource. - ``undefined`` implies that a physical name will be allocated by CloudFormation during deployment. - a concrete value implies a specific physical name - ``PhysicalName.GENERATE_IF_NEEDED`` is a marker that indicates that a physical will only be generated by the CDK if it is needed for cross-environment references. Otherwise, it will be allocated by CloudFormation. Default: - The physical name will be allocated by CloudFormation at deployment time\n')
    region: typing.Optional[str] = pydantic.Field(None, description='The AWS region this resource belongs to. Default: - the resource is in the same region as the stack it belongs to')
    _init_params: typing.ClassVar[list[str]] = ['account', 'environment_from_arn', 'physical_name', 'region']
    _method_names: typing.ClassVar[list[str]] = ['add_dynamo_db_data_source', 'add_elasticsearch_data_source', 'add_event_bridge_data_source', 'add_http_data_source', 'add_lambda_data_source', 'add_none_data_source', 'add_open_search_data_source', 'add_rds_data_source', 'add_rds_data_source_v2', 'add_schema_dependency', 'apply_removal_policy', 'create_resolver', 'grant', 'grant_mutation', 'grant_query', 'grant_subscription']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.GraphqlApiBase'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.GraphqlApiBaseDefConfig] = pydantic.Field(None)


class GraphqlApiBaseDefConfig(pydantic.BaseModel):
    add_dynamo_db_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefAddDynamoDbDataSourceParams]] = pydantic.Field(None, description='add a new DynamoDB data source to this API.')
    add_elasticsearch_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefAddElasticsearchDataSourceParams]] = pydantic.Field(None, description='(deprecated) add a new elasticsearch data source to this API.')
    add_event_bridge_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefAddEventBridgeDataSourceParams]] = pydantic.Field(None, description='Add an EventBridge data source to this api.')
    add_http_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefAddHttpDataSourceParams]] = pydantic.Field(None, description='add a new http data source to this API.')
    add_lambda_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefAddLambdaDataSourceParams]] = pydantic.Field(None, description='add a new Lambda data source to this API.')
    add_none_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefAddNoneDataSourceParams]] = pydantic.Field(None, description="add a new dummy data source to this API.\nUseful for pipeline resolvers\nand for backend changes that don't require a data source.")
    add_open_search_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefAddOpenSearchDataSourceParams]] = pydantic.Field(None, description='add a new OpenSearch data source to this API.')
    add_rds_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefAddRdsDataSourceParams]] = pydantic.Field(None, description='add a new Rds data source to this API.')
    add_rds_data_source_v2: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefAddRdsDataSourceV2Params]] = pydantic.Field(None, description='add a new Rds data source to this API.')
    add_schema_dependency: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefAddSchemaDependencyParams]] = pydantic.Field(None, description='Add schema dependency if not imported.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    create_resolver: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')
    grant: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefGrantParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this GraphQLApi to an IAM principal's policy.")
    grant_mutation: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefGrantMutationParams]] = pydantic.Field(None, description="Adds an IAM policy statement for Mutation access to this GraphQLApi to an IAM principal's policy.")
    grant_query: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefGrantQueryParams]] = pydantic.Field(None, description="Adds an IAM policy statement for Query access to this GraphQLApi to an IAM principal's policy.")
    grant_subscription: typing.Optional[list[models.aws_appsync.GraphqlApiBaseDefGrantSubscriptionParams]] = pydantic.Field(None, description="Adds an IAM policy statement for Subscription access to this GraphQLApi to an IAM principal's policy.")

class GraphqlApiBaseDefAddDynamoDbDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    table: typing.Union[models.aws_dynamodb.TableBaseDef, models.aws_dynamodb.TableDef] = pydantic.Field(..., description='The DynamoDB table backing this data source.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.DynamoDbDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefAddElasticsearchDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    domain: typing.Union[models.aws_elasticsearch.DomainDef] = pydantic.Field(..., description='The elasticsearch domain for this data source.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id\n\n:deprecated: - use ``addOpenSearchDataSource``\n\n:stability: deprecated\n')
    return_config: typing.Optional[list[models.aws_appsync.ElasticsearchDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefAddEventBridgeDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    event_bus: typing.Union[models.aws_events.EventBusDef] = pydantic.Field(..., description='The EventBridge EventBus on which to put events.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.EventBridgeDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefAddHttpDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    endpoint: str = pydantic.Field(..., description='The http endpoint.\n')
    authorization_config: typing.Union[models.aws_appsync.AwsIamConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The authorization config in case the HTTP endpoint requires authorization. Default: - none\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.HttpDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefAddLambdaDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    lambda_function: typing.Union[models.aws_lambda.FunctionBaseDef, models.aws_lambda.QualifiedFunctionBaseDef, models.aws_lambda.AliasDef, models.aws_lambda.DockerImageFunctionDef, models.aws_lambda.FunctionDef, models.aws_lambda.SingletonFunctionDef, models.aws_lambda.VersionDef, models.aws_lambda_nodejs.NodejsFunctionDef, models.triggers.TriggerFunctionDef] = pydantic.Field(..., description='The Lambda function to call to interact with this data source.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.LambdaDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefAddNoneDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.NoneDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefAddOpenSearchDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    domain: typing.Union[models.aws_opensearchservice.DomainDef] = pydantic.Field(..., description='The OpenSearch domain for this data source.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.OpenSearchDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefAddRdsDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    serverless_cluster: typing.Union[models.aws_rds.ServerlessClusterDef, models.aws_rds.ServerlessClusterFromSnapshotDef] = pydantic.Field(..., description='The serverless cluster to interact with this data source.\n')
    secret_store: typing.Union[models.aws_docdb.DatabaseSecretDef, models.aws_rds.DatabaseSecretDef, models.aws_secretsmanager.SecretDef, models.aws_secretsmanager.SecretTargetAttachmentDef] = pydantic.Field(..., description='The secret store that contains the username and password for the serverless cluster.\n')
    database_name: typing.Optional[str] = pydantic.Field(None, description='The optional name of the database to use within the cluster.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.RdsDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefAddRdsDataSourceV2Params(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    serverless_cluster: typing.Union[models.aws_rds.DatabaseClusterBaseDef, models.aws_rds.DatabaseClusterDef, models.aws_rds.DatabaseClusterFromSnapshotDef] = pydantic.Field(..., description='The serverless V2 cluster to interact with this data source.\n')
    secret_store: typing.Union[models.aws_docdb.DatabaseSecretDef, models.aws_rds.DatabaseSecretDef, models.aws_secretsmanager.SecretDef, models.aws_secretsmanager.SecretTargetAttachmentDef] = pydantic.Field(..., description='The secret store that contains the username and password for the serverless cluster.\n')
    database_name: typing.Optional[str] = pydantic.Field(None, description='The optional name of the database to use within the cluster.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.RdsDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefAddSchemaDependencyParams(pydantic.BaseModel):
    construct_: models.CfnResourceDef = pydantic.Field(..., description='the dependee.', alias='construct')
    ...

class GraphqlApiBaseDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class GraphqlApiBaseDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    data_source: typing.Optional[models.aws_appsync.BaseDataSourceDef] = pydantic.Field(None, description='The data source this resolver is using. Default: - No datasource\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...

class GraphqlApiBaseDefGrantParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal.\n')
    resources: models.aws_appsync.IamResourceDef = pydantic.Field(..., description='The set of resources to allow (i.e. ...:[region]:[accountId]:apis/GraphQLId/...).\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefGrantMutationParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal.\n')
    fields: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefGrantQueryParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal.\n')
    fields: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiBaseDefGrantSubscriptionParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal.\n')
    fields: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_appsync.IamResource
class IamResourceDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['resource_arns']
    _classmethod_names: typing.ClassVar[list[str]] = ['all', 'custom', 'of_type']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.IamResource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.IamResourceDefConfig] = pydantic.Field(None)


class IamResourceDefConfig(pydantic.BaseModel):
    all: typing.Optional[list[models.aws_appsync.IamResourceDefAllParams]] = pydantic.Field(None, description='Generate the resource names that accepts all types: ``*``.')
    custom: typing.Optional[list[models.aws_appsync.IamResourceDefCustomParams]] = pydantic.Field(None, description='Generate the resource names given custom arns.')
    of_type: typing.Optional[list[models.aws_appsync.IamResourceDefOfTypeParams]] = pydantic.Field(None, description='Generate the resource names given a type and fields.')
    resource_arns: typing.Optional[list[models.aws_appsync.IamResourceDefResourceArnsParams]] = pydantic.Field(None, description='Return the Resource ARN.')

class IamResourceDefAllParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_appsync.IamResourceDefConfig]] = pydantic.Field(None)
    ...

class IamResourceDefCustomParams(pydantic.BaseModel):
    arns: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_appsync.IamResourceDefConfig]] = pydantic.Field(None)
    ...

class IamResourceDefOfTypeParams(pydantic.BaseModel):
    type: str = pydantic.Field(..., description='The type that needs to be allowed.\n')
    fields: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_appsync.IamResourceDefConfig]] = pydantic.Field(None)
    ...

class IamResourceDefResourceArnsParams(pydantic.BaseModel):
    api: models.aws_appsync.GraphqlApiBaseDef = pydantic.Field(..., description='The GraphQL API to give permissions.')
    ...


#  autogenerated from aws_cdk.aws_appsync.InlineCode
class InlineCodeDef(BaseClass):
    code: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['code']
    _method_names: typing.ClassVar[list[str]] = ['bind']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_asset', 'from_inline']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.InlineCode'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_asset', 'from_inline']
    ...


    from_asset: typing.Optional[models.aws_appsync.InlineCodeDefFromAssetParams] = pydantic.Field(None, description='Loads the function code from a local disk path.')
    from_inline: typing.Optional[models.aws_appsync.InlineCodeDefFromInlineParams] = pydantic.Field(None, description='Inline code for AppSync function.')
    resource_config: typing.Optional[models.aws_appsync.InlineCodeDefConfig] = pydantic.Field(None)


class InlineCodeDefConfig(pydantic.BaseModel):
    bind: typing.Optional[list[models.aws_appsync.InlineCodeDefBindParams]] = pydantic.Field(None, description='Bind source code to an AppSync Function or resolver.')

class InlineCodeDefBindParams(pydantic.BaseModel):
    ...

class InlineCodeDefFromAssetParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path to the source code file.\n')
    deploy_time: typing.Optional[bool] = pydantic.Field(None, description='Whether or not the asset needs to exist beyond deployment time; i.e. are copied over to a different location and not needed afterwards. Setting this property to true has an impact on the lifecycle of the asset, because we will assume that it is safe to delete after the CloudFormation deployment succeeds. For example, Lambda Function assets are copied over to Lambda during deployment. Therefore, it is not necessary to store the asset in S3, so we consider those deployTime assets. Default: false\n')
    readers: typing.Optional[typing.Sequence[models.AnyResource]] = pydantic.Field(None, description='A list of principals that should be able to read this asset from S3. You can use ``asset.grantRead(principal)`` to grant read permissions later. Default: - No principals that can read file asset.\n')
    asset_hash: typing.Optional[str] = pydantic.Field(None, description='Specify a custom hash for this asset. If ``assetHashType`` is set it must be set to ``AssetHashType.CUSTOM``. For consistency, this custom hash will be SHA256 hashed and encoded as hex. The resulting hash will be the asset hash. NOTE: the hash is used in order to identify a specific revision of the asset, and used for optimizing and caching deployment activities related to this asset such as packaging, uploading to Amazon S3, etc. If you chose to customize the hash, you will need to make sure it is updated every time the asset changes, or otherwise it is possible that some deployments will not be invalidated. Default: - based on ``assetHashType``\n')
    asset_hash_type: typing.Optional[aws_cdk.AssetHashType] = pydantic.Field(None, description='Specifies the type of hash to calculate for this asset. If ``assetHash`` is configured, this option must be ``undefined`` or ``AssetHashType.CUSTOM``. Default: - the default is ``AssetHashType.SOURCE``, but if ``assetHash`` is explicitly specified this value defaults to ``AssetHashType.CUSTOM``.\n')
    bundling: typing.Union[models.BundlingOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Bundle the asset by executing a command in a Docker container or a custom bundling provider. The asset path will be mounted at ``/asset-input``. The Docker container is responsible for putting content at ``/asset-output``. The content at ``/asset-output`` will be zipped and used as the final asset. Default: - uploaded as-is to S3 if the asset is a regular file or a .zip file, archived into a .zip file and uploaded to S3 otherwise\n')
    exclude: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='File paths matching the patterns will be excluded. See ``ignoreMode`` to set the matching behavior. Has no effect on Assets bundled using the ``bundling`` property. Default: - nothing is excluded\n')
    follow_symlinks: typing.Optional[aws_cdk.SymlinkFollowMode] = pydantic.Field(None, description='A strategy for how to handle symlinks. Default: SymlinkFollowMode.NEVER\n')
    ignore_mode: typing.Optional[aws_cdk.IgnoreMode] = pydantic.Field(None, description='The ignore behavior to use for ``exclude`` patterns. Default: IgnoreMode.GLOB')
    ...

class InlineCodeDefFromInlineParams(pydantic.BaseModel):
    code: str = pydantic.Field(..., description='The actual handler code (limited to 4KiB).\n')
    ...


#  autogenerated from aws_cdk.aws_appsync.KeyCondition
class KeyConditionDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['and_', 'render_template']
    _classmethod_names: typing.ClassVar[list[str]] = ['begins_with', 'between', 'eq', 'ge', 'gt', 'le', 'lt']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.KeyCondition'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.KeyConditionDefConfig] = pydantic.Field(None)


class KeyConditionDefConfig(pydantic.BaseModel):
    and_: typing.Optional[list[models.aws_appsync.KeyConditionDefAndParams]] = pydantic.Field(None, description='Conjunction between two conditions.')
    begins_with: typing.Optional[list[models.aws_appsync.KeyConditionDefBeginsWithParams]] = pydantic.Field(None, description='Condition (k, arg).\nTrue if the key attribute k begins with the Query argument.')
    between: typing.Optional[list[models.aws_appsync.KeyConditionDefBetweenParams]] = pydantic.Field(None, description='Condition k BETWEEN arg1 AND arg2, true if k >= arg1 and k <= arg2.')
    eq: typing.Optional[list[models.aws_appsync.KeyConditionDefEqParams]] = pydantic.Field(None, description='Condition k = arg, true if the key attribute k is equal to the Query argument.')
    ge: typing.Optional[list[models.aws_appsync.KeyConditionDefGeParams]] = pydantic.Field(None, description='Condition k >= arg, true if the key attribute k is greater or equal to the Query argument.')
    gt: typing.Optional[list[models.aws_appsync.KeyConditionDefGtParams]] = pydantic.Field(None, description='Condition k > arg, true if the key attribute k is greater than the the Query argument.')
    le: typing.Optional[list[models.aws_appsync.KeyConditionDefLeParams]] = pydantic.Field(None, description='Condition k <= arg, true if the key attribute k is less than or equal to the Query argument.')
    lt: typing.Optional[list[models.aws_appsync.KeyConditionDefLtParams]] = pydantic.Field(None, description='Condition k < arg, true if the key attribute k is less than the Query argument.')
    render_template: typing.Optional[bool] = pydantic.Field(None, description='Renders the key condition to a VTL string.')

class KeyConditionDefAndParams(pydantic.BaseModel):
    key_cond: models.aws_appsync.KeyConditionDef = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_appsync.KeyConditionDefConfig]] = pydantic.Field(None)
    ...

class KeyConditionDefBeginsWithParams(pydantic.BaseModel):
    key_name: str = pydantic.Field(..., description='-\n')
    arg: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_appsync.KeyConditionDefConfig]] = pydantic.Field(None)
    ...

class KeyConditionDefBetweenParams(pydantic.BaseModel):
    key_name: str = pydantic.Field(..., description='-\n')
    arg1: str = pydantic.Field(..., description='-\n')
    arg2: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_appsync.KeyConditionDefConfig]] = pydantic.Field(None)
    ...

class KeyConditionDefEqParams(pydantic.BaseModel):
    key_name: str = pydantic.Field(..., description='-\n')
    arg: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_appsync.KeyConditionDefConfig]] = pydantic.Field(None)
    ...

class KeyConditionDefGeParams(pydantic.BaseModel):
    key_name: str = pydantic.Field(..., description='-\n')
    arg: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_appsync.KeyConditionDefConfig]] = pydantic.Field(None)
    ...

class KeyConditionDefGtParams(pydantic.BaseModel):
    key_name: str = pydantic.Field(..., description='-\n')
    arg: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_appsync.KeyConditionDefConfig]] = pydantic.Field(None)
    ...

class KeyConditionDefLeParams(pydantic.BaseModel):
    key_name: str = pydantic.Field(..., description='-\n')
    arg: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_appsync.KeyConditionDefConfig]] = pydantic.Field(None)
    ...

class KeyConditionDefLtParams(pydantic.BaseModel):
    key_name: str = pydantic.Field(..., description='-\n')
    arg: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_appsync.KeyConditionDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_appsync.MappingTemplate
class MappingTemplateDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = ['render_template']
    _classmethod_names: typing.ClassVar[list[str]] = ['dynamo_db_delete_item', 'dynamo_db_get_item', 'dynamo_db_put_item', 'dynamo_db_query', 'dynamo_db_result_item', 'dynamo_db_result_list', 'dynamo_db_scan_table', 'from_file', 'from_string', 'lambda_request', 'lambda_result']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.MappingTemplate'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_file', 'from_string']
    ...


    from_file: typing.Optional[models.aws_appsync.MappingTemplateDefFromFileParams] = pydantic.Field(None, description='Create a mapping template from the given file.')
    from_string: typing.Optional[models.aws_appsync.MappingTemplateDefFromStringParams] = pydantic.Field(None, description='Create a mapping template from the given string.')
    resource_config: typing.Optional[models.aws_appsync.MappingTemplateDefConfig] = pydantic.Field(None)


class MappingTemplateDefConfig(pydantic.BaseModel):
    dynamo_db_delete_item: typing.Optional[list[models.aws_appsync.MappingTemplateDefDynamoDbDeleteItemParams]] = pydantic.Field(None, description='Mapping template to delete a single item from a DynamoDB table.')
    dynamo_db_get_item: typing.Optional[list[models.aws_appsync.MappingTemplateDefDynamoDbGetItemParams]] = pydantic.Field(None, description='Mapping template to get a single item from a DynamoDB table.')
    dynamo_db_put_item: typing.Optional[list[models.aws_appsync.MappingTemplateDefDynamoDbPutItemParams]] = pydantic.Field(None, description='Mapping template to save a single item to a DynamoDB table.')
    dynamo_db_query: typing.Optional[list[models.aws_appsync.MappingTemplateDefDynamoDbQueryParams]] = pydantic.Field(None, description='Mapping template to query a set of items from a DynamoDB table.')
    dynamo_db_result_item: typing.Optional[list[models.aws_appsync.MappingTemplateDefDynamoDbResultItemParams]] = pydantic.Field(None, description='Mapping template for a single result item from DynamoDB.')
    dynamo_db_result_list: typing.Optional[list[models.aws_appsync.MappingTemplateDefDynamoDbResultListParams]] = pydantic.Field(None, description='Mapping template for a result list from DynamoDB.')
    dynamo_db_scan_table: typing.Optional[list[models.aws_appsync.MappingTemplateDefDynamoDbScanTableParams]] = pydantic.Field(None, description='Mapping template to scan a DynamoDB table to fetch all entries.')
    lambda_request: typing.Optional[list[models.aws_appsync.MappingTemplateDefLambdaRequestParams]] = pydantic.Field(None, description='Mapping template to invoke a Lambda function.')
    lambda_result: typing.Optional[list[models.aws_appsync.MappingTemplateDefLambdaResultParams]] = pydantic.Field(None, description='Mapping template to return the Lambda result to the caller.')
    render_template: typing.Optional[bool] = pydantic.Field(None, description='this is called to render the mapping template to a VTL string.')

class MappingTemplateDefDynamoDbDeleteItemParams(pydantic.BaseModel):
    key_name: str = pydantic.Field(..., description='the name of the hash key field.\n')
    id_arg: str = pydantic.Field(..., description='the name of the Mutation argument.')
    return_config: typing.Optional[list[models.aws_appsync.MappingTemplateDefConfig]] = pydantic.Field(None)
    ...

class MappingTemplateDefDynamoDbGetItemParams(pydantic.BaseModel):
    key_name: str = pydantic.Field(..., description='the name of the hash key field.\n')
    id_arg: str = pydantic.Field(..., description='the name of the Query argument.\n')
    consistent_read: typing.Optional[bool] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.aws_appsync.MappingTemplateDefConfig]] = pydantic.Field(None)
    ...

class MappingTemplateDefDynamoDbPutItemParams(pydantic.BaseModel):
    key: models.aws_appsync.PrimaryKeyDef = pydantic.Field(..., description='the assigment of Mutation values to the primary key.\n')
    values: models.aws_appsync.AttributeValuesDef = pydantic.Field(..., description='the assignment of Mutation values to the table attributes.')
    return_config: typing.Optional[list[models.aws_appsync.MappingTemplateDefConfig]] = pydantic.Field(None)
    ...

class MappingTemplateDefDynamoDbQueryParams(pydantic.BaseModel):
    cond: models.aws_appsync.KeyConditionDef = pydantic.Field(..., description='the key condition for the query.\n')
    index_name: typing.Optional[str] = pydantic.Field(None, description='-\n')
    consistent_read: typing.Optional[bool] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.aws_appsync.MappingTemplateDefConfig]] = pydantic.Field(None)
    ...

class MappingTemplateDefDynamoDbResultItemParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_appsync.MappingTemplateDefConfig]] = pydantic.Field(None)
    ...

class MappingTemplateDefDynamoDbResultListParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_appsync.MappingTemplateDefConfig]] = pydantic.Field(None)
    ...

class MappingTemplateDefDynamoDbScanTableParams(pydantic.BaseModel):
    consistent_read: typing.Optional[bool] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.aws_appsync.MappingTemplateDefConfig]] = pydantic.Field(None)
    ...

class MappingTemplateDefFromFileParams(pydantic.BaseModel):
    file_name: str = pydantic.Field(..., description='-')
    ...

class MappingTemplateDefFromStringParams(pydantic.BaseModel):
    template: str = pydantic.Field(..., description='-')
    ...

class MappingTemplateDefLambdaRequestParams(pydantic.BaseModel):
    payload: typing.Optional[str] = pydantic.Field(None, description='the VTL template snippet of the payload to send to the lambda. If no payload is provided all available context fields are sent to the Lambda function\n')
    operation: typing.Optional[str] = pydantic.Field(None, description='the type of operation AppSync should perform on the data source.')
    return_config: typing.Optional[list[models.aws_appsync.MappingTemplateDefConfig]] = pydantic.Field(None)
    ...

class MappingTemplateDefLambdaResultParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_appsync.MappingTemplateDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_appsync.PartitionKey
class PartitionKeyDef(BaseClass):
    pkey: typing.Union[models.aws_appsync.AssignDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['pkey']
    _method_names: typing.ClassVar[list[str]] = ['render_template', 'sort']
    _classmethod_names: typing.ClassVar[list[str]] = ['partition']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.PartitionKey'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['partition']
    ...


    partition: typing.Optional[models.aws_appsync.PartitionKeyDefPartitionParams] = pydantic.Field(None, description='Allows assigning a value to the partition key.')
    resource_config: typing.Optional[models.aws_appsync.PartitionKeyDefConfig] = pydantic.Field(None)


class PartitionKeyDefConfig(pydantic.BaseModel):
    render_template: typing.Optional[bool] = pydantic.Field(None, description='Renders the key assignment to a VTL string.')
    sort: typing.Optional[list[models.aws_appsync.PartitionKeyDefSortParams]] = pydantic.Field(None, description='Allows assigning a value to the sort key.')

class PartitionKeyDefPartitionParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-')
    ...

class PartitionKeyDefSortParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_appsync.SortKeyStepDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_appsync.PartitionKeyStep
class PartitionKeyStepDef(BaseClass):
    key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['key']
    _method_names: typing.ClassVar[list[str]] = ['auto']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.PartitionKeyStep'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.PartitionKeyStepDefConfig] = pydantic.Field(None)


class PartitionKeyStepDefConfig(pydantic.BaseModel):
    auto: typing.Optional[list[models.aws_appsync.PartitionKeyStepDefAutoParams]] = pydantic.Field(None, description='Assign an auto-generated value to the partition key.')

class PartitionKeyStepDefAutoParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_appsync.PartitionKeyDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_appsync.PrimaryKey
class PrimaryKeyDef(BaseClass):
    pkey: typing.Union[models.aws_appsync.AssignDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    skey: typing.Optional[models.aws_appsync.AssignDef] = pydantic.Field(None, description='-')
    _init_params: typing.ClassVar[list[str]] = ['pkey', 'skey']
    _method_names: typing.ClassVar[list[str]] = ['render_template']
    _classmethod_names: typing.ClassVar[list[str]] = ['partition']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.PrimaryKey'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['partition']
    ...


    partition: typing.Optional[models.aws_appsync.PrimaryKeyDefPartitionParams] = pydantic.Field(None, description='Allows assigning a value to the partition key.')
    resource_config: typing.Optional[models.aws_appsync.PrimaryKeyDefConfig] = pydantic.Field(None)


class PrimaryKeyDefConfig(pydantic.BaseModel):
    render_template: typing.Optional[bool] = pydantic.Field(None, description='Renders the key assignment to a VTL string.')

class PrimaryKeyDefPartitionParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-')
    ...


#  autogenerated from aws_cdk.aws_appsync.SchemaFile
class SchemaFileDef(BaseClass):
    file_path: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The file path for the schema. When this option is configured, then the schema will be generated from an existing file from disk.')
    _init_params: typing.ClassVar[list[str]] = ['file_path']
    _method_names: typing.ClassVar[list[str]] = ['bind']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_asset']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.SchemaFile'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_asset']
    ...


    from_asset: typing.Optional[models.aws_appsync.SchemaFileDefFromAssetParams] = pydantic.Field(None, description='Generate a Schema from file.')
    resource_config: typing.Optional[models.aws_appsync.SchemaFileDefConfig] = pydantic.Field(None)


class SchemaFileDefConfig(pydantic.BaseModel):
    bind: typing.Optional[list[models.aws_appsync.SchemaFileDefBindParams]] = pydantic.Field(None, description='Called when the GraphQL Api is initialized to allow this object to bind to the stack.')

class SchemaFileDefBindParams(pydantic.BaseModel):
    api: typing.Union[models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(..., description='The binding GraphQL Api.')
    ...

class SchemaFileDefFromAssetParams(pydantic.BaseModel):
    file_path: str = pydantic.Field(..., description='the file path of the schema file.\n')
    ...


#  autogenerated from aws_cdk.aws_appsync.SortKeyStep
class SortKeyStepDef(BaseClass):
    pkey: typing.Union[models.aws_appsync.AssignDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    skey: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='-')
    _init_params: typing.ClassVar[list[str]] = ['pkey', 'skey']
    _method_names: typing.ClassVar[list[str]] = ['auto']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.SortKeyStep'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.SortKeyStepDefConfig] = pydantic.Field(None)


class SortKeyStepDefConfig(pydantic.BaseModel):
    auto: typing.Optional[list[models.aws_appsync.SortKeyStepDefAutoParams]] = pydantic.Field(None, description='Assign an auto-generated value to the sort key.')

class SortKeyStepDefAutoParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_appsync.PrimaryKeyDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_appsync.Values
class ValuesDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['attribute', 'projecting']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.Values'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['attribute', 'projecting']
    ...


    attribute: typing.Optional[models.aws_appsync.ValuesDefAttributeParams] = pydantic.Field(None, description='Allows assigning a value to the specified attribute.')
    projecting: typing.Optional[models.aws_appsync.ValuesDefProjectingParams] = pydantic.Field(None, description='Treats the specified object as a map of assignments, where the property names represent attribute names.\nIt’s opinionated about how it represents\nsome of the nested objects: e.g., it will use lists (“L”) rather than sets\n(“SS”, “NS”, “BS”). By default it projects the argument container ("$ctx.args").')

class ValuesDefAttributeParams(pydantic.BaseModel):
    attr: str = pydantic.Field(..., description='-')
    ...

class ValuesDefProjectingParams(pydantic.BaseModel):
    arg: typing.Optional[str] = pydantic.Field(None, description='-')
    ...


#  autogenerated from aws_cdk.aws_appsync.AppsyncFunction
class AppsyncFunctionDef(BaseConstruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='the GraphQL Api linked to this AppSync Function.\n')
    data_source: typing.Union[models.aws_appsync.BaseDataSourceDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='the data source linked to this AppSync Function.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    _init_params: typing.ClassVar[list[str]] = ['api', 'data_source', 'name', 'code', 'description', 'max_batch_size', 'request_mapping_template', 'response_mapping_template', 'runtime']
    _method_names: typing.ClassVar[list[str]] = ['apply_removal_policy']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_appsync_function_attributes']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.AppsyncFunction'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_appsync_function_attributes']
    ...


    from_appsync_function_attributes: typing.Optional[models.aws_appsync.AppsyncFunctionDefFromAppsyncFunctionAttributesParams] = pydantic.Field(None, description='Import Appsync Function from arn.')
    resource_config: typing.Optional[models.aws_appsync.AppsyncFunctionDefConfig] = pydantic.Field(None)


class AppsyncFunctionDefConfig(pydantic.BaseModel):
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    data_source_config: typing.Optional[models.aws_appsync.BaseDataSourceDefConfig] = pydantic.Field(None)

class AppsyncFunctionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class AppsyncFunctionDefFromAppsyncFunctionAttributesParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-\n')
    id: str = pydantic.Field(..., description='-\n')
    function_arn: str = pydantic.Field(..., description='the ARN of the AppSync function.')
    ...


#  autogenerated from aws_cdk.aws_appsync.DynamoDbDataSource
class DynamoDbDataSourceDef(BaseConstruct):
    table: typing.Union[_REQUIRED_INIT_PARAM, models.aws_dynamodb.TableBaseDef, models.aws_dynamodb.TableDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The DynamoDB table backing this data source.\n')
    read_only_access: typing.Optional[bool] = pydantic.Field(None, description='Specify whether this DS is read only or has read and write permissions to the DynamoDB table. Default: false\n')
    use_caller_credentials: typing.Optional[bool] = pydantic.Field(None, description='use credentials of caller to access DynamoDB. Default: false\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source')
    _init_params: typing.ClassVar[list[str]] = ['table', 'read_only_access', 'use_caller_credentials', 'service_role', 'api', 'description', 'name']
    _method_names: typing.ClassVar[list[str]] = ['create_function', 'create_resolver']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.DynamoDbDataSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.DynamoDbDataSourceDefConfig] = pydantic.Field(None)


class DynamoDbDataSourceDefConfig(pydantic.BaseModel):
    create_function: typing.Optional[list[models.aws_appsync.DynamoDbDataSourceDefCreateFunctionParams]] = pydantic.Field(None, description='creates a new appsync function for this datasource and API using the given properties.')
    create_resolver: typing.Optional[list[models.aws_appsync.DynamoDbDataSourceDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')
    grant_principal_config: typing.Optional[models._interface_methods.AwsIamIPrincipalDefConfig] = pydantic.Field(None)

class DynamoDbDataSourceDefCreateFunctionParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    name: str = pydantic.Field(..., description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    return_config: typing.Optional[list[models.aws_appsync.AppsyncFunctionDefConfig]] = pydantic.Field(None)
    ...

class DynamoDbDataSourceDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...


#  autogenerated from aws_cdk.aws_appsync.ElasticsearchDataSource
class ElasticsearchDataSourceDef(BaseConstruct):
    domain: typing.Union[_REQUIRED_INIT_PARAM, models.aws_elasticsearch.DomainDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='(deprecated) The elasticsearch domain containing the endpoint for the data source.\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n\n:stability: deprecated\n')
    _init_params: typing.ClassVar[list[str]] = ['domain', 'service_role', 'api', 'description', 'name']
    _method_names: typing.ClassVar[list[str]] = ['create_function', 'create_resolver']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.ElasticsearchDataSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.ElasticsearchDataSourceDefConfig] = pydantic.Field(None)


class ElasticsearchDataSourceDefConfig(pydantic.BaseModel):
    create_function: typing.Optional[list[models.aws_appsync.ElasticsearchDataSourceDefCreateFunctionParams]] = pydantic.Field(None, description='creates a new appsync function for this datasource and API using the given properties.')
    create_resolver: typing.Optional[list[models.aws_appsync.ElasticsearchDataSourceDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')
    grant_principal_config: typing.Optional[models._interface_methods.AwsIamIPrincipalDefConfig] = pydantic.Field(None)

class ElasticsearchDataSourceDefCreateFunctionParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    name: str = pydantic.Field(..., description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    return_config: typing.Optional[list[models.aws_appsync.AppsyncFunctionDefConfig]] = pydantic.Field(None)
    ...

class ElasticsearchDataSourceDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...


#  autogenerated from aws_cdk.aws_appsync.EventBridgeDataSource
class EventBridgeDataSourceDef(BaseConstruct):
    event_bus: typing.Union[_REQUIRED_INIT_PARAM, models.aws_events.EventBusDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The EventBridge EventBus.\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source')
    _init_params: typing.ClassVar[list[str]] = ['event_bus', 'service_role', 'api', 'description', 'name']
    _method_names: typing.ClassVar[list[str]] = ['create_function', 'create_resolver']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.EventBridgeDataSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.EventBridgeDataSourceDefConfig] = pydantic.Field(None)


class EventBridgeDataSourceDefConfig(pydantic.BaseModel):
    create_function: typing.Optional[list[models.aws_appsync.EventBridgeDataSourceDefCreateFunctionParams]] = pydantic.Field(None, description='creates a new appsync function for this datasource and API using the given properties.')
    create_resolver: typing.Optional[list[models.aws_appsync.EventBridgeDataSourceDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')
    grant_principal_config: typing.Optional[models._interface_methods.AwsIamIPrincipalDefConfig] = pydantic.Field(None)

class EventBridgeDataSourceDefCreateFunctionParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    name: str = pydantic.Field(..., description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    return_config: typing.Optional[list[models.aws_appsync.AppsyncFunctionDefConfig]] = pydantic.Field(None)
    ...

class EventBridgeDataSourceDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...


#  autogenerated from aws_cdk.aws_appsync.GraphqlApi
class GraphqlApiDef(BaseConstruct):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='the name of the GraphQL API.\n')
    authorization_config: typing.Union[models.aws_appsync.AuthorizationConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Optional authorization configuration. Default: - API Key authorization\n')
    definition: typing.Optional[models.aws_appsync.DefinitionDef] = pydantic.Field(None, description='Definition (schema file or source APIs) for this GraphQL Api.\n')
    domain_name: typing.Union[models.aws_appsync.DomainOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The domain name configuration for the GraphQL API. The Route 53 hosted zone and CName DNS record must be configured in addition to this setting to enable custom domain URL Default: - no domain name\n')
    environment_variables: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='A map containing the list of resources with their properties and environment variables. There are a few rules you must follow when creating keys and values: - Keys must begin with a letter. - Keys must be between 2 and 64 characters long. - Keys can only contain letters, numbers, and the underscore character (_). - Values can be up to 512 characters long. - You can configure up to 50 key-value pairs in a GraphQL API. Default: - No environment variables.\n')
    introspection_config: typing.Optional[aws_cdk.aws_appsync.IntrospectionConfig] = pydantic.Field(None, description='A value indicating whether the API to enable (ENABLED) or disable (DISABLED) introspection. Default: IntrospectionConfig.ENABLED\n')
    log_config: typing.Union[models.aws_appsync.LogConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Logging configuration for this api. Default: - None\n')
    query_depth_limit: typing.Union[int, float, None] = pydantic.Field(None, description='A number indicating the maximum depth resolvers should be accepted when handling queries. Value must be withing range of 0 to 75 Default: - The default value is 0 (or unspecified) which indicates no maximum depth.\n')
    resolver_count_limit: typing.Union[int, float, None] = pydantic.Field(None, description='A number indicating the maximum number of resolvers that should be accepted when handling queries. Value must be withing range of 0 to 10000 Default: - The default value is 0 (or unspecified), which will set the limit to 10000\n')
    schema_: typing.Optional[typing.Union[models.aws_appsync.SchemaFileDef]] = pydantic.Field(None, description='(deprecated) GraphQL schema definition. Specify how you want to define your schema. SchemaFile.fromAsset(filePath: string) allows schema definition through schema.graphql file Default: - schema will be generated code-first (i.e. addType, addObjectType, etc.)\n', alias='schema')
    visibility: typing.Optional[aws_cdk.aws_appsync.Visibility] = pydantic.Field(None, description='A value indicating whether the API is accessible from anywhere (GLOBAL) or can only be access from a VPC (PRIVATE). Default: - GLOBAL\n')
    xray_enabled: typing.Optional[bool] = pydantic.Field(None, description='A flag indicating whether or not X-Ray tracing is enabled for the GraphQL API. Default: - false')
    _init_params: typing.ClassVar[list[str]] = ['name', 'authorization_config', 'definition', 'domain_name', 'environment_variables', 'introspection_config', 'log_config', 'query_depth_limit', 'resolver_count_limit', 'schema', 'visibility', 'xray_enabled']
    _method_names: typing.ClassVar[list[str]] = ['add_dynamo_db_data_source', 'add_elasticsearch_data_source', 'add_environment_variable', 'add_event_bridge_data_source', 'add_http_data_source', 'add_lambda_data_source', 'add_none_data_source', 'add_open_search_data_source', 'add_rds_data_source', 'add_rds_data_source_v2', 'add_schema_dependency', 'apply_removal_policy', 'create_resolver', 'grant', 'grant_mutation', 'grant_query', 'grant_subscription']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_graphql_api_attributes']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.GraphqlApi'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_graphql_api_attributes']
    ...


    from_graphql_api_attributes: typing.Optional[models.aws_appsync.GraphqlApiDefFromGraphqlApiAttributesParams] = pydantic.Field(None, description='Import a GraphQL API through this function.')
    resource_config: typing.Optional[models.aws_appsync.GraphqlApiDefConfig] = pydantic.Field(None)


class GraphqlApiDefConfig(pydantic.BaseModel):
    add_dynamo_db_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiDefAddDynamoDbDataSourceParams]] = pydantic.Field(None, description='add a new DynamoDB data source to this API.')
    add_elasticsearch_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiDefAddElasticsearchDataSourceParams]] = pydantic.Field(None, description='(deprecated) add a new elasticsearch data source to this API.')
    add_environment_variable: typing.Optional[list[models.aws_appsync.GraphqlApiDefAddEnvironmentVariableParams]] = pydantic.Field(None, description='Add an environment variable to the construct.')
    add_event_bridge_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiDefAddEventBridgeDataSourceParams]] = pydantic.Field(None, description='Add an EventBridge data source to this api.')
    add_http_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiDefAddHttpDataSourceParams]] = pydantic.Field(None, description='add a new http data source to this API.')
    add_lambda_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiDefAddLambdaDataSourceParams]] = pydantic.Field(None, description='add a new Lambda data source to this API.')
    add_none_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiDefAddNoneDataSourceParams]] = pydantic.Field(None, description="add a new dummy data source to this API.\nUseful for pipeline resolvers\nand for backend changes that don't require a data source.")
    add_open_search_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiDefAddOpenSearchDataSourceParams]] = pydantic.Field(None, description='add a new OpenSearch data source to this API.')
    add_rds_data_source: typing.Optional[list[models.aws_appsync.GraphqlApiDefAddRdsDataSourceParams]] = pydantic.Field(None, description='add a new Rds data source to this API.')
    add_rds_data_source_v2: typing.Optional[list[models.aws_appsync.GraphqlApiDefAddRdsDataSourceV2Params]] = pydantic.Field(None, description='add a new Rds data source to this API.')
    add_schema_dependency: typing.Optional[list[models.aws_appsync.GraphqlApiDefAddSchemaDependencyParams]] = pydantic.Field(None, description='Add schema dependency to a given construct.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    create_resolver: typing.Optional[list[models.aws_appsync.GraphqlApiDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')
    grant: typing.Optional[list[models.aws_appsync.GraphqlApiDefGrantParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this GraphQLApi to an IAM principal's policy.")
    grant_mutation: typing.Optional[list[models.aws_appsync.GraphqlApiDefGrantMutationParams]] = pydantic.Field(None, description="Adds an IAM policy statement for Mutation access to this GraphQLApi to an IAM principal's policy.")
    grant_query: typing.Optional[list[models.aws_appsync.GraphqlApiDefGrantQueryParams]] = pydantic.Field(None, description="Adds an IAM policy statement for Query access to this GraphQLApi to an IAM principal's policy.")
    grant_subscription: typing.Optional[list[models.aws_appsync.GraphqlApiDefGrantSubscriptionParams]] = pydantic.Field(None, description="Adds an IAM policy statement for Subscription access to this GraphQLApi to an IAM principal's policy.")
    log_group_config: typing.Optional[models._interface_methods.AwsLogsILogGroupDefConfig] = pydantic.Field(None)
    schema_config: typing.Optional[models._interface_methods.AwsAppsyncISchemaDefConfig] = pydantic.Field(None)

class GraphqlApiDefAddDynamoDbDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    table: typing.Union[models.aws_dynamodb.TableBaseDef, models.aws_dynamodb.TableDef] = pydantic.Field(..., description='The DynamoDB table backing this data source.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.DynamoDbDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefAddElasticsearchDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    domain: typing.Union[models.aws_elasticsearch.DomainDef] = pydantic.Field(..., description='The elasticsearch domain for this data source.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id\n\n:deprecated: - use ``addOpenSearchDataSource``\n\n:stability: deprecated\n')
    return_config: typing.Optional[list[models.aws_appsync.ElasticsearchDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefAddEnvironmentVariableParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: str = pydantic.Field(..., description='-')
    ...

class GraphqlApiDefAddEventBridgeDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    event_bus: typing.Union[models.aws_events.EventBusDef] = pydantic.Field(..., description='The EventBridge EventBus on which to put events.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.EventBridgeDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefAddHttpDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    endpoint: str = pydantic.Field(..., description='The http endpoint.\n')
    authorization_config: typing.Union[models.aws_appsync.AwsIamConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The authorization config in case the HTTP endpoint requires authorization. Default: - none\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.HttpDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefAddLambdaDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    lambda_function: typing.Union[models.aws_lambda.FunctionBaseDef, models.aws_lambda.QualifiedFunctionBaseDef, models.aws_lambda.AliasDef, models.aws_lambda.DockerImageFunctionDef, models.aws_lambda.FunctionDef, models.aws_lambda.SingletonFunctionDef, models.aws_lambda.VersionDef, models.aws_lambda_nodejs.NodejsFunctionDef, models.triggers.TriggerFunctionDef] = pydantic.Field(..., description='The Lambda function to call to interact with this data source.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.LambdaDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefAddNoneDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.NoneDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefAddOpenSearchDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    domain: typing.Union[models.aws_opensearchservice.DomainDef] = pydantic.Field(..., description='The OpenSearch domain for this data source.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.OpenSearchDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefAddRdsDataSourceParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    serverless_cluster: typing.Union[models.aws_rds.ServerlessClusterDef, models.aws_rds.ServerlessClusterFromSnapshotDef] = pydantic.Field(..., description='The serverless cluster to interact with this data source.\n')
    secret_store: typing.Union[models.aws_docdb.DatabaseSecretDef, models.aws_rds.DatabaseSecretDef, models.aws_secretsmanager.SecretDef, models.aws_secretsmanager.SecretTargetAttachmentDef] = pydantic.Field(..., description='The secret store that contains the username and password for the serverless cluster.\n')
    database_name: typing.Optional[str] = pydantic.Field(None, description='The optional name of the database to use within the cluster.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.RdsDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefAddRdsDataSourceV2Params(pydantic.BaseModel):
    id: str = pydantic.Field(..., description="The data source's id.\n")
    serverless_cluster: typing.Union[models.aws_rds.DatabaseClusterBaseDef, models.aws_rds.DatabaseClusterDef, models.aws_rds.DatabaseClusterFromSnapshotDef] = pydantic.Field(..., description='The serverless V2 cluster to interact with this data source.\n')
    secret_store: typing.Union[models.aws_docdb.DatabaseSecretDef, models.aws_rds.DatabaseSecretDef, models.aws_secretsmanager.SecretDef, models.aws_secretsmanager.SecretTargetAttachmentDef] = pydantic.Field(..., description='The secret store that contains the username and password for the serverless cluster.\n')
    database_name: typing.Optional[str] = pydantic.Field(None, description='The optional name of the database to use within the cluster.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id')
    return_config: typing.Optional[list[models.aws_appsync.RdsDataSourceDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefAddSchemaDependencyParams(pydantic.BaseModel):
    construct_: models.CfnResourceDef = pydantic.Field(..., description='the dependee.', alias='construct')
    ...

class GraphqlApiDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class GraphqlApiDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    data_source: typing.Optional[models.aws_appsync.BaseDataSourceDef] = pydantic.Field(None, description='The data source this resolver is using. Default: - No datasource\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...

class GraphqlApiDefFromGraphqlApiAttributesParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='scope.\n')
    id: str = pydantic.Field(..., description='id.\n')
    graphql_api_id: str = pydantic.Field(..., description="an unique AWS AppSync GraphQL API identifier i.e. 'lxz775lwdrgcndgz3nurvac7oa'.\n")
    graphql_api_arn: typing.Optional[str] = pydantic.Field(None, description='the arn for the GraphQL Api. Default: - autogenerated arn\n')
    graph_ql_endpoint_arn: typing.Optional[str] = pydantic.Field(None, description='The GraphQl endpoint arn for the GraphQL API. Default: - none, required to construct event rules from imported APIs\n')
    modes: typing.Optional[typing.Sequence[aws_cdk.aws_appsync.AuthorizationType]] = pydantic.Field(None, description='The Authorization Types for this GraphQL Api. Default: - none, required to construct event rules from imported APIs\n')
    visibility: typing.Optional[aws_cdk.aws_appsync.Visibility] = pydantic.Field(None, description='The GraphQl API visibility. Default: - GLOBAL')
    ...

class GraphqlApiDefGrantParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal.\n')
    resources: models.aws_appsync.IamResourceDef = pydantic.Field(..., description='The set of resources to allow (i.e. ...:[region]:[accountId]:apis/GraphQLId/...).\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefGrantMutationParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal.\n')
    fields: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefGrantQueryParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal.\n')
    fields: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class GraphqlApiDefGrantSubscriptionParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal.\n')
    fields: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_appsync.HttpDataSource
class HttpDataSourceDef(BaseConstruct):
    endpoint: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The http endpoint.\n')
    authorization_config: typing.Union[models.aws_appsync.AwsIamConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The authorization config in case the HTTP endpoint requires authorization. Default: - none\n')
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source')
    _init_params: typing.ClassVar[list[str]] = ['endpoint', 'authorization_config', 'api', 'description', 'name']
    _method_names: typing.ClassVar[list[str]] = ['create_function', 'create_resolver']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.HttpDataSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.HttpDataSourceDefConfig] = pydantic.Field(None)


class HttpDataSourceDefConfig(pydantic.BaseModel):
    create_function: typing.Optional[list[models.aws_appsync.HttpDataSourceDefCreateFunctionParams]] = pydantic.Field(None, description='creates a new appsync function for this datasource and API using the given properties.')
    create_resolver: typing.Optional[list[models.aws_appsync.HttpDataSourceDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')
    grant_principal_config: typing.Optional[models._interface_methods.AwsIamIPrincipalDefConfig] = pydantic.Field(None)

class HttpDataSourceDefCreateFunctionParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    name: str = pydantic.Field(..., description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    return_config: typing.Optional[list[models.aws_appsync.AppsyncFunctionDefConfig]] = pydantic.Field(None)
    ...

class HttpDataSourceDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...


#  autogenerated from aws_cdk.aws_appsync.LambdaDataSource
class LambdaDataSourceDef(BaseConstruct):
    lambda_function: typing.Union[_REQUIRED_INIT_PARAM, models.aws_lambda.FunctionBaseDef, models.aws_lambda.QualifiedFunctionBaseDef, models.aws_lambda.AliasDef, models.aws_lambda.DockerImageFunctionDef, models.aws_lambda.FunctionDef, models.aws_lambda.SingletonFunctionDef, models.aws_lambda.VersionDef, models.aws_lambda_nodejs.NodejsFunctionDef, models.triggers.TriggerFunctionDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Lambda function to call to interact with this data source.\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source')
    _init_params: typing.ClassVar[list[str]] = ['lambda_function', 'service_role', 'api', 'description', 'name']
    _method_names: typing.ClassVar[list[str]] = ['create_function', 'create_resolver']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.LambdaDataSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.LambdaDataSourceDefConfig] = pydantic.Field(None)


class LambdaDataSourceDefConfig(pydantic.BaseModel):
    create_function: typing.Optional[list[models.aws_appsync.LambdaDataSourceDefCreateFunctionParams]] = pydantic.Field(None, description='creates a new appsync function for this datasource and API using the given properties.')
    create_resolver: typing.Optional[list[models.aws_appsync.LambdaDataSourceDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')
    grant_principal_config: typing.Optional[models._interface_methods.AwsIamIPrincipalDefConfig] = pydantic.Field(None)

class LambdaDataSourceDefCreateFunctionParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    name: str = pydantic.Field(..., description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    return_config: typing.Optional[list[models.aws_appsync.AppsyncFunctionDefConfig]] = pydantic.Field(None)
    ...

class LambdaDataSourceDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...


#  autogenerated from aws_cdk.aws_appsync.NoneDataSource
class NoneDataSourceDef(BaseConstruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name']
    _method_names: typing.ClassVar[list[str]] = ['create_function', 'create_resolver']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.NoneDataSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.NoneDataSourceDefConfig] = pydantic.Field(None)


class NoneDataSourceDefConfig(pydantic.BaseModel):
    create_function: typing.Optional[list[models.aws_appsync.NoneDataSourceDefCreateFunctionParams]] = pydantic.Field(None, description='creates a new appsync function for this datasource and API using the given properties.')
    create_resolver: typing.Optional[list[models.aws_appsync.NoneDataSourceDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')

class NoneDataSourceDefCreateFunctionParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    name: str = pydantic.Field(..., description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    return_config: typing.Optional[list[models.aws_appsync.AppsyncFunctionDefConfig]] = pydantic.Field(None)
    ...

class NoneDataSourceDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...


#  autogenerated from aws_cdk.aws_appsync.OpenSearchDataSource
class OpenSearchDataSourceDef(BaseConstruct):
    domain: typing.Union[_REQUIRED_INIT_PARAM, models.aws_opensearchservice.DomainDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The OpenSearch domain containing the endpoint for the data source.\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source')
    _init_params: typing.ClassVar[list[str]] = ['domain', 'service_role', 'api', 'description', 'name']
    _method_names: typing.ClassVar[list[str]] = ['create_function', 'create_resolver']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.OpenSearchDataSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.OpenSearchDataSourceDefConfig] = pydantic.Field(None)


class OpenSearchDataSourceDefConfig(pydantic.BaseModel):
    create_function: typing.Optional[list[models.aws_appsync.OpenSearchDataSourceDefCreateFunctionParams]] = pydantic.Field(None, description='creates a new appsync function for this datasource and API using the given properties.')
    create_resolver: typing.Optional[list[models.aws_appsync.OpenSearchDataSourceDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')
    grant_principal_config: typing.Optional[models._interface_methods.AwsIamIPrincipalDefConfig] = pydantic.Field(None)

class OpenSearchDataSourceDefCreateFunctionParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    name: str = pydantic.Field(..., description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    return_config: typing.Optional[list[models.aws_appsync.AppsyncFunctionDefConfig]] = pydantic.Field(None)
    ...

class OpenSearchDataSourceDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...


#  autogenerated from aws_cdk.aws_appsync.RdsDataSource
class RdsDataSourceDef(BaseConstruct):
    secret_store: typing.Union[_REQUIRED_INIT_PARAM, models.aws_docdb.DatabaseSecretDef, models.aws_rds.DatabaseSecretDef, models.aws_secretsmanager.SecretDef, models.aws_secretsmanager.SecretTargetAttachmentDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The secret containing the credentials for the database.\n')
    serverless_cluster: typing.Union[_REQUIRED_INIT_PARAM, models.aws_rds.ServerlessClusterDef, models.aws_rds.ServerlessClusterFromSnapshotDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The serverless cluster to call to interact with this data source.\n')
    database_name: typing.Optional[str] = pydantic.Field(None, description='The name of the database to use within the cluster. Default: - None\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source')
    _init_params: typing.ClassVar[list[str]] = ['secret_store', 'serverless_cluster', 'database_name', 'service_role', 'api', 'description', 'name']
    _method_names: typing.ClassVar[list[str]] = ['create_function', 'create_resolver']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.RdsDataSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.RdsDataSourceDefConfig] = pydantic.Field(None)


class RdsDataSourceDefConfig(pydantic.BaseModel):
    create_function: typing.Optional[list[models.aws_appsync.RdsDataSourceDefCreateFunctionParams]] = pydantic.Field(None, description='creates a new appsync function for this datasource and API using the given properties.')
    create_resolver: typing.Optional[list[models.aws_appsync.RdsDataSourceDefCreateResolverParams]] = pydantic.Field(None, description='creates a new resolver for this datasource and API using the given properties.')
    grant_principal_config: typing.Optional[models._interface_methods.AwsIamIPrincipalDefConfig] = pydantic.Field(None)

class RdsDataSourceDefCreateFunctionParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    name: str = pydantic.Field(..., description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    return_config: typing.Optional[list[models.aws_appsync.AppsyncFunctionDefConfig]] = pydantic.Field(None)
    ...

class RdsDataSourceDefCreateResolverParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    field_name: str = pydantic.Field(..., description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: str = pydantic.Field(..., description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    ...


#  autogenerated from aws_cdk.aws_appsync.Resolver
class ResolverDef(BaseConstruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API this resolver is attached to.\n')
    data_source: typing.Optional[models.aws_appsync.BaseDataSourceDef] = pydantic.Field(None, description='The data source this resolver is using. Default: - No datasource\n')
    field_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used')
    _init_params: typing.ClassVar[list[str]] = ['api', 'data_source', 'field_name', 'type_name', 'caching_config', 'code', 'max_batch_size', 'pipeline_config', 'request_mapping_template', 'response_mapping_template', 'runtime']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.Resolver'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.SourceApiAssociation
class SourceApiAssociationDef(BaseConstruct):
    merged_api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The merged api to associate.\n')
    merged_api_execution_role: typing.Union[_REQUIRED_INIT_PARAM, models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The merged api execution role for adding the access policy for the source api.\n')
    source_api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The source api to associate.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the source api association. Default: - None\n')
    merge_type: typing.Optional[aws_cdk.aws_appsync.MergeType] = pydantic.Field(None, description='The merge type for the source. Default: - AUTO_MERGE')
    _init_params: typing.ClassVar[list[str]] = ['merged_api', 'merged_api_execution_role', 'source_api', 'description', 'merge_type']
    _method_names: typing.ClassVar[list[str]] = ['apply_removal_policy']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_source_api_association_attributes']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.SourceApiAssociation'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_source_api_association_attributes']
    ...


    from_source_api_association_attributes: typing.Optional[models.aws_appsync.SourceApiAssociationDefFromSourceApiAssociationAttributesParams] = pydantic.Field(None, description='Import Appsync Source Api Association from source API, merged api, and merge type.')
    resource_config: typing.Optional[models.aws_appsync.SourceApiAssociationDefConfig] = pydantic.Field(None)


class SourceApiAssociationDefConfig(pydantic.BaseModel):
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    association_config: typing.Optional[models.aws_appsync.CfnSourceApiAssociationDefConfig] = pydantic.Field(None)
    merged_api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)
    source_api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)

class SourceApiAssociationDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class SourceApiAssociationDefFromSourceApiAssociationAttributesParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-\n')
    id: str = pydantic.Field(..., description='-\n')
    association_arn: str = pydantic.Field(..., description='The association arn.\n')
    merged_api: typing.Union[models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(..., description='The merged api in the association.\n')
    source_api: typing.Union[models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(..., description='The source api in the association.')
    ...


#  autogenerated from aws_cdk.aws_appsync.ApiKeyConfig
class ApiKeyConfigDef(BaseStruct):
    description: typing.Optional[str] = pydantic.Field(None, description="Description of API key. Default: - 'Default API Key created by CDK'\n")
    expires: typing.Optional[models.ExpirationDef] = pydantic.Field(None, description='The time from creation time after which the API key expires. It must be a minimum of 1 day and a maximum of 365 days from date of creation. Rounded down to the nearest hour. Default: - 7 days rounded down to nearest hour\n')
    name: typing.Optional[str] = pydantic.Field(None, description='Unique name of the API Key. Default: - \'DefaultAPIKey\'\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_appsync as appsync\n\n    # expiration: cdk.Expiration\n\n    api_key_config = appsync.ApiKeyConfig(\n        description="description",\n        expires=expiration,\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['description', 'expires', 'name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.ApiKeyConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.AppsyncFunctionAttributes
class AppsyncFunctionAttributesDef(BaseStruct):
    function_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='the ARN of the AppSync function.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    appsync_function_attributes = appsync.AppsyncFunctionAttributes(\n        function_arn="functionArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['function_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.AppsyncFunctionAttributes'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.AppsyncFunctionProps
class AppsyncFunctionPropsDef(BaseStruct):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used\n')
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='the GraphQL Api linked to this AppSync Function.\n')
    data_source: typing.Union[models.aws_appsync.BaseDataSourceDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='the data source linked to this AppSync Function.\n\n:exampleMetadata: infused\n\nExample::\n\n    # api: appsync.GraphqlApi\n\n\n    appsync_function = appsync.AppsyncFunction(self, "function",\n        name="appsync_function",\n        api=api,\n        data_source=api.add_none_data_source("none"),\n        request_mapping_template=appsync.MappingTemplate.from_file("request.vtl"),\n        response_mapping_template=appsync.MappingTemplate.from_file("response.vtl")\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'code', 'description', 'max_batch_size', 'request_mapping_template', 'response_mapping_template', 'runtime', 'api', 'data_source']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.AppsyncFunctionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.AppsyncFunctionPropsDefConfig] = pydantic.Field(None)


class AppsyncFunctionPropsDefConfig(pydantic.BaseModel):
    api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)
    data_source_config: typing.Optional[models.aws_appsync.BaseDataSourceDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.AuthorizationConfig
class AuthorizationConfigDef(BaseStruct):
    additional_authorization_modes: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AuthorizationModeDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Additional authorization modes. Default: - No other modes\n')
    default_authorization: typing.Union[models.aws_appsync.AuthorizationModeDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Optional authorization configuration. Default: - API Key authorization\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_appsync as appsync\n\n\n    api = appsync.GraphqlApi(self, "api",\n        name="api",\n        definition=appsync.Definition.from_file("schema.graphql"),\n        authorization_config=appsync.AuthorizationConfig(\n            default_authorization=appsync.AuthorizationMode(authorization_type=appsync.AuthorizationType.IAM)\n        )\n    )\n\n    rule = events.Rule(self, "Rule",\n        schedule=events.Schedule.rate(cdk.Duration.hours(1))\n    )\n\n    rule.add_target(targets.AppSync(api,\n        graph_qLOperation="mutation Publish($message: String!){ publish(message: $message) { message } }",\n        variables=events.RuleTargetInput.from_object({\n            "message": "hello world"\n        })\n    ))\n')
    _init_params: typing.ClassVar[list[str]] = ['additional_authorization_modes', 'default_authorization']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.AuthorizationConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.AuthorizationMode
class AuthorizationModeDef(BaseStruct):
    authorization_type: typing.Union[aws_cdk.aws_appsync.AuthorizationType, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='One of possible four values AppSync supports. Default: - ``AuthorizationType.API_KEY``\n')
    api_key_config: typing.Union[models.aws_appsync.ApiKeyConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description="If authorizationType is ``AuthorizationType.API_KEY``, this option can be configured. Default: - name: 'DefaultAPIKey' | description: 'Default API Key created by CDK'\n")
    lambda_authorizer_config: typing.Union[models.aws_appsync.LambdaAuthorizerConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='If authorizationType is ``AuthorizationType.LAMBDA``, this option is required. Default: - none\n')
    open_id_connect_config: typing.Union[models.aws_appsync.OpenIdConnectConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='If authorizationType is ``AuthorizationType.OIDC``, this option is required. Default: - none\n')
    user_pool_config: typing.Union[models.aws_appsync.UserPoolConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='If authorizationType is ``AuthorizationType.USER_POOL``, this option is required. Default: - none\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_appsync as appsync\n\n\n    api = appsync.GraphqlApi(self, "api",\n        name="api",\n        definition=appsync.Definition.from_file("schema.graphql"),\n        authorization_config=appsync.AuthorizationConfig(\n            default_authorization=appsync.AuthorizationMode(authorization_type=appsync.AuthorizationType.IAM)\n        )\n    )\n\n    rule = events.Rule(self, "Rule",\n        schedule=events.Schedule.rate(cdk.Duration.hours(1))\n    )\n\n    rule.add_target(targets.AppSync(api,\n        graph_qLOperation="mutation Publish($message: String!){ publish(message: $message) { message } }",\n        variables=events.RuleTargetInput.from_object({\n            "message": "hello world"\n        })\n    ))\n')
    _init_params: typing.ClassVar[list[str]] = ['authorization_type', 'api_key_config', 'lambda_authorizer_config', 'open_id_connect_config', 'user_pool_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.AuthorizationMode'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.AwsIamConfig
class AwsIamConfigDef(BaseStruct):
    signing_region: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The signing region for AWS IAM authorization.\n')
    signing_service_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The signing service name for AWS IAM authorization.\n\n:exampleMetadata: infused\n\nExample::\n\n    api = appsync.GraphqlApi(self, "api",\n        name="api",\n        definition=appsync.Definition.from_file(path.join(__dirname, "schema.graphql"))\n    )\n\n    http_ds = api.add_http_data_source("ds", "https://states.amazonaws.com",\n        name="httpDsWithStepF",\n        description="from appsync to StepFunctions Workflow",\n        authorization_config=appsync.AwsIamConfig(\n            signing_region="us-east-1",\n            signing_service_name="states"\n        )\n    )\n\n    http_ds.create_resolver("MutationCallStepFunctionResolver",\n        type_name="Mutation",\n        field_name="callStepFunction",\n        request_mapping_template=appsync.MappingTemplate.from_file("request.vtl"),\n        response_mapping_template=appsync.MappingTemplate.from_file("response.vtl")\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['signing_region', 'signing_service_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.AwsIamConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.BackedDataSourceProps
class BackedDataSourcePropsDef(BaseStruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n    from aws_cdk import aws_iam as iam\n\n    # graphql_api: appsync.GraphqlApi\n    # role: iam.Role\n\n    backed_data_source_props = appsync.BackedDataSourceProps(\n        api=graphql_api,\n\n        # the properties below are optional\n        description="description",\n        name="name",\n        service_role=role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name', 'service_role']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.BackedDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.BackedDataSourcePropsDefConfig] = pydantic.Field(None)


class BackedDataSourcePropsDefConfig(pydantic.BaseModel):
    api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.BaseAppsyncFunctionProps
class BaseAppsyncFunctionPropsDef(BaseStruct):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='the name of the AppSync Function.\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description for this AppSync Function. Default: - no description\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a BatchInvoke operation. Can only be set when using LambdaDataSource. Default: - No max batch size\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the request mapping template for the AppSync Function. Default: - no request mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='the response mapping template for the AppSync Function. Default: - no response mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    # code: appsync.Code\n    # function_runtime: appsync.FunctionRuntime\n    # mapping_template: appsync.MappingTemplate\n\n    base_appsync_function_props = appsync.BaseAppsyncFunctionProps(\n        name="name",\n\n        # the properties below are optional\n        code=code,\n        description="description",\n        max_batch_size=123,\n        request_mapping_template=mapping_template,\n        response_mapping_template=mapping_template,\n        runtime=function_runtime\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'code', 'description', 'max_batch_size', 'request_mapping_template', 'response_mapping_template', 'runtime']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.BaseAppsyncFunctionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.BaseDataSourceProps
class BaseDataSourcePropsDef(BaseStruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    # graphql_api: appsync.GraphqlApi\n\n    base_data_source_props = appsync.BaseDataSourceProps(\n        api=graphql_api,\n\n        # the properties below are optional\n        description="description",\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.BaseDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.BaseResolverProps
class BaseResolverPropsDef(BaseStruct):
    field_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used\n\n:exampleMetadata: infused\n\nExample::\n\n    # Build a data source for AppSync to access the database.\n    # api: appsync.GraphqlApi\n    # Create username and password secret for DB Cluster\n    secret = rds.DatabaseSecret(self, "AuroraSecret",\n        username="clusteradmin"\n    )\n\n    # The VPC to place the cluster in\n    vpc = ec2.Vpc(self, "AuroraVpc")\n\n    # Create the serverless cluster, provide all values needed to customise the database.\n    cluster = rds.ServerlessCluster(self, "AuroraCluster",\n        engine=rds.DatabaseClusterEngine.AURORA_MYSQL,\n        vpc=vpc,\n        credentials={"username": "clusteradmin"},\n        cluster_identifier="db-endpoint-test",\n        default_database_name="demos"\n    )\n    rds_dS = api.add_rds_data_source("rds", cluster, secret, "demos")\n\n    # Set up a resolver for an RDS query.\n    rds_dS.create_resolver("QueryGetDemosRdsResolver",\n        type_name="Query",\n        field_name="getDemosRds",\n        request_mapping_template=appsync.MappingTemplate.from_string("""\n              {\n                "version": "2018-05-29",\n                "statements": [\n                  "SELECT * FROM demos"\n                ]\n              }\n              """),\n        response_mapping_template=appsync.MappingTemplate.from_string("""\n                $utils.toJson($utils.rds.toJsonObject($ctx.result)[0])\n              """)\n    )\n\n    # Set up a resolver for an RDS mutation.\n    rds_dS.create_resolver("MutationAddDemoRdsResolver",\n        type_name="Mutation",\n        field_name="addDemoRds",\n        request_mapping_template=appsync.MappingTemplate.from_string("""\n              {\n                "version": "2018-05-29",\n                "statements": [\n                  "INSERT INTO demos VALUES (:id, :version)",\n                  "SELECT * WHERE id = :id"\n                ],\n                "variableMap": {\n                  ":id": $util.toJson($util.autoId()),\n                  ":version": $util.toJson($ctx.args.version)\n                }\n              }\n              """),\n        response_mapping_template=appsync.MappingTemplate.from_string("""\n                $utils.toJson($utils.rds.toJsonObject($ctx.result)[1][0])\n              """)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['field_name', 'type_name', 'caching_config', 'code', 'max_batch_size', 'pipeline_config', 'request_mapping_template', 'response_mapping_template', 'runtime']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.BaseResolverProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CachingConfig
class CachingConfigDef(BaseStruct):
    ttl: typing.Union[models.DurationDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The TTL in seconds for a resolver that has caching enabled. Valid values are between 1 and 3600 seconds.\n')
    caching_keys: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The caching keys for a resolver that has caching enabled. Valid values are entries from the $context.arguments, $context.source, and $context.identity maps. Default: - No caching keys\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_appsync as appsync\n\n    caching_config = appsync.CachingConfig(\n        ttl=cdk.Duration.minutes(30),\n\n        # the properties below are optional\n        caching_keys=["cachingKeys"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['ttl', 'caching_keys']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CachingConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.CachingConfigDefConfig] = pydantic.Field(None)


class CachingConfigDefConfig(pydantic.BaseModel):
    ttl_config: typing.Optional[models.core.DurationDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.CfnDataSource.AuthorizationConfigProperty
class CfnDataSource_AuthorizationConfigPropertyDef(BaseStruct):
    authorization_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The authorization type that the HTTP endpoint requires. - *AWS_IAM* : The authorization type is Signature Version 4 (SigV4).\n')
    aws_iam_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_AwsIamConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The AWS Identity and Access Management settings.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-datasource-authorizationconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    authorization_config_property = appsync.CfnDataSource.AuthorizationConfigProperty(\n        authorization_type="authorizationType",\n\n        # the properties below are optional\n        aws_iam_config=appsync.CfnDataSource.AwsIamConfigProperty(\n            signing_region="signingRegion",\n            signing_service_name="signingServiceName"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['authorization_type', 'aws_iam_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource.AuthorizationConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDataSource.AwsIamConfigProperty
class CfnDataSource_AwsIamConfigPropertyDef(BaseStruct):
    signing_region: typing.Optional[str] = pydantic.Field(None, description='The signing Region for AWS Identity and Access Management authorization.\n')
    signing_service_name: typing.Optional[str] = pydantic.Field(None, description='The signing service name for AWS Identity and Access Management authorization.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-datasource-awsiamconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    aws_iam_config_property = appsync.CfnDataSource.AwsIamConfigProperty(\n        signing_region="signingRegion",\n        signing_service_name="signingServiceName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['signing_region', 'signing_service_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource.AwsIamConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDataSource.DeltaSyncConfigProperty
class CfnDataSource_DeltaSyncConfigPropertyDef(BaseStruct):
    base_table_ttl: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The number of minutes that an Item is stored in the data source.\n')
    delta_sync_table_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Delta Sync table name.\n')
    delta_sync_table_ttl: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The number of minutes that a Delta Sync log entry is stored in the Delta Sync table.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-datasource-deltasyncconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    delta_sync_config_property = appsync.CfnDataSource.DeltaSyncConfigProperty(\n        base_table_ttl="baseTableTtl",\n        delta_sync_table_name="deltaSyncTableName",\n        delta_sync_table_ttl="deltaSyncTableTtl"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['base_table_ttl', 'delta_sync_table_name', 'delta_sync_table_ttl']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource.DeltaSyncConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDataSource.DynamoDBConfigProperty
class CfnDataSource_DynamoDBConfigPropertyDef(BaseStruct):
    aws_region: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS Region.\n')
    table_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The table name.\n')
    delta_sync_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_DeltaSyncConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The ``DeltaSyncConfig`` for a versioned datasource.\n')
    use_caller_credentials: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Set to ``TRUE`` to use AWS Identity and Access Management with this data source.\n')
    versioned: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Set to TRUE to use Conflict Detection and Resolution with this data source.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-datasource-dynamodbconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    dynamo_dBConfig_property = appsync.CfnDataSource.DynamoDBConfigProperty(\n        aws_region="awsRegion",\n        table_name="tableName",\n\n        # the properties below are optional\n        delta_sync_config=appsync.CfnDataSource.DeltaSyncConfigProperty(\n            base_table_ttl="baseTableTtl",\n            delta_sync_table_name="deltaSyncTableName",\n            delta_sync_table_ttl="deltaSyncTableTtl"\n        ),\n        use_caller_credentials=False,\n        versioned=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['aws_region', 'table_name', 'delta_sync_config', 'use_caller_credentials', 'versioned']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource.DynamoDBConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDataSource.ElasticsearchConfigProperty
class CfnDataSource_ElasticsearchConfigPropertyDef(BaseStruct):
    aws_region: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS Region.\n')
    endpoint: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The endpoint.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-datasource-elasticsearchconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    elasticsearch_config_property = appsync.CfnDataSource.ElasticsearchConfigProperty(\n        aws_region="awsRegion",\n        endpoint="endpoint"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['aws_region', 'endpoint']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource.ElasticsearchConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDataSource.EventBridgeConfigProperty
class CfnDataSource_EventBridgeConfigPropertyDef(BaseStruct):
    event_bus_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The event bus pipeline\'s ARN. For more information about event buses, see `EventBridge event buses <https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-event-bus.html>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-datasource-eventbridgeconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    event_bridge_config_property = appsync.CfnDataSource.EventBridgeConfigProperty(\n        event_bus_arn="eventBusArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['event_bus_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource.EventBridgeConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDataSource.HttpConfigProperty
class CfnDataSource_HttpConfigPropertyDef(BaseStruct):
    endpoint: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The endpoint.\n')
    authorization_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_AuthorizationConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The authorization configuration.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-datasource-httpconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    http_config_property = appsync.CfnDataSource.HttpConfigProperty(\n        endpoint="endpoint",\n\n        # the properties below are optional\n        authorization_config=appsync.CfnDataSource.AuthorizationConfigProperty(\n            authorization_type="authorizationType",\n\n            # the properties below are optional\n            aws_iam_config=appsync.CfnDataSource.AwsIamConfigProperty(\n                signing_region="signingRegion",\n                signing_service_name="signingServiceName"\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['endpoint', 'authorization_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource.HttpConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDataSource.LambdaConfigProperty
class CfnDataSource_LambdaConfigPropertyDef(BaseStruct):
    lambda_function_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN for the Lambda function.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-datasource-lambdaconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    lambda_config_property = appsync.CfnDataSource.LambdaConfigProperty(\n        lambda_function_arn="lambdaFunctionArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['lambda_function_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource.LambdaConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDataSource.OpenSearchServiceConfigProperty
class CfnDataSource_OpenSearchServiceConfigPropertyDef(BaseStruct):
    aws_region: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS Region.\n')
    endpoint: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The endpoint.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-datasource-opensearchserviceconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    open_search_service_config_property = appsync.CfnDataSource.OpenSearchServiceConfigProperty(\n        aws_region="awsRegion",\n        endpoint="endpoint"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['aws_region', 'endpoint']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource.OpenSearchServiceConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDataSource.RdsHttpEndpointConfigProperty
class CfnDataSource_RdsHttpEndpointConfigPropertyDef(BaseStruct):
    aws_region: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='AWS Region for RDS HTTP endpoint.\n')
    aws_secret_store_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN for database credentials stored in AWS Secrets Manager .\n')
    db_cluster_identifier: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Amazon RDS cluster Amazon Resource Name (ARN).\n')
    database_name: typing.Optional[str] = pydantic.Field(None, description='Logical database name.\n')
    schema_: typing.Optional[str] = pydantic.Field(None, description='Logical schema name.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-datasource-rdshttpendpointconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    rds_http_endpoint_config_property = appsync.CfnDataSource.RdsHttpEndpointConfigProperty(\n        aws_region="awsRegion",\n        aws_secret_store_arn="awsSecretStoreArn",\n        db_cluster_identifier="dbClusterIdentifier",\n\n        # the properties below are optional\n        database_name="databaseName",\n        schema="schema"\n    )\n', alias='schema')
    _init_params: typing.ClassVar[list[str]] = ['aws_region', 'aws_secret_store_arn', 'db_cluster_identifier', 'database_name', 'schema']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource.RdsHttpEndpointConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDataSource.RelationalDatabaseConfigProperty
class CfnDataSource_RelationalDatabaseConfigPropertyDef(BaseStruct):
    relational_database_source_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of relational data source.\n')
    rds_http_endpoint_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_RdsHttpEndpointConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Information about the Amazon RDS resource.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-datasource-relationaldatabaseconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    relational_database_config_property = appsync.CfnDataSource.RelationalDatabaseConfigProperty(\n        relational_database_source_type="relationalDatabaseSourceType",\n\n        # the properties below are optional\n        rds_http_endpoint_config=appsync.CfnDataSource.RdsHttpEndpointConfigProperty(\n            aws_region="awsRegion",\n            aws_secret_store_arn="awsSecretStoreArn",\n            db_cluster_identifier="dbClusterIdentifier",\n\n            # the properties below are optional\n            database_name="databaseName",\n            schema="schema"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['relational_database_source_type', 'rds_http_endpoint_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource.RelationalDatabaseConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnFunctionConfiguration.AppSyncRuntimeProperty
class CfnFunctionConfiguration_AppSyncRuntimePropertyDef(BaseStruct):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ``name`` of the runtime to use. Currently, the only allowed value is ``APPSYNC_JS`` .\n')
    runtime_version: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ``version`` of the runtime to use. Currently, the only allowed version is ``1.0.0`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-functionconfiguration-appsyncruntime.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    app_sync_runtime_property = appsync.CfnFunctionConfiguration.AppSyncRuntimeProperty(\n        name="name",\n        runtime_version="runtimeVersion"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'runtime_version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnFunctionConfiguration.AppSyncRuntimeProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnFunctionConfiguration.LambdaConflictHandlerConfigProperty
class CfnFunctionConfiguration_LambdaConflictHandlerConfigPropertyDef(BaseStruct):
    lambda_conflict_handler_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) for the Lambda function to use as the Conflict Handler.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-functionconfiguration-lambdaconflicthandlerconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    lambda_conflict_handler_config_property = appsync.CfnFunctionConfiguration.LambdaConflictHandlerConfigProperty(\n        lambda_conflict_handler_arn="lambdaConflictHandlerArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['lambda_conflict_handler_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnFunctionConfiguration.LambdaConflictHandlerConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnFunctionConfiguration.SyncConfigProperty
class CfnFunctionConfiguration_SyncConfigPropertyDef(BaseStruct):
    conflict_detection: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Conflict Detection strategy to use. - *VERSION* : Detect conflicts based on object versions for this resolver. - *NONE* : Do not detect conflicts when invoking this resolver.\n')
    conflict_handler: typing.Optional[str] = pydantic.Field(None, description="The Conflict Resolution strategy to perform in the event of a conflict. - *OPTIMISTIC_CONCURRENCY* : Resolve conflicts by rejecting mutations when versions don't match the latest version at the server. - *AUTOMERGE* : Resolve conflicts with the Automerge conflict resolution strategy. - *LAMBDA* : Resolve conflicts with an AWS Lambda function supplied in the ``LambdaConflictHandlerConfig`` .\n")
    lambda_conflict_handler_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnFunctionConfiguration_LambdaConflictHandlerConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The ``LambdaConflictHandlerConfig`` when configuring ``LAMBDA`` as the Conflict Handler.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-functionconfiguration-syncconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    sync_config_property = appsync.CfnFunctionConfiguration.SyncConfigProperty(\n        conflict_detection="conflictDetection",\n\n        # the properties below are optional\n        conflict_handler="conflictHandler",\n        lambda_conflict_handler_config=appsync.CfnFunctionConfiguration.LambdaConflictHandlerConfigProperty(\n            lambda_conflict_handler_arn="lambdaConflictHandlerArn"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['conflict_detection', 'conflict_handler', 'lambda_conflict_handler_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnFunctionConfiguration.SyncConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnGraphQLApi.AdditionalAuthenticationProviderProperty
class CfnGraphQLApi_AdditionalAuthenticationProviderPropertyDef(BaseStruct):
    authentication_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The authentication type for API key, AWS Identity and Access Management , OIDC, Amazon Cognito user pools , or AWS Lambda . Valid Values: ``API_KEY`` | ``AWS_IAM`` | ``OPENID_CONNECT`` | ``AMAZON_COGNITO_USER_POOLS`` | ``AWS_LAMBDA``\n')
    lambda_authorizer_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_LambdaAuthorizerConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configuration for AWS Lambda function authorization.\n')
    open_id_connect_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_OpenIDConnectConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The OIDC configuration.\n')
    user_pool_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_CognitoUserPoolConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Amazon Cognito user pool configuration.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-graphqlapi-additionalauthenticationprovider.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    additional_authentication_provider_property = appsync.CfnGraphQLApi.AdditionalAuthenticationProviderProperty(\n        authentication_type="authenticationType",\n\n        # the properties below are optional\n        lambda_authorizer_config=appsync.CfnGraphQLApi.LambdaAuthorizerConfigProperty(\n            authorizer_result_ttl_in_seconds=123,\n            authorizer_uri="authorizerUri",\n            identity_validation_expression="identityValidationExpression"\n        ),\n        open_id_connect_config=appsync.CfnGraphQLApi.OpenIDConnectConfigProperty(\n            auth_ttl=123,\n            client_id="clientId",\n            iat_ttl=123,\n            issuer="issuer"\n        ),\n        user_pool_config=appsync.CfnGraphQLApi.CognitoUserPoolConfigProperty(\n            app_id_client_regex="appIdClientRegex",\n            aws_region="awsRegion",\n            user_pool_id="userPoolId"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['authentication_type', 'lambda_authorizer_config', 'open_id_connect_config', 'user_pool_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnGraphQLApi.AdditionalAuthenticationProviderProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnGraphQLApi.CognitoUserPoolConfigProperty
class CfnGraphQLApi_CognitoUserPoolConfigPropertyDef(BaseStruct):
    app_id_client_regex: typing.Optional[str] = pydantic.Field(None, description="A regular expression for validating the incoming Amazon Cognito user pool app client ID. If this value isn't set, no filtering is applied.\n")
    aws_region: typing.Optional[str] = pydantic.Field(None, description='The AWS Region in which the user pool was created.\n')
    user_pool_id: typing.Optional[str] = pydantic.Field(None, description='The user pool ID.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-graphqlapi-cognitouserpoolconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    cognito_user_pool_config_property = appsync.CfnGraphQLApi.CognitoUserPoolConfigProperty(\n        app_id_client_regex="appIdClientRegex",\n        aws_region="awsRegion",\n        user_pool_id="userPoolId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['app_id_client_regex', 'aws_region', 'user_pool_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnGraphQLApi.CognitoUserPoolConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnGraphQLApi.EnhancedMetricsConfigProperty
class CfnGraphQLApi_EnhancedMetricsConfigPropertyDef(BaseStruct):
    data_source_level_metrics_behavior: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Controls how data source metrics will be emitted to CloudWatch. Data source metrics include:. - *Requests* : The number of invocations that occured during a request. - *Latency* : The time to complete a data source invocation. - *Errors* : The number of errors that occurred during a data source invocation. These metrics can be emitted to CloudWatch per data source or for all data sources in the request. Metrics will be recorded by API ID and data source name. ``dataSourceLevelMetricsBehavior`` accepts one of these values at a time: - ``FULL_REQUEST_DATA_SOURCE_METRICS`` : Records and emits metric data for all data sources in the request. - ``PER_DATA_SOURCE_METRICS`` : Records and emits metric data for data sources that have the ``MetricsConfig`` value set to ``ENABLED`` .\n')
    operation_level_metrics_config: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Controls how operation metrics will be emitted to CloudWatch. Operation metrics include:. - *Requests* : The number of times a specified GraphQL operation was called. - *GraphQL errors* : The number of GraphQL errors that occurred during a specified GraphQL operation. Metrics will be recorded by API ID and operation name. You can set the value to ``ENABLED`` or ``DISABLED`` .\n')
    resolver_level_metrics_behavior: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Controls how resolver metrics will be emitted to CloudWatch. Resolver metrics include:. - *GraphQL errors* : The number of GraphQL errors that occurred. - *Requests* : The number of invocations that occurred during a request. - *Latency* : The time to complete a resolver invocation. - *Cache hits* : The number of cache hits during a request. - *Cache misses* : The number of cache misses during a request. These metrics can be emitted to CloudWatch per resolver or for all resolvers in the request. Metrics will be recorded by API ID and resolver name. ``resolverLevelMetricsBehavior`` accepts one of these values at a time: - ``FULL_REQUEST_RESOLVER_METRICS`` : Records and emits metric data for all resolvers in the request. - ``PER_RESOLVER_METRICS`` : Records and emits metric data for resolvers that have the ``MetricsConfig`` value set to ``ENABLED`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-graphqlapi-enhancedmetricsconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    enhanced_metrics_config_property = appsync.CfnGraphQLApi.EnhancedMetricsConfigProperty(\n        data_source_level_metrics_behavior="dataSourceLevelMetricsBehavior",\n        operation_level_metrics_config="operationLevelMetricsConfig",\n        resolver_level_metrics_behavior="resolverLevelMetricsBehavior"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['data_source_level_metrics_behavior', 'operation_level_metrics_config', 'resolver_level_metrics_behavior']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnGraphQLApi.EnhancedMetricsConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnGraphQLApi.LambdaAuthorizerConfigProperty
class CfnGraphQLApi_LambdaAuthorizerConfigPropertyDef(BaseStruct):
    authorizer_result_ttl_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description="The number of seconds a response should be cached for. The default is 0 seconds, which disables caching. If you don't specify a value for ``authorizerResultTtlInSeconds`` , the default value is used. The maximum value is one hour (3600 seconds). The Lambda function can override this by returning a ``ttlOverride`` key in its response.\n")
    authorizer_uri: typing.Optional[str] = pydantic.Field(None, description='The ARN of the Lambda function to be called for authorization. This may be a standard Lambda ARN, a version ARN ( ``.../v3`` ) or alias ARN. *Note* : This Lambda function must have the following resource-based policy assigned to it. When configuring Lambda authorizers in the console, this is done for you. To do so with the AWS CLI , run the following: ``aws lambda add-permission --function-name "arn:aws:lambda:us-east-2:111122223333:function:my-function" --statement-id "appsync" --principal appsync.amazonaws.com --action lambda:InvokeFunction``\n')
    identity_validation_expression: typing.Optional[str] = pydantic.Field(None, description='A regular expression for validation of tokens before the Lambda function is called.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-graphqlapi-lambdaauthorizerconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    lambda_authorizer_config_property = appsync.CfnGraphQLApi.LambdaAuthorizerConfigProperty(\n        authorizer_result_ttl_in_seconds=123,\n        authorizer_uri="authorizerUri",\n        identity_validation_expression="identityValidationExpression"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['authorizer_result_ttl_in_seconds', 'authorizer_uri', 'identity_validation_expression']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnGraphQLApi.LambdaAuthorizerConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnGraphQLApi.LogConfigProperty
class CfnGraphQLApi_LogConfigPropertyDef(BaseStruct):
    cloud_watch_logs_role_arn: typing.Optional[str] = pydantic.Field(None, description='The service role that AWS AppSync will assume to publish to Amazon CloudWatch Logs in your account.\n')
    exclude_verbose_content: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Set to TRUE to exclude sections that contain information such as headers, context, and evaluated mapping templates, regardless of logging level.\n')
    field_log_level: typing.Optional[str] = pydantic.Field(None, description='The field logging level. Values can be NONE, ERROR, or ALL. - *NONE* : No field-level logs are captured. - *ERROR* : Logs the following information only for the fields that are in error: - The error section in the server response. - Field-level errors. - The generated request/response functions that got resolved for error fields. - *ALL* : The following information is logged for all fields in the query: - Field-level tracing information. - The generated request/response functions that got resolved for each field.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-graphqlapi-logconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    log_config_property = appsync.CfnGraphQLApi.LogConfigProperty(\n        cloud_watch_logs_role_arn="cloudWatchLogsRoleArn",\n        exclude_verbose_content=False,\n        field_log_level="fieldLogLevel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cloud_watch_logs_role_arn', 'exclude_verbose_content', 'field_log_level']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnGraphQLApi.LogConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnGraphQLApi.OpenIDConnectConfigProperty
class CfnGraphQLApi_OpenIDConnectConfigPropertyDef(BaseStruct):
    auth_ttl: typing.Union[int, float, None] = pydantic.Field(None, description='The number of milliseconds that a token is valid after being authenticated.\n')
    client_id: typing.Optional[str] = pydantic.Field(None, description='The client identifier of the Relying party at the OpenID identity provider. This identifier is typically obtained when the Relying party is registered with the OpenID identity provider. You can specify a regular expression so that AWS AppSync can validate against multiple client identifiers at a time.\n')
    iat_ttl: typing.Union[int, float, None] = pydantic.Field(None, description="The number of milliseconds that a token is valid after it's issued to a user.\n")
    issuer: typing.Optional[str] = pydantic.Field(None, description='The issuer for the OIDC configuration. The issuer returned by discovery must exactly match the value of ``iss`` in the ID token.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-graphqlapi-openidconnectconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    open_iDConnect_config_property = appsync.CfnGraphQLApi.OpenIDConnectConfigProperty(\n        auth_ttl=123,\n        client_id="clientId",\n        iat_ttl=123,\n        issuer="issuer"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['auth_ttl', 'client_id', 'iat_ttl', 'issuer']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnGraphQLApi.OpenIDConnectConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnGraphQLApi.UserPoolConfigProperty
class CfnGraphQLApi_UserPoolConfigPropertyDef(BaseStruct):
    app_id_client_regex: typing.Optional[str] = pydantic.Field(None, description="A regular expression for validating the incoming Amazon Cognito user pool app client ID. If this value isn't set, no filtering is applied.\n")
    aws_region: typing.Optional[str] = pydantic.Field(None, description='The AWS Region in which the user pool was created.\n')
    default_action: typing.Optional[str] = pydantic.Field(None, description="The action that you want your GraphQL API to take when a request that uses Amazon Cognito user pool authentication doesn't match the Amazon Cognito user pool configuration. When specifying Amazon Cognito user pools as the default authentication, you must set the value for ``DefaultAction`` to ``ALLOW`` if specifying ``AdditionalAuthenticationProviders`` .\n")
    user_pool_id: typing.Optional[str] = pydantic.Field(None, description='The user pool ID.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-graphqlapi-userpoolconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    user_pool_config_property = appsync.CfnGraphQLApi.UserPoolConfigProperty(\n        app_id_client_regex="appIdClientRegex",\n        aws_region="awsRegion",\n        default_action="defaultAction",\n        user_pool_id="userPoolId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['app_id_client_regex', 'aws_region', 'default_action', 'user_pool_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnGraphQLApi.UserPoolConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnResolver.AppSyncRuntimeProperty
class CfnResolver_AppSyncRuntimePropertyDef(BaseStruct):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ``name`` of the runtime to use. Currently, the only allowed value is ``APPSYNC_JS`` .\n')
    runtime_version: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ``version`` of the runtime to use. Currently, the only allowed version is ``1.0.0`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-resolver-appsyncruntime.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    app_sync_runtime_property = appsync.CfnResolver.AppSyncRuntimeProperty(\n        name="name",\n        runtime_version="runtimeVersion"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'runtime_version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnResolver.AppSyncRuntimeProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnResolver.CachingConfigProperty
class CfnResolver_CachingConfigPropertyDef(BaseStruct):
    ttl: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The TTL in seconds for a resolver that has caching activated. Valid values are 1–3,600 seconds.\n')
    caching_keys: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The caching keys for a resolver that has caching activated. Valid values are entries from the ``$context.arguments`` , ``$context.source`` , and ``$context.identity`` maps.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-resolver-cachingconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    caching_config_property = appsync.CfnResolver.CachingConfigProperty(\n        ttl=123,\n\n        # the properties below are optional\n        caching_keys=["cachingKeys"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['ttl', 'caching_keys']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnResolver.CachingConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnResolver.LambdaConflictHandlerConfigProperty
class CfnResolver_LambdaConflictHandlerConfigPropertyDef(BaseStruct):
    lambda_conflict_handler_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) for the Lambda function to use as the Conflict Handler.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-resolver-lambdaconflicthandlerconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    lambda_conflict_handler_config_property = appsync.CfnResolver.LambdaConflictHandlerConfigProperty(\n        lambda_conflict_handler_arn="lambdaConflictHandlerArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['lambda_conflict_handler_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnResolver.LambdaConflictHandlerConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnResolver.PipelineConfigProperty
class CfnResolver_PipelineConfigPropertyDef(BaseStruct):
    functions: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of ``Function`` objects.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-resolver-pipelineconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    pipeline_config_property = appsync.CfnResolver.PipelineConfigProperty(\n        functions=["functions"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['functions']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnResolver.PipelineConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnResolver.SyncConfigProperty
class CfnResolver_SyncConfigPropertyDef(BaseStruct):
    conflict_detection: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Conflict Detection strategy to use. - *VERSION* : Detect conflicts based on object versions for this resolver. - *NONE* : Do not detect conflicts when invoking this resolver.\n')
    conflict_handler: typing.Optional[str] = pydantic.Field(None, description="The Conflict Resolution strategy to perform in the event of a conflict. - *OPTIMISTIC_CONCURRENCY* : Resolve conflicts by rejecting mutations when versions don't match the latest version at the server. - *AUTOMERGE* : Resolve conflicts with the Automerge conflict resolution strategy. - *LAMBDA* : Resolve conflicts with an AWS Lambda function supplied in the ``LambdaConflictHandlerConfig`` .\n")
    lambda_conflict_handler_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnResolver_LambdaConflictHandlerConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The ``LambdaConflictHandlerConfig`` when configuring ``LAMBDA`` as the Conflict Handler.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-resolver-syncconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    sync_config_property = appsync.CfnResolver.SyncConfigProperty(\n        conflict_detection="conflictDetection",\n\n        # the properties below are optional\n        conflict_handler="conflictHandler",\n        lambda_conflict_handler_config=appsync.CfnResolver.LambdaConflictHandlerConfigProperty(\n            lambda_conflict_handler_arn="lambdaConflictHandlerArn"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['conflict_detection', 'conflict_handler', 'lambda_conflict_handler_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnResolver.SyncConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnSourceApiAssociation.SourceApiAssociationConfigProperty
class CfnSourceApiAssociation_SourceApiAssociationConfigPropertyDef(BaseStruct):
    merge_type: typing.Optional[str] = pydantic.Field(None, description='The property that indicates which merging option is enabled in the source API association. Valid merge types are ``MANUAL_MERGE`` (default) and ``AUTO_MERGE`` . Manual merges are the default behavior and require the user to trigger any changes from the source APIs to the merged API manually. Auto merges subscribe the merged API to the changes performed on the source APIs so that any change in the source APIs are also made to the merged API. Auto merges use ``MergedApiExecutionRoleArn`` to perform merge operations. The following values are valid: ``MANUAL_MERGE | AUTO_MERGE``\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-appsync-sourceapiassociation-sourceapiassociationconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    source_api_association_config_property = appsync.CfnSourceApiAssociation.SourceApiAssociationConfigProperty(\n        merge_type="mergeType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['merge_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnSourceApiAssociation.SourceApiAssociationConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CodeConfig
class CodeConfigDef(BaseStruct):
    inline_code: typing.Optional[str] = pydantic.Field(None, description='Inline code (mutually exclusive with ``s3Location``). Default: - code is not inline code\n')
    s3_location: typing.Optional[str] = pydantic.Field(None, description='The location of the code in S3 (mutually exclusive with ``inlineCode``. Default: - code is not an s3 location\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    code_config = appsync.CodeConfig(\n        inline_code="inlineCode",\n        s3_location="s3Location"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['inline_code', 's3_location']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CodeConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.DataSourceOptions
class DataSourceOptionsDef(BaseStruct):
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    data_source_options = appsync.DataSourceOptions(\n        description="description",\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['description', 'name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.DataSourceOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.DomainOptions
class DomainOptionsDef(BaseStruct):
    certificate: typing.Union[_REQUIRED_INIT_PARAM, models.aws_certificatemanager.CertificateDef, models.aws_certificatemanager.DnsValidatedCertificateDef, models.aws_certificatemanager.PrivateCertificateDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The certificate to use with the domain name.\n')
    domain_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The actual domain name. For example, ``api.example.com``.\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_certificatemanager as acm\n    import aws_cdk.aws_route53 as route53\n\n    # hosted zone and route53 features\n    # hosted_zone_id: str\n    zone_name = "example.com"\n\n\n    my_domain_name = "api.example.com"\n    certificate = acm.Certificate(self, "cert", domain_name=my_domain_name)\n    schema = appsync.SchemaFile(file_path="mySchemaFile")\n    api = appsync.GraphqlApi(self, "api",\n        name="myApi",\n        definition=appsync.Definition.from_schema(schema),\n        domain_name=appsync.DomainOptions(\n            certificate=certificate,\n            domain_name=my_domain_name\n        )\n    )\n\n    # hosted zone for adding appsync domain\n    zone = route53.HostedZone.from_hosted_zone_attributes(self, "HostedZone",\n        hosted_zone_id=hosted_zone_id,\n        zone_name=zone_name\n    )\n\n    # create a cname to the appsync domain. will map to something like xxxx.cloudfront.net\n    route53.CnameRecord(self, "CnameApiRecord",\n        record_name="api",\n        zone=zone,\n        domain_name=api.app_sync_domain_name\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['certificate', 'domain_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.DomainOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.DomainOptionsDefConfig] = pydantic.Field(None)


class DomainOptionsDefConfig(pydantic.BaseModel):
    certificate_config: typing.Optional[models._interface_methods.AwsCertificatemanagerICertificateDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.DynamoDbDataSourceProps
class DynamoDbDataSourcePropsDef(BaseStruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    table: typing.Union[_REQUIRED_INIT_PARAM, models.aws_dynamodb.TableBaseDef, models.aws_dynamodb.TableDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The DynamoDB table backing this data source.\n')
    read_only_access: typing.Optional[bool] = pydantic.Field(None, description='Specify whether this DS is read only or has read and write permissions to the DynamoDB table. Default: false\n')
    use_caller_credentials: typing.Optional[bool] = pydantic.Field(None, description='use credentials of caller to access DynamoDB. Default: false\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n    from aws_cdk import aws_dynamodb as dynamodb\n    from aws_cdk import aws_iam as iam\n\n    # graphql_api: appsync.GraphqlApi\n    # role: iam.Role\n    # table: dynamodb.Table\n\n    dynamo_db_data_source_props = appsync.DynamoDbDataSourceProps(\n        api=graphql_api,\n        table=table,\n\n        # the properties below are optional\n        description="description",\n        name="name",\n        read_only_access=False,\n        service_role=role,\n        use_caller_credentials=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name', 'service_role', 'table', 'read_only_access', 'use_caller_credentials']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.DynamoDbDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.DynamoDbDataSourcePropsDefConfig] = pydantic.Field(None)


class DynamoDbDataSourcePropsDefConfig(pydantic.BaseModel):
    api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)
    table_config: typing.Optional[models._interface_methods.AwsDynamodbITableDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.ElasticsearchDataSourceProps
class ElasticsearchDataSourcePropsDef(BaseStruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    domain: typing.Union[_REQUIRED_INIT_PARAM, models.aws_elasticsearch.DomainDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='(deprecated) The elasticsearch domain containing the endpoint for the data source.\n\n:deprecated: - use ``OpenSearchDataSourceProps`` with ``OpenSearchDataSource``\n\n:stability: deprecated\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n    from aws_cdk import aws_elasticsearch as elasticsearch\n    from aws_cdk import aws_iam as iam\n\n    # domain: elasticsearch.Domain\n    # graphql_api: appsync.GraphqlApi\n    # role: iam.Role\n\n    elasticsearch_data_source_props = appsync.ElasticsearchDataSourceProps(\n        api=graphql_api,\n        domain=domain,\n\n        # the properties below are optional\n        description="description",\n        name="name",\n        service_role=role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name', 'service_role', 'domain']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.ElasticsearchDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.ElasticsearchDataSourcePropsDefConfig] = pydantic.Field(None)


class ElasticsearchDataSourcePropsDefConfig(pydantic.BaseModel):
    api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)
    domain_config: typing.Optional[models._interface_methods.AwsElasticsearchIDomainDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.EventBridgeDataSourceProps
class EventBridgeDataSourcePropsDef(BaseStruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    event_bus: typing.Union[_REQUIRED_INIT_PARAM, models.aws_events.EventBusDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The EventBridge EventBus.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n    from aws_cdk import aws_events as events\n    from aws_cdk import aws_iam as iam\n\n    # event_bus: events.EventBus\n    # graphql_api: appsync.GraphqlApi\n    # role: iam.Role\n\n    event_bridge_data_source_props = appsync.EventBridgeDataSourceProps(\n        api=graphql_api,\n        event_bus=event_bus,\n\n        # the properties below are optional\n        description="description",\n        name="name",\n        service_role=role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name', 'service_role', 'event_bus']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.EventBridgeDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.EventBridgeDataSourcePropsDefConfig] = pydantic.Field(None)


class EventBridgeDataSourcePropsDefConfig(pydantic.BaseModel):
    api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)
    event_bus_config: typing.Optional[models._interface_methods.AwsEventsIEventBusDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.ExtendedDataSourceProps
class ExtendedDataSourcePropsDef(BaseStruct):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='the type of the AppSync datasource.\n')
    dynamo_db_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_DynamoDBConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for DynamoDB Datasource. Default: - No config\n')
    elasticsearch_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_ElasticsearchConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='(deprecated) configuration for Elasticsearch data source. Default: - No config\n')
    event_bridge_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_EventBridgeConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for EventBridge Datasource. Default: - No config\n')
    http_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_HttpConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for HTTP Datasource. Default: - No config\n')
    lambda_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_LambdaConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for Lambda Datasource. Default: - No config\n')
    open_search_service_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_OpenSearchServiceConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for OpenSearch data source. Default: - No config\n')
    relational_database_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_RelationalDatabaseConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='configuration for RDS Datasource. Default: - No config\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    extended_data_source_props = appsync.ExtendedDataSourceProps(\n        type="type",\n\n        # the properties below are optional\n        dynamo_db_config=appsync.CfnDataSource.DynamoDBConfigProperty(\n            aws_region="awsRegion",\n            table_name="tableName",\n\n            # the properties below are optional\n            delta_sync_config=appsync.CfnDataSource.DeltaSyncConfigProperty(\n                base_table_ttl="baseTableTtl",\n                delta_sync_table_name="deltaSyncTableName",\n                delta_sync_table_ttl="deltaSyncTableTtl"\n            ),\n            use_caller_credentials=False,\n            versioned=False\n        ),\n        elasticsearch_config=appsync.CfnDataSource.ElasticsearchConfigProperty(\n            aws_region="awsRegion",\n            endpoint="endpoint"\n        ),\n        event_bridge_config=appsync.CfnDataSource.EventBridgeConfigProperty(\n            event_bus_arn="eventBusArn"\n        ),\n        http_config=appsync.CfnDataSource.HttpConfigProperty(\n            endpoint="endpoint",\n\n            # the properties below are optional\n            authorization_config=appsync.CfnDataSource.AuthorizationConfigProperty(\n                authorization_type="authorizationType",\n\n                # the properties below are optional\n                aws_iam_config=appsync.CfnDataSource.AwsIamConfigProperty(\n                    signing_region="signingRegion",\n                    signing_service_name="signingServiceName"\n                )\n            )\n        ),\n        lambda_config=appsync.CfnDataSource.LambdaConfigProperty(\n            lambda_function_arn="lambdaFunctionArn"\n        ),\n        open_search_service_config=appsync.CfnDataSource.OpenSearchServiceConfigProperty(\n            aws_region="awsRegion",\n            endpoint="endpoint"\n        ),\n        relational_database_config=appsync.CfnDataSource.RelationalDatabaseConfigProperty(\n            relational_database_source_type="relationalDatabaseSourceType",\n\n            # the properties below are optional\n            rds_http_endpoint_config=appsync.CfnDataSource.RdsHttpEndpointConfigProperty(\n                aws_region="awsRegion",\n                aws_secret_store_arn="awsSecretStoreArn",\n                db_cluster_identifier="dbClusterIdentifier",\n\n                # the properties below are optional\n                database_name="databaseName",\n                schema="schema"\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type', 'dynamo_db_config', 'elasticsearch_config', 'event_bridge_config', 'http_config', 'lambda_config', 'open_search_service_config', 'relational_database_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.ExtendedDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.ExtendedResolverProps
class ExtendedResolverPropsDef(BaseStruct):
    field_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used\n')
    data_source: typing.Optional[models.aws_appsync.BaseDataSourceDef] = pydantic.Field(None, description='The data source this resolver is using. Default: - No datasource\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_appsync as appsync\n\n    # appsync_function: appsync.AppsyncFunction\n    # base_data_source: appsync.BaseDataSource\n    # code: appsync.Code\n    # function_runtime: appsync.FunctionRuntime\n    # mapping_template: appsync.MappingTemplate\n\n    extended_resolver_props = appsync.ExtendedResolverProps(\n        field_name="fieldName",\n        type_name="typeName",\n\n        # the properties below are optional\n        caching_config=appsync.CachingConfig(\n            ttl=cdk.Duration.minutes(30),\n\n            # the properties below are optional\n            caching_keys=["cachingKeys"]\n        ),\n        code=code,\n        data_source=base_data_source,\n        max_batch_size=123,\n        pipeline_config=[appsync_function],\n        request_mapping_template=mapping_template,\n        response_mapping_template=mapping_template,\n        runtime=function_runtime\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['field_name', 'type_name', 'caching_config', 'code', 'max_batch_size', 'pipeline_config', 'request_mapping_template', 'response_mapping_template', 'runtime', 'data_source']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.ExtendedResolverProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.GraphqlApiAttributes
class GraphqlApiAttributesDef(BaseStruct):
    graphql_api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="an unique AWS AppSync GraphQL API identifier i.e. 'lxz775lwdrgcndgz3nurvac7oa'.\n")
    graphql_api_arn: typing.Optional[str] = pydantic.Field(None, description='the arn for the GraphQL Api. Default: - autogenerated arn\n')
    graph_ql_endpoint_arn: typing.Optional[str] = pydantic.Field(None, description='The GraphQl endpoint arn for the GraphQL API. Default: - none, required to construct event rules from imported APIs\n')
    modes: typing.Optional[typing.Sequence[aws_cdk.aws_appsync.AuthorizationType]] = pydantic.Field(None, description='The Authorization Types for this GraphQL Api. Default: - none, required to construct event rules from imported APIs\n')
    visibility: typing.Optional[aws_cdk.aws_appsync.Visibility] = pydantic.Field(None, description='The GraphQl API visibility. Default: - GLOBAL\n\n:exampleMetadata: infused\n\nExample::\n\n    source_api = appsync.GraphqlApi(self, "FirstSourceAPI",\n        name="FirstSourceAPI",\n        definition=appsync.Definition.from_file(path.join(__dirname, "appsync.merged-api-1.graphql"))\n    )\n\n    imported_merged_api = appsync.GraphqlApi.from_graphql_api_attributes(self, "ImportedMergedApi",\n        graphql_api_id="MyApiId",\n        graphql_api_arn="MyApiArn"\n    )\n\n    imported_execution_role = iam.Role.from_role_arn(self, "ExecutionRole", "arn:aws:iam::ACCOUNT:role/MyExistingRole")\n    appsync.SourceApiAssociation(self, "SourceApiAssociation2",\n        source_api=source_api,\n        merged_api=imported_merged_api,\n        merge_type=appsync.MergeType.MANUAL_MERGE,\n        merged_api_execution_role=imported_execution_role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['graphql_api_id', 'graphql_api_arn', 'graph_ql_endpoint_arn', 'modes', 'visibility']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.GraphqlApiAttributes'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.GraphqlApiProps
class GraphqlApiPropsDef(BaseStruct):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='the name of the GraphQL API.\n')
    authorization_config: typing.Union[models.aws_appsync.AuthorizationConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Optional authorization configuration. Default: - API Key authorization\n')
    definition: typing.Optional[models.aws_appsync.DefinitionDef] = pydantic.Field(None, description='Definition (schema file or source APIs) for this GraphQL Api.\n')
    domain_name: typing.Union[models.aws_appsync.DomainOptionsDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The domain name configuration for the GraphQL API. The Route 53 hosted zone and CName DNS record must be configured in addition to this setting to enable custom domain URL Default: - no domain name\n')
    environment_variables: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='A map containing the list of resources with their properties and environment variables. There are a few rules you must follow when creating keys and values: - Keys must begin with a letter. - Keys must be between 2 and 64 characters long. - Keys can only contain letters, numbers, and the underscore character (_). - Values can be up to 512 characters long. - You can configure up to 50 key-value pairs in a GraphQL API. Default: - No environment variables.\n')
    introspection_config: typing.Optional[aws_cdk.aws_appsync.IntrospectionConfig] = pydantic.Field(None, description='A value indicating whether the API to enable (ENABLED) or disable (DISABLED) introspection. Default: IntrospectionConfig.ENABLED\n')
    log_config: typing.Union[models.aws_appsync.LogConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Logging configuration for this api. Default: - None\n')
    query_depth_limit: typing.Union[int, float, None] = pydantic.Field(None, description='A number indicating the maximum depth resolvers should be accepted when handling queries. Value must be withing range of 0 to 75 Default: - The default value is 0 (or unspecified) which indicates no maximum depth.\n')
    resolver_count_limit: typing.Union[int, float, None] = pydantic.Field(None, description='A number indicating the maximum number of resolvers that should be accepted when handling queries. Value must be withing range of 0 to 10000 Default: - The default value is 0 (or unspecified), which will set the limit to 10000\n')
    schema_: typing.Optional[typing.Union[models.aws_appsync.SchemaFileDef]] = pydantic.Field(None, description='(deprecated) GraphQL schema definition. Specify how you want to define your schema. SchemaFile.fromAsset(filePath: string) allows schema definition through schema.graphql file Default: - schema will be generated code-first (i.e. addType, addObjectType, etc.)\n', alias='schema')
    visibility: typing.Optional[aws_cdk.aws_appsync.Visibility] = pydantic.Field(None, description='A value indicating whether the API is accessible from anywhere (GLOBAL) or can only be access from a VPC (PRIVATE). Default: - GLOBAL\n')
    xray_enabled: typing.Optional[bool] = pydantic.Field(None, description='A flag indicating whether or not X-Ray tracing is enabled for the GraphQL API. Default: - false\n\n:exampleMetadata: infused\n\nExample::\n\n    source_api = appsync.GraphqlApi(self, "FirstSourceAPI",\n        name="FirstSourceAPI",\n        definition=appsync.Definition.from_file(path.join(__dirname, "appsync.merged-api-1.graphql"))\n    )\n\n    imported_merged_api = appsync.GraphqlApi.from_graphql_api_attributes(self, "ImportedMergedApi",\n        graphql_api_id="MyApiId",\n        graphql_api_arn="MyApiArn"\n    )\n\n    imported_execution_role = iam.Role.from_role_arn(self, "ExecutionRole", "arn:aws:iam::ACCOUNT:role/MyExistingRole")\n    appsync.SourceApiAssociation(self, "SourceApiAssociation2",\n        source_api=source_api,\n        merged_api=imported_merged_api,\n        merge_type=appsync.MergeType.MANUAL_MERGE,\n        merged_api_execution_role=imported_execution_role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'authorization_config', 'definition', 'domain_name', 'environment_variables', 'introspection_config', 'log_config', 'query_depth_limit', 'resolver_count_limit', 'schema', 'visibility', 'xray_enabled']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.GraphqlApiProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.HttpDataSourceOptions
class HttpDataSourceOptionsDef(BaseStruct):
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source. Default: - No description\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source, overrides the id given by cdk. Default: - generated by cdk given the id\n')
    authorization_config: typing.Union[models.aws_appsync.AwsIamConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The authorization config in case the HTTP endpoint requires authorization. Default: - none\n\n:exampleMetadata: infused\n\nExample::\n\n    api = appsync.GraphqlApi(self, "api",\n        name="api",\n        definition=appsync.Definition.from_file(path.join(__dirname, "schema.graphql"))\n    )\n\n    http_ds = api.add_http_data_source("ds", "https://states.amazonaws.com",\n        name="httpDsWithStepF",\n        description="from appsync to StepFunctions Workflow",\n        authorization_config=appsync.AwsIamConfig(\n            signing_region="us-east-1",\n            signing_service_name="states"\n        )\n    )\n\n    http_ds.create_resolver("MutationCallStepFunctionResolver",\n        type_name="Mutation",\n        field_name="callStepFunction",\n        request_mapping_template=appsync.MappingTemplate.from_file("request.vtl"),\n        response_mapping_template=appsync.MappingTemplate.from_file("response.vtl")\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['description', 'name', 'authorization_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.HttpDataSourceOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.HttpDataSourceProps
class HttpDataSourcePropsDef(BaseStruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n')
    endpoint: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The http endpoint.\n')
    authorization_config: typing.Union[models.aws_appsync.AwsIamConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The authorization config in case the HTTP endpoint requires authorization. Default: - none\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    # graphql_api: appsync.GraphqlApi\n\n    http_data_source_props = appsync.HttpDataSourceProps(\n        api=graphql_api,\n        endpoint="endpoint",\n\n        # the properties below are optional\n        authorization_config=appsync.AwsIamConfig(\n            signing_region="signingRegion",\n            signing_service_name="signingServiceName"\n        ),\n        description="description",\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name', 'endpoint', 'authorization_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.HttpDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.LambdaAuthorizerConfig
class LambdaAuthorizerConfigDef(BaseStruct):
    handler: typing.Union[_REQUIRED_INIT_PARAM, models.aws_lambda.FunctionBaseDef, models.aws_lambda.QualifiedFunctionBaseDef, models.aws_lambda.AliasDef, models.aws_lambda.DockerImageFunctionDef, models.aws_lambda.FunctionDef, models.aws_lambda.SingletonFunctionDef, models.aws_lambda.VersionDef, models.aws_lambda_nodejs.NodejsFunctionDef, models.triggers.TriggerFunctionDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The authorizer lambda function.\n')
    results_cache_ttl: typing.Optional[models.DurationDef] = pydantic.Field(None, description='How long the results are cached. Disable caching by setting this to 0. Default: Duration.minutes(5)\n')
    validation_regex: typing.Optional[str] = pydantic.Field(None, description='A regular expression for validation of tokens before the Lambda function is called. Default: - no regex filter will be applied.\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_lambda as lambda_\n    # auth_function: lambda.Function\n\n\n    appsync.GraphqlApi(self, "api",\n        name="api",\n        definition=appsync.Definition.from_file(path.join(__dirname, "appsync.test.graphql")),\n        authorization_config=appsync.AuthorizationConfig(\n            default_authorization=appsync.AuthorizationMode(\n                authorization_type=appsync.AuthorizationType.LAMBDA,\n                lambda_authorizer_config=appsync.LambdaAuthorizerConfig(\n                    handler=auth_function\n                )\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['handler', 'results_cache_ttl', 'validation_regex']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.LambdaAuthorizerConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.LambdaAuthorizerConfigDefConfig] = pydantic.Field(None)


class LambdaAuthorizerConfigDefConfig(pydantic.BaseModel):
    handler_config: typing.Optional[models._interface_methods.AwsLambdaIFunctionDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.LambdaDataSourceProps
class LambdaDataSourcePropsDef(BaseStruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    lambda_function: typing.Union[_REQUIRED_INIT_PARAM, models.aws_lambda.FunctionBaseDef, models.aws_lambda.QualifiedFunctionBaseDef, models.aws_lambda.AliasDef, models.aws_lambda.DockerImageFunctionDef, models.aws_lambda.FunctionDef, models.aws_lambda.SingletonFunctionDef, models.aws_lambda.VersionDef, models.aws_lambda_nodejs.NodejsFunctionDef, models.triggers.TriggerFunctionDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Lambda function to call to interact with this data source.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n    from aws_cdk import aws_iam as iam\n    from aws_cdk import aws_lambda as lambda_\n\n    # function_: lambda.Function\n    # graphql_api: appsync.GraphqlApi\n    # role: iam.Role\n\n    lambda_data_source_props = appsync.LambdaDataSourceProps(\n        api=graphql_api,\n        lambda_function=function_,\n\n        # the properties below are optional\n        description="description",\n        name="name",\n        service_role=role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name', 'service_role', 'lambda_function']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.LambdaDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.LambdaDataSourcePropsDefConfig] = pydantic.Field(None)


class LambdaDataSourcePropsDefConfig(pydantic.BaseModel):
    api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)
    lambda_function_config: typing.Optional[models._interface_methods.AwsLambdaIFunctionDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.LogConfig
class LogConfigDef(BaseStruct):
    exclude_verbose_content: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='exclude verbose content. Default: false\n')
    field_log_level: typing.Optional[aws_cdk.aws_appsync.FieldLogLevel] = pydantic.Field(None, description='log level for fields. Default: - Use AppSync default\n')
    retention: typing.Optional[aws_cdk.aws_logs.RetentionDays] = pydantic.Field(None, description="The number of days log events are kept in CloudWatch Logs. By default AppSync keeps the logs infinitely. When updating this property, unsetting it doesn't remove the log retention policy. To remove the retention policy, set the value to ``INFINITE`` Default: RetentionDays.INFINITE\n")
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The role for CloudWatch Logs. Default: - None\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_logs as logs\n\n\n    log_config = appsync.LogConfig(\n        retention=logs.RetentionDays.ONE_WEEK\n    )\n\n    appsync.GraphqlApi(self, "api",\n        authorization_config=appsync.AuthorizationConfig(),\n        name="myApi",\n        definition=appsync.Definition.from_file(path.join(__dirname, "myApi.graphql")),\n        log_config=log_config\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['exclude_verbose_content', 'field_log_level', 'retention', 'role']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.LogConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.NoneDataSourceProps
class NoneDataSourcePropsDef(BaseStruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    # graphql_api: appsync.GraphqlApi\n\n    none_data_source_props = appsync.NoneDataSourceProps(\n        api=graphql_api,\n\n        # the properties below are optional\n        description="description",\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.NoneDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.NoneDataSourcePropsDefConfig] = pydantic.Field(None)


class NoneDataSourcePropsDefConfig(pydantic.BaseModel):
    api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.OpenIdConnectConfig
class OpenIdConnectConfigDef(BaseStruct):
    oidc_provider: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The issuer for the OIDC configuration. The issuer returned by discovery must exactly match the value of ``iss`` in the OIDC token.\n')
    client_id: typing.Optional[str] = pydantic.Field(None, description='The client identifier of the Relying party at the OpenID identity provider. A regular expression can be specified so AppSync can validate against multiple client identifiers at a time. Default: - - (All)\n')
    token_expiry_from_auth: typing.Union[int, float, None] = pydantic.Field(None, description='The number of milliseconds an OIDC token is valid after being authenticated by OIDC provider. ``auth_time`` claim in OIDC token is required for this validation to work. Default: - no validation\n')
    token_expiry_from_issue: typing.Union[int, float, None] = pydantic.Field(None, description='The number of milliseconds an OIDC token is valid after being issued to a user. This validation uses ``iat`` claim of OIDC token. Default: - no validation\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    open_id_connect_config = appsync.OpenIdConnectConfig(\n        oidc_provider="oidcProvider",\n\n        # the properties below are optional\n        client_id="clientId",\n        token_expiry_from_auth=123,\n        token_expiry_from_issue=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['oidc_provider', 'client_id', 'token_expiry_from_auth', 'token_expiry_from_issue']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.OpenIdConnectConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.OpenSearchDataSourceProps
class OpenSearchDataSourcePropsDef(BaseStruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    domain: typing.Union[_REQUIRED_INIT_PARAM, models.aws_opensearchservice.DomainDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The OpenSearch domain containing the endpoint for the data source.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n    from aws_cdk import aws_iam as iam\n    from aws_cdk import aws_opensearchservice as opensearchservice\n\n    # domain: opensearchservice.Domain\n    # graphql_api: appsync.GraphqlApi\n    # role: iam.Role\n\n    open_search_data_source_props = appsync.OpenSearchDataSourceProps(\n        api=graphql_api,\n        domain=domain,\n\n        # the properties below are optional\n        description="description",\n        name="name",\n        service_role=role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name', 'service_role', 'domain']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.OpenSearchDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.OpenSearchDataSourcePropsDefConfig] = pydantic.Field(None)


class OpenSearchDataSourcePropsDefConfig(pydantic.BaseModel):
    api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)
    domain_config: typing.Optional[models._interface_methods.AwsOpensearchserviceIDomainDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.RdsDataSourceProps
class RdsDataSourcePropsDef(BaseStruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    secret_store: typing.Union[_REQUIRED_INIT_PARAM, models.aws_docdb.DatabaseSecretDef, models.aws_rds.DatabaseSecretDef, models.aws_secretsmanager.SecretDef, models.aws_secretsmanager.SecretTargetAttachmentDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The secret containing the credentials for the database.\n')
    serverless_cluster: typing.Union[_REQUIRED_INIT_PARAM, models.aws_rds.ServerlessClusterDef, models.aws_rds.ServerlessClusterFromSnapshotDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The serverless cluster to call to interact with this data source.\n')
    database_name: typing.Optional[str] = pydantic.Field(None, description='The name of the database to use within the cluster. Default: - None\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n    from aws_cdk import aws_iam as iam\n    from aws_cdk import aws_rds as rds\n    from aws_cdk import aws_secretsmanager as secretsmanager\n\n    # graphql_api: appsync.GraphqlApi\n    # role: iam.Role\n    # secret: secretsmanager.Secret\n    # serverless_cluster: rds.ServerlessCluster\n\n    rds_data_source_props = appsync.RdsDataSourceProps(\n        api=graphql_api,\n        secret_store=secret,\n        serverless_cluster=serverless_cluster,\n\n        # the properties below are optional\n        database_name="databaseName",\n        description="description",\n        name="name",\n        service_role=role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name', 'service_role', 'secret_store', 'serverless_cluster', 'database_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.RdsDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.RdsDataSourcePropsDefConfig] = pydantic.Field(None)


class RdsDataSourcePropsDefConfig(pydantic.BaseModel):
    api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)
    secret_store_config: typing.Optional[models._interface_methods.AwsSecretsmanagerISecretDefConfig] = pydantic.Field(None)
    serverless_cluster_config: typing.Optional[models._interface_methods.AwsRdsIServerlessClusterDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.RdsDataSourcePropsV2
class RdsDataSourcePropsV2Def(BaseStruct):
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API to attach this data source to.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='the description of the data source. Default: - None\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the data source. Default: - id of data source\n')
    service_role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='The IAM service role to be assumed by AppSync to interact with the data source. Default: - Create a new role\n')
    secret_store: typing.Union[_REQUIRED_INIT_PARAM, models.aws_docdb.DatabaseSecretDef, models.aws_rds.DatabaseSecretDef, models.aws_secretsmanager.SecretDef, models.aws_secretsmanager.SecretTargetAttachmentDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The secret containing the credentials for the database.\n')
    serverless_cluster: typing.Union[_REQUIRED_INIT_PARAM, models.aws_rds.DatabaseClusterBaseDef, models.aws_rds.DatabaseClusterDef, models.aws_rds.DatabaseClusterFromSnapshotDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The serverless cluster to call to interact with this data source.\n')
    database_name: typing.Optional[str] = pydantic.Field(None, description='The name of the database to use within the cluster. Default: - None\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n    from aws_cdk import aws_iam as iam\n    from aws_cdk import aws_rds as rds\n    from aws_cdk import aws_secretsmanager as secretsmanager\n\n    # database_cluster: rds.DatabaseCluster\n    # graphql_api: appsync.GraphqlApi\n    # role: iam.Role\n    # secret: secretsmanager.Secret\n\n    rds_data_source_props_v2 = appsync.RdsDataSourcePropsV2(\n        api=graphql_api,\n        secret_store=secret,\n        serverless_cluster=database_cluster,\n\n        # the properties below are optional\n        database_name="databaseName",\n        description="description",\n        name="name",\n        service_role=role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api', 'description', 'name', 'service_role', 'secret_store', 'serverless_cluster', 'database_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.RdsDataSourcePropsV2'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.RdsDataSourcePropsV2DefConfig] = pydantic.Field(None)


class RdsDataSourcePropsV2DefConfig(pydantic.BaseModel):
    api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)
    secret_store_config: typing.Optional[models._interface_methods.AwsSecretsmanagerISecretDefConfig] = pydantic.Field(None)
    serverless_cluster_config: typing.Optional[models._interface_methods.AwsRdsIDatabaseClusterDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.ResolverProps
class ResolverPropsDef(BaseStruct):
    field_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='name of the GraphQL field in the given type this resolver is attached to.\n')
    type_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='name of the GraphQL type this resolver is attached to.\n')
    caching_config: typing.Union[models.aws_appsync.CachingConfigDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for this resolver. Default: - No caching configuration\n')
    code: typing.Optional[models.aws_appsync.CodeDef] = pydantic.Field(None, description='The function code. Default: - no code is used\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of elements per batch, when using batch invoke. Default: - No max batch size\n')
    pipeline_config: typing.Optional[typing.Sequence[typing.Union[models.aws_appsync.AppsyncFunctionDef]]] = pydantic.Field(None, description='configuration of the pipeline resolver. Default: - no pipeline resolver configuration An empty array | undefined sets resolver to be of kind, unit\n')
    request_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The request mapping template for this resolver. Default: - No mapping template\n')
    response_mapping_template: typing.Optional[models.aws_appsync.MappingTemplateDef] = pydantic.Field(None, description='The response mapping template for this resolver. Default: - No mapping template\n')
    runtime: typing.Optional[models.aws_appsync.FunctionRuntimeDef] = pydantic.Field(None, description='The functions runtime. Default: - no function runtime, VTL mapping templates used\n')
    data_source: typing.Optional[models.aws_appsync.BaseDataSourceDef] = pydantic.Field(None, description='The data source this resolver is using. Default: - No datasource\n')
    api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API this resolver is attached to.\n\n:exampleMetadata: infused\n\nExample::\n\n    # api: appsync.GraphqlApi\n    # appsync_function: appsync.AppsyncFunction\n\n\n    pipeline_resolver = appsync.Resolver(self, "pipeline",\n        api=api,\n        data_source=api.add_none_data_source("none"),\n        type_name="typeName",\n        field_name="fieldName",\n        request_mapping_template=appsync.MappingTemplate.from_file("beforeRequest.vtl"),\n        pipeline_config=[appsync_function],\n        response_mapping_template=appsync.MappingTemplate.from_file("afterResponse.vtl")\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['field_name', 'type_name', 'caching_config', 'code', 'max_batch_size', 'pipeline_config', 'request_mapping_template', 'response_mapping_template', 'runtime', 'data_source', 'api']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.ResolverProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.ResolverPropsDefConfig] = pydantic.Field(None)


class ResolverPropsDefConfig(pydantic.BaseModel):
    api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.RuntimeConfig
class RuntimeConfigDef(BaseStruct):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the runtime.\n')
    runtime_version: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The version string of the runtime.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    runtime_config = appsync.RuntimeConfig(\n        name="name",\n        runtime_version="runtimeVersion"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'runtime_version']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.RuntimeConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.SchemaBindOptions
class SchemaBindOptionsDef(BaseStruct):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.SchemaBindOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.SchemaProps
class SchemaPropsDef(BaseStruct):
    file_path: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The file path for the schema. When this option is configured, then the schema will be generated from an existing file from disk.\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_certificatemanager as acm\n    import aws_cdk.aws_route53 as route53\n\n    # hosted zone and route53 features\n    # hosted_zone_id: str\n    zone_name = "example.com"\n\n\n    my_domain_name = "api.example.com"\n    certificate = acm.Certificate(self, "cert", domain_name=my_domain_name)\n    schema = appsync.SchemaFile(file_path="mySchemaFile")\n    api = appsync.GraphqlApi(self, "api",\n        name="myApi",\n        definition=appsync.Definition.from_schema(schema),\n        domain_name=appsync.DomainOptions(\n            certificate=certificate,\n            domain_name=my_domain_name\n        )\n    )\n\n    # hosted zone for adding appsync domain\n    zone = route53.HostedZone.from_hosted_zone_attributes(self, "HostedZone",\n        hosted_zone_id=hosted_zone_id,\n        zone_name=zone_name\n    )\n\n    # create a cname to the appsync domain. will map to something like xxxx.cloudfront.net\n    route53.CnameRecord(self, "CnameApiRecord",\n        record_name="api",\n        zone=zone,\n        domain_name=api.app_sync_domain_name\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['file_path']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.SchemaProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.SourceApi
class SourceApiDef(BaseStruct):
    source_api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='Source API that is associated with the merged API.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='Description of the Source API asssociation.\n')
    merge_type: typing.Optional[aws_cdk.aws_appsync.MergeType] = pydantic.Field(None, description='Merging option used to associate the source API to the Merged API. Default: - Auto merge. The merge is triggered automatically when the source API has changed\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    # graphql_api: appsync.GraphqlApi\n\n    source_api = appsync.SourceApi(\n        source_api=graphql_api,\n\n        # the properties below are optional\n        description="description",\n        merge_type=appsync.MergeType.MANUAL_MERGE\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['source_api', 'description', 'merge_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.SourceApi'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.SourceApiDefConfig] = pydantic.Field(None)


class SourceApiDefConfig(pydantic.BaseModel):
    source_api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.SourceApiAssociationAttributes
class SourceApiAssociationAttributesDef(BaseStruct):
    association_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The association arn.\n')
    merged_api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The merged api in the association.\n')
    source_api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The source api in the association.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    # graphql_api: appsync.GraphqlApi\n\n    source_api_association_attributes = appsync.SourceApiAssociationAttributes(\n        association_arn="associationArn",\n        merged_api=graphql_api,\n        source_api=graphql_api\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['association_arn', 'merged_api', 'source_api']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.SourceApiAssociationAttributes'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.SourceApiAssociationAttributesDefConfig] = pydantic.Field(None)


class SourceApiAssociationAttributesDefConfig(pydantic.BaseModel):
    merged_api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)
    source_api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.SourceApiAssociationProps
class SourceApiAssociationPropsDef(BaseStruct):
    merged_api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The merged api to associate.\n')
    merged_api_execution_role: typing.Union[_REQUIRED_INIT_PARAM, models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The merged api execution role for adding the access policy for the source api.\n')
    source_api: typing.Union[_REQUIRED_INIT_PARAM, models.aws_appsync.GraphqlApiBaseDef, models.aws_appsync.GraphqlApiDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The source api to associate.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the source api association. Default: - None\n')
    merge_type: typing.Optional[aws_cdk.aws_appsync.MergeType] = pydantic.Field(None, description='The merge type for the source. Default: - AUTO_MERGE\n\n:exampleMetadata: infused\n\nExample::\n\n    source_api = appsync.GraphqlApi(self, "FirstSourceAPI",\n        name="FirstSourceAPI",\n        definition=appsync.Definition.from_file(path.join(__dirname, "appsync.merged-api-1.graphql"))\n    )\n\n    imported_merged_api = appsync.GraphqlApi.from_graphql_api_attributes(self, "ImportedMergedApi",\n        graphql_api_id="MyApiId",\n        graphql_api_arn="MyApiArn"\n    )\n\n    imported_execution_role = iam.Role.from_role_arn(self, "ExecutionRole", "arn:aws:iam::ACCOUNT:role/MyExistingRole")\n    appsync.SourceApiAssociation(self, "SourceApiAssociation2",\n        source_api=source_api,\n        merged_api=imported_merged_api,\n        merge_type=appsync.MergeType.MANUAL_MERGE,\n        merged_api_execution_role=imported_execution_role\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['merged_api', 'merged_api_execution_role', 'source_api', 'description', 'merge_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.SourceApiAssociationProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.SourceApiAssociationPropsDefConfig] = pydantic.Field(None)


class SourceApiAssociationPropsDefConfig(pydantic.BaseModel):
    merged_api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)
    merged_api_execution_role_config: typing.Optional[models._interface_methods.AwsIamIRoleDefConfig] = pydantic.Field(None)
    source_api_config: typing.Optional[models._interface_methods.AwsAppsyncIGraphqlApiDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.SourceApiOptions
class SourceApiOptionsDef(BaseStruct):
    source_apis: typing.Union[typing.Sequence[typing.Union[models.aws_appsync.SourceApiDef, dict[str, typing.Any]]], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Definition of source APIs associated with this Merged API.\n')
    merged_api_execution_role: typing.Optional[models.aws_iam.RoleDef] = pydantic.Field(None, description='IAM Role used to validate access to source APIs at runtime and to update the merged API endpoint with the source API changes. Default: - An IAM Role with acccess to source schemas will be created\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk as cdk\n\n\n    # first source API\n    first_api = appsync.GraphqlApi(self, "FirstSourceAPI",\n        name="FirstSourceAPI",\n        definition=appsync.Definition.from_file(path.join(__dirname, "appsync.merged-api-1.graphql"))\n    )\n\n    # second source API\n    second_api = appsync.GraphqlApi(self, "SecondSourceAPI",\n        name="SecondSourceAPI",\n        definition=appsync.Definition.from_file(path.join(__dirname, "appsync.merged-api-2.graphql"))\n    )\n\n    # Merged API\n    merged_api = appsync.GraphqlApi(self, "MergedAPI",\n        name="MergedAPI",\n        definition=appsync.Definition.from_source_apis(\n            source_apis=[appsync.SourceApi(\n                source_api=first_api,\n                merge_type=appsync.MergeType.MANUAL_MERGE\n            ), appsync.SourceApi(\n                source_api=second_api,\n                merge_type=appsync.MergeType.AUTO_MERGE\n            )\n            ]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['source_apis', 'merged_api_execution_role']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.SourceApiOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.UserPoolConfig
class UserPoolConfigDef(BaseStruct):
    user_pool: typing.Union[_REQUIRED_INIT_PARAM, models.aws_cognito.UserPoolDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Cognito user pool to use as identity source.\n')
    app_id_client_regex: typing.Optional[str] = pydantic.Field(None, description='the optional app id regex. Default: - None\n')
    default_action: typing.Optional[aws_cdk.aws_appsync.UserPoolDefaultAction] = pydantic.Field(None, description='Default auth action. Default: ALLOW\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n    from aws_cdk import aws_cognito as cognito\n\n    # user_pool: cognito.UserPool\n\n    user_pool_config = appsync.UserPoolConfig(\n        user_pool=user_pool,\n\n        # the properties below are optional\n        app_id_client_regex="appIdClientRegex",\n        default_action=appsync.UserPoolDefaultAction.ALLOW\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['user_pool', 'app_id_client_regex', 'default_action']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.UserPoolConfig'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.UserPoolConfigDefConfig] = pydantic.Field(None)


class UserPoolConfigDefConfig(pydantic.BaseModel):
    user_pool_config: typing.Optional[models._interface_methods.AwsCognitoIUserPoolDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_appsync.AuthorizationType
# skipping emum

#  autogenerated from aws_cdk.aws_appsync.FieldLogLevel
# skipping emum

#  autogenerated from aws_cdk.aws_appsync.FunctionRuntimeFamily
# skipping emum

#  autogenerated from aws_cdk.aws_appsync.IntrospectionConfig
# skipping emum

#  autogenerated from aws_cdk.aws_appsync.MergeType
# skipping emum

#  autogenerated from aws_cdk.aws_appsync.UserPoolDefaultAction
# skipping emum

#  autogenerated from aws_cdk.aws_appsync.Visibility
# skipping emum

#  autogenerated from aws_cdk.aws_appsync.IAppsyncFunction
#  skipping Interface

#  autogenerated from aws_cdk.aws_appsync.IGraphqlApi
#  skipping Interface

#  autogenerated from aws_cdk.aws_appsync.ISchema
#  skipping Interface

#  autogenerated from aws_cdk.aws_appsync.ISchemaConfig
#  skipping Interface

#  autogenerated from aws_cdk.aws_appsync.ISourceApiAssociation
#  skipping Interface

#  autogenerated from aws_cdk.aws_appsync.CfnApiCache
class CfnApiCacheDef(BaseCfnResource):
    api_caching_behavior: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Caching behavior. - *FULL_REQUEST_CACHING* : All requests are fully cached. - *PER_RESOLVER_CACHING* : Individual resolvers that you specify are cached.\n')
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The GraphQL API ID.\n')
    ttl: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='TTL in seconds for cache entries. Valid values are 1–3,600 seconds.\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The cache instance type. Valid values are. - ``SMALL`` - ``MEDIUM`` - ``LARGE`` - ``XLARGE`` - ``LARGE_2X`` - ``LARGE_4X`` - ``LARGE_8X`` (not available in all regions) - ``LARGE_12X`` Historically, instance types were identified by an EC2-style value. As of July 2020, this is deprecated, and the generic identifiers above should be used. The following legacy instance types are available, but their use is discouraged: - *T2_SMALL* : A t2.small instance type. - *T2_MEDIUM* : A t2.medium instance type. - *R4_LARGE* : A r4.large instance type. - *R4_XLARGE* : A r4.xlarge instance type. - *R4_2XLARGE* : A r4.2xlarge instance type. - *R4_4XLARGE* : A r4.4xlarge instance type. - *R4_8XLARGE* : A r4.8xlarge instance type.\n')
    at_rest_encryption_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='At-rest encryption flag for cache. You cannot update this setting after creation.\n')
    health_metrics_config: typing.Optional[str] = pydantic.Field(None, description='Controls how cache health metrics will be emitted to CloudWatch. Cache health metrics include:. - *NetworkBandwidthOutAllowanceExceeded* : The network packets dropped because the throughput exceeded the aggregated bandwidth limit. This is useful for diagnosing bottlenecks in a cache configuration. - *EngineCPUUtilization* : The CPU utilization (percentage) allocated to the Redis process. This is useful for diagnosing bottlenecks in a cache configuration. Metrics will be recorded by API ID. You can set the value to ``ENABLED`` or ``DISABLED`` .\n')
    transit_encryption_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Transit encryption flag when connecting to cache. You cannot update this setting after creation.')
    _init_params: typing.ClassVar[list[str]] = ['api_caching_behavior', 'api_id', 'ttl', 'type', 'at_rest_encryption_enabled', 'health_metrics_config', 'transit_encryption_enabled']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnApiCache'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.CfnApiCacheDefConfig] = pydantic.Field(None)


class CfnApiCacheDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_appsync.CfnApiCacheDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_appsync.CfnApiCacheDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_appsync.CfnApiCacheDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_appsync.CfnApiCacheDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_appsync.CfnApiCacheDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_appsync.CfnApiCacheDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_appsync.CfnApiCacheDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_appsync.CfnApiCacheDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_appsync.CfnApiCacheDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_appsync.CfnApiCacheDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_appsync.CfnApiCacheDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_appsync.CfnApiCacheDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_appsync.CfnApiCacheDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnApiCacheDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnApiCacheDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnApiCacheDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnApiCacheDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnApiCacheDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnApiCacheDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnApiCacheDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnApiCacheDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnApiCacheDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnApiCacheDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnApiCacheDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnApiCacheDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnApiCacheDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnApiCacheDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_appsync.CfnApiKey
class CfnApiKeyDef(BaseCfnResource):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Unique AWS AppSync GraphQL API ID for this API key.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='Unique description of your API key.\n')
    expires: typing.Union[int, float, None] = pydantic.Field(None, description='The time after which the API key expires. The date is represented as seconds since the epoch, rounded down to the nearest hour.')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'description', 'expires']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnApiKey'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.CfnApiKeyDefConfig] = pydantic.Field(None)


class CfnApiKeyDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_appsync.CfnApiKeyDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_appsync.CfnApiKeyDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_appsync.CfnApiKeyDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_appsync.CfnApiKeyDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_appsync.CfnApiKeyDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_appsync.CfnApiKeyDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_appsync.CfnApiKeyDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_appsync.CfnApiKeyDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_appsync.CfnApiKeyDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_appsync.CfnApiKeyDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_appsync.CfnApiKeyDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_appsync.CfnApiKeyDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_appsync.CfnApiKeyDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnApiKeyDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnApiKeyDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnApiKeyDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnApiKeyDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnApiKeyDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnApiKeyDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnApiKeyDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnApiKeyDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnApiKeyDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnApiKeyDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnApiKeyDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnApiKeyDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnApiKeyDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnApiKeyDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_appsync.CfnDataSource
class CfnDataSourceDef(BaseCfnResource):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Unique AWS AppSync GraphQL API identifier where this data source will be created.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Friendly name for you to identify your AppSync data source after creation.\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of the data source. - *AWS_LAMBDA* : The data source is an AWS Lambda function. - *AMAZON_DYNAMODB* : The data source is an Amazon DynamoDB table. - *AMAZON_ELASTICSEARCH* : The data source is an Amazon OpenSearch Service domain. - *AMAZON_EVENTBRIDGE* : The data source is an Amazon EventBridge event bus. - *AMAZON_OPENSEARCH_SERVICE* : The data source is an Amazon OpenSearch Service domain. - *NONE* : There is no data source. This type is used when you wish to invoke a GraphQL operation without connecting to a data source, such as performing data transformation with resolvers or triggering a subscription to be invoked from a mutation. - *HTTP* : The data source is an HTTP endpoint. - *RELATIONAL_DATABASE* : The data source is a relational database.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source.\n')
    dynamo_db_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_DynamoDBConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='AWS Region and TableName for an Amazon DynamoDB table in your account.\n')
    elasticsearch_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_ElasticsearchConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='AWS Region and Endpoints for an Amazon OpenSearch Service domain in your account. As of September 2021, Amazon Elasticsearch Service is Amazon OpenSearch Service . This property is deprecated. For new data sources, use *OpenSearchServiceConfig* to specify an OpenSearch Service data source.\n')
    event_bridge_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_EventBridgeConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An EventBridge configuration that contains a valid ARN of an event bus.\n')
    http_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_HttpConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Endpoints for an HTTP data source.\n')
    lambda_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_LambdaConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An ARN of a Lambda function in valid ARN format. This can be the ARN of a Lambda function that exists in the current account or in another account.\n')
    metrics_config: typing.Optional[str] = pydantic.Field(None, description="Enables or disables enhanced data source metrics for specified data sources. Note that ``MetricsConfig`` won't be used unless the ``dataSourceLevelMetricsBehavior`` value is set to ``PER_DATA_SOURCE_METRICS`` . If the ``dataSourceLevelMetricsBehavior`` is set to ``FULL_REQUEST_DATA_SOURCE_METRICS`` instead, ``MetricsConfig`` will be ignored. However, you can still set its value. ``MetricsConfig`` can be ``ENABLED`` or ``DISABLED`` .\n")
    open_search_service_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_OpenSearchServiceConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='AWS Region and Endpoints for an Amazon OpenSearch Service domain in your account.\n')
    relational_database_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_RelationalDatabaseConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Relational Database configuration of the relational database data source.\n')
    service_role_arn: typing.Optional[str] = pydantic.Field(None, description='The AWS Identity and Access Management service role ARN for the data source. The system assumes this role when accessing the data source. Required if ``Type`` is specified as ``AWS_LAMBDA`` , ``AMAZON_DYNAMODB`` , ``AMAZON_ELASTICSEARCH`` , ``AMAZON_EVENTBRIDGE`` , or ``AMAZON_OPENSEARCH_SERVICE`` .')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'name', 'type', 'description', 'dynamo_db_config', 'elasticsearch_config', 'event_bridge_config', 'http_config', 'lambda_config', 'metrics_config', 'open_search_service_config', 'relational_database_config', 'service_role_arn']
    _method_names: typing.ClassVar[list[str]] = ['AuthorizationConfigProperty', 'AwsIamConfigProperty', 'DeltaSyncConfigProperty', 'DynamoDBConfigProperty', 'ElasticsearchConfigProperty', 'EventBridgeConfigProperty', 'HttpConfigProperty', 'LambdaConfigProperty', 'OpenSearchServiceConfigProperty', 'RdsHttpEndpointConfigProperty', 'RelationalDatabaseConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSource'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.CfnDataSourceDefConfig] = pydantic.Field(None)


class CfnDataSourceDefConfig(pydantic.BaseModel):
    AuthorizationConfigProperty: typing.Optional[list[models.aws_appsync.CfnDataSourceDefAuthorizationconfigpropertyParams]] = pydantic.Field(None, description='')
    AwsIamConfigProperty: typing.Optional[list[models.aws_appsync.CfnDataSourceDefAwsiamconfigpropertyParams]] = pydantic.Field(None, description='')
    DeltaSyncConfigProperty: typing.Optional[list[models.aws_appsync.CfnDataSourceDefDeltasyncconfigpropertyParams]] = pydantic.Field(None, description='')
    DynamoDBConfigProperty: typing.Optional[list[models.aws_appsync.CfnDataSourceDefDynamodbconfigpropertyParams]] = pydantic.Field(None, description='')
    ElasticsearchConfigProperty: typing.Optional[list[models.aws_appsync.CfnDataSourceDefElasticsearchconfigpropertyParams]] = pydantic.Field(None, description='')
    EventBridgeConfigProperty: typing.Optional[list[models.aws_appsync.CfnDataSourceDefEventbridgeconfigpropertyParams]] = pydantic.Field(None, description='')
    HttpConfigProperty: typing.Optional[list[models.aws_appsync.CfnDataSourceDefHttpconfigpropertyParams]] = pydantic.Field(None, description='')
    LambdaConfigProperty: typing.Optional[list[models.aws_appsync.CfnDataSourceDefLambdaconfigpropertyParams]] = pydantic.Field(None, description='')
    OpenSearchServiceConfigProperty: typing.Optional[list[models.aws_appsync.CfnDataSourceDefOpensearchserviceconfigpropertyParams]] = pydantic.Field(None, description='')
    RdsHttpEndpointConfigProperty: typing.Optional[list[models.aws_appsync.CfnDataSourceDefRdshttpendpointconfigpropertyParams]] = pydantic.Field(None, description='')
    RelationalDatabaseConfigProperty: typing.Optional[list[models.aws_appsync.CfnDataSourceDefRelationaldatabaseconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_appsync.CfnDataSourceDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_appsync.CfnDataSourceDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_appsync.CfnDataSourceDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_appsync.CfnDataSourceDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_appsync.CfnDataSourceDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_appsync.CfnDataSourceDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_appsync.CfnDataSourceDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_appsync.CfnDataSourceDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_appsync.CfnDataSourceDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_appsync.CfnDataSourceDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_appsync.CfnDataSourceDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_appsync.CfnDataSourceDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_appsync.CfnDataSourceDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnDataSourceDefAuthorizationconfigpropertyParams(pydantic.BaseModel):
    authorization_type: str = pydantic.Field(..., description='')
    aws_iam_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_AwsIamConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDataSourceDefAwsiamconfigpropertyParams(pydantic.BaseModel):
    signing_region: typing.Optional[str] = pydantic.Field(None, description='')
    signing_service_name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDataSourceDefDeltasyncconfigpropertyParams(pydantic.BaseModel):
    base_table_ttl: str = pydantic.Field(..., description='')
    delta_sync_table_name: str = pydantic.Field(..., description='')
    delta_sync_table_ttl: str = pydantic.Field(..., description='')
    ...

class CfnDataSourceDefDynamodbconfigpropertyParams(pydantic.BaseModel):
    aws_region: str = pydantic.Field(..., description='')
    table_name: str = pydantic.Field(..., description='')
    delta_sync_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_DeltaSyncConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    use_caller_credentials: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    versioned: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnDataSourceDefElasticsearchconfigpropertyParams(pydantic.BaseModel):
    aws_region: str = pydantic.Field(..., description='')
    endpoint: str = pydantic.Field(..., description='')
    ...

class CfnDataSourceDefEventbridgeconfigpropertyParams(pydantic.BaseModel):
    event_bus_arn: str = pydantic.Field(..., description='')
    ...

class CfnDataSourceDefHttpconfigpropertyParams(pydantic.BaseModel):
    endpoint: str = pydantic.Field(..., description='')
    authorization_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_AuthorizationConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDataSourceDefLambdaconfigpropertyParams(pydantic.BaseModel):
    lambda_function_arn: str = pydantic.Field(..., description='')
    ...

class CfnDataSourceDefOpensearchserviceconfigpropertyParams(pydantic.BaseModel):
    aws_region: str = pydantic.Field(..., description='')
    endpoint: str = pydantic.Field(..., description='')
    ...

class CfnDataSourceDefRdshttpendpointconfigpropertyParams(pydantic.BaseModel):
    aws_region: str = pydantic.Field(..., description='')
    aws_secret_store_arn: str = pydantic.Field(..., description='')
    db_cluster_identifier: str = pydantic.Field(..., description='')
    database_name: typing.Optional[str] = pydantic.Field(None, description='')
    schema_: typing.Optional[str] = pydantic.Field(None, description='', alias='schema')
    ...

class CfnDataSourceDefRelationaldatabaseconfigpropertyParams(pydantic.BaseModel):
    relational_database_source_type: str = pydantic.Field(..., description='')
    rds_http_endpoint_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_RdsHttpEndpointConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnDataSourceDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnDataSourceDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDataSourceDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnDataSourceDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDataSourceDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnDataSourceDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnDataSourceDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnDataSourceDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnDataSourceDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnDataSourceDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDataSourceDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnDataSourceDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnDataSourceDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDataSourceDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_appsync.CfnDomainName
class CfnDomainNameDef(BaseCfnResource):
    certificate_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the certificate. This will be an AWS Certificate Manager certificate.\n')
    domain_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The domain name.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The decription for your domain name.')
    _init_params: typing.ClassVar[list[str]] = ['certificate_arn', 'domain_name', 'description']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDomainName'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.CfnDomainNameDefConfig] = pydantic.Field(None)


class CfnDomainNameDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_appsync.CfnDomainNameDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_appsync.CfnDomainNameDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_appsync.CfnDomainNameDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_appsync.CfnDomainNameDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_appsync.CfnDomainNameDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_appsync.CfnDomainNameDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_appsync.CfnDomainNameDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_appsync.CfnDomainNameDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_appsync.CfnDomainNameDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_appsync.CfnDomainNameDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_appsync.CfnDomainNameDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_appsync.CfnDomainNameDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_appsync.CfnDomainNameDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnDomainNameDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnDomainNameDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDomainNameDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnDomainNameDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDomainNameDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnDomainNameDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnDomainNameDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnDomainNameDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnDomainNameDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnDomainNameDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDomainNameDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnDomainNameDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnDomainNameDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDomainNameDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_appsync.CfnDomainNameApiAssociation
class CfnDomainNameApiAssociationDef(BaseCfnResource):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API ID.\n')
    domain_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The domain name.')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'domain_name']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDomainNameApiAssociation'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.CfnDomainNameApiAssociationDefConfig] = pydantic.Field(None)


class CfnDomainNameApiAssociationDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_appsync.CfnDomainNameApiAssociationDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnDomainNameApiAssociationDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnDomainNameApiAssociationDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDomainNameApiAssociationDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnDomainNameApiAssociationDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDomainNameApiAssociationDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnDomainNameApiAssociationDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnDomainNameApiAssociationDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnDomainNameApiAssociationDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnDomainNameApiAssociationDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnDomainNameApiAssociationDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDomainNameApiAssociationDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnDomainNameApiAssociationDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnDomainNameApiAssociationDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDomainNameApiAssociationDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_appsync.CfnFunctionConfiguration
class CfnFunctionConfigurationDef(BaseCfnResource):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS AppSync GraphQL API that you want to attach using this function.\n')
    data_source_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of data source this function will attach.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the function.\n')
    code: typing.Optional[str] = pydantic.Field(None, description='The ``resolver`` code that contains the request and response functions. When code is used, the ``runtime`` is required. The runtime value must be ``APPSYNC_JS`` .\n')
    code_s3_location: typing.Optional[str] = pydantic.Field(None, description='The Amazon S3 endpoint.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The ``Function`` description.\n')
    function_version: typing.Optional[str] = pydantic.Field(None, description='The version of the request mapping template. Currently, only the 2018-05-29 version of the template is supported.\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a ``BatchInvoke`` operation.\n')
    request_mapping_template: typing.Optional[str] = pydantic.Field(None, description='The ``Function`` request mapping template. Functions support only the 2018-05-29 version of the request mapping template.\n')
    request_mapping_template_s3_location: typing.Optional[str] = pydantic.Field(None, description='Describes a Sync configuration for a resolver. Contains information on which Conflict Detection, as well as Resolution strategy, should be performed when the resolver is invoked.\n')
    response_mapping_template: typing.Optional[str] = pydantic.Field(None, description='The ``Function`` response mapping template.\n')
    response_mapping_template_s3_location: typing.Optional[str] = pydantic.Field(None, description='The location of a response mapping template in an Amazon S3 bucket. Use this if you want to provision with a template file in Amazon S3 rather than embedding it in your CloudFormation template.\n')
    runtime: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnFunctionConfiguration_AppSyncRuntimePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes a runtime used by an AWS AppSync resolver or AWS AppSync function. Specifies the name and version of the runtime to use. Note that if a runtime is specified, code must also be specified.\n')
    sync_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnFunctionConfiguration_SyncConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes a Sync configuration for a resolver. Specifies which Conflict Detection strategy and Resolution strategy to use when the resolver is invoked.')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'data_source_name', 'name', 'code', 'code_s3_location', 'description', 'function_version', 'max_batch_size', 'request_mapping_template', 'request_mapping_template_s3_location', 'response_mapping_template', 'response_mapping_template_s3_location', 'runtime', 'sync_config']
    _method_names: typing.ClassVar[list[str]] = ['AppSyncRuntimeProperty', 'LambdaConflictHandlerConfigProperty', 'SyncConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnFunctionConfiguration'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.CfnFunctionConfigurationDefConfig] = pydantic.Field(None)


class CfnFunctionConfigurationDefConfig(pydantic.BaseModel):
    AppSyncRuntimeProperty: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefAppsyncruntimepropertyParams]] = pydantic.Field(None, description='')
    LambdaConflictHandlerConfigProperty: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefLambdaconflicthandlerconfigpropertyParams]] = pydantic.Field(None, description='')
    SyncConfigProperty: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefSyncconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_appsync.CfnFunctionConfigurationDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnFunctionConfigurationDefAppsyncruntimepropertyParams(pydantic.BaseModel):
    name: str = pydantic.Field(..., description='')
    runtime_version: str = pydantic.Field(..., description='')
    ...

class CfnFunctionConfigurationDefLambdaconflicthandlerconfigpropertyParams(pydantic.BaseModel):
    lambda_conflict_handler_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnFunctionConfigurationDefSyncconfigpropertyParams(pydantic.BaseModel):
    conflict_detection: str = pydantic.Field(..., description='')
    conflict_handler: typing.Optional[str] = pydantic.Field(None, description='')
    lambda_conflict_handler_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnFunctionConfiguration_LambdaConflictHandlerConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnFunctionConfigurationDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnFunctionConfigurationDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnFunctionConfigurationDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnFunctionConfigurationDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnFunctionConfigurationDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnFunctionConfigurationDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnFunctionConfigurationDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnFunctionConfigurationDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnFunctionConfigurationDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnFunctionConfigurationDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnFunctionConfigurationDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnFunctionConfigurationDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnFunctionConfigurationDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnFunctionConfigurationDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_appsync.CfnGraphQLApi
class CfnGraphQLApiDef(BaseCfnResource):
    authentication_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Security configuration for your GraphQL API. For allowed values (such as ``API_KEY`` , ``AWS_IAM`` , ``AMAZON_COGNITO_USER_POOLS`` , ``OPENID_CONNECT`` , or ``AWS_LAMBDA`` ), see `Security <https://docs.aws.amazon.com/appsync/latest/devguide/security.html>`_ in the *AWS AppSync Developer Guide* .\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API name.\n')
    additional_authentication_providers: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_AdditionalAuthenticationProviderPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A list of additional authentication providers for the ``GraphqlApi`` API.\n')
    api_type: typing.Optional[str] = pydantic.Field(None, description='The value that indicates whether the GraphQL API is a standard API ( ``GRAPHQL`` ) or merged API ( ``MERGED`` ). *WARNING* : If the ``ApiType`` has not been defined, *explicitly* setting it to ``GRAPHQL`` in a template/stack update will result in an API replacement and new DNS values. The following values are valid: ``GRAPHQL | MERGED``\n')
    enhanced_metrics_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_EnhancedMetricsConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Enables and controls the enhanced metrics feature. Enhanced metrics emit granular data on API usage and performance such as AppSync request and error counts, latency, and cache hits/misses. All enhanced metric data is sent to your CloudWatch account, and you can configure the types of data that will be sent. Enhanced metrics can be configured at the resolver, data source, and operation levels. For more information, see `Monitoring and logging <https://docs.aws.amazon.com//appsync/latest/devguide/monitoring.html#cw-metrics>`_ in the *AWS AppSync User Guide* .\n')
    environment_variables: typing.Any = pydantic.Field(None, description='A map containing the list of resources with their properties and environment variables. For more information, see `Environmental variables <https://docs.aws.amazon.com/appsync/latest/devguide/environmental-variables.html>`_ . *Pattern* : ``^[A-Za-z]+\\\\w*$\\\\`` *Minimum* : 2 *Maximum* : 64\n')
    introspection_config: typing.Optional[str] = pydantic.Field(None, description='Sets the value of the GraphQL API to enable ( ``ENABLED`` ) or disable ( ``DISABLED`` ) introspection. If no value is provided, the introspection configuration will be set to ``ENABLED`` by default. This field will produce an error if the operation attempts to use the introspection feature while this field is disabled. For more information about introspection, see `GraphQL introspection <https://docs.aws.amazon.com/https://graphql.org/learn/introspection/>`_ .\n')
    lambda_authorizer_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_LambdaAuthorizerConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A ``LambdaAuthorizerConfig`` holds configuration on how to authorize AWS AppSync API access when using the ``AWS_LAMBDA`` authorizer mode. Be aware that an AWS AppSync API may have only one Lambda authorizer configured at a time.\n')
    log_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_LogConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Amazon CloudWatch Logs configuration.\n')
    merged_api_execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The AWS Identity and Access Management service role ARN for a merged API. The AppSync service assumes this role on behalf of the Merged API to validate access to source APIs at runtime and to prompt the ``AUTO_MERGE`` to update the merged API endpoint with the source API changes automatically.\n')
    open_id_connect_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_OpenIDConnectConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The OpenID Connect configuration.\n')
    owner_contact: typing.Optional[str] = pydantic.Field(None, description='The owner contact information for an API resource. This field accepts any string input with a length of 0 - 256 characters.\n')
    query_depth_limit: typing.Union[int, float, None] = pydantic.Field(None, description="The maximum depth a query can have in a single request. Depth refers to the amount of nested levels allowed in the body of query. The default value is ``0`` (or unspecified), which indicates there's no depth limit. If you set a limit, it can be between ``1`` and ``75`` nested levels. This field will produce a limit error if the operation falls out of bounds. Note that fields can still be set to nullable or non-nullable. If a non-nullable field produces an error, the error will be thrown upwards to the first nullable field available.\n")
    resolver_count_limit: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolvers that can be invoked in a single request. The default value is ``0`` (or unspecified), which will set the limit to ``10000`` . When specified, the limit value can be between ``1`` and ``10000`` . This field will produce a limit error if the operation falls out of bounds.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='An arbitrary set of tags (key-value pairs) for this GraphQL API.\n')
    user_pool_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_UserPoolConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Optional authorization configuration for using Amazon Cognito user pools with your GraphQL endpoint.\n')
    visibility: typing.Optional[str] = pydantic.Field(None, description='Sets the scope of the GraphQL API to public ( ``GLOBAL`` ) or private ( ``PRIVATE`` ). By default, the scope is set to ``Global`` if no value is provided. *WARNING* : If ``Visibility`` has not been defined, *explicitly* setting it to ``GLOBAL`` in a template/stack update will result in an API replacement and new DNS values.\n')
    xray_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='A flag indicating whether to use AWS X-Ray tracing for this ``GraphqlApi`` .')
    _init_params: typing.ClassVar[list[str]] = ['authentication_type', 'name', 'additional_authentication_providers', 'api_type', 'enhanced_metrics_config', 'environment_variables', 'introspection_config', 'lambda_authorizer_config', 'log_config', 'merged_api_execution_role_arn', 'open_id_connect_config', 'owner_contact', 'query_depth_limit', 'resolver_count_limit', 'tags', 'user_pool_config', 'visibility', 'xray_enabled']
    _method_names: typing.ClassVar[list[str]] = ['AdditionalAuthenticationProviderProperty', 'CognitoUserPoolConfigProperty', 'EnhancedMetricsConfigProperty', 'LambdaAuthorizerConfigProperty', 'LogConfigProperty', 'OpenIDConnectConfigProperty', 'UserPoolConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnGraphQLApi'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.CfnGraphQLApiDefConfig] = pydantic.Field(None)


class CfnGraphQLApiDefConfig(pydantic.BaseModel):
    AdditionalAuthenticationProviderProperty: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefAdditionalauthenticationproviderpropertyParams]] = pydantic.Field(None, description='')
    CognitoUserPoolConfigProperty: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefCognitouserpoolconfigpropertyParams]] = pydantic.Field(None, description='')
    EnhancedMetricsConfigProperty: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefEnhancedmetricsconfigpropertyParams]] = pydantic.Field(None, description='')
    LambdaAuthorizerConfigProperty: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefLambdaauthorizerconfigpropertyParams]] = pydantic.Field(None, description='')
    LogConfigProperty: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefLogconfigpropertyParams]] = pydantic.Field(None, description='')
    OpenIDConnectConfigProperty: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefOpenidconnectconfigpropertyParams]] = pydantic.Field(None, description='')
    UserPoolConfigProperty: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefUserpoolconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_appsync.CfnGraphQLApiDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnGraphQLApiDefAdditionalauthenticationproviderpropertyParams(pydantic.BaseModel):
    authentication_type: str = pydantic.Field(..., description='')
    lambda_authorizer_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_LambdaAuthorizerConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    open_id_connect_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_OpenIDConnectConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    user_pool_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_CognitoUserPoolConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnGraphQLApiDefCognitouserpoolconfigpropertyParams(pydantic.BaseModel):
    app_id_client_regex: typing.Optional[str] = pydantic.Field(None, description='')
    aws_region: typing.Optional[str] = pydantic.Field(None, description='')
    user_pool_id: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnGraphQLApiDefEnhancedmetricsconfigpropertyParams(pydantic.BaseModel):
    data_source_level_metrics_behavior: str = pydantic.Field(..., description='')
    operation_level_metrics_config: str = pydantic.Field(..., description='')
    resolver_level_metrics_behavior: str = pydantic.Field(..., description='')
    ...

class CfnGraphQLApiDefLambdaauthorizerconfigpropertyParams(pydantic.BaseModel):
    authorizer_result_ttl_in_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    authorizer_uri: typing.Optional[str] = pydantic.Field(None, description='')
    identity_validation_expression: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnGraphQLApiDefLogconfigpropertyParams(pydantic.BaseModel):
    cloud_watch_logs_role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    exclude_verbose_content: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    field_log_level: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnGraphQLApiDefOpenidconnectconfigpropertyParams(pydantic.BaseModel):
    auth_ttl: typing.Union[int, float, None] = pydantic.Field(None, description='')
    client_id: typing.Optional[str] = pydantic.Field(None, description='')
    iat_ttl: typing.Union[int, float, None] = pydantic.Field(None, description='')
    issuer: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnGraphQLApiDefUserpoolconfigpropertyParams(pydantic.BaseModel):
    app_id_client_regex: typing.Optional[str] = pydantic.Field(None, description='')
    aws_region: typing.Optional[str] = pydantic.Field(None, description='')
    default_action: typing.Optional[str] = pydantic.Field(None, description='')
    user_pool_id: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnGraphQLApiDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnGraphQLApiDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnGraphQLApiDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnGraphQLApiDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnGraphQLApiDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnGraphQLApiDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnGraphQLApiDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnGraphQLApiDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnGraphQLApiDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnGraphQLApiDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnGraphQLApiDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnGraphQLApiDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnGraphQLApiDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnGraphQLApiDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_appsync.CfnGraphQLSchema
class CfnGraphQLSchemaDef(BaseCfnResource):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS AppSync GraphQL API identifier to which you want to apply this schema.\n')
    definition: typing.Optional[str] = pydantic.Field(None, description='The text representation of a GraphQL schema in SDL format. For more information about using the ``Ref`` function, see `Ref <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-ref>`_ .\n')
    definition_s3_location: typing.Optional[str] = pydantic.Field(None, description='The location of a GraphQL schema file in an Amazon S3 bucket. Use this if you want to provision with the schema living in Amazon S3 rather than embedding it in your CloudFormation template.')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'definition', 'definition_s3_location']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnGraphQLSchema'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.CfnGraphQLSchemaDefConfig] = pydantic.Field(None)


class CfnGraphQLSchemaDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_appsync.CfnGraphQLSchemaDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnGraphQLSchemaDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnGraphQLSchemaDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnGraphQLSchemaDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnGraphQLSchemaDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnGraphQLSchemaDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnGraphQLSchemaDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnGraphQLSchemaDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnGraphQLSchemaDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnGraphQLSchemaDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnGraphQLSchemaDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnGraphQLSchemaDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnGraphQLSchemaDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnGraphQLSchemaDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnGraphQLSchemaDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_appsync.CfnResolver
class CfnResolverDef(BaseCfnResource):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS AppSync GraphQL API to which you want to attach this resolver.\n')
    field_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The GraphQL field on a type that invokes the resolver.\n')
    type_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The GraphQL type that invokes this resolver.\n')
    caching_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnResolver_CachingConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for the resolver.\n')
    code: typing.Optional[str] = pydantic.Field(None, description='The ``resolver`` code that contains the request and response functions. When code is used, the ``runtime`` is required. The runtime value must be ``APPSYNC_JS`` .\n')
    code_s3_location: typing.Optional[str] = pydantic.Field(None, description='The Amazon S3 endpoint.\n')
    data_source_name: typing.Optional[str] = pydantic.Field(None, description='The resolver data source name.\n')
    kind: typing.Optional[str] = pydantic.Field(None, description='The resolver type. - *UNIT* : A UNIT resolver type. A UNIT resolver is the default resolver type. You can use a UNIT resolver to run a GraphQL query against a single data source. - *PIPELINE* : A PIPELINE resolver type. You can use a PIPELINE resolver to invoke a series of ``Function`` objects in a serial manner. You can use a pipeline resolver to run a GraphQL query against multiple data sources.\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a ``BatchInvoke`` operation.\n')
    metrics_config: typing.Optional[str] = pydantic.Field(None, description="Enables or disables enhanced resolver metrics for specified resolvers. Note that ``MetricsConfig`` won't be used unless the ``resolverLevelMetricsBehavior`` value is set to ``PER_RESOLVER_METRICS`` . If the ``resolverLevelMetricsBehavior`` is set to ``FULL_REQUEST_RESOLVER_METRICS`` instead, ``MetricsConfig`` will be ignored. However, you can still set its value.\n")
    pipeline_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnResolver_PipelineConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Functions linked with the pipeline resolver.\n')
    request_mapping_template: typing.Optional[str] = pydantic.Field(None, description='The request mapping template. Request mapping templates are optional when using a Lambda data source. For all other data sources, a request mapping template is required.\n')
    request_mapping_template_s3_location: typing.Optional[str] = pydantic.Field(None, description='The location of a request mapping template in an Amazon S3 bucket. Use this if you want to provision with a template file in Amazon S3 rather than embedding it in your CloudFormation template.\n')
    response_mapping_template: typing.Optional[str] = pydantic.Field(None, description='The response mapping template.\n')
    response_mapping_template_s3_location: typing.Optional[str] = pydantic.Field(None, description='The location of a response mapping template in an Amazon S3 bucket. Use this if you want to provision with a template file in Amazon S3 rather than embedding it in your CloudFormation template.\n')
    runtime: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnResolver_AppSyncRuntimePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes a runtime used by an AWS AppSync resolver or AWS AppSync function. Specifies the name and version of the runtime to use. Note that if a runtime is specified, code must also be specified.\n')
    sync_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnResolver_SyncConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The ``SyncConfig`` for a resolver attached to a versioned data source.')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'field_name', 'type_name', 'caching_config', 'code', 'code_s3_location', 'data_source_name', 'kind', 'max_batch_size', 'metrics_config', 'pipeline_config', 'request_mapping_template', 'request_mapping_template_s3_location', 'response_mapping_template', 'response_mapping_template_s3_location', 'runtime', 'sync_config']
    _method_names: typing.ClassVar[list[str]] = ['AppSyncRuntimeProperty', 'CachingConfigProperty', 'LambdaConflictHandlerConfigProperty', 'PipelineConfigProperty', 'SyncConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnResolver'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.CfnResolverDefConfig] = pydantic.Field(None)


class CfnResolverDefConfig(pydantic.BaseModel):
    AppSyncRuntimeProperty: typing.Optional[list[models.aws_appsync.CfnResolverDefAppsyncruntimepropertyParams]] = pydantic.Field(None, description='')
    CachingConfigProperty: typing.Optional[list[models.aws_appsync.CfnResolverDefCachingconfigpropertyParams]] = pydantic.Field(None, description='')
    LambdaConflictHandlerConfigProperty: typing.Optional[list[models.aws_appsync.CfnResolverDefLambdaconflicthandlerconfigpropertyParams]] = pydantic.Field(None, description='')
    PipelineConfigProperty: typing.Optional[list[models.aws_appsync.CfnResolverDefPipelineconfigpropertyParams]] = pydantic.Field(None, description='')
    SyncConfigProperty: typing.Optional[list[models.aws_appsync.CfnResolverDefSyncconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_appsync.CfnResolverDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_appsync.CfnResolverDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_appsync.CfnResolverDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_appsync.CfnResolverDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_appsync.CfnResolverDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_appsync.CfnResolverDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_appsync.CfnResolverDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_appsync.CfnResolverDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_appsync.CfnResolverDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_appsync.CfnResolverDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_appsync.CfnResolverDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_appsync.CfnResolverDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_appsync.CfnResolverDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnResolverDefAppsyncruntimepropertyParams(pydantic.BaseModel):
    name: str = pydantic.Field(..., description='')
    runtime_version: str = pydantic.Field(..., description='')
    ...

class CfnResolverDefCachingconfigpropertyParams(pydantic.BaseModel):
    ttl: typing.Union[int, float] = pydantic.Field(..., description='')
    caching_keys: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnResolverDefLambdaconflicthandlerconfigpropertyParams(pydantic.BaseModel):
    lambda_conflict_handler_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnResolverDefPipelineconfigpropertyParams(pydantic.BaseModel):
    functions: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnResolverDefSyncconfigpropertyParams(pydantic.BaseModel):
    conflict_detection: str = pydantic.Field(..., description='')
    conflict_handler: typing.Optional[str] = pydantic.Field(None, description='')
    lambda_conflict_handler_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnResolver_LambdaConflictHandlerConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnResolverDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnResolverDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnResolverDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnResolverDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnResolverDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnResolverDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnResolverDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnResolverDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnResolverDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnResolverDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnResolverDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnResolverDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnResolverDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnResolverDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_appsync.CfnSourceApiAssociation
class CfnSourceApiAssociationDef(BaseCfnResource):
    description: typing.Optional[str] = pydantic.Field(None, description='The description field of the association configuration.\n')
    merged_api_identifier: typing.Optional[str] = pydantic.Field(None, description='The identifier of the AppSync Merged API. This is generated by the AppSync service. In most cases, Merged APIs (especially in your account) only require the API ID value or ARN of the merged API. However, Merged APIs from other accounts (cross-account use cases) strictly require the full resource ARN of the merged API.\n')
    source_api_association_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnSourceApiAssociation_SourceApiAssociationConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The ``SourceApiAssociationConfig`` object data.\n')
    source_api_identifier: typing.Optional[str] = pydantic.Field(None, description='The identifier of the AppSync Source API. This is generated by the AppSync service. In most cases, source APIs (especially in your account) only require the API ID value or ARN of the source API. However, source APIs from other accounts (cross-account use cases) strictly require the full resource ARN of the source API.')
    _init_params: typing.ClassVar[list[str]] = ['description', 'merged_api_identifier', 'source_api_association_config', 'source_api_identifier']
    _method_names: typing.ClassVar[list[str]] = ['SourceApiAssociationConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnSourceApiAssociation'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_appsync.CfnSourceApiAssociationDefConfig] = pydantic.Field(None)


class CfnSourceApiAssociationDefConfig(pydantic.BaseModel):
    SourceApiAssociationConfigProperty: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefSourceapiassociationconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_appsync.CfnSourceApiAssociationDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnSourceApiAssociationDefSourceapiassociationconfigpropertyParams(pydantic.BaseModel):
    merge_type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnSourceApiAssociationDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnSourceApiAssociationDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnSourceApiAssociationDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnSourceApiAssociationDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnSourceApiAssociationDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnSourceApiAssociationDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnSourceApiAssociationDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnSourceApiAssociationDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnSourceApiAssociationDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnSourceApiAssociationDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnSourceApiAssociationDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnSourceApiAssociationDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnSourceApiAssociationDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnSourceApiAssociationDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_appsync.CfnApiCacheProps
class CfnApiCachePropsDef(BaseCfnProperty):
    api_caching_behavior: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Caching behavior. - *FULL_REQUEST_CACHING* : All requests are fully cached. - *PER_RESOLVER_CACHING* : Individual resolvers that you specify are cached.\n')
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The GraphQL API ID.\n')
    ttl: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='TTL in seconds for cache entries. Valid values are 1–3,600 seconds.\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The cache instance type. Valid values are. - ``SMALL`` - ``MEDIUM`` - ``LARGE`` - ``XLARGE`` - ``LARGE_2X`` - ``LARGE_4X`` - ``LARGE_8X`` (not available in all regions) - ``LARGE_12X`` Historically, instance types were identified by an EC2-style value. As of July 2020, this is deprecated, and the generic identifiers above should be used. The following legacy instance types are available, but their use is discouraged: - *T2_SMALL* : A t2.small instance type. - *T2_MEDIUM* : A t2.medium instance type. - *R4_LARGE* : A r4.large instance type. - *R4_XLARGE* : A r4.xlarge instance type. - *R4_2XLARGE* : A r4.2xlarge instance type. - *R4_4XLARGE* : A r4.4xlarge instance type. - *R4_8XLARGE* : A r4.8xlarge instance type.\n')
    at_rest_encryption_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='At-rest encryption flag for cache. You cannot update this setting after creation.\n')
    health_metrics_config: typing.Optional[str] = pydantic.Field(None, description='Controls how cache health metrics will be emitted to CloudWatch. Cache health metrics include:. - *NetworkBandwidthOutAllowanceExceeded* : The network packets dropped because the throughput exceeded the aggregated bandwidth limit. This is useful for diagnosing bottlenecks in a cache configuration. - *EngineCPUUtilization* : The CPU utilization (percentage) allocated to the Redis process. This is useful for diagnosing bottlenecks in a cache configuration. Metrics will be recorded by API ID. You can set the value to ``ENABLED`` or ``DISABLED`` .\n')
    transit_encryption_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Transit encryption flag when connecting to cache. You cannot update this setting after creation.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-apicache.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    cfn_api_cache_props = appsync.CfnApiCacheProps(\n        api_caching_behavior="apiCachingBehavior",\n        api_id="apiId",\n        ttl=123,\n        type="type",\n\n        # the properties below are optional\n        at_rest_encryption_enabled=False,\n        health_metrics_config="healthMetricsConfig",\n        transit_encryption_enabled=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api_caching_behavior', 'api_id', 'ttl', 'type', 'at_rest_encryption_enabled', 'health_metrics_config', 'transit_encryption_enabled']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnApiCacheProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnApiKeyProps
class CfnApiKeyPropsDef(BaseCfnProperty):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Unique AWS AppSync GraphQL API ID for this API key.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='Unique description of your API key.\n')
    expires: typing.Union[int, float, None] = pydantic.Field(None, description='The time after which the API key expires. The date is represented as seconds since the epoch, rounded down to the nearest hour.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-apikey.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    cfn_api_key_props = appsync.CfnApiKeyProps(\n        api_id="apiId",\n\n        # the properties below are optional\n        description="description",\n        expires=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'description', 'expires']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnApiKeyProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDataSourceProps
class CfnDataSourcePropsDef(BaseCfnProperty):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Unique AWS AppSync GraphQL API identifier where this data source will be created.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Friendly name for you to identify your AppSync data source after creation.\n')
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The type of the data source. - *AWS_LAMBDA* : The data source is an AWS Lambda function. - *AMAZON_DYNAMODB* : The data source is an Amazon DynamoDB table. - *AMAZON_ELASTICSEARCH* : The data source is an Amazon OpenSearch Service domain. - *AMAZON_EVENTBRIDGE* : The data source is an Amazon EventBridge event bus. - *AMAZON_OPENSEARCH_SERVICE* : The data source is an Amazon OpenSearch Service domain. - *NONE* : There is no data source. This type is used when you wish to invoke a GraphQL operation without connecting to a data source, such as performing data transformation with resolvers or triggering a subscription to be invoked from a mutation. - *HTTP* : The data source is an HTTP endpoint. - *RELATIONAL_DATABASE* : The data source is a relational database.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The description of the data source.\n')
    dynamo_db_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_DynamoDBConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='AWS Region and TableName for an Amazon DynamoDB table in your account.\n')
    elasticsearch_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_ElasticsearchConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='AWS Region and Endpoints for an Amazon OpenSearch Service domain in your account. As of September 2021, Amazon Elasticsearch Service is Amazon OpenSearch Service . This property is deprecated. For new data sources, use *OpenSearchServiceConfig* to specify an OpenSearch Service data source.\n')
    event_bridge_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_EventBridgeConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An EventBridge configuration that contains a valid ARN of an event bus.\n')
    http_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_HttpConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Endpoints for an HTTP data source.\n')
    lambda_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_LambdaConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An ARN of a Lambda function in valid ARN format. This can be the ARN of a Lambda function that exists in the current account or in another account.\n')
    metrics_config: typing.Optional[str] = pydantic.Field(None, description="Enables or disables enhanced data source metrics for specified data sources. Note that ``MetricsConfig`` won't be used unless the ``dataSourceLevelMetricsBehavior`` value is set to ``PER_DATA_SOURCE_METRICS`` . If the ``dataSourceLevelMetricsBehavior`` is set to ``FULL_REQUEST_DATA_SOURCE_METRICS`` instead, ``MetricsConfig`` will be ignored. However, you can still set its value. ``MetricsConfig`` can be ``ENABLED`` or ``DISABLED`` .\n")
    open_search_service_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_OpenSearchServiceConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='AWS Region and Endpoints for an Amazon OpenSearch Service domain in your account.\n')
    relational_database_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnDataSource_RelationalDatabaseConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Relational Database configuration of the relational database data source.\n')
    service_role_arn: typing.Optional[str] = pydantic.Field(None, description='The AWS Identity and Access Management service role ARN for the data source. The system assumes this role when accessing the data source. Required if ``Type`` is specified as ``AWS_LAMBDA`` , ``AMAZON_DYNAMODB`` , ``AMAZON_ELASTICSEARCH`` , ``AMAZON_EVENTBRIDGE`` , or ``AMAZON_OPENSEARCH_SERVICE`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-datasource.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    cfn_data_source_props = appsync.CfnDataSourceProps(\n        api_id="apiId",\n        name="name",\n        type="type",\n\n        # the properties below are optional\n        description="description",\n        dynamo_db_config=appsync.CfnDataSource.DynamoDBConfigProperty(\n            aws_region="awsRegion",\n            table_name="tableName",\n\n            # the properties below are optional\n            delta_sync_config=appsync.CfnDataSource.DeltaSyncConfigProperty(\n                base_table_ttl="baseTableTtl",\n                delta_sync_table_name="deltaSyncTableName",\n                delta_sync_table_ttl="deltaSyncTableTtl"\n            ),\n            use_caller_credentials=False,\n            versioned=False\n        ),\n        elasticsearch_config=appsync.CfnDataSource.ElasticsearchConfigProperty(\n            aws_region="awsRegion",\n            endpoint="endpoint"\n        ),\n        event_bridge_config=appsync.CfnDataSource.EventBridgeConfigProperty(\n            event_bus_arn="eventBusArn"\n        ),\n        http_config=appsync.CfnDataSource.HttpConfigProperty(\n            endpoint="endpoint",\n\n            # the properties below are optional\n            authorization_config=appsync.CfnDataSource.AuthorizationConfigProperty(\n                authorization_type="authorizationType",\n\n                # the properties below are optional\n                aws_iam_config=appsync.CfnDataSource.AwsIamConfigProperty(\n                    signing_region="signingRegion",\n                    signing_service_name="signingServiceName"\n                )\n            )\n        ),\n        lambda_config=appsync.CfnDataSource.LambdaConfigProperty(\n            lambda_function_arn="lambdaFunctionArn"\n        ),\n        metrics_config="metricsConfig",\n        open_search_service_config=appsync.CfnDataSource.OpenSearchServiceConfigProperty(\n            aws_region="awsRegion",\n            endpoint="endpoint"\n        ),\n        relational_database_config=appsync.CfnDataSource.RelationalDatabaseConfigProperty(\n            relational_database_source_type="relationalDatabaseSourceType",\n\n            # the properties below are optional\n            rds_http_endpoint_config=appsync.CfnDataSource.RdsHttpEndpointConfigProperty(\n                aws_region="awsRegion",\n                aws_secret_store_arn="awsSecretStoreArn",\n                db_cluster_identifier="dbClusterIdentifier",\n\n                # the properties below are optional\n                database_name="databaseName",\n                schema="schema"\n            )\n        ),\n        service_role_arn="serviceRoleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'name', 'type', 'description', 'dynamo_db_config', 'elasticsearch_config', 'event_bridge_config', 'http_config', 'lambda_config', 'metrics_config', 'open_search_service_config', 'relational_database_config', 'service_role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDataSourceProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDomainNameApiAssociationProps
class CfnDomainNameApiAssociationPropsDef(BaseCfnProperty):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API ID.\n')
    domain_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The domain name.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-domainnameapiassociation.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    cfn_domain_name_api_association_props = appsync.CfnDomainNameApiAssociationProps(\n        api_id="apiId",\n        domain_name="domainName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'domain_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDomainNameApiAssociationProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnDomainNameProps
class CfnDomainNamePropsDef(BaseCfnProperty):
    certificate_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the certificate. This will be an AWS Certificate Manager certificate.\n')
    domain_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The domain name.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The decription for your domain name.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-domainname.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    cfn_domain_name_props = appsync.CfnDomainNameProps(\n        certificate_arn="certificateArn",\n        domain_name="domainName",\n\n        # the properties below are optional\n        description="description"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['certificate_arn', 'domain_name', 'description']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnDomainNameProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnFunctionConfigurationProps
class CfnFunctionConfigurationPropsDef(BaseCfnProperty):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS AppSync GraphQL API that you want to attach using this function.\n')
    data_source_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of data source this function will attach.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the function.\n')
    code: typing.Optional[str] = pydantic.Field(None, description='The ``resolver`` code that contains the request and response functions. When code is used, the ``runtime`` is required. The runtime value must be ``APPSYNC_JS`` .\n')
    code_s3_location: typing.Optional[str] = pydantic.Field(None, description='The Amazon S3 endpoint.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='The ``Function`` description.\n')
    function_version: typing.Optional[str] = pydantic.Field(None, description='The version of the request mapping template. Currently, only the 2018-05-29 version of the template is supported.\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a ``BatchInvoke`` operation.\n')
    request_mapping_template: typing.Optional[str] = pydantic.Field(None, description='The ``Function`` request mapping template. Functions support only the 2018-05-29 version of the request mapping template.\n')
    request_mapping_template_s3_location: typing.Optional[str] = pydantic.Field(None, description='Describes a Sync configuration for a resolver. Contains information on which Conflict Detection, as well as Resolution strategy, should be performed when the resolver is invoked.\n')
    response_mapping_template: typing.Optional[str] = pydantic.Field(None, description='The ``Function`` response mapping template.\n')
    response_mapping_template_s3_location: typing.Optional[str] = pydantic.Field(None, description='The location of a response mapping template in an Amazon S3 bucket. Use this if you want to provision with a template file in Amazon S3 rather than embedding it in your CloudFormation template.\n')
    runtime: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnFunctionConfiguration_AppSyncRuntimePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes a runtime used by an AWS AppSync resolver or AWS AppSync function. Specifies the name and version of the runtime to use. Note that if a runtime is specified, code must also be specified.\n')
    sync_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnFunctionConfiguration_SyncConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes a Sync configuration for a resolver. Specifies which Conflict Detection strategy and Resolution strategy to use when the resolver is invoked.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-functionconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    cfn_function_configuration_props = appsync.CfnFunctionConfigurationProps(\n        api_id="apiId",\n        data_source_name="dataSourceName",\n        name="name",\n\n        # the properties below are optional\n        code="code",\n        code_s3_location="codeS3Location",\n        description="description",\n        function_version="functionVersion",\n        max_batch_size=123,\n        request_mapping_template="requestMappingTemplate",\n        request_mapping_template_s3_location="requestMappingTemplateS3Location",\n        response_mapping_template="responseMappingTemplate",\n        response_mapping_template_s3_location="responseMappingTemplateS3Location",\n        runtime=appsync.CfnFunctionConfiguration.AppSyncRuntimeProperty(\n            name="name",\n            runtime_version="runtimeVersion"\n        ),\n        sync_config=appsync.CfnFunctionConfiguration.SyncConfigProperty(\n            conflict_detection="conflictDetection",\n\n            # the properties below are optional\n            conflict_handler="conflictHandler",\n            lambda_conflict_handler_config=appsync.CfnFunctionConfiguration.LambdaConflictHandlerConfigProperty(\n                lambda_conflict_handler_arn="lambdaConflictHandlerArn"\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'data_source_name', 'name', 'code', 'code_s3_location', 'description', 'function_version', 'max_batch_size', 'request_mapping_template', 'request_mapping_template_s3_location', 'response_mapping_template', 'response_mapping_template_s3_location', 'runtime', 'sync_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnFunctionConfigurationProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnGraphQLApiProps
class CfnGraphQLApiPropsDef(BaseCfnProperty):
    authentication_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Security configuration for your GraphQL API. For allowed values (such as ``API_KEY`` , ``AWS_IAM`` , ``AMAZON_COGNITO_USER_POOLS`` , ``OPENID_CONNECT`` , or ``AWS_LAMBDA`` ), see `Security <https://docs.aws.amazon.com/appsync/latest/devguide/security.html>`_ in the *AWS AppSync Developer Guide* .\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The API name.\n')
    additional_authentication_providers: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_AdditionalAuthenticationProviderPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A list of additional authentication providers for the ``GraphqlApi`` API.\n')
    api_type: typing.Optional[str] = pydantic.Field(None, description='The value that indicates whether the GraphQL API is a standard API ( ``GRAPHQL`` ) or merged API ( ``MERGED`` ). *WARNING* : If the ``ApiType`` has not been defined, *explicitly* setting it to ``GRAPHQL`` in a template/stack update will result in an API replacement and new DNS values. The following values are valid: ``GRAPHQL | MERGED``\n')
    enhanced_metrics_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_EnhancedMetricsConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Enables and controls the enhanced metrics feature. Enhanced metrics emit granular data on API usage and performance such as AppSync request and error counts, latency, and cache hits/misses. All enhanced metric data is sent to your CloudWatch account, and you can configure the types of data that will be sent. Enhanced metrics can be configured at the resolver, data source, and operation levels. For more information, see `Monitoring and logging <https://docs.aws.amazon.com//appsync/latest/devguide/monitoring.html#cw-metrics>`_ in the *AWS AppSync User Guide* .\n')
    environment_variables: typing.Any = pydantic.Field(None, description='A map containing the list of resources with their properties and environment variables. For more information, see `Environmental variables <https://docs.aws.amazon.com/appsync/latest/devguide/environmental-variables.html>`_ . *Pattern* : ``^[A-Za-z]+\\\\w*$\\\\`` *Minimum* : 2 *Maximum* : 64\n')
    introspection_config: typing.Optional[str] = pydantic.Field(None, description='Sets the value of the GraphQL API to enable ( ``ENABLED`` ) or disable ( ``DISABLED`` ) introspection. If no value is provided, the introspection configuration will be set to ``ENABLED`` by default. This field will produce an error if the operation attempts to use the introspection feature while this field is disabled. For more information about introspection, see `GraphQL introspection <https://docs.aws.amazon.com/https://graphql.org/learn/introspection/>`_ .\n')
    lambda_authorizer_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_LambdaAuthorizerConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A ``LambdaAuthorizerConfig`` holds configuration on how to authorize AWS AppSync API access when using the ``AWS_LAMBDA`` authorizer mode. Be aware that an AWS AppSync API may have only one Lambda authorizer configured at a time.\n')
    log_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_LogConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Amazon CloudWatch Logs configuration.\n')
    merged_api_execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The AWS Identity and Access Management service role ARN for a merged API. The AppSync service assumes this role on behalf of the Merged API to validate access to source APIs at runtime and to prompt the ``AUTO_MERGE`` to update the merged API endpoint with the source API changes automatically.\n')
    open_id_connect_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_OpenIDConnectConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The OpenID Connect configuration.\n')
    owner_contact: typing.Optional[str] = pydantic.Field(None, description='The owner contact information for an API resource. This field accepts any string input with a length of 0 - 256 characters.\n')
    query_depth_limit: typing.Union[int, float, None] = pydantic.Field(None, description="The maximum depth a query can have in a single request. Depth refers to the amount of nested levels allowed in the body of query. The default value is ``0`` (or unspecified), which indicates there's no depth limit. If you set a limit, it can be between ``1`` and ``75`` nested levels. This field will produce a limit error if the operation falls out of bounds. Note that fields can still be set to nullable or non-nullable. If a non-nullable field produces an error, the error will be thrown upwards to the first nullable field available.\n")
    resolver_count_limit: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolvers that can be invoked in a single request. The default value is ``0`` (or unspecified), which will set the limit to ``10000`` . When specified, the limit value can be between ``1`` and ``10000`` . This field will produce a limit error if the operation falls out of bounds.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='An arbitrary set of tags (key-value pairs) for this GraphQL API.\n')
    user_pool_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnGraphQLApi_UserPoolConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Optional authorization configuration for using Amazon Cognito user pools with your GraphQL endpoint.\n')
    visibility: typing.Optional[str] = pydantic.Field(None, description='Sets the scope of the GraphQL API to public ( ``GLOBAL`` ) or private ( ``PRIVATE`` ). By default, the scope is set to ``Global`` if no value is provided. *WARNING* : If ``Visibility`` has not been defined, *explicitly* setting it to ``GLOBAL`` in a template/stack update will result in an API replacement and new DNS values.\n')
    xray_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='A flag indicating whether to use AWS X-Ray tracing for this ``GraphqlApi`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-graphqlapi.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    # environment_variables: Any\n\n    cfn_graph_qLApi_props = appsync.CfnGraphQLApiProps(\n        authentication_type="authenticationType",\n        name="name",\n\n        # the properties below are optional\n        additional_authentication_providers=[appsync.CfnGraphQLApi.AdditionalAuthenticationProviderProperty(\n            authentication_type="authenticationType",\n\n            # the properties below are optional\n            lambda_authorizer_config=appsync.CfnGraphQLApi.LambdaAuthorizerConfigProperty(\n                authorizer_result_ttl_in_seconds=123,\n                authorizer_uri="authorizerUri",\n                identity_validation_expression="identityValidationExpression"\n            ),\n            open_id_connect_config=appsync.CfnGraphQLApi.OpenIDConnectConfigProperty(\n                auth_ttl=123,\n                client_id="clientId",\n                iat_ttl=123,\n                issuer="issuer"\n            ),\n            user_pool_config=appsync.CfnGraphQLApi.CognitoUserPoolConfigProperty(\n                app_id_client_regex="appIdClientRegex",\n                aws_region="awsRegion",\n                user_pool_id="userPoolId"\n            )\n        )],\n        api_type="apiType",\n        enhanced_metrics_config=appsync.CfnGraphQLApi.EnhancedMetricsConfigProperty(\n            data_source_level_metrics_behavior="dataSourceLevelMetricsBehavior",\n            operation_level_metrics_config="operationLevelMetricsConfig",\n            resolver_level_metrics_behavior="resolverLevelMetricsBehavior"\n        ),\n        environment_variables=environment_variables,\n        introspection_config="introspectionConfig",\n        lambda_authorizer_config=appsync.CfnGraphQLApi.LambdaAuthorizerConfigProperty(\n            authorizer_result_ttl_in_seconds=123,\n            authorizer_uri="authorizerUri",\n            identity_validation_expression="identityValidationExpression"\n        ),\n        log_config=appsync.CfnGraphQLApi.LogConfigProperty(\n            cloud_watch_logs_role_arn="cloudWatchLogsRoleArn",\n            exclude_verbose_content=False,\n            field_log_level="fieldLogLevel"\n        ),\n        merged_api_execution_role_arn="mergedApiExecutionRoleArn",\n        open_id_connect_config=appsync.CfnGraphQLApi.OpenIDConnectConfigProperty(\n            auth_ttl=123,\n            client_id="clientId",\n            iat_ttl=123,\n            issuer="issuer"\n        ),\n        owner_contact="ownerContact",\n        query_depth_limit=123,\n        resolver_count_limit=123,\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        user_pool_config=appsync.CfnGraphQLApi.UserPoolConfigProperty(\n            app_id_client_regex="appIdClientRegex",\n            aws_region="awsRegion",\n            default_action="defaultAction",\n            user_pool_id="userPoolId"\n        ),\n        visibility="visibility",\n        xray_enabled=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['authentication_type', 'name', 'additional_authentication_providers', 'api_type', 'enhanced_metrics_config', 'environment_variables', 'introspection_config', 'lambda_authorizer_config', 'log_config', 'merged_api_execution_role_arn', 'open_id_connect_config', 'owner_contact', 'query_depth_limit', 'resolver_count_limit', 'tags', 'user_pool_config', 'visibility', 'xray_enabled']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnGraphQLApiProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnGraphQLSchemaProps
class CfnGraphQLSchemaPropsDef(BaseCfnProperty):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS AppSync GraphQL API identifier to which you want to apply this schema.\n')
    definition: typing.Optional[str] = pydantic.Field(None, description='The text representation of a GraphQL schema in SDL format. For more information about using the ``Ref`` function, see `Ref <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-ref>`_ .\n')
    definition_s3_location: typing.Optional[str] = pydantic.Field(None, description='The location of a GraphQL schema file in an Amazon S3 bucket. Use this if you want to provision with the schema living in Amazon S3 rather than embedding it in your CloudFormation template.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-graphqlschema.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    cfn_graph_qLSchema_props = appsync.CfnGraphQLSchemaProps(\n        api_id="apiId",\n\n        # the properties below are optional\n        definition="definition",\n        definition_s3_location="definitionS3Location"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'definition', 'definition_s3_location']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnGraphQLSchemaProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnResolverProps
class CfnResolverPropsDef(BaseCfnProperty):
    api_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS AppSync GraphQL API to which you want to attach this resolver.\n')
    field_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The GraphQL field on a type that invokes the resolver.\n')
    type_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The GraphQL type that invokes this resolver.\n')
    caching_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnResolver_CachingConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The caching configuration for the resolver.\n')
    code: typing.Optional[str] = pydantic.Field(None, description='The ``resolver`` code that contains the request and response functions. When code is used, the ``runtime`` is required. The runtime value must be ``APPSYNC_JS`` .\n')
    code_s3_location: typing.Optional[str] = pydantic.Field(None, description='The Amazon S3 endpoint.\n')
    data_source_name: typing.Optional[str] = pydantic.Field(None, description='The resolver data source name.\n')
    kind: typing.Optional[str] = pydantic.Field(None, description='The resolver type. - *UNIT* : A UNIT resolver type. A UNIT resolver is the default resolver type. You can use a UNIT resolver to run a GraphQL query against a single data source. - *PIPELINE* : A PIPELINE resolver type. You can use a PIPELINE resolver to invoke a series of ``Function`` objects in a serial manner. You can use a pipeline resolver to run a GraphQL query against multiple data sources.\n')
    max_batch_size: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of resolver request inputs that will be sent to a single AWS Lambda function in a ``BatchInvoke`` operation.\n')
    metrics_config: typing.Optional[str] = pydantic.Field(None, description="Enables or disables enhanced resolver metrics for specified resolvers. Note that ``MetricsConfig`` won't be used unless the ``resolverLevelMetricsBehavior`` value is set to ``PER_RESOLVER_METRICS`` . If the ``resolverLevelMetricsBehavior`` is set to ``FULL_REQUEST_RESOLVER_METRICS`` instead, ``MetricsConfig`` will be ignored. However, you can still set its value.\n")
    pipeline_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnResolver_PipelineConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Functions linked with the pipeline resolver.\n')
    request_mapping_template: typing.Optional[str] = pydantic.Field(None, description='The request mapping template. Request mapping templates are optional when using a Lambda data source. For all other data sources, a request mapping template is required.\n')
    request_mapping_template_s3_location: typing.Optional[str] = pydantic.Field(None, description='The location of a request mapping template in an Amazon S3 bucket. Use this if you want to provision with a template file in Amazon S3 rather than embedding it in your CloudFormation template.\n')
    response_mapping_template: typing.Optional[str] = pydantic.Field(None, description='The response mapping template.\n')
    response_mapping_template_s3_location: typing.Optional[str] = pydantic.Field(None, description='The location of a response mapping template in an Amazon S3 bucket. Use this if you want to provision with a template file in Amazon S3 rather than embedding it in your CloudFormation template.\n')
    runtime: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnResolver_AppSyncRuntimePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes a runtime used by an AWS AppSync resolver or AWS AppSync function. Specifies the name and version of the runtime to use. Note that if a runtime is specified, code must also be specified.\n')
    sync_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnResolver_SyncConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The ``SyncConfig`` for a resolver attached to a versioned data source.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-resolver.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    cfn_resolver_props = appsync.CfnResolverProps(\n        api_id="apiId",\n        field_name="fieldName",\n        type_name="typeName",\n\n        # the properties below are optional\n        caching_config=appsync.CfnResolver.CachingConfigProperty(\n            ttl=123,\n\n            # the properties below are optional\n            caching_keys=["cachingKeys"]\n        ),\n        code="code",\n        code_s3_location="codeS3Location",\n        data_source_name="dataSourceName",\n        kind="kind",\n        max_batch_size=123,\n        metrics_config="metricsConfig",\n        pipeline_config=appsync.CfnResolver.PipelineConfigProperty(\n            functions=["functions"]\n        ),\n        request_mapping_template="requestMappingTemplate",\n        request_mapping_template_s3_location="requestMappingTemplateS3Location",\n        response_mapping_template="responseMappingTemplate",\n        response_mapping_template_s3_location="responseMappingTemplateS3Location",\n        runtime=appsync.CfnResolver.AppSyncRuntimeProperty(\n            name="name",\n            runtime_version="runtimeVersion"\n        ),\n        sync_config=appsync.CfnResolver.SyncConfigProperty(\n            conflict_detection="conflictDetection",\n\n            # the properties below are optional\n            conflict_handler="conflictHandler",\n            lambda_conflict_handler_config=appsync.CfnResolver.LambdaConflictHandlerConfigProperty(\n                lambda_conflict_handler_arn="lambdaConflictHandlerArn"\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['api_id', 'field_name', 'type_name', 'caching_config', 'code', 'code_s3_location', 'data_source_name', 'kind', 'max_batch_size', 'metrics_config', 'pipeline_config', 'request_mapping_template', 'request_mapping_template_s3_location', 'response_mapping_template', 'response_mapping_template_s3_location', 'runtime', 'sync_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnResolverProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_appsync.CfnSourceApiAssociationProps
class CfnSourceApiAssociationPropsDef(BaseCfnProperty):
    description: typing.Optional[str] = pydantic.Field(None, description='The description field of the association configuration.\n')
    merged_api_identifier: typing.Optional[str] = pydantic.Field(None, description='The identifier of the AppSync Merged API. This is generated by the AppSync service. In most cases, Merged APIs (especially in your account) only require the API ID value or ARN of the merged API. However, Merged APIs from other accounts (cross-account use cases) strictly require the full resource ARN of the merged API.\n')
    source_api_association_config: typing.Union[models.UnsupportedResource, models.aws_appsync.CfnSourceApiAssociation_SourceApiAssociationConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The ``SourceApiAssociationConfig`` object data.\n')
    source_api_identifier: typing.Optional[str] = pydantic.Field(None, description='The identifier of the AppSync Source API. This is generated by the AppSync service. In most cases, source APIs (especially in your account) only require the API ID value or ARN of the source API. However, source APIs from other accounts (cross-account use cases) strictly require the full resource ARN of the source API.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-appsync-sourceapiassociation.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_appsync as appsync\n\n    cfn_source_api_association_props = appsync.CfnSourceApiAssociationProps(\n        description="description",\n        merged_api_identifier="mergedApiIdentifier",\n        source_api_association_config=appsync.CfnSourceApiAssociation.SourceApiAssociationConfigProperty(\n            merge_type="mergeType"\n        ),\n        source_api_identifier="sourceApiIdentifier"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['description', 'merged_api_identifier', 'source_api_association_config', 'source_api_identifier']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_appsync.CfnSourceApiAssociationProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




class ModuleModel(pydantic.BaseModel):
    AssetCode: typing.Optional[dict[str, models.aws_appsync.AssetCodeDef]] = pydantic.Field(None)
    Assign: typing.Optional[dict[str, models.aws_appsync.AssignDef]] = pydantic.Field(None)
    AttributeValues: typing.Optional[dict[str, models.aws_appsync.AttributeValuesDef]] = pydantic.Field(None)
    AttributeValuesStep: typing.Optional[dict[str, models.aws_appsync.AttributeValuesStepDef]] = pydantic.Field(None)
    BackedDataSource: typing.Optional[dict[str, models.aws_appsync.BackedDataSourceDef]] = pydantic.Field(None)
    BaseDataSource: typing.Optional[dict[str, models.aws_appsync.BaseDataSourceDef]] = pydantic.Field(None)
    Code: typing.Optional[dict[str, models.aws_appsync.CodeDef]] = pydantic.Field(None)
    Definition: typing.Optional[dict[str, models.aws_appsync.DefinitionDef]] = pydantic.Field(None)
    FunctionRuntime: typing.Optional[dict[str, models.aws_appsync.FunctionRuntimeDef]] = pydantic.Field(None)
    GraphqlApiBase: typing.Optional[dict[str, models.aws_appsync.GraphqlApiBaseDef]] = pydantic.Field(None)
    IamResource: typing.Optional[dict[str, models.aws_appsync.IamResourceDef]] = pydantic.Field(None)
    InlineCode: typing.Optional[dict[str, models.aws_appsync.InlineCodeDef]] = pydantic.Field(None)
    KeyCondition: typing.Optional[dict[str, models.aws_appsync.KeyConditionDef]] = pydantic.Field(None)
    MappingTemplate: typing.Optional[dict[str, models.aws_appsync.MappingTemplateDef]] = pydantic.Field(None)
    PartitionKey: typing.Optional[dict[str, models.aws_appsync.PartitionKeyDef]] = pydantic.Field(None)
    PartitionKeyStep: typing.Optional[dict[str, models.aws_appsync.PartitionKeyStepDef]] = pydantic.Field(None)
    PrimaryKey: typing.Optional[dict[str, models.aws_appsync.PrimaryKeyDef]] = pydantic.Field(None)
    SchemaFile: typing.Optional[dict[str, models.aws_appsync.SchemaFileDef]] = pydantic.Field(None)
    SortKeyStep: typing.Optional[dict[str, models.aws_appsync.SortKeyStepDef]] = pydantic.Field(None)
    Values: typing.Optional[dict[str, models.aws_appsync.ValuesDef]] = pydantic.Field(None)
    AppsyncFunction: typing.Optional[dict[str, models.aws_appsync.AppsyncFunctionDef]] = pydantic.Field(None)
    DynamoDbDataSource: typing.Optional[dict[str, models.aws_appsync.DynamoDbDataSourceDef]] = pydantic.Field(None)
    ElasticsearchDataSource: typing.Optional[dict[str, models.aws_appsync.ElasticsearchDataSourceDef]] = pydantic.Field(None)
    EventBridgeDataSource: typing.Optional[dict[str, models.aws_appsync.EventBridgeDataSourceDef]] = pydantic.Field(None)
    GraphqlApi: typing.Optional[dict[str, models.aws_appsync.GraphqlApiDef]] = pydantic.Field(None)
    HttpDataSource: typing.Optional[dict[str, models.aws_appsync.HttpDataSourceDef]] = pydantic.Field(None)
    LambdaDataSource: typing.Optional[dict[str, models.aws_appsync.LambdaDataSourceDef]] = pydantic.Field(None)
    NoneDataSource: typing.Optional[dict[str, models.aws_appsync.NoneDataSourceDef]] = pydantic.Field(None)
    OpenSearchDataSource: typing.Optional[dict[str, models.aws_appsync.OpenSearchDataSourceDef]] = pydantic.Field(None)
    RdsDataSource: typing.Optional[dict[str, models.aws_appsync.RdsDataSourceDef]] = pydantic.Field(None)
    Resolver: typing.Optional[dict[str, models.aws_appsync.ResolverDef]] = pydantic.Field(None)
    SourceApiAssociation: typing.Optional[dict[str, models.aws_appsync.SourceApiAssociationDef]] = pydantic.Field(None)
    ApiKeyConfig: typing.Optional[dict[str, models.aws_appsync.ApiKeyConfigDef]] = pydantic.Field(None)
    AppsyncFunctionAttributes: typing.Optional[dict[str, models.aws_appsync.AppsyncFunctionAttributesDef]] = pydantic.Field(None)
    AppsyncFunctionProps: typing.Optional[dict[str, models.aws_appsync.AppsyncFunctionPropsDef]] = pydantic.Field(None)
    AuthorizationConfig: typing.Optional[dict[str, models.aws_appsync.AuthorizationConfigDef]] = pydantic.Field(None)
    AuthorizationMode: typing.Optional[dict[str, models.aws_appsync.AuthorizationModeDef]] = pydantic.Field(None)
    AwsIamConfig: typing.Optional[dict[str, models.aws_appsync.AwsIamConfigDef]] = pydantic.Field(None)
    BackedDataSourceProps: typing.Optional[dict[str, models.aws_appsync.BackedDataSourcePropsDef]] = pydantic.Field(None)
    BaseAppsyncFunctionProps: typing.Optional[dict[str, models.aws_appsync.BaseAppsyncFunctionPropsDef]] = pydantic.Field(None)
    BaseDataSourceProps: typing.Optional[dict[str, models.aws_appsync.BaseDataSourcePropsDef]] = pydantic.Field(None)
    BaseResolverProps: typing.Optional[dict[str, models.aws_appsync.BaseResolverPropsDef]] = pydantic.Field(None)
    CachingConfig: typing.Optional[dict[str, models.aws_appsync.CachingConfigDef]] = pydantic.Field(None)
    CfnDataSource_AuthorizationConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnDataSource_AuthorizationConfigPropertyDef]] = pydantic.Field(None)
    CfnDataSource_AwsIamConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnDataSource_AwsIamConfigPropertyDef]] = pydantic.Field(None)
    CfnDataSource_DeltaSyncConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnDataSource_DeltaSyncConfigPropertyDef]] = pydantic.Field(None)
    CfnDataSource_DynamoDBConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnDataSource_DynamoDBConfigPropertyDef]] = pydantic.Field(None)
    CfnDataSource_ElasticsearchConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnDataSource_ElasticsearchConfigPropertyDef]] = pydantic.Field(None)
    CfnDataSource_EventBridgeConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnDataSource_EventBridgeConfigPropertyDef]] = pydantic.Field(None)
    CfnDataSource_HttpConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnDataSource_HttpConfigPropertyDef]] = pydantic.Field(None)
    CfnDataSource_LambdaConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnDataSource_LambdaConfigPropertyDef]] = pydantic.Field(None)
    CfnDataSource_OpenSearchServiceConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnDataSource_OpenSearchServiceConfigPropertyDef]] = pydantic.Field(None)
    CfnDataSource_RdsHttpEndpointConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnDataSource_RdsHttpEndpointConfigPropertyDef]] = pydantic.Field(None)
    CfnDataSource_RelationalDatabaseConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnDataSource_RelationalDatabaseConfigPropertyDef]] = pydantic.Field(None)
    CfnFunctionConfiguration_AppSyncRuntimeProperty: typing.Optional[dict[str, models.aws_appsync.CfnFunctionConfiguration_AppSyncRuntimePropertyDef]] = pydantic.Field(None)
    CfnFunctionConfiguration_LambdaConflictHandlerConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnFunctionConfiguration_LambdaConflictHandlerConfigPropertyDef]] = pydantic.Field(None)
    CfnFunctionConfiguration_SyncConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnFunctionConfiguration_SyncConfigPropertyDef]] = pydantic.Field(None)
    CfnGraphQLApi_AdditionalAuthenticationProviderProperty: typing.Optional[dict[str, models.aws_appsync.CfnGraphQLApi_AdditionalAuthenticationProviderPropertyDef]] = pydantic.Field(None)
    CfnGraphQLApi_CognitoUserPoolConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnGraphQLApi_CognitoUserPoolConfigPropertyDef]] = pydantic.Field(None)
    CfnGraphQLApi_EnhancedMetricsConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnGraphQLApi_EnhancedMetricsConfigPropertyDef]] = pydantic.Field(None)
    CfnGraphQLApi_LambdaAuthorizerConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnGraphQLApi_LambdaAuthorizerConfigPropertyDef]] = pydantic.Field(None)
    CfnGraphQLApi_LogConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnGraphQLApi_LogConfigPropertyDef]] = pydantic.Field(None)
    CfnGraphQLApi_OpenIDConnectConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnGraphQLApi_OpenIDConnectConfigPropertyDef]] = pydantic.Field(None)
    CfnGraphQLApi_UserPoolConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnGraphQLApi_UserPoolConfigPropertyDef]] = pydantic.Field(None)
    CfnResolver_AppSyncRuntimeProperty: typing.Optional[dict[str, models.aws_appsync.CfnResolver_AppSyncRuntimePropertyDef]] = pydantic.Field(None)
    CfnResolver_CachingConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnResolver_CachingConfigPropertyDef]] = pydantic.Field(None)
    CfnResolver_LambdaConflictHandlerConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnResolver_LambdaConflictHandlerConfigPropertyDef]] = pydantic.Field(None)
    CfnResolver_PipelineConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnResolver_PipelineConfigPropertyDef]] = pydantic.Field(None)
    CfnResolver_SyncConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnResolver_SyncConfigPropertyDef]] = pydantic.Field(None)
    CfnSourceApiAssociation_SourceApiAssociationConfigProperty: typing.Optional[dict[str, models.aws_appsync.CfnSourceApiAssociation_SourceApiAssociationConfigPropertyDef]] = pydantic.Field(None)
    CodeConfig: typing.Optional[dict[str, models.aws_appsync.CodeConfigDef]] = pydantic.Field(None)
    DataSourceOptions: typing.Optional[dict[str, models.aws_appsync.DataSourceOptionsDef]] = pydantic.Field(None)
    DomainOptions: typing.Optional[dict[str, models.aws_appsync.DomainOptionsDef]] = pydantic.Field(None)
    DynamoDbDataSourceProps: typing.Optional[dict[str, models.aws_appsync.DynamoDbDataSourcePropsDef]] = pydantic.Field(None)
    ElasticsearchDataSourceProps: typing.Optional[dict[str, models.aws_appsync.ElasticsearchDataSourcePropsDef]] = pydantic.Field(None)
    EventBridgeDataSourceProps: typing.Optional[dict[str, models.aws_appsync.EventBridgeDataSourcePropsDef]] = pydantic.Field(None)
    ExtendedDataSourceProps: typing.Optional[dict[str, models.aws_appsync.ExtendedDataSourcePropsDef]] = pydantic.Field(None)
    ExtendedResolverProps: typing.Optional[dict[str, models.aws_appsync.ExtendedResolverPropsDef]] = pydantic.Field(None)
    GraphqlApiAttributes: typing.Optional[dict[str, models.aws_appsync.GraphqlApiAttributesDef]] = pydantic.Field(None)
    GraphqlApiProps: typing.Optional[dict[str, models.aws_appsync.GraphqlApiPropsDef]] = pydantic.Field(None)
    HttpDataSourceOptions: typing.Optional[dict[str, models.aws_appsync.HttpDataSourceOptionsDef]] = pydantic.Field(None)
    HttpDataSourceProps: typing.Optional[dict[str, models.aws_appsync.HttpDataSourcePropsDef]] = pydantic.Field(None)
    LambdaAuthorizerConfig: typing.Optional[dict[str, models.aws_appsync.LambdaAuthorizerConfigDef]] = pydantic.Field(None)
    LambdaDataSourceProps: typing.Optional[dict[str, models.aws_appsync.LambdaDataSourcePropsDef]] = pydantic.Field(None)
    LogConfig: typing.Optional[dict[str, models.aws_appsync.LogConfigDef]] = pydantic.Field(None)
    NoneDataSourceProps: typing.Optional[dict[str, models.aws_appsync.NoneDataSourcePropsDef]] = pydantic.Field(None)
    OpenIdConnectConfig: typing.Optional[dict[str, models.aws_appsync.OpenIdConnectConfigDef]] = pydantic.Field(None)
    OpenSearchDataSourceProps: typing.Optional[dict[str, models.aws_appsync.OpenSearchDataSourcePropsDef]] = pydantic.Field(None)
    RdsDataSourceProps: typing.Optional[dict[str, models.aws_appsync.RdsDataSourcePropsDef]] = pydantic.Field(None)
    RdsDataSourcePropsV2: typing.Optional[dict[str, models.aws_appsync.RdsDataSourcePropsV2Def]] = pydantic.Field(None)
    ResolverProps: typing.Optional[dict[str, models.aws_appsync.ResolverPropsDef]] = pydantic.Field(None)
    RuntimeConfig: typing.Optional[dict[str, models.aws_appsync.RuntimeConfigDef]] = pydantic.Field(None)
    SchemaBindOptions: typing.Optional[dict[str, models.aws_appsync.SchemaBindOptionsDef]] = pydantic.Field(None)
    SchemaProps: typing.Optional[dict[str, models.aws_appsync.SchemaPropsDef]] = pydantic.Field(None)
    SourceApi: typing.Optional[dict[str, models.aws_appsync.SourceApiDef]] = pydantic.Field(None)
    SourceApiAssociationAttributes: typing.Optional[dict[str, models.aws_appsync.SourceApiAssociationAttributesDef]] = pydantic.Field(None)
    SourceApiAssociationProps: typing.Optional[dict[str, models.aws_appsync.SourceApiAssociationPropsDef]] = pydantic.Field(None)
    SourceApiOptions: typing.Optional[dict[str, models.aws_appsync.SourceApiOptionsDef]] = pydantic.Field(None)
    UserPoolConfig: typing.Optional[dict[str, models.aws_appsync.UserPoolConfigDef]] = pydantic.Field(None)
    CfnApiCache: typing.Optional[dict[str, models.aws_appsync.CfnApiCacheDef]] = pydantic.Field(None)
    CfnApiKey: typing.Optional[dict[str, models.aws_appsync.CfnApiKeyDef]] = pydantic.Field(None)
    CfnDataSource: typing.Optional[dict[str, models.aws_appsync.CfnDataSourceDef]] = pydantic.Field(None)
    CfnDomainName: typing.Optional[dict[str, models.aws_appsync.CfnDomainNameDef]] = pydantic.Field(None)
    CfnDomainNameApiAssociation: typing.Optional[dict[str, models.aws_appsync.CfnDomainNameApiAssociationDef]] = pydantic.Field(None)
    CfnFunctionConfiguration: typing.Optional[dict[str, models.aws_appsync.CfnFunctionConfigurationDef]] = pydantic.Field(None)
    CfnGraphQLApi: typing.Optional[dict[str, models.aws_appsync.CfnGraphQLApiDef]] = pydantic.Field(None)
    CfnGraphQLSchema: typing.Optional[dict[str, models.aws_appsync.CfnGraphQLSchemaDef]] = pydantic.Field(None)
    CfnResolver: typing.Optional[dict[str, models.aws_appsync.CfnResolverDef]] = pydantic.Field(None)
    CfnSourceApiAssociation: typing.Optional[dict[str, models.aws_appsync.CfnSourceApiAssociationDef]] = pydantic.Field(None)
    CfnApiCacheProps: typing.Optional[dict[str, models.aws_appsync.CfnApiCachePropsDef]] = pydantic.Field(None)
    CfnApiKeyProps: typing.Optional[dict[str, models.aws_appsync.CfnApiKeyPropsDef]] = pydantic.Field(None)
    CfnDataSourceProps: typing.Optional[dict[str, models.aws_appsync.CfnDataSourcePropsDef]] = pydantic.Field(None)
    CfnDomainNameApiAssociationProps: typing.Optional[dict[str, models.aws_appsync.CfnDomainNameApiAssociationPropsDef]] = pydantic.Field(None)
    CfnDomainNameProps: typing.Optional[dict[str, models.aws_appsync.CfnDomainNamePropsDef]] = pydantic.Field(None)
    CfnFunctionConfigurationProps: typing.Optional[dict[str, models.aws_appsync.CfnFunctionConfigurationPropsDef]] = pydantic.Field(None)
    CfnGraphQLApiProps: typing.Optional[dict[str, models.aws_appsync.CfnGraphQLApiPropsDef]] = pydantic.Field(None)
    CfnGraphQLSchemaProps: typing.Optional[dict[str, models.aws_appsync.CfnGraphQLSchemaPropsDef]] = pydantic.Field(None)
    CfnResolverProps: typing.Optional[dict[str, models.aws_appsync.CfnResolverPropsDef]] = pydantic.Field(None)
    CfnSourceApiAssociationProps: typing.Optional[dict[str, models.aws_appsync.CfnSourceApiAssociationPropsDef]] = pydantic.Field(None)
    ...

import models
