from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_lookoutequipment.CfnInferenceScheduler.DataInputConfigurationProperty
class CfnInferenceScheduler_DataInputConfigurationPropertyDef(BaseStruct):
    s3_input_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_lookoutequipment.CfnInferenceScheduler_S3InputConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies configuration information for the input data for the inference, including input data S3 location.\n')
    inference_input_name_configuration: typing.Union[models.UnsupportedResource, models.aws_lookoutequipment.CfnInferenceScheduler_InputNameConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies configuration information for the input data for the inference, including timestamp format and delimiter.\n')
    input_time_zone_offset: typing.Optional[str] = pydantic.Field(None, description='Indicates the difference between your time zone and Greenwich Mean Time (GMT).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-lookoutequipment-inferencescheduler-datainputconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_lookoutequipment as lookoutequipment\n\n    data_input_configuration_property = lookoutequipment.CfnInferenceScheduler.DataInputConfigurationProperty(\n        s3_input_configuration=lookoutequipment.CfnInferenceScheduler.S3InputConfigurationProperty(\n            bucket="bucket",\n\n            # the properties below are optional\n            prefix="prefix"\n        ),\n\n        # the properties below are optional\n        inference_input_name_configuration=lookoutequipment.CfnInferenceScheduler.InputNameConfigurationProperty(\n            component_timestamp_delimiter="componentTimestampDelimiter",\n            timestamp_format="timestampFormat"\n        ),\n        input_time_zone_offset="inputTimeZoneOffset"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['s3_input_configuration', 'inference_input_name_configuration', 'input_time_zone_offset']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_lookoutequipment.CfnInferenceScheduler.DataInputConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_lookoutequipment.CfnInferenceScheduler.DataOutputConfigurationProperty
class CfnInferenceScheduler_DataOutputConfigurationPropertyDef(BaseStruct):
    s3_output_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_lookoutequipment.CfnInferenceScheduler_S3OutputConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies configuration information for the output results from the inference, including output S3 location.\n')
    kms_key_id: typing.Optional[str] = pydantic.Field(None, description='The ID number for the AWS KMS key used to encrypt the inference output.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-lookoutequipment-inferencescheduler-dataoutputconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_lookoutequipment as lookoutequipment\n\n    data_output_configuration_property = lookoutequipment.CfnInferenceScheduler.DataOutputConfigurationProperty(\n        s3_output_configuration=lookoutequipment.CfnInferenceScheduler.S3OutputConfigurationProperty(\n            bucket="bucket",\n\n            # the properties below are optional\n            prefix="prefix"\n        ),\n\n        # the properties below are optional\n        kms_key_id="kmsKeyId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['s3_output_configuration', 'kms_key_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_lookoutequipment.CfnInferenceScheduler.DataOutputConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_lookoutequipment.CfnInferenceScheduler.InputNameConfigurationProperty
class CfnInferenceScheduler_InputNameConfigurationPropertyDef(BaseStruct):
    component_timestamp_delimiter: typing.Optional[str] = pydantic.Field(None, description='Indicates the delimiter character used between items in the data.\n')
    timestamp_format: typing.Optional[str] = pydantic.Field(None, description='The format of the timestamp, whether Epoch time, or standard, with or without hyphens (-).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-lookoutequipment-inferencescheduler-inputnameconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_lookoutequipment as lookoutequipment\n\n    input_name_configuration_property = lookoutequipment.CfnInferenceScheduler.InputNameConfigurationProperty(\n        component_timestamp_delimiter="componentTimestampDelimiter",\n        timestamp_format="timestampFormat"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['component_timestamp_delimiter', 'timestamp_format']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_lookoutequipment.CfnInferenceScheduler.InputNameConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_lookoutequipment.CfnInferenceScheduler.S3InputConfigurationProperty
class CfnInferenceScheduler_S3InputConfigurationPropertyDef(BaseStruct):
    bucket: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='')
    prefix: typing.Optional[str] = pydantic.Field(None, description='')
    _init_params: typing.ClassVar[list[str]] = ['bucket', 'prefix']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_lookoutequipment.CfnInferenceScheduler.S3InputConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_lookoutequipment.CfnInferenceScheduler.S3OutputConfigurationProperty
class CfnInferenceScheduler_S3OutputConfigurationPropertyDef(BaseStruct):
    bucket: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='')
    prefix: typing.Optional[str] = pydantic.Field(None, description='')
    _init_params: typing.ClassVar[list[str]] = ['bucket', 'prefix']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_lookoutequipment.CfnInferenceScheduler.S3OutputConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_lookoutequipment.CfnInferenceScheduler
class CfnInferenceSchedulerDef(BaseCfnResource):
    data_input_configuration: typing.Union[typing.Any, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location.\n')
    data_output_configuration: typing.Union[typing.Any, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies configuration information for the output results for the inference scheduler, including the Amazon S3 location for the output.\n')
    data_upload_frequency: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='How often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes.\n')
    model_config = pydantic.ConfigDict(protected_namespaces=())
    model_name_: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the machine learning model used for the inference scheduler.\n', alias='model_name')
    role_arn_: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of a role with permission to access the data source being used for the inference.\n', alias='role_arn')
    data_delay_offset_in_minutes_: typing.Union[int, float, None] = pydantic.Field(None, description="A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if an offset delay time of five minutes was selected, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.\n", alias='data_delay_offset_in_minutes')
    inference_scheduler_name_: typing.Optional[str] = pydantic.Field(None, description='The name of the inference scheduler.\n', alias='inference_scheduler_name')
    server_side_kms_key_id_: typing.Optional[str] = pydantic.Field(None, description='Provides the identifier of the AWS KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment .\n', alias='server_side_kms_key_id')
    tags_: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Any tags associated with the inference scheduler. For more information, see `Tag <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html>`_ .', alias='tags')
    _init_params: typing.ClassVar[list[str]] = ['data_input_configuration', 'data_output_configuration', 'data_upload_frequency', 'model_name', 'role_arn', 'data_delay_offset_in_minutes', 'inference_scheduler_name', 'server_side_kms_key_id', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['DataInputConfigurationProperty', 'DataOutputConfigurationProperty', 'InputNameConfigurationProperty', 'S3InputConfigurationProperty', 'S3OutputConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_lookoutequipment.CfnInferenceScheduler'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_lookoutequipment.CfnInferenceSchedulerDefConfig] = pydantic.Field(None)


class CfnInferenceSchedulerDefConfig(pydantic.BaseModel):
    DataInputConfigurationProperty: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefDatainputconfigurationpropertyParams]] = pydantic.Field(None, description='')
    DataOutputConfigurationProperty: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefDataoutputconfigurationpropertyParams]] = pydantic.Field(None, description='')
    InputNameConfigurationProperty: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefInputnameconfigurationpropertyParams]] = pydantic.Field(None, description='')
    S3InputConfigurationProperty: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefS3InputconfigurationpropertyParams]] = pydantic.Field(None, description='')
    S3OutputConfigurationProperty: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefS3OutputconfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_lookoutequipment.CfnInferenceSchedulerDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnInferenceSchedulerDefDatainputconfigurationpropertyParams(pydantic.BaseModel):
    s3_input_configuration: typing.Union[models.UnsupportedResource, models.aws_lookoutequipment.CfnInferenceScheduler_S3InputConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    inference_input_name_configuration: typing.Union[models.UnsupportedResource, models.aws_lookoutequipment.CfnInferenceScheduler_InputNameConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    input_time_zone_offset: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnInferenceSchedulerDefDataoutputconfigurationpropertyParams(pydantic.BaseModel):
    s3_output_configuration: typing.Union[models.UnsupportedResource, models.aws_lookoutequipment.CfnInferenceScheduler_S3OutputConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    kms_key_id: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnInferenceSchedulerDefInputnameconfigurationpropertyParams(pydantic.BaseModel):
    component_timestamp_delimiter: typing.Optional[str] = pydantic.Field(None, description='')
    timestamp_format: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnInferenceSchedulerDefS3InputconfigurationpropertyParams(pydantic.BaseModel):
    bucket: str = pydantic.Field(..., description='')
    prefix: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnInferenceSchedulerDefS3OutputconfigurationpropertyParams(pydantic.BaseModel):
    bucket: str = pydantic.Field(..., description='')
    prefix: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnInferenceSchedulerDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnInferenceSchedulerDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnInferenceSchedulerDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnInferenceSchedulerDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnInferenceSchedulerDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnInferenceSchedulerDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnInferenceSchedulerDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnInferenceSchedulerDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnInferenceSchedulerDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnInferenceSchedulerDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnInferenceSchedulerDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnInferenceSchedulerDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnInferenceSchedulerDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnInferenceSchedulerDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_lookoutequipment.CfnInferenceSchedulerProps
class CfnInferenceSchedulerPropsDef(BaseCfnProperty):
    data_input_configuration: typing.Union[typing.Any, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location.\n')
    data_output_configuration: typing.Union[typing.Any, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies configuration information for the output results for the inference scheduler, including the Amazon S3 location for the output.\n')
    data_upload_frequency: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='How often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes.\n')
    model_config = pydantic.ConfigDict(protected_namespaces=())
    model_name_: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the machine learning model used for the inference scheduler.\n', alias='model_name')
    role_arn_: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of a role with permission to access the data source being used for the inference.\n', alias='role_arn')
    data_delay_offset_in_minutes_: typing.Union[int, float, None] = pydantic.Field(None, description="A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if an offset delay time of five minutes was selected, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.\n", alias='data_delay_offset_in_minutes')
    inference_scheduler_name_: typing.Optional[str] = pydantic.Field(None, description='The name of the inference scheduler.\n', alias='inference_scheduler_name')
    server_side_kms_key_id_: typing.Optional[str] = pydantic.Field(None, description='Provides the identifier of the AWS KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment .\n', alias='server_side_kms_key_id')
    tags_: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Any tags associated with the inference scheduler. For more information, see `Tag <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lookoutequipment-inferencescheduler.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_lookoutequipment as lookoutequipment\n\n    # data_input_configuration: Any\n    # data_output_configuration: Any\n\n    cfn_inference_scheduler_props = lookoutequipment.CfnInferenceSchedulerProps(\n        data_input_configuration=data_input_configuration,\n        data_output_configuration=data_output_configuration,\n        data_upload_frequency="dataUploadFrequency",\n        model_name="modelName",\n        role_arn="roleArn",\n\n        # the properties below are optional\n        data_delay_offset_in_minutes=123,\n        inference_scheduler_name="inferenceSchedulerName",\n        server_side_kms_key_id="serverSideKmsKeyId",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n', alias='tags')
    _init_params: typing.ClassVar[list[str]] = ['data_input_configuration', 'data_output_configuration', 'data_upload_frequency', 'model_name', 'role_arn', 'data_delay_offset_in_minutes', 'inference_scheduler_name', 'server_side_kms_key_id', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_lookoutequipment.CfnInferenceSchedulerProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




class ModuleModel(pydantic.BaseModel):
    CfnInferenceScheduler_DataInputConfigurationProperty: typing.Optional[dict[str, models.aws_lookoutequipment.CfnInferenceScheduler_DataInputConfigurationPropertyDef]] = pydantic.Field(None)
    CfnInferenceScheduler_DataOutputConfigurationProperty: typing.Optional[dict[str, models.aws_lookoutequipment.CfnInferenceScheduler_DataOutputConfigurationPropertyDef]] = pydantic.Field(None)
    CfnInferenceScheduler_InputNameConfigurationProperty: typing.Optional[dict[str, models.aws_lookoutequipment.CfnInferenceScheduler_InputNameConfigurationPropertyDef]] = pydantic.Field(None)
    CfnInferenceScheduler_S3InputConfigurationProperty: typing.Optional[dict[str, models.aws_lookoutequipment.CfnInferenceScheduler_S3InputConfigurationPropertyDef]] = pydantic.Field(None)
    CfnInferenceScheduler_S3OutputConfigurationProperty: typing.Optional[dict[str, models.aws_lookoutequipment.CfnInferenceScheduler_S3OutputConfigurationPropertyDef]] = pydantic.Field(None)
    CfnInferenceScheduler: typing.Optional[dict[str, models.aws_lookoutequipment.CfnInferenceSchedulerDef]] = pydantic.Field(None)
    CfnInferenceSchedulerProps: typing.Optional[dict[str, models.aws_lookoutequipment.CfnInferenceSchedulerPropsDef]] = pydantic.Field(None)
    ...

import models
