from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams

#  autogenerated from aws_cdk.aws_mwaa.CfnEnvironment.LoggingConfigurationProperty
class CfnEnvironment_LoggingConfigurationPropertyDef(BaseStruct):
    dag_processing_logs: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_ModuleLoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines the processing logs sent to CloudWatch Logs and the logging level to send.\n')
    scheduler_logs: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_ModuleLoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines the scheduler logs sent to CloudWatch Logs and the logging level to send.\n')
    task_logs: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_ModuleLoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines the task logs sent to CloudWatch Logs and the logging level to send.\n')
    webserver_logs: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_ModuleLoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines the web server logs sent to CloudWatch Logs and the logging level to send.\n')
    worker_logs: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_ModuleLoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines the worker logs sent to CloudWatch Logs and the logging level to send.\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-mwaa-environment-loggingconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_mwaa as mwaa\n\n    logging_configuration_property = mwaa.CfnEnvironment.LoggingConfigurationProperty(\n        dag_processing_logs=mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty(\n            cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n            enabled=False,\n            log_level="logLevel"\n        ),\n        scheduler_logs=mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty(\n            cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n            enabled=False,\n            log_level="logLevel"\n        ),\n        task_logs=mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty(\n            cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n            enabled=False,\n            log_level="logLevel"\n        ),\n        webserver_logs=mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty(\n            cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n            enabled=False,\n            log_level="logLevel"\n        ),\n        worker_logs=mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty(\n            cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n            enabled=False,\n            log_level="logLevel"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['dag_processing_logs', 'scheduler_logs', 'task_logs', 'webserver_logs', 'worker_logs']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_mwaa.CfnEnvironment.LoggingConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty
class CfnEnvironment_ModuleLoggingConfigurationPropertyDef(BaseStruct):
    cloud_watch_log_group_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the CloudWatch Logs log group for each type of Apache Airflow log type that you have enabled. .. epigraph:: ``CloudWatchLogGroupArn`` is available only as a return value, accessible when specified as an attribute in the ```Fn:GetAtt`` <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-mwaa-environment.html#aws-resource-mwaa-environment-return-values>`_ intrinsic function. Any value you provide for ``CloudWatchLogGroupArn`` is discarded by Amazon MWAA.\n')
    enabled: typing.Union[bool, typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], None] = pydantic.Field(None, description='Indicates whether to enable the Apache Airflow log type (e.g. ``DagProcessingLogs`` ) in CloudWatch Logs.\n')
    log_level: typing.Optional[str] = pydantic.Field(None, description='Defines the Apache Airflow logs to send for the log type (e.g. ``DagProcessingLogs`` ) to CloudWatch Logs. Valid values: ``CRITICAL`` , ``ERROR`` , ``WARNING`` , ``INFO`` .\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-mwaa-environment-moduleloggingconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_mwaa as mwaa\n\n    module_logging_configuration_property = mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty(\n        cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n        enabled=False,\n        log_level="logLevel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['cloud_watch_log_group_arn', 'enabled', 'log_level']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_mwaa.CfnEnvironment.NetworkConfigurationProperty
class CfnEnvironment_NetworkConfigurationPropertyDef(BaseStruct):
    security_group_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of one or more security group IDs. Accepts up to 5 security group IDs. A security group must be attached to the same VPC as the subnets. To learn more, see `Security in your VPC on Amazon MWAA <https://docs.aws.amazon.com/mwaa/latest/userguide/vpc-security.html>`_ .\n')
    subnet_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of subnet IDs. *Required* to create an environment. Must be private subnets in two different availability zones. A subnet must be attached to the same VPC as the security group. To learn more, see `About networking on Amazon MWAA <https://docs.aws.amazon.com/mwaa/latest/userguide/networking-about.html>`_ .\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-mwaa-environment-networkconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_mwaa as mwaa\n\n    network_configuration_property = mwaa.CfnEnvironment.NetworkConfigurationProperty(\n        security_group_ids=["securityGroupIds"],\n        subnet_ids=["subnetIds"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['security_group_ids', 'subnet_ids']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_mwaa.CfnEnvironment.NetworkConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_mwaa.CfnEnvironment
class CfnEnvironmentDef(BaseCfnResource):
    name: str = pydantic.Field(..., description='The name of your Amazon MWAA environment.\n')
    airflow_configuration_options: typing.Any = pydantic.Field(None, description='A list of key-value pairs containing the Airflow configuration options for your environment. For example, ``core.default_timezone: utc`` . To learn more, see `Apache Airflow configuration options <https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-env-variables.html>`_ .\n')
    airflow_version: typing.Optional[str] = pydantic.Field(None, description='The version of Apache Airflow to use for the environment. If no value is specified, defaults to the latest version. *Allowed Values* : ``2.0.2`` | ``1.10.12`` | ``2.2.2`` | ``2.4.3`` | ``2.5.1`` (latest)\n')
    dag_s3_path: typing.Optional[str] = pydantic.Field(None, description='The relative path to the DAGs folder on your Amazon S3 bucket. For example, ``dags`` . To learn more, see `Adding or updating DAGs <https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-folder.html>`_ .\n')
    environment_class: typing.Optional[str] = pydantic.Field(None, description='The environment class type. Valid values: ``mw1.small`` , ``mw1.medium`` , ``mw1.large`` . To learn more, see `Amazon MWAA environment class <https://docs.aws.amazon.com/mwaa/latest/userguide/environment-class.html>`_ .\n')
    execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the execution role in IAM that allows MWAA to access AWS resources in your environment. For example, ``arn:aws:iam::123456789:role/my-execution-role`` . To learn more, see `Amazon MWAA Execution role <https://docs.aws.amazon.com/mwaa/latest/userguide/mwaa-create-role.html>`_ .\n')
    kms_key: typing.Optional[str] = pydantic.Field(None, description='The AWS Key Management Service (KMS) key to encrypt and decrypt the data in your environment. You can use an AWS KMS key managed by MWAA, or a customer-managed KMS key (advanced).\n')
    logging_configuration: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_LoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Apache Airflow logs being sent to CloudWatch Logs: ``DagProcessingLogs`` , ``SchedulerLogs`` , ``TaskLogs`` , ``WebserverLogs`` , ``WorkerLogs`` .\n')
    max_workers: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of workers that you want to run in your environment. MWAA scales the number of Apache Airflow workers up to the number you specify in the ``MaxWorkers`` field. For example, ``20`` . When there are no more tasks running, and no more in the queue, MWAA disposes of the extra workers leaving the one worker that is included with your environment, or the number you specify in ``MinWorkers`` .\n')
    min_workers: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum number of workers that you want to run in your environment. MWAA scales the number of Apache Airflow workers up to the number you specify in the ``MaxWorkers`` field. When there are no more tasks running, and no more in the queue, MWAA disposes of the extra workers leaving the worker count you specify in the ``MinWorkers`` field. For example, ``2`` .\n')
    network_configuration: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_NetworkConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The VPC networking components used to secure and enable network traffic between the AWS resources for your environment. To learn more, see `About networking on Amazon MWAA <https://docs.aws.amazon.com/mwaa/latest/userguide/networking-about.html>`_ .\n')
    plugins_s3_object_version: typing.Optional[str] = pydantic.Field(None, description='The version of the plugins.zip file on your Amazon S3 bucket. To learn more, see `Installing custom plugins <https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-import-plugins.html>`_ .\n')
    plugins_s3_path: typing.Optional[str] = pydantic.Field(None, description='The relative path to the ``plugins.zip`` file on your Amazon S3 bucket. For example, ``plugins.zip`` . To learn more, see `Installing custom plugins <https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-import-plugins.html>`_ .\n')
    requirements_s3_object_version: typing.Optional[str] = pydantic.Field(None, description='The version of the requirements.txt file on your Amazon S3 bucket. To learn more, see `Installing Python dependencies <https://docs.aws.amazon.com/mwaa/latest/userguide/working-dags-dependencies.html>`_ .\n')
    requirements_s3_path: typing.Optional[str] = pydantic.Field(None, description='The relative path to the ``requirements.txt`` file on your Amazon S3 bucket. For example, ``requirements.txt`` . To learn more, see `Installing Python dependencies <https://docs.aws.amazon.com/mwaa/latest/userguide/working-dags-dependencies.html>`_ .\n')
    schedulers: typing.Union[int, float, None] = pydantic.Field(None, description='The number of schedulers that you want to run in your environment. Valid values:. - *v2* - Accepts between 2 to 5. Defaults to 2. - *v1* - Accepts 1.\n')
    source_bucket_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the Amazon S3 bucket where your DAG code and supporting files are stored. For example, ``arn:aws:s3:::my-airflow-bucket-unique-name`` . To learn more, see `Create an Amazon S3 bucket for Amazon MWAA <https://docs.aws.amazon.com/mwaa/latest/userguide/mwaa-s3-bucket.html>`_ .\n')
    startup_script_s3_object_version: typing.Optional[str] = pydantic.Field(None, description='The version of the startup shell script in your Amazon S3 bucket. You must specify the `version ID <https://docs.aws.amazon.com/AmazonS3/latest/userguide/versioning-workflows.html>`_ that Amazon S3 assigns to the file every time you update the script. Version IDs are Unicode, UTF-8 encoded, URL-ready, opaque strings that are no more than 1,024 bytes long. The following is an example: ``3sL4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo`` For more information, see `Using a startup script <https://docs.aws.amazon.com/mwaa/latest/userguide/using-startup-script.html>`_ .\n')
    startup_script_s3_path: typing.Optional[str] = pydantic.Field(None, description='The relative path to the startup shell script in your Amazon S3 bucket. For example, ``s3://mwaa-environment/startup.sh`` . Amazon MWAA runs the script as your environment starts, and before running the Apache Airflow process. You can use this script to install dependencies, modify Apache Airflow configuration options, and set environment variables. For more information, see `Using a startup script <https://docs.aws.amazon.com/mwaa/latest/userguide/using-startup-script.html>`_ .\n')
    tags: typing.Any = pydantic.Field(None, description='The key-value tag pairs associated to your environment. For example, ``"Environment": "Staging"`` . To learn more, see `Tagging <https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html>`_ .\n')
    webserver_access_mode: typing.Optional[str] = pydantic.Field(None, description='The Apache Airflow *Web server* access mode. To learn more, see `Apache Airflow access modes <https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-networking.html>`_ . Valid values: ``PRIVATE_ONLY`` or ``PUBLIC_ONLY`` .\n')
    weekly_maintenance_window_start: typing.Optional[str] = pydantic.Field(None, description='The day and time of the week to start weekly maintenance updates of your environment in the following format: ``DAY:HH:MM`` . For example: ``TUE:03:30`` . You can specify a start time in 30 minute increments only. Supported input includes the following: - MON|TUE|WED|THU|FRI|SAT|SUN:([01]\\d|2[0-3]):(00|30)')
    _init_params: typing.ClassVar[list[str]] = ['name', 'airflow_configuration_options', 'airflow_version', 'dag_s3_path', 'environment_class', 'execution_role_arn', 'kms_key', 'logging_configuration', 'max_workers', 'min_workers', 'network_configuration', 'plugins_s3_object_version', 'plugins_s3_path', 'requirements_s3_object_version', 'requirements_s3_path', 'schedulers', 'source_bucket_arn', 'startup_script_s3_object_version', 'startup_script_s3_path', 'tags', 'webserver_access_mode', 'weekly_maintenance_window_start']
    _method_names: typing.ClassVar[list[str]] = ['LoggingConfigurationProperty', 'ModuleLoggingConfigurationProperty', 'NetworkConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_mwaa.CfnEnvironment'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnEnvironmentDefConfig] = pydantic.Field(None)


class CfnEnvironmentDefConfig(pydantic.BaseModel):
    LoggingConfigurationProperty: typing.Optional[list[CfnEnvironmentDefLoggingconfigurationpropertyParams]] = pydantic.Field(None, description='')
    ModuleLoggingConfigurationProperty: typing.Optional[list[CfnEnvironmentDefModuleloggingconfigurationpropertyParams]] = pydantic.Field(None, description='')
    NetworkConfigurationProperty: typing.Optional[list[CfnEnvironmentDefNetworkconfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnEnvironmentDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnEnvironmentDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnEnvironmentDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnEnvironmentDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnEnvironmentDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnEnvironmentDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnEnvironmentDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnEnvironmentDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnEnvironmentDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnEnvironmentDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnEnvironmentDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnEnvironmentDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnEnvironmentDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnEnvironmentDefLoggingconfigurationpropertyParams(pydantic.BaseModel):
    dag_processing_logs: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_ModuleLoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    scheduler_logs: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_ModuleLoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    task_logs: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_ModuleLoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    webserver_logs: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_ModuleLoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    worker_logs: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_ModuleLoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnEnvironmentDefModuleloggingconfigurationpropertyParams(pydantic.BaseModel):
    cloud_watch_log_group_arn: typing.Optional[str] = pydantic.Field(None, description='')
    enabled: typing.Union[bool, typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], None] = pydantic.Field(None, description='')
    log_level: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnEnvironmentDefNetworkconfigurationpropertyParams(pydantic.BaseModel):
    security_group_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    subnet_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnEnvironmentDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnEnvironmentDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnEnvironmentDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnEnvironmentDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnEnvironmentDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnEnvironmentDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnEnvironmentDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnEnvironmentDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnEnvironmentDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnEnvironmentDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnEnvironmentDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='- tree inspector to collect and process attributes.')
    ...

class CfnEnvironmentDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnEnvironmentDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnEnvironmentDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_mwaa.CfnEnvironmentProps
class CfnEnvironmentPropsDef(BaseCfnProperty):
    name: str = pydantic.Field(..., description='The name of your Amazon MWAA environment.\n')
    airflow_configuration_options: typing.Any = pydantic.Field(None, description='A list of key-value pairs containing the Airflow configuration options for your environment. For example, ``core.default_timezone: utc`` . To learn more, see `Apache Airflow configuration options <https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-env-variables.html>`_ .\n')
    airflow_version: typing.Optional[str] = pydantic.Field(None, description='The version of Apache Airflow to use for the environment. If no value is specified, defaults to the latest version. *Allowed Values* : ``2.0.2`` | ``1.10.12`` | ``2.2.2`` | ``2.4.3`` | ``2.5.1`` (latest)\n')
    dag_s3_path: typing.Optional[str] = pydantic.Field(None, description='The relative path to the DAGs folder on your Amazon S3 bucket. For example, ``dags`` . To learn more, see `Adding or updating DAGs <https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-folder.html>`_ .\n')
    environment_class: typing.Optional[str] = pydantic.Field(None, description='The environment class type. Valid values: ``mw1.small`` , ``mw1.medium`` , ``mw1.large`` . To learn more, see `Amazon MWAA environment class <https://docs.aws.amazon.com/mwaa/latest/userguide/environment-class.html>`_ .\n')
    execution_role_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the execution role in IAM that allows MWAA to access AWS resources in your environment. For example, ``arn:aws:iam::123456789:role/my-execution-role`` . To learn more, see `Amazon MWAA Execution role <https://docs.aws.amazon.com/mwaa/latest/userguide/mwaa-create-role.html>`_ .\n')
    kms_key: typing.Optional[str] = pydantic.Field(None, description='The AWS Key Management Service (KMS) key to encrypt and decrypt the data in your environment. You can use an AWS KMS key managed by MWAA, or a customer-managed KMS key (advanced).\n')
    logging_configuration: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_LoggingConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Apache Airflow logs being sent to CloudWatch Logs: ``DagProcessingLogs`` , ``SchedulerLogs`` , ``TaskLogs`` , ``WebserverLogs`` , ``WorkerLogs`` .\n')
    max_workers: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum number of workers that you want to run in your environment. MWAA scales the number of Apache Airflow workers up to the number you specify in the ``MaxWorkers`` field. For example, ``20`` . When there are no more tasks running, and no more in the queue, MWAA disposes of the extra workers leaving the one worker that is included with your environment, or the number you specify in ``MinWorkers`` .\n')
    min_workers: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum number of workers that you want to run in your environment. MWAA scales the number of Apache Airflow workers up to the number you specify in the ``MaxWorkers`` field. When there are no more tasks running, and no more in the queue, MWAA disposes of the extra workers leaving the worker count you specify in the ``MinWorkers`` field. For example, ``2`` .\n')
    network_configuration: typing.Union[typing.Union[models.CfnDynamicReferenceDef, models.IntrinsicDef, models.JsonNullDef, models.ReferenceDef, models.SecretValueDef, models.CfnConditionDef, models.CfnJsonDef, models.aws_events.EventFieldDef, models.aws_events.MatchDef, models.aws_iam.PolicyDocumentDef, models.custom_resources.PhysicalResourceIdReferenceDef], models.aws_mwaa.CfnEnvironment_NetworkConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The VPC networking components used to secure and enable network traffic between the AWS resources for your environment. To learn more, see `About networking on Amazon MWAA <https://docs.aws.amazon.com/mwaa/latest/userguide/networking-about.html>`_ .\n')
    plugins_s3_object_version: typing.Optional[str] = pydantic.Field(None, description='The version of the plugins.zip file on your Amazon S3 bucket. To learn more, see `Installing custom plugins <https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-import-plugins.html>`_ .\n')
    plugins_s3_path: typing.Optional[str] = pydantic.Field(None, description='The relative path to the ``plugins.zip`` file on your Amazon S3 bucket. For example, ``plugins.zip`` . To learn more, see `Installing custom plugins <https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-import-plugins.html>`_ .\n')
    requirements_s3_object_version: typing.Optional[str] = pydantic.Field(None, description='The version of the requirements.txt file on your Amazon S3 bucket. To learn more, see `Installing Python dependencies <https://docs.aws.amazon.com/mwaa/latest/userguide/working-dags-dependencies.html>`_ .\n')
    requirements_s3_path: typing.Optional[str] = pydantic.Field(None, description='The relative path to the ``requirements.txt`` file on your Amazon S3 bucket. For example, ``requirements.txt`` . To learn more, see `Installing Python dependencies <https://docs.aws.amazon.com/mwaa/latest/userguide/working-dags-dependencies.html>`_ .\n')
    schedulers: typing.Union[int, float, None] = pydantic.Field(None, description='The number of schedulers that you want to run in your environment. Valid values:. - *v2* - Accepts between 2 to 5. Defaults to 2. - *v1* - Accepts 1.\n')
    source_bucket_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the Amazon S3 bucket where your DAG code and supporting files are stored. For example, ``arn:aws:s3:::my-airflow-bucket-unique-name`` . To learn more, see `Create an Amazon S3 bucket for Amazon MWAA <https://docs.aws.amazon.com/mwaa/latest/userguide/mwaa-s3-bucket.html>`_ .\n')
    startup_script_s3_object_version: typing.Optional[str] = pydantic.Field(None, description='The version of the startup shell script in your Amazon S3 bucket. You must specify the `version ID <https://docs.aws.amazon.com/AmazonS3/latest/userguide/versioning-workflows.html>`_ that Amazon S3 assigns to the file every time you update the script. Version IDs are Unicode, UTF-8 encoded, URL-ready, opaque strings that are no more than 1,024 bytes long. The following is an example: ``3sL4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo`` For more information, see `Using a startup script <https://docs.aws.amazon.com/mwaa/latest/userguide/using-startup-script.html>`_ .\n')
    startup_script_s3_path: typing.Optional[str] = pydantic.Field(None, description='The relative path to the startup shell script in your Amazon S3 bucket. For example, ``s3://mwaa-environment/startup.sh`` . Amazon MWAA runs the script as your environment starts, and before running the Apache Airflow process. You can use this script to install dependencies, modify Apache Airflow configuration options, and set environment variables. For more information, see `Using a startup script <https://docs.aws.amazon.com/mwaa/latest/userguide/using-startup-script.html>`_ .\n')
    tags: typing.Any = pydantic.Field(None, description='The key-value tag pairs associated to your environment. For example, ``"Environment": "Staging"`` . To learn more, see `Tagging <https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html>`_ .\n')
    webserver_access_mode: typing.Optional[str] = pydantic.Field(None, description='The Apache Airflow *Web server* access mode. To learn more, see `Apache Airflow access modes <https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-networking.html>`_ . Valid values: ``PRIVATE_ONLY`` or ``PUBLIC_ONLY`` .\n')
    weekly_maintenance_window_start: typing.Optional[str] = pydantic.Field(None, description='The day and time of the week to start weekly maintenance updates of your environment in the following format: ``DAY:HH:MM`` . For example: ``TUE:03:30`` . You can specify a start time in 30 minute increments only. Supported input includes the following: - MON|TUE|WED|THU|FRI|SAT|SUN:([01]\\d|2[0-3]):(00|30)\n\n:link: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-mwaa-environment.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_mwaa as mwaa\n\n    # airflow_configuration_options: Any\n    # tags: Any\n\n    cfn_environment_props = mwaa.CfnEnvironmentProps(\n        name="name",\n\n        # the properties below are optional\n        airflow_configuration_options=airflow_configuration_options,\n        airflow_version="airflowVersion",\n        dag_s3_path="dagS3Path",\n        environment_class="environmentClass",\n        execution_role_arn="executionRoleArn",\n        kms_key="kmsKey",\n        logging_configuration=mwaa.CfnEnvironment.LoggingConfigurationProperty(\n            dag_processing_logs=mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty(\n                cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n                enabled=False,\n                log_level="logLevel"\n            ),\n            scheduler_logs=mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty(\n                cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n                enabled=False,\n                log_level="logLevel"\n            ),\n            task_logs=mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty(\n                cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n                enabled=False,\n                log_level="logLevel"\n            ),\n            webserver_logs=mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty(\n                cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n                enabled=False,\n                log_level="logLevel"\n            ),\n            worker_logs=mwaa.CfnEnvironment.ModuleLoggingConfigurationProperty(\n                cloud_watch_log_group_arn="cloudWatchLogGroupArn",\n                enabled=False,\n                log_level="logLevel"\n            )\n        ),\n        max_workers=123,\n        min_workers=123,\n        network_configuration=mwaa.CfnEnvironment.NetworkConfigurationProperty(\n            security_group_ids=["securityGroupIds"],\n            subnet_ids=["subnetIds"]\n        ),\n        plugins_s3_object_version="pluginsS3ObjectVersion",\n        plugins_s3_path="pluginsS3Path",\n        requirements_s3_object_version="requirementsS3ObjectVersion",\n        requirements_s3_path="requirementsS3Path",\n        schedulers=123,\n        source_bucket_arn="sourceBucketArn",\n        startup_script_s3_object_version="startupScriptS3ObjectVersion",\n        startup_script_s3_path="startupScriptS3Path",\n        tags=tags,\n        webserver_access_mode="webserverAccessMode",\n        weekly_maintenance_window_start="weeklyMaintenanceWindowStart"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'airflow_configuration_options', 'airflow_version', 'dag_s3_path', 'environment_class', 'execution_role_arn', 'kms_key', 'logging_configuration', 'max_workers', 'min_workers', 'network_configuration', 'plugins_s3_object_version', 'plugins_s3_path', 'requirements_s3_object_version', 'requirements_s3_path', 'schedulers', 'source_bucket_arn', 'startup_script_s3_object_version', 'startup_script_s3_path', 'tags', 'webserver_access_mode', 'weekly_maintenance_window_start']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_mwaa.CfnEnvironmentProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




import models

class ModuleModel(pydantic.BaseModel):
    CfnEnvironment_LoggingConfigurationProperty: typing.Optional[dict[str, CfnEnvironment_LoggingConfigurationPropertyDef]] = pydantic.Field(None)
    CfnEnvironment_ModuleLoggingConfigurationProperty: typing.Optional[dict[str, CfnEnvironment_ModuleLoggingConfigurationPropertyDef]] = pydantic.Field(None)
    CfnEnvironment_NetworkConfigurationProperty: typing.Optional[dict[str, CfnEnvironment_NetworkConfigurationPropertyDef]] = pydantic.Field(None)
    CfnEnvironment: typing.Optional[dict[str, CfnEnvironmentDef]] = pydantic.Field(None)
    CfnEnvironmentProps: typing.Optional[dict[str, CfnEnvironmentPropsDef]] = pydantic.Field(None)
    ...
