from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_transfer.CfnConnector.As2ConfigProperty
class CfnConnector_As2ConfigPropertyDef(BaseStruct):
    basic_auth_secret_id: typing.Optional[str] = pydantic.Field(None, description='Provides Basic authentication support to the AS2 Connectors API. To use Basic authentication, you must provide the name or Amazon Resource Name (ARN) of a secret in AWS Secrets Manager . The default value for this parameter is ``null`` , which indicates that Basic authentication is not enabled for the connector. If the connector should use Basic authentication, the secret needs to be in the following format: ``{ "Username": "user-name", "Password": "user-password" }`` Replace ``user-name`` and ``user-password`` with the credentials for the actual user that is being authenticated. Note the following: - You are storing these credentials in Secrets Manager, *not passing them directly* into this API. - If you are using the API, SDKs, or CloudFormation to configure your connector, then you must create the secret before you can enable Basic authentication. However, if you are using the AWS management console, you can have the system create the secret for you. If you have previously enabled Basic authentication for a connector, you can disable it by using the ``UpdateConnector`` API call. For example, if you are using the CLI, you can run the following command to remove Basic authentication: ``update-connector --connector-id my-connector-id --as2-config \'BasicAuthSecretId=""\'``\n')
    compression: typing.Optional[str] = pydantic.Field(None, description='Specifies whether the AS2 file is compressed.\n')
    encryption_algorithm: typing.Optional[str] = pydantic.Field(None, description='The algorithm that is used to encrypt the file. .. epigraph:: You can only specify ``NONE`` if the URL for your connector uses HTTPS. This ensures that no traffic is sent in clear text.\n')
    local_profile_id: typing.Optional[str] = pydantic.Field(None, description='A unique identifier for the AS2 local profile.\n')
    mdn_response: typing.Optional[str] = pydantic.Field(None, description='Used for outbound requests (from an AWS Transfer Family server to a partner AS2 server) to determine whether the partner response for transfers is synchronous or asynchronous. Specify either of the following values: - ``SYNC`` : The system expects a synchronous MDN response, confirming that the file was transferred successfully (or not). - ``NONE`` : Specifies that no MDN response is required.\n')
    mdn_signing_algorithm: typing.Optional[str] = pydantic.Field(None, description='The signing algorithm for the MDN response. .. epigraph:: If set to DEFAULT (or not set at all), the value for ``SigningAlgorithm`` is used.\n')
    message_subject: typing.Optional[str] = pydantic.Field(None, description='Used as the ``Subject`` HTTP header attribute in AS2 messages that are being sent with the connector.\n')
    partner_profile_id: typing.Optional[str] = pydantic.Field(None, description='A unique identifier for the partner profile for the connector.\n')
    signing_algorithm: typing.Optional[str] = pydantic.Field(None, description='The algorithm that is used to sign the AS2 messages sent with the connector.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-connector-as2config.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    as2_config_property = transfer.CfnConnector.As2ConfigProperty(\n        basic_auth_secret_id="basicAuthSecretId",\n        compression="compression",\n        encryption_algorithm="encryptionAlgorithm",\n        local_profile_id="localProfileId",\n        mdn_response="mdnResponse",\n        mdn_signing_algorithm="mdnSigningAlgorithm",\n        message_subject="messageSubject",\n        partner_profile_id="partnerProfileId",\n        signing_algorithm="signingAlgorithm"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['basic_auth_secret_id', 'compression', 'encryption_algorithm', 'local_profile_id', 'mdn_response', 'mdn_signing_algorithm', 'message_subject', 'partner_profile_id', 'signing_algorithm']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnConnector.As2ConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnConnector.SftpConfigProperty
class CfnConnector_SftpConfigPropertyDef(BaseStruct):
    trusted_host_keys: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The public portion of the host key, or keys, that are used to identify the external server to which you are connecting. You can use the ``ssh-keyscan`` command against the SFTP server to retrieve the necessary key. The three standard SSH public key format elements are ``<key type>`` , ``<body base64>`` , and an optional ``<comment>`` , with spaces between each element. Specify only the ``<key type>`` and ``<body base64>`` : do not enter the ``<comment>`` portion of the key. For the trusted host key, AWS Transfer Family accepts RSA and ECDSA keys. - For RSA keys, the ``<key type>`` string is ``ssh-rsa`` . - For ECDSA keys, the ``<key type>`` string is either ``ecdsa-sha2-nistp256`` , ``ecdsa-sha2-nistp384`` , or ``ecdsa-sha2-nistp521`` , depending on the size of the key you generated.\n')
    user_secret_id: typing.Optional[str] = pydantic.Field(None, description='The identifier for the secret (in AWS Secrets Manager) that contains the SFTP user\'s private key, password, or both. The identifier must be the Amazon Resource Name (ARN) of the secret.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-connector-sftpconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    sftp_config_property = transfer.CfnConnector.SftpConfigProperty(\n        trusted_host_keys=["trustedHostKeys"],\n        user_secret_id="userSecretId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['trusted_host_keys', 'user_secret_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnConnector.SftpConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnServer.EndpointDetailsProperty
class CfnServer_EndpointDetailsPropertyDef(BaseStruct):
    address_allocation_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="A list of address allocation IDs that are required to attach an Elastic IP address to your server's endpoint. .. epigraph:: This property can only be set when ``EndpointType`` is set to ``VPC`` and it is only valid in the ``UpdateServer`` API.\n")
    security_group_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="A list of security groups IDs that are available to attach to your server's endpoint. .. epigraph:: This property can only be set when ``EndpointType`` is set to ``VPC`` . You can edit the ``SecurityGroupIds`` property in the `UpdateServer <https://docs.aws.amazon.com/transfer/latest/userguide/API_UpdateServer.html>`_ API only if you are changing the ``EndpointType`` from ``PUBLIC`` or ``VPC_ENDPOINT`` to ``VPC`` . To change security groups associated with your server's VPC endpoint after creation, use the Amazon EC2 `ModifyVpcEndpoint <https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_ModifyVpcEndpoint.html>`_ API.\n")
    subnet_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of subnet IDs that are required to host your server endpoint in your VPC. .. epigraph:: This property can only be set when ``EndpointType`` is set to ``VPC`` .\n')
    vpc_endpoint_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the VPC endpoint. .. epigraph:: This property can only be set when ``EndpointType`` is set to ``VPC_ENDPOINT`` .\n')
    vpc_id: typing.Optional[str] = pydantic.Field(None, description='The VPC ID of the virtual private cloud in which the server\'s endpoint will be hosted. .. epigraph:: This property can only be set when ``EndpointType`` is set to ``VPC`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-server-endpointdetails.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    endpoint_details_property = transfer.CfnServer.EndpointDetailsProperty(\n        address_allocation_ids=["addressAllocationIds"],\n        security_group_ids=["securityGroupIds"],\n        subnet_ids=["subnetIds"],\n        vpc_endpoint_id="vpcEndpointId",\n        vpc_id="vpcId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['address_allocation_ids', 'security_group_ids', 'subnet_ids', 'vpc_endpoint_id', 'vpc_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnServer.EndpointDetailsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnServer.IdentityProviderDetailsProperty
class CfnServer_IdentityProviderDetailsPropertyDef(BaseStruct):
    directory_id: typing.Optional[str] = pydantic.Field(None, description='The identifier of the AWS Directory Service directory that you want to stop sharing.\n')
    function: typing.Optional[str] = pydantic.Field(None, description='The ARN for a Lambda function to use for the Identity provider.\n')
    invocation_role: typing.Optional[str] = pydantic.Field(None, description='This parameter is only applicable if your ``IdentityProviderType`` is ``API_GATEWAY`` . Provides the type of ``InvocationRole`` used to authenticate the user account.\n')
    sftp_authentication_methods: typing.Optional[str] = pydantic.Field(None, description='For SFTP-enabled servers, and for custom identity providers *only* , you can specify whether to authenticate using a password, SSH key pair, or both. - ``PASSWORD`` - users must provide their password to connect. - ``PUBLIC_KEY`` - users must provide their private key to connect. - ``PUBLIC_KEY_OR_PASSWORD`` - users can authenticate with either their password or their key. This is the default value. - ``PUBLIC_KEY_AND_PASSWORD`` - users must provide both their private key and their password to connect. The server checks the key first, and then if the key is valid, the system prompts for a password. If the private key provided does not match the public key that is stored, authentication fails.\n')
    url: typing.Optional[str] = pydantic.Field(None, description='Provides the location of the service endpoint used to authenticate users.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-server-identityproviderdetails.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    identity_provider_details_property = transfer.CfnServer.IdentityProviderDetailsProperty(\n        directory_id="directoryId",\n        function="function",\n        invocation_role="invocationRole",\n        sftp_authentication_methods="sftpAuthenticationMethods",\n        url="url"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['directory_id', 'function', 'invocation_role', 'sftp_authentication_methods', 'url']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnServer.IdentityProviderDetailsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnServer.ProtocolDetailsProperty
class CfnServer_ProtocolDetailsPropertyDef(BaseStruct):
    as2_transports: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='List of ``As2Transport`` objects.\n')
    passive_ip: typing.Optional[str] = pydantic.Field(None, description='Indicates passive mode, for FTP and FTPS protocols. Enter a single IPv4 address, such as the public IP address of a firewall, router, or load balancer. For example: ``aws transfer update-server --protocol-details PassiveIp=0.0.0.0`` Replace ``0.0.0.0`` in the example above with the actual IP address you want to use. .. epigraph:: If you change the ``PassiveIp`` value, you must stop and then restart your Transfer Family server for the change to take effect. For details on using passive mode (PASV) in a NAT environment, see `Configuring your FTPS server behind a firewall or NAT with AWS Transfer Family <https://docs.aws.amazon.com/storage/configuring-your-ftps-server-behind-a-firewall-or-nat-with-aws-transfer-family/>`_ . *Special values* The ``AUTO`` and ``0.0.0.0`` are special values for the ``PassiveIp`` parameter. The value ``PassiveIp=AUTO`` is assigned by default to FTP and FTPS type servers. In this case, the server automatically responds with one of the endpoint IPs within the PASV response. ``PassiveIp=0.0.0.0`` has a more unique application for its usage. For example, if you have a High Availability (HA) Network Load Balancer (NLB) environment, where you have 3 subnets, you can only specify a single IP address using the ``PassiveIp`` parameter. This reduces the effectiveness of having High Availability. In this case, you can specify ``PassiveIp=0.0.0.0`` . This tells the client to use the same IP address as the Control connection and utilize all AZs for their connections. Note, however, that not all FTP clients support the ``PassiveIp=0.0.0.0`` response. FileZilla and WinSCP do support it. If you are using other clients, check to see if your client supports the ``PassiveIp=0.0.0.0`` response.\n')
    set_stat_option: typing.Optional[str] = pydantic.Field(None, description='Use the ``SetStatOption`` to ignore the error that is generated when the client attempts to use ``SETSTAT`` on a file you are uploading to an S3 bucket. Some SFTP file transfer clients can attempt to change the attributes of remote files, including timestamp and permissions, using commands, such as ``SETSTAT`` when uploading the file. However, these commands are not compatible with object storage systems, such as Amazon S3. Due to this incompatibility, file uploads from these clients can result in errors even when the file is otherwise successfully uploaded. Set the value to ``ENABLE_NO_OP`` to have the Transfer Family server ignore the ``SETSTAT`` command, and upload files without needing to make any changes to your SFTP client. While the ``SetStatOption`` ``ENABLE_NO_OP`` setting ignores the error, it does generate a log entry in Amazon CloudWatch Logs, so you can determine when the client is making a ``SETSTAT`` call. .. epigraph:: If you want to preserve the original timestamp for your file, and modify other file attributes using ``SETSTAT`` , you can use Amazon EFS as backend storage with Transfer Family.\n')
    tls_session_resumption_mode: typing.Optional[str] = pydantic.Field(None, description='A property used with Transfer Family servers that use the FTPS protocol. TLS Session Resumption provides a mechanism to resume or share a negotiated secret key between the control and data connection for an FTPS session. ``TlsSessionResumptionMode`` determines whether or not the server resumes recent, negotiated sessions through a unique session ID. This property is available during ``CreateServer`` and ``UpdateServer`` calls. If a ``TlsSessionResumptionMode`` value is not specified during ``CreateServer`` , it is set to ``ENFORCED`` by default. - ``DISABLED`` : the server does not process TLS session resumption client requests and creates a new TLS session for each request. - ``ENABLED`` : the server processes and accepts clients that are performing TLS session resumption. The server doesn\'t reject client data connections that do not perform the TLS session resumption client processing. - ``ENFORCED`` : the server processes and accepts clients that are performing TLS session resumption. The server rejects client data connections that do not perform the TLS session resumption client processing. Before you set the value to ``ENFORCED`` , test your clients. .. epigraph:: Not all FTPS clients perform TLS session resumption. So, if you choose to enforce TLS session resumption, you prevent any connections from FTPS clients that don\'t perform the protocol negotiation. To determine whether or not you can use the ``ENFORCED`` value, you need to test your clients.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-server-protocoldetails.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    protocol_details_property = transfer.CfnServer.ProtocolDetailsProperty(\n        as2_transports=["as2Transports"],\n        passive_ip="passiveIp",\n        set_stat_option="setStatOption",\n        tls_session_resumption_mode="tlsSessionResumptionMode"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['as2_transports', 'passive_ip', 'set_stat_option', 'tls_session_resumption_mode']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnServer.ProtocolDetailsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnServer.WorkflowDetailProperty
class CfnServer_WorkflowDetailPropertyDef(BaseStruct):
    execution_role: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Includes the necessary permissions for S3, EFS, and Lambda operations that Transfer can assume, so that all workflow steps can operate on the required resources.\n')
    workflow_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A unique identifier for the workflow.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-server-workflowdetail.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    workflow_detail_property = transfer.CfnServer.WorkflowDetailProperty(\n        execution_role="executionRole",\n        workflow_id="workflowId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['execution_role', 'workflow_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnServer.WorkflowDetailProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnServer.WorkflowDetailsProperty
class CfnServer_WorkflowDetailsPropertyDef(BaseStruct):
    on_partial_upload: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_WorkflowDetailPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A trigger that starts a workflow if a file is only partially uploaded. You can attach a workflow to a server that executes whenever there is a partial upload. A *partial upload* occurs when a file is open when the session disconnects.\n')
    on_upload: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_WorkflowDetailPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A trigger that starts a workflow: the workflow begins to execute after a file is uploaded. To remove an associated workflow from a server, you can provide an empty ``OnUpload`` object, as in the following example. ``aws transfer update-server --server-id s-01234567890abcdef --workflow-details \'{"OnUpload":[]}\'``\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-server-workflowdetails.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    workflow_details_property = transfer.CfnServer.WorkflowDetailsProperty(\n        on_partial_upload=[transfer.CfnServer.WorkflowDetailProperty(\n            execution_role="executionRole",\n            workflow_id="workflowId"\n        )],\n        on_upload=[transfer.CfnServer.WorkflowDetailProperty(\n            execution_role="executionRole",\n            workflow_id="workflowId"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['on_partial_upload', 'on_upload']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnServer.WorkflowDetailsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnUser.HomeDirectoryMapEntryProperty
class CfnUser_HomeDirectoryMapEntryPropertyDef(BaseStruct):
    entry: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Represents an entry for ``HomeDirectoryMappings`` .\n')
    target: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Represents the map target that is used in a ``HomeDirectorymapEntry`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-user-homedirectorymapentry.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    home_directory_map_entry_property = transfer.CfnUser.HomeDirectoryMapEntryProperty(\n        entry="entry",\n        target="target"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['entry', 'target']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnUser.HomeDirectoryMapEntryProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnUser.PosixProfileProperty
class CfnUser_PosixProfilePropertyDef(BaseStruct):
    gid: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The POSIX group ID used for all EFS operations by this user.\n')
    uid: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The POSIX user ID used for all EFS operations by this user.\n')
    secondary_gids: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[int, float]], None] = pydantic.Field(None, description='The secondary POSIX group IDs used for all EFS operations by this user.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-user-posixprofile.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    posix_profile_property = transfer.CfnUser.PosixProfileProperty(\n        gid=123,\n        uid=123,\n\n        # the properties below are optional\n        secondary_gids=[123]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['gid', 'uid', 'secondary_gids']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnUser.PosixProfileProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow.CopyStepDetailsProperty
class CfnWorkflow_CopyStepDetailsPropertyDef(BaseStruct):
    destination_file_location: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_S3FileLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the location for the file being copied. Use ``${Transfer:UserName}`` or ``${Transfer:UploadDate}`` in this field to parametrize the destination prefix by username or uploaded date. - Set the value of ``DestinationFileLocation`` to ``${Transfer:UserName}`` to copy uploaded files to an Amazon S3 bucket that is prefixed with the name of the Transfer Family user that uploaded the file. - Set the value of ``DestinationFileLocation`` to ``${Transfer:UploadDate}`` to copy uploaded files to an Amazon S3 bucket that is prefixed with the date of the upload. .. epigraph:: The system resolves ``UploadDate`` to a date format of *YYYY-MM-DD* , based on the date the file is uploaded in UTC.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the step, used as an identifier.\n')
    overwrite_existing: typing.Optional[str] = pydantic.Field(None, description='A flag that indicates whether to overwrite an existing file of the same name. The default is ``FALSE`` . If the workflow is processing a file that has the same name as an existing file, the behavior is as follows: - If ``OverwriteExisting`` is ``TRUE`` , the existing file is replaced with the file being processed. - If ``OverwriteExisting`` is ``FALSE`` , nothing happens, and the workflow processing stops.\n')
    source_file_location: typing.Optional[str] = pydantic.Field(None, description='Specifies which file to use as input to the workflow step: either the output from the previous step, or the originally uploaded file for the workflow. - To use the previous file as the input, enter ``${previous.file}`` . In this case, this workflow step uses the output file from the previous workflow step as input. This is the default value. - To use the originally uploaded file location as input for this step, enter ``${original.file}`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-workflow-copystepdetails.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    copy_step_details_property = transfer.CfnWorkflow.CopyStepDetailsProperty(\n        destination_file_location=transfer.CfnWorkflow.S3FileLocationProperty(\n            s3_file_location=transfer.CfnWorkflow.S3InputFileLocationProperty(\n                bucket="bucket",\n                key="key"\n            )\n        ),\n        name="name",\n        overwrite_existing="overwriteExisting",\n        source_file_location="sourceFileLocation"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['destination_file_location', 'name', 'overwrite_existing', 'source_file_location']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow.CopyStepDetailsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow.CustomStepDetailsProperty
class CfnWorkflow_CustomStepDetailsPropertyDef(BaseStruct):
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the step, used as an identifier.\n')
    source_file_location: typing.Optional[str] = pydantic.Field(None, description='Specifies which file to use as input to the workflow step: either the output from the previous step, or the originally uploaded file for the workflow. - To use the previous file as the input, enter ``${previous.file}`` . In this case, this workflow step uses the output file from the previous workflow step as input. This is the default value. - To use the originally uploaded file location as input for this step, enter ``${original.file}`` .\n')
    target: typing.Optional[str] = pydantic.Field(None, description='The ARN for the Lambda function that is being called.\n')
    timeout_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='Timeout, in seconds, for the step.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-workflow-customstepdetails.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    custom_step_details_property = transfer.CfnWorkflow.CustomStepDetailsProperty(\n        name="name",\n        source_file_location="sourceFileLocation",\n        target="target",\n        timeout_seconds=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'source_file_location', 'target', 'timeout_seconds']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow.CustomStepDetailsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow.DecryptStepDetailsProperty
class CfnWorkflow_DecryptStepDetailsPropertyDef(BaseStruct):
    destination_file_location: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_InputFileLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the location for the file being decrypted. Use ``${Transfer:UserName}`` or ``${Transfer:UploadDate}`` in this field to parametrize the destination prefix by username or uploaded date. - Set the value of ``DestinationFileLocation`` to ``${Transfer:UserName}`` to decrypt uploaded files to an Amazon S3 bucket that is prefixed with the name of the Transfer Family user that uploaded the file. - Set the value of ``DestinationFileLocation`` to ``${Transfer:UploadDate}`` to decrypt uploaded files to an Amazon S3 bucket that is prefixed with the date of the upload. .. epigraph:: The system resolves ``UploadDate`` to a date format of *YYYY-MM-DD* , based on the date the file is uploaded in UTC.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the step, used as an identifier.\n')
    overwrite_existing: typing.Optional[str] = pydantic.Field(None, description='A flag that indicates whether to overwrite an existing file of the same name. The default is ``FALSE`` . If the workflow is processing a file that has the same name as an existing file, the behavior is as follows: - If ``OverwriteExisting`` is ``TRUE`` , the existing file is replaced with the file being processed. - If ``OverwriteExisting`` is ``FALSE`` , nothing happens, and the workflow processing stops.\n')
    source_file_location: typing.Optional[str] = pydantic.Field(None, description='Specifies which file to use as input to the workflow step: either the output from the previous step, or the originally uploaded file for the workflow. - To use the previous file as the input, enter ``${previous.file}`` . In this case, this workflow step uses the output file from the previous workflow step as input. This is the default value. - To use the originally uploaded file location as input for this step, enter ``${original.file}`` .\n')
    type: typing.Optional[str] = pydantic.Field(None, description='The type of encryption used. Currently, this value must be ``PGP`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-workflow-decryptstepdetails.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    decrypt_step_details_property = transfer.CfnWorkflow.DecryptStepDetailsProperty(\n        destination_file_location=transfer.CfnWorkflow.InputFileLocationProperty(\n            efs_file_location=transfer.CfnWorkflow.EfsInputFileLocationProperty(\n                file_system_id="fileSystemId",\n                path="path"\n            ),\n            s3_file_location=transfer.CfnWorkflow.S3InputFileLocationProperty(\n                bucket="bucket",\n                key="key"\n            )\n        ),\n        name="name",\n        overwrite_existing="overwriteExisting",\n        source_file_location="sourceFileLocation",\n        type="type"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['destination_file_location', 'name', 'overwrite_existing', 'source_file_location', 'type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow.DecryptStepDetailsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow.DeleteStepDetailsProperty
class CfnWorkflow_DeleteStepDetailsPropertyDef(BaseStruct):
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the step, used as an identifier.\n')
    source_file_location: typing.Optional[str] = pydantic.Field(None, description='Specifies which file to use as input to the workflow step: either the output from the previous step, or the originally uploaded file for the workflow. - To use the previous file as the input, enter ``${previous.file}`` . In this case, this workflow step uses the output file from the previous workflow step as input. This is the default value. - To use the originally uploaded file location as input for this step, enter ``${original.file}`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-workflow-deletestepdetails.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    delete_step_details_property = transfer.CfnWorkflow.DeleteStepDetailsProperty(\n        name="name",\n        source_file_location="sourceFileLocation"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'source_file_location']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow.DeleteStepDetailsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow.EfsInputFileLocationProperty
class CfnWorkflow_EfsInputFileLocationPropertyDef(BaseStruct):
    file_system_id: typing.Optional[str] = pydantic.Field(None, description='The identifier of the file system, assigned by Amazon EFS.\n')
    path: typing.Optional[str] = pydantic.Field(None, description='The pathname for the folder being used by a workflow.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-workflow-efsinputfilelocation.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    efs_input_file_location_property = transfer.CfnWorkflow.EfsInputFileLocationProperty(\n        file_system_id="fileSystemId",\n        path="path"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['file_system_id', 'path']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow.EfsInputFileLocationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow.InputFileLocationProperty
class CfnWorkflow_InputFileLocationPropertyDef(BaseStruct):
    efs_file_location: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_EfsInputFileLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Specifies the details for the Amazon Elastic File System (Amazon EFS) file that's being decrypted.\n")
    s3_file_location: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_S3InputFileLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the details for the Amazon S3 file that\'s being copied or decrypted.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-workflow-inputfilelocation.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    input_file_location_property = transfer.CfnWorkflow.InputFileLocationProperty(\n        efs_file_location=transfer.CfnWorkflow.EfsInputFileLocationProperty(\n            file_system_id="fileSystemId",\n            path="path"\n        ),\n        s3_file_location=transfer.CfnWorkflow.S3InputFileLocationProperty(\n            bucket="bucket",\n            key="key"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['efs_file_location', 's3_file_location']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow.InputFileLocationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow.S3FileLocationProperty
class CfnWorkflow_S3FileLocationPropertyDef(BaseStruct):
    s3_file_location: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_S3InputFileLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the details for the file location for the file that\'s being used in the workflow. Only applicable if you are using Amazon S3 storage.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-workflow-s3filelocation.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    s3_file_location_property = transfer.CfnWorkflow.S3FileLocationProperty(\n        s3_file_location=transfer.CfnWorkflow.S3InputFileLocationProperty(\n            bucket="bucket",\n            key="key"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['s3_file_location']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow.S3FileLocationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow.S3InputFileLocationProperty
class CfnWorkflow_S3InputFileLocationPropertyDef(BaseStruct):
    bucket: typing.Optional[str] = pydantic.Field(None, description='Specifies the S3 bucket for the customer input file.\n')
    key: typing.Optional[str] = pydantic.Field(None, description='The name assigned to the file when it was created in Amazon S3. You use the object key to retrieve the object.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-workflow-s3inputfilelocation.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    s3_input_file_location_property = transfer.CfnWorkflow.S3InputFileLocationProperty(\n        bucket="bucket",\n        key="key"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['bucket', 'key']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow.S3InputFileLocationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow.S3TagProperty
class CfnWorkflow_S3TagPropertyDef(BaseStruct):
    key: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name assigned to the tag that you create.\n')
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The value that corresponds to the key.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-workflow-s3tag.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    s3_tag_property = transfer.CfnWorkflow.S3TagProperty(\n        key="key",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['key', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow.S3TagProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow.TagStepDetailsProperty
class CfnWorkflow_TagStepDetailsPropertyDef(BaseStruct):
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the step, used as an identifier.\n')
    source_file_location: typing.Optional[str] = pydantic.Field(None, description='Specifies which file to use as input to the workflow step: either the output from the previous step, or the originally uploaded file for the workflow. - To use the previous file as the input, enter ``${previous.file}`` . In this case, this workflow step uses the output file from the previous workflow step as input. This is the default value. - To use the originally uploaded file location as input for this step, enter ``${original.file}`` .\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.aws_transfer.CfnWorkflow_S3TagPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Array that contains from 1 to 10 key/value pairs.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-workflow-tagstepdetails.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    tag_step_details_property = transfer.CfnWorkflow.TagStepDetailsProperty(\n        name="name",\n        source_file_location="sourceFileLocation",\n        tags=[transfer.CfnWorkflow.S3TagProperty(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'source_file_location', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow.TagStepDetailsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow.WorkflowStepProperty
class CfnWorkflow_WorkflowStepPropertyDef(BaseStruct):
    copy_step_details: typing.Any = pydantic.Field(None, description='Details for a step that performs a file copy. Consists of the following values: - A description - An Amazon S3 location for the destination of the file copy. - A flag that indicates whether to overwrite an existing file of the same name. The default is ``FALSE`` .\n')
    custom_step_details: typing.Any = pydantic.Field(None, description="Details for a step that invokes an AWS Lambda function. Consists of the Lambda function's name, target, and timeout (in seconds).\n")
    decrypt_step_details: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_DecryptStepDetailsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Details for a step that decrypts an encrypted file. Consists of the following values: - A descriptive name - An Amazon S3 or Amazon Elastic File System (Amazon EFS) location for the source file to decrypt. - An S3 or Amazon EFS location for the destination of the file decryption. - A flag that indicates whether to overwrite an existing file of the same name. The default is ``FALSE`` . - The type of encryption that's used. Currently, only PGP encryption is supported.\n")
    delete_step_details: typing.Any = pydantic.Field(None, description='Details for a step that deletes the file.\n')
    tag_step_details: typing.Any = pydantic.Field(None, description='Details for a step that creates one or more tags. You specify one or more tags. Each tag contains a key-value pair.\n')
    type: typing.Optional[str] = pydantic.Field(None, description='Currently, the following step types are supported. - *``COPY``* - Copy the file to another location. - *``CUSTOM``* - Perform a custom step with an AWS Lambda function target. - *``DECRYPT``* - Decrypt a file that was encrypted before it was uploaded. - *``DELETE``* - Delete the file. - *``TAG``* - Add a tag to the file.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-transfer-workflow-workflowstep.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    # copy_step_details: Any\n    # custom_step_details: Any\n    # delete_step_details: Any\n    # tag_step_details: Any\n\n    workflow_step_property = transfer.CfnWorkflow.WorkflowStepProperty(\n        copy_step_details=copy_step_details,\n        custom_step_details=custom_step_details,\n        decrypt_step_details=transfer.CfnWorkflow.DecryptStepDetailsProperty(\n            destination_file_location=transfer.CfnWorkflow.InputFileLocationProperty(\n                efs_file_location=transfer.CfnWorkflow.EfsInputFileLocationProperty(\n                    file_system_id="fileSystemId",\n                    path="path"\n                ),\n                s3_file_location=transfer.CfnWorkflow.S3InputFileLocationProperty(\n                    bucket="bucket",\n                    key="key"\n                )\n            ),\n            name="name",\n            overwrite_existing="overwriteExisting",\n            source_file_location="sourceFileLocation",\n            type="type"\n        ),\n        delete_step_details=delete_step_details,\n        tag_step_details=tag_step_details,\n        type="type"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['copy_step_details', 'custom_step_details', 'decrypt_step_details', 'delete_step_details', 'tag_step_details', 'type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow.WorkflowStepProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnAgreement
class CfnAgreementDef(BaseCfnResource):
    access_role: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Connectors are used to send files using either the AS2 or SFTP protocol. For the access role, provide the Amazon Resource Name (ARN) of the AWS Identity and Access Management role to use. *For AS2 connectors* With AS2, you can send files by calling ``StartFileTransfer`` and specifying the file paths in the request parameter, ``SendFilePaths`` . We use the file’s parent directory (for example, for ``--send-file-paths /bucket/dir/file.txt`` , parent directory is ``/bucket/dir/`` ) to temporarily store a processed AS2 message file, store the MDN when we receive them from the partner, and write a final JSON file containing relevant metadata of the transmission. So, the ``AccessRole`` needs to provide read and write access to the parent directory of the file location used in the ``StartFileTransfer`` request. Additionally, you need to provide read and write access to the parent directory of the files that you intend to send with ``StartFileTransfer`` . If you are using Basic authentication for your AS2 connector, the access role requires the ``secretsmanager:GetSecretValue`` permission for the secret. If the secret is encrypted using a customer-managed key instead of the AWS managed key in Secrets Manager, then the role also needs the ``kms:Decrypt`` permission for that key. *For SFTP connectors* Make sure that the access role provides read and write access to the parent directory of the file location that's used in the ``StartFileTransfer`` request. Additionally, make sure that the role provides ``secretsmanager:GetSecretValue`` permission to AWS Secrets Manager .\n")
    base_directory: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The landing directory (folder) for files that are transferred by using the AS2 protocol.\n')
    local_profile_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A unique identifier for the AS2 local profile.\n')
    partner_profile_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A unique identifier for the partner profile used in the agreement.\n')
    server_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A system-assigned unique identifier for a server instance. This identifier indicates the specific server that the agreement uses.\n')
    description: typing.Optional[str] = pydantic.Field(None, description="The name or short description that's used to identify the agreement.\n")
    status: typing.Optional[str] = pydantic.Field(None, description='The current status of the agreement, either ``ACTIVE`` or ``INACTIVE`` .\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for agreements.')
    _init_params: typing.ClassVar[list[str]] = ['access_role', 'base_directory', 'local_profile_id', 'partner_profile_id', 'server_id', 'description', 'status', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnAgreement'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnAgreementDefConfig] = pydantic.Field(None)


class CfnAgreementDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnAgreementDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnAgreementDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnAgreementDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnAgreementDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnAgreementDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnAgreementDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnAgreementDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnAgreementDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnAgreementDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnAgreementDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnAgreementDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnAgreementDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnAgreementDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnAgreementDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnAgreementDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnAgreementDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnAgreementDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnAgreementDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnAgreementDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnAgreementDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnAgreementDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnAgreementDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnAgreementDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnAgreementDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnAgreementDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnAgreementDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnAgreementDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_transfer.CfnCertificate
class CfnCertificateDef(BaseCfnResource):
    certificate: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The file name for the certificate.\n')
    usage: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies whether this certificate is used for signing or encryption.\n')
    active_date: typing.Optional[str] = pydantic.Field(None, description='An optional date that specifies when the certificate becomes active.\n')
    certificate_chain: typing.Optional[str] = pydantic.Field(None, description='The list of certificates that make up the chain for the certificate.\n')
    description: typing.Optional[str] = pydantic.Field(None, description="The name or description that's used to identity the certificate.\n")
    inactive_date: typing.Optional[str] = pydantic.Field(None, description='An optional date that specifies when the certificate becomes inactive.\n')
    private_key: typing.Optional[str] = pydantic.Field(None, description="The file that contains the private key for the certificate that's being imported.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for certificates.')
    _init_params: typing.ClassVar[list[str]] = ['certificate', 'usage', 'active_date', 'certificate_chain', 'description', 'inactive_date', 'private_key', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnCertificate'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnCertificateDefConfig] = pydantic.Field(None)


class CfnCertificateDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnCertificateDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnCertificateDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnCertificateDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnCertificateDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnCertificateDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnCertificateDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnCertificateDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnCertificateDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnCertificateDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnCertificateDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnCertificateDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnCertificateDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnCertificateDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnCertificateDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnCertificateDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnCertificateDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnCertificateDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnCertificateDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnCertificateDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnCertificateDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnCertificateDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnCertificateDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnCertificateDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnCertificateDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnCertificateDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnCertificateDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnCertificateDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_transfer.CfnConnector
class CfnConnectorDef(BaseCfnResource):
    access_role: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Connectors are used to send files using either the AS2 or SFTP protocol. For the access role, provide the Amazon Resource Name (ARN) of the AWS Identity and Access Management role to use. *For AS2 connectors* With AS2, you can send files by calling ``StartFileTransfer`` and specifying the file paths in the request parameter, ``SendFilePaths`` . We use the file’s parent directory (for example, for ``--send-file-paths /bucket/dir/file.txt`` , parent directory is ``/bucket/dir/`` ) to temporarily store a processed AS2 message file, store the MDN when we receive them from the partner, and write a final JSON file containing relevant metadata of the transmission. So, the ``AccessRole`` needs to provide read and write access to the parent directory of the file location used in the ``StartFileTransfer`` request. Additionally, you need to provide read and write access to the parent directory of the files that you intend to send with ``StartFileTransfer`` . If you are using Basic authentication for your AS2 connector, the access role requires the ``secretsmanager:GetSecretValue`` permission for the secret. If the secret is encrypted using a customer-managed key instead of the AWS managed key in Secrets Manager, then the role also needs the ``kms:Decrypt`` permission for that key. *For SFTP connectors* Make sure that the access role provides read and write access to the parent directory of the file location that's used in the ``StartFileTransfer`` request. Additionally, make sure that the role provides ``secretsmanager:GetSecretValue`` permission to AWS Secrets Manager .\n")
    url: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The URL of the partner's AS2 or SFTP endpoint.\n")
    as2_config: typing.Any = pydantic.Field(None, description='A structure that contains the parameters for an AS2 connector object.\n')
    logging_role: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows a connector to turn on CloudWatch logging for Amazon S3 events. When set, you can view connector activity in your CloudWatch logs.\n')
    sftp_config: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnConnector_SftpConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A structure that contains the parameters for an SFTP connector object.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for connectors.')
    _init_params: typing.ClassVar[list[str]] = ['access_role', 'url', 'as2_config', 'logging_role', 'sftp_config', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['As2ConfigProperty', 'SftpConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnConnector'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnConnectorDefConfig] = pydantic.Field(None)


class CfnConnectorDefConfig(pydantic.BaseModel):
    As2ConfigProperty: typing.Optional[list[CfnConnectorDefAs2ConfigpropertyParams]] = pydantic.Field(None, description='')
    SftpConfigProperty: typing.Optional[list[CfnConnectorDefSftpconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnConnectorDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnConnectorDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnConnectorDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnConnectorDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnConnectorDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnConnectorDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnConnectorDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnConnectorDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnConnectorDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnConnectorDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnConnectorDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnConnectorDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnConnectorDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnConnectorDefAs2ConfigpropertyParams(pydantic.BaseModel):
    basic_auth_secret_id: typing.Optional[str] = pydantic.Field(None, description='')
    compression: typing.Optional[str] = pydantic.Field(None, description='')
    encryption_algorithm: typing.Optional[str] = pydantic.Field(None, description='')
    local_profile_id: typing.Optional[str] = pydantic.Field(None, description='')
    mdn_response: typing.Optional[str] = pydantic.Field(None, description='')
    mdn_signing_algorithm: typing.Optional[str] = pydantic.Field(None, description='')
    message_subject: typing.Optional[str] = pydantic.Field(None, description='')
    partner_profile_id: typing.Optional[str] = pydantic.Field(None, description='')
    signing_algorithm: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnConnectorDefSftpconfigpropertyParams(pydantic.BaseModel):
    trusted_host_keys: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    user_secret_id: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnConnectorDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnConnectorDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnConnectorDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnConnectorDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnConnectorDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnConnectorDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnConnectorDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnConnectorDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnConnectorDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnConnectorDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnConnectorDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnConnectorDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnConnectorDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnConnectorDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_transfer.CfnProfile
class CfnProfileDef(BaseCfnResource):
    as2_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ``As2Id`` is the *AS2-name* , as defined in the `RFC 4130 <https://docs.aws.amazon.com/https://datatracker.ietf.org/doc/html/rfc4130>`_ . For inbound transfers, this is the ``AS2-From`` header for the AS2 messages sent from the partner. For outbound connectors, this is the ``AS2-To`` header for the AS2 messages sent to the partner using the ``StartFileTransfer`` API operation. This ID cannot include spaces.\n')
    profile_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Indicates whether to list only ``LOCAL`` type profiles or only ``PARTNER`` type profiles. If not supplied in the request, the command lists all types of profiles.\n')
    certificate_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of identifiers for the imported certificates. You use this identifier for working with profiles and partner profiles.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for profiles.')
    _init_params: typing.ClassVar[list[str]] = ['as2_id', 'profile_type', 'certificate_ids', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnProfile'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnProfileDefConfig] = pydantic.Field(None)


class CfnProfileDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnProfileDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnProfileDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnProfileDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnProfileDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnProfileDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnProfileDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnProfileDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnProfileDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnProfileDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnProfileDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnProfileDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnProfileDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnProfileDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnProfileDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnProfileDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnProfileDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnProfileDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnProfileDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnProfileDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnProfileDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnProfileDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnProfileDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnProfileDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnProfileDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnProfileDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnProfileDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnProfileDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_transfer.CfnServer
class CfnServerDef(BaseCfnResource):
    certificate: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the AWS Certificate Manager (ACM) certificate. Required when ``Protocols`` is set to ``FTPS`` . To request a new public certificate, see `Request a public certificate <https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-request-public.html>`_ in the *AWS Certificate Manager User Guide* . To import an existing certificate into ACM, see `Importing certificates into ACM <https://docs.aws.amazon.com/acm/latest/userguide/import-certificate.html>`_ in the *AWS Certificate Manager User Guide* . To request a private certificate to use FTPS through private IP addresses, see `Request a private certificate <https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-request-private.html>`_ in the *AWS Certificate Manager User Guide* . Certificates with the following cryptographic algorithms and key sizes are supported: - 2048-bit RSA (RSA_2048) - 4096-bit RSA (RSA_4096) - Elliptic Prime Curve 256 bit (EC_prime256v1) - Elliptic Prime Curve 384 bit (EC_secp384r1) - Elliptic Prime Curve 521 bit (EC_secp521r1) .. epigraph:: The certificate must be a valid SSL/TLS X.509 version 3 certificate with FQDN or IP address specified and information about the issuer.\n')
    domain: typing.Optional[str] = pydantic.Field(None, description='Specifies the domain of the storage system that is used for file transfers.\n')
    endpoint_details: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_EndpointDetailsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="The virtual private cloud (VPC) endpoint settings that are configured for your server. When you host your endpoint within your VPC, you can make your endpoint accessible only to resources within your VPC, or you can attach Elastic IP addresses and make your endpoint accessible to clients over the internet. Your VPC's default security groups are automatically assigned to your endpoint.\n")
    endpoint_type: typing.Optional[str] = pydantic.Field(None, description="The type of endpoint that you want your server to use. You can choose to make your server's endpoint publicly accessible (PUBLIC) or host it inside your VPC. With an endpoint that is hosted in a VPC, you can restrict access to your server and resources only within your VPC or choose to make it internet facing by attaching Elastic IP addresses directly to it. .. epigraph:: After May 19, 2021, you won't be able to create a server using ``EndpointType=VPC_ENDPOINT`` in your AWS account if your account hasn't already done so before May 19, 2021. If you have already created servers with ``EndpointType=VPC_ENDPOINT`` in your AWS account on or before May 19, 2021, you will not be affected. After this date, use ``EndpointType`` = ``VPC`` . For more information, see `Discontinuing the use of VPC_ENDPOINT <https://docs.aws.amazon.com//transfer/latest/userguide/create-server-in-vpc.html#deprecate-vpc-endpoint>`_ . It is recommended that you use ``VPC`` as the ``EndpointType`` . With this endpoint type, you have the option to directly associate up to three Elastic IPv4 addresses (BYO IP included) with your server's endpoint and use VPC security groups to restrict traffic by the client's public IP address. This is not possible with ``EndpointType`` set to ``VPC_ENDPOINT`` .\n")
    identity_provider_details: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_IdentityProviderDetailsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Required when ``IdentityProviderType`` is set to ``AWS_DIRECTORY_SERVICE`` , ``AWS _LAMBDA`` or ``API_GATEWAY`` . Accepts an array containing all of the information required to use a directory in ``AWS_DIRECTORY_SERVICE`` or invoke a customer-supplied authentication API, including the API Gateway URL. Not required when ``IdentityProviderType`` is set to ``SERVICE_MANAGED`` .\n')
    identity_provider_type: typing.Optional[str] = pydantic.Field(None, description='The mode of authentication for a server. The default value is ``SERVICE_MANAGED`` , which allows you to store and access user credentials within the AWS Transfer Family service. Use ``AWS_DIRECTORY_SERVICE`` to provide access to Active Directory groups in AWS Directory Service for Microsoft Active Directory or Microsoft Active Directory in your on-premises environment or in AWS using AD Connector. This option also requires you to provide a Directory ID by using the ``IdentityProviderDetails`` parameter. Use the ``API_GATEWAY`` value to integrate with an identity provider of your choosing. The ``API_GATEWAY`` setting requires you to provide an Amazon API Gateway endpoint URL to call for authentication by using the ``IdentityProviderDetails`` parameter. Use the ``AWS_LAMBDA`` value to directly use an AWS Lambda function as your identity provider. If you choose this value, you must specify the ARN for the Lambda function in the ``Function`` parameter for the ``IdentityProviderDetails`` data type.\n')
    logging_role: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows a server to turn on Amazon CloudWatch logging for Amazon S3 or Amazon EFSevents. When set, you can view user activity in your CloudWatch logs.\n')
    post_authentication_login_banner: typing.Optional[str] = pydantic.Field(None, description='Specifies a string to display when users connect to a server. This string is displayed after the user authenticates. .. epigraph:: The SFTP protocol does not support post-authentication display banners.\n')
    pre_authentication_login_banner: typing.Optional[str] = pydantic.Field(None, description='Specifies a string to display when users connect to a server. This string is displayed before the user authenticates. For example, the following banner displays details about using the system: ``This system is for the use of authorized users only. Individuals using this computer system without authority, or in excess of their authority, are subject to having all of their activities on this system monitored and recorded by system personnel.``\n')
    protocol_details: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_ProtocolDetailsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The protocol settings that are configured for your server. - To indicate passive mode (for FTP and FTPS protocols), use the ``PassiveIp`` parameter. Enter a single dotted-quad IPv4 address, such as the external IP address of a firewall, router, or load balancer. - To ignore the error that is generated when the client attempts to use the ``SETSTAT`` command on a file that you are uploading to an Amazon S3 bucket, use the ``SetStatOption`` parameter. To have the AWS Transfer Family server ignore the ``SETSTAT`` command and upload files without needing to make any changes to your SFTP client, set the value to ``ENABLE_NO_OP`` . If you set the ``SetStatOption`` parameter to ``ENABLE_NO_OP`` , Transfer Family generates a log entry to Amazon CloudWatch Logs, so that you can determine when the client is making a ``SETSTAT`` call. - To determine whether your AWS Transfer Family server resumes recent, negotiated sessions through a unique session ID, use the ``TlsSessionResumptionMode`` parameter. - ``As2Transports`` indicates the transport method for the AS2 messages. Currently, only HTTP is supported. The ``Protocols`` parameter is an array of strings. *Allowed values* : One or more of ``SFTP`` , ``FTPS`` , ``FTP`` , ``AS2``\n')
    protocols: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="Specifies the file transfer protocol or protocols over which your file transfer protocol client can connect to your server's endpoint. The available protocols are: - ``SFTP`` (Secure Shell (SSH) File Transfer Protocol): File transfer over SSH - ``FTPS`` (File Transfer Protocol Secure): File transfer with TLS encryption - ``FTP`` (File Transfer Protocol): Unencrypted file transfer - ``AS2`` (Applicability Statement 2): used for transporting structured business-to-business data .. epigraph:: - If you select ``FTPS`` , you must choose a certificate stored in AWS Certificate Manager (ACM) which is used to identify your server when clients connect to it over FTPS. - If ``Protocol`` includes either ``FTP`` or ``FTPS`` , then the ``EndpointType`` must be ``VPC`` and the ``IdentityProviderType`` must be either ``AWS_DIRECTORY_SERVICE`` , ``AWS_LAMBDA`` , or ``API_GATEWAY`` . - If ``Protocol`` includes ``FTP`` , then ``AddressAllocationIds`` cannot be associated. - If ``Protocol`` is set only to ``SFTP`` , the ``EndpointType`` can be set to ``PUBLIC`` and the ``IdentityProviderType`` can be set any of the supported identity types: ``SERVICE_MANAGED`` , ``AWS_DIRECTORY_SERVICE`` , ``AWS_LAMBDA`` , or ``API_GATEWAY`` . - If ``Protocol`` includes ``AS2`` , then the ``EndpointType`` must be ``VPC`` , and domain must be Amazon S3. The ``Protocols`` parameter is an array of strings. *Allowed values* : One or more of ``SFTP`` , ``FTPS`` , ``FTP`` , ``AS2``\n")
    security_policy_name: typing.Optional[str] = pydantic.Field(None, description='Specifies the name of the security policy that is attached to the server.\n')
    structured_log_destinations: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Specifies the log groups to which your server logs are sent. To specify a log group, you must provide the ARN for an existing log group. In this case, the format of the log group is as follows: ``arn:aws:logs:region-name:amazon-account-id:log-group:log-group-name:*`` For example, ``arn:aws:logs:us-east-1:111122223333:log-group:mytestgroup:*`` If you have previously specified a log group for a server, you can clear it, and in effect turn off structured logging, by providing an empty value for this parameter in an ``update-server`` call. For example: ``update-server --server-id s-1234567890abcdef0 --structured-log-destinations``\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for servers.\n')
    workflow_details: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_WorkflowDetailsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Specifies the workflow ID for the workflow to assign and the execution role that's used for executing the workflow. In addition to a workflow to execute when a file is uploaded completely, ``WorkflowDetails`` can also contain a workflow ID (and execution role) for a workflow to execute on partial upload. A partial upload occurs when a file is open when the session disconnects.")
    _init_params: typing.ClassVar[list[str]] = ['certificate', 'domain', 'endpoint_details', 'endpoint_type', 'identity_provider_details', 'identity_provider_type', 'logging_role', 'post_authentication_login_banner', 'pre_authentication_login_banner', 'protocol_details', 'protocols', 'security_policy_name', 'structured_log_destinations', 'tags', 'workflow_details']
    _method_names: typing.ClassVar[list[str]] = ['EndpointDetailsProperty', 'IdentityProviderDetailsProperty', 'ProtocolDetailsProperty', 'WorkflowDetailProperty', 'WorkflowDetailsProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnServer'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnServerDefConfig] = pydantic.Field(None)


class CfnServerDefConfig(pydantic.BaseModel):
    EndpointDetailsProperty: typing.Optional[list[CfnServerDefEndpointdetailspropertyParams]] = pydantic.Field(None, description='')
    IdentityProviderDetailsProperty: typing.Optional[list[CfnServerDefIdentityproviderdetailspropertyParams]] = pydantic.Field(None, description='')
    ProtocolDetailsProperty: typing.Optional[list[CfnServerDefProtocoldetailspropertyParams]] = pydantic.Field(None, description='')
    WorkflowDetailProperty: typing.Optional[list[CfnServerDefWorkflowdetailpropertyParams]] = pydantic.Field(None, description='')
    WorkflowDetailsProperty: typing.Optional[list[CfnServerDefWorkflowdetailspropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnServerDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnServerDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnServerDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnServerDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnServerDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnServerDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnServerDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnServerDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnServerDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnServerDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnServerDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnServerDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnServerDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnServerDefEndpointdetailspropertyParams(pydantic.BaseModel):
    address_allocation_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    security_group_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    subnet_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    vpc_endpoint_id: typing.Optional[str] = pydantic.Field(None, description='')
    vpc_id: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnServerDefIdentityproviderdetailspropertyParams(pydantic.BaseModel):
    directory_id: typing.Optional[str] = pydantic.Field(None, description='')
    function: typing.Optional[str] = pydantic.Field(None, description='')
    invocation_role: typing.Optional[str] = pydantic.Field(None, description='')
    sftp_authentication_methods: typing.Optional[str] = pydantic.Field(None, description='')
    url: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnServerDefProtocoldetailspropertyParams(pydantic.BaseModel):
    as2_transports: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    passive_ip: typing.Optional[str] = pydantic.Field(None, description='')
    set_stat_option: typing.Optional[str] = pydantic.Field(None, description='')
    tls_session_resumption_mode: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnServerDefWorkflowdetailpropertyParams(pydantic.BaseModel):
    execution_role: str = pydantic.Field(..., description='')
    workflow_id: str = pydantic.Field(..., description='')
    ...

class CfnServerDefWorkflowdetailspropertyParams(pydantic.BaseModel):
    on_partial_upload: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_WorkflowDetailPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    on_upload: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_WorkflowDetailPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnServerDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnServerDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnServerDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnServerDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnServerDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnServerDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnServerDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnServerDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnServerDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnServerDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnServerDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnServerDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnServerDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnServerDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_transfer.CfnUser
class CfnUserDef(BaseCfnResource):
    role: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that controls your users' access to your Amazon S3 bucket or Amazon EFS file system. The policies attached to this role determine the level of access that you want to provide your users when transferring files into and out of your Amazon S3 bucket or Amazon EFS file system. The IAM role should also contain a trust relationship that allows the server to access your resources when servicing your users' transfer requests.\n")
    server_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A system-assigned unique identifier for a server instance. This is the specific server that you added your user to.\n')
    user_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="A unique string that identifies a user and is associated with a ``ServerId`` . This user name must be a minimum of 3 and a maximum of 100 characters long. The following are valid characters: a-z, A-Z, 0-9, underscore '_', hyphen '-', period '.', and at sign '@'. The user name can't start with a hyphen, period, or at sign.\n")
    home_directory: typing.Optional[str] = pydantic.Field(None, description='The landing directory (folder) for a user when they log in to the server using the client. A ``HomeDirectory`` example is ``/bucket_name/home/mydirectory`` . .. epigraph:: The ``HomeDirectory`` parameter is only used if ``HomeDirectoryType`` is set to ``PATH`` .\n')
    home_directory_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_transfer.CfnUser_HomeDirectoryMapEntryPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Logical directory mappings that specify what Amazon S3 or Amazon EFS paths and keys should be visible to your user and how you want to make them visible. You must specify the ``Entry`` and ``Target`` pair, where ``Entry`` shows how the path is made visible and ``Target`` is the actual Amazon S3 or Amazon EFS path. If you only specify a target, it is displayed as is. You also must ensure that your AWS Identity and Access Management (IAM) role provides access to paths in ``Target`` . This value can be set only when ``HomeDirectoryType`` is set to *LOGICAL* . The following is an ``Entry`` and ``Target`` pair example. ``[ { "Entry": "/directory1", "Target": "/bucket_name/home/mydirectory" } ]`` In most cases, you can use this value instead of the session policy to lock your user down to the designated home directory (" ``chroot`` "). To do this, you can set ``Entry`` to ``/`` and set ``Target`` to the value the user should see for their home directory when they log in. The following is an ``Entry`` and ``Target`` pair example for ``chroot`` . ``[ { "Entry": "/", "Target": "/bucket_name/home/mydirectory" } ]``\n')
    home_directory_type: typing.Optional[str] = pydantic.Field(None, description="The type of landing directory (folder) that you want your users' home directory to be when they log in to the server. If you set it to ``PATH`` , the user will see the absolute Amazon S3 bucket or Amazon EFS path as is in their file transfer protocol clients. If you set it to ``LOGICAL`` , you need to provide mappings in the ``HomeDirectoryMappings`` for how you want to make Amazon S3 or Amazon EFS paths visible to your users. .. epigraph:: If ``HomeDirectoryType`` is ``LOGICAL`` , you must provide mappings, using the ``HomeDirectoryMappings`` parameter. If, on the other hand, ``HomeDirectoryType`` is ``PATH`` , you provide an absolute path using the ``HomeDirectory`` parameter. You cannot have both ``HomeDirectory`` and ``HomeDirectoryMappings`` in your template.\n")
    policy: typing.Optional[str] = pydantic.Field(None, description='A session policy for your user so you can use the same IAM role across multiple users. This policy restricts user access to portions of their Amazon S3 bucket. Variables that you can use inside this policy include ``${Transfer:UserName}`` , ``${Transfer:HomeDirectory}`` , and ``${Transfer:HomeBucket}`` . .. epigraph:: For session policies, AWS Transfer Family stores the policy as a JSON blob, instead of the Amazon Resource Name (ARN) of the policy. You save the policy as a JSON blob and pass it in the ``Policy`` argument. For an example of a session policy, see `Example session policy <https://docs.aws.amazon.com/transfer/latest/userguide/session-policy.html>`_ . For more information, see `AssumeRole <https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html>`_ in the *AWS Security Token Service API Reference* .\n')
    posix_profile: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnUser_PosixProfilePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Specifies the full POSIX identity, including user ID ( ``Uid`` ), group ID ( ``Gid`` ), and any secondary groups IDs ( ``SecondaryGids`` ), that controls your users' access to your Amazon Elastic File System (Amazon EFS) file systems. The POSIX permissions that are set on files and directories in your file system determine the level of access your users get when transferring files into and out of your Amazon EFS file systems.\n")
    ssh_public_keys: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Specifies the public key portion of the Secure Shell (SSH) keys stored for the described user.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for users. Tags are metadata attached to users for any purpose.')
    _init_params: typing.ClassVar[list[str]] = ['role', 'server_id', 'user_name', 'home_directory', 'home_directory_mappings', 'home_directory_type', 'policy', 'posix_profile', 'ssh_public_keys', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['HomeDirectoryMapEntryProperty', 'PosixProfileProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnUser'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnUserDefConfig] = pydantic.Field(None)


class CfnUserDefConfig(pydantic.BaseModel):
    HomeDirectoryMapEntryProperty: typing.Optional[list[CfnUserDefHomedirectorymapentrypropertyParams]] = pydantic.Field(None, description='')
    PosixProfileProperty: typing.Optional[list[CfnUserDefPosixprofilepropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnUserDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnUserDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnUserDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnUserDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnUserDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnUserDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnUserDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnUserDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnUserDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnUserDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnUserDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnUserDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnUserDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnUserDefHomedirectorymapentrypropertyParams(pydantic.BaseModel):
    entry: str = pydantic.Field(..., description='')
    target: str = pydantic.Field(..., description='')
    ...

class CfnUserDefPosixprofilepropertyParams(pydantic.BaseModel):
    gid: typing.Union[int, float] = pydantic.Field(..., description='')
    uid: typing.Union[int, float] = pydantic.Field(..., description='')
    secondary_gids: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[int, float]], None] = pydantic.Field(None, description='')
    ...

class CfnUserDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnUserDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnUserDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnUserDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnUserDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnUserDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnUserDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnUserDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnUserDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnUserDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnUserDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnUserDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnUserDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnUserDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_transfer.CfnWorkflow
class CfnWorkflowDef(BaseCfnResource):
    steps: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_WorkflowStepPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the details for the steps that are in the specified workflow.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='Specifies the text description for the workflow.\n')
    on_exception_steps: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_WorkflowStepPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Specifies the steps (actions) to take if errors are encountered during execution of the workflow.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for workflows. Tags are metadata attached to workflows for any purpose.')
    _init_params: typing.ClassVar[list[str]] = ['steps', 'description', 'on_exception_steps', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['CopyStepDetailsProperty', 'CustomStepDetailsProperty', 'DecryptStepDetailsProperty', 'DeleteStepDetailsProperty', 'EfsInputFileLocationProperty', 'InputFileLocationProperty', 'S3FileLocationProperty', 'S3InputFileLocationProperty', 'S3TagProperty', 'TagStepDetailsProperty', 'WorkflowStepProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflow'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnWorkflowDefConfig] = pydantic.Field(None)


class CfnWorkflowDefConfig(pydantic.BaseModel):
    CopyStepDetailsProperty: typing.Optional[list[CfnWorkflowDefCopystepdetailspropertyParams]] = pydantic.Field(None, description='')
    CustomStepDetailsProperty: typing.Optional[list[CfnWorkflowDefCustomstepdetailspropertyParams]] = pydantic.Field(None, description='')
    DecryptStepDetailsProperty: typing.Optional[list[CfnWorkflowDefDecryptstepdetailspropertyParams]] = pydantic.Field(None, description='')
    DeleteStepDetailsProperty: typing.Optional[list[CfnWorkflowDefDeletestepdetailspropertyParams]] = pydantic.Field(None, description='')
    EfsInputFileLocationProperty: typing.Optional[list[CfnWorkflowDefEfsinputfilelocationpropertyParams]] = pydantic.Field(None, description='')
    InputFileLocationProperty: typing.Optional[list[CfnWorkflowDefInputfilelocationpropertyParams]] = pydantic.Field(None, description='')
    S3FileLocationProperty: typing.Optional[list[CfnWorkflowDefS3FilelocationpropertyParams]] = pydantic.Field(None, description='')
    S3InputFileLocationProperty: typing.Optional[list[CfnWorkflowDefS3InputfilelocationpropertyParams]] = pydantic.Field(None, description='')
    S3TagProperty: typing.Optional[list[CfnWorkflowDefS3TagpropertyParams]] = pydantic.Field(None, description='')
    TagStepDetailsProperty: typing.Optional[list[CfnWorkflowDefTagstepdetailspropertyParams]] = pydantic.Field(None, description='')
    WorkflowStepProperty: typing.Optional[list[CfnWorkflowDefWorkflowsteppropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnWorkflowDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnWorkflowDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnWorkflowDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnWorkflowDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnWorkflowDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnWorkflowDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnWorkflowDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnWorkflowDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnWorkflowDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnWorkflowDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnWorkflowDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnWorkflowDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnWorkflowDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnWorkflowDefCopystepdetailspropertyParams(pydantic.BaseModel):
    destination_file_location: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_S3FileLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    name: typing.Optional[str] = pydantic.Field(None, description='')
    overwrite_existing: typing.Optional[str] = pydantic.Field(None, description='')
    source_file_location: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnWorkflowDefCustomstepdetailspropertyParams(pydantic.BaseModel):
    name: typing.Optional[str] = pydantic.Field(None, description='')
    source_file_location: typing.Optional[str] = pydantic.Field(None, description='')
    target: typing.Optional[str] = pydantic.Field(None, description='')
    timeout_seconds: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnWorkflowDefDecryptstepdetailspropertyParams(pydantic.BaseModel):
    destination_file_location: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_InputFileLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    name: typing.Optional[str] = pydantic.Field(None, description='')
    overwrite_existing: typing.Optional[str] = pydantic.Field(None, description='')
    source_file_location: typing.Optional[str] = pydantic.Field(None, description='')
    type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnWorkflowDefDeletestepdetailspropertyParams(pydantic.BaseModel):
    name: typing.Optional[str] = pydantic.Field(None, description='')
    source_file_location: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnWorkflowDefEfsinputfilelocationpropertyParams(pydantic.BaseModel):
    file_system_id: typing.Optional[str] = pydantic.Field(None, description='')
    path: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnWorkflowDefInputfilelocationpropertyParams(pydantic.BaseModel):
    efs_file_location: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_EfsInputFileLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    s3_file_location: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_S3InputFileLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnWorkflowDefS3FilelocationpropertyParams(pydantic.BaseModel):
    s3_file_location: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_S3InputFileLocationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnWorkflowDefS3InputfilelocationpropertyParams(pydantic.BaseModel):
    bucket: typing.Optional[str] = pydantic.Field(None, description='')
    key: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnWorkflowDefS3TagpropertyParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='')
    value: str = pydantic.Field(..., description='')
    ...

class CfnWorkflowDefTagstepdetailspropertyParams(pydantic.BaseModel):
    name: typing.Optional[str] = pydantic.Field(None, description='')
    source_file_location: typing.Optional[str] = pydantic.Field(None, description='')
    tags: typing.Optional[typing.Sequence[typing.Union[models.aws_transfer.CfnWorkflow_S3TagPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='')
    ...

class CfnWorkflowDefWorkflowsteppropertyParams(pydantic.BaseModel):
    copy_step_details: typing.Any = pydantic.Field(None, description='')
    custom_step_details: typing.Any = pydantic.Field(None, description='')
    decrypt_step_details: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_DecryptStepDetailsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    delete_step_details: typing.Any = pydantic.Field(None, description='')
    tag_step_details: typing.Any = pydantic.Field(None, description='')
    type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnWorkflowDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnWorkflowDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnWorkflowDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnWorkflowDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnWorkflowDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnWorkflowDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnWorkflowDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnWorkflowDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnWorkflowDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnWorkflowDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnWorkflowDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnWorkflowDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnWorkflowDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnWorkflowDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_transfer.CfnAgreementProps
class CfnAgreementPropsDef(BaseCfnProperty):
    access_role: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Connectors are used to send files using either the AS2 or SFTP protocol. For the access role, provide the Amazon Resource Name (ARN) of the AWS Identity and Access Management role to use. *For AS2 connectors* With AS2, you can send files by calling ``StartFileTransfer`` and specifying the file paths in the request parameter, ``SendFilePaths`` . We use the file’s parent directory (for example, for ``--send-file-paths /bucket/dir/file.txt`` , parent directory is ``/bucket/dir/`` ) to temporarily store a processed AS2 message file, store the MDN when we receive them from the partner, and write a final JSON file containing relevant metadata of the transmission. So, the ``AccessRole`` needs to provide read and write access to the parent directory of the file location used in the ``StartFileTransfer`` request. Additionally, you need to provide read and write access to the parent directory of the files that you intend to send with ``StartFileTransfer`` . If you are using Basic authentication for your AS2 connector, the access role requires the ``secretsmanager:GetSecretValue`` permission for the secret. If the secret is encrypted using a customer-managed key instead of the AWS managed key in Secrets Manager, then the role also needs the ``kms:Decrypt`` permission for that key. *For SFTP connectors* Make sure that the access role provides read and write access to the parent directory of the file location that's used in the ``StartFileTransfer`` request. Additionally, make sure that the role provides ``secretsmanager:GetSecretValue`` permission to AWS Secrets Manager .\n")
    base_directory: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The landing directory (folder) for files that are transferred by using the AS2 protocol.\n')
    local_profile_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A unique identifier for the AS2 local profile.\n')
    partner_profile_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A unique identifier for the partner profile used in the agreement.\n')
    server_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A system-assigned unique identifier for a server instance. This identifier indicates the specific server that the agreement uses.\n')
    description: typing.Optional[str] = pydantic.Field(None, description="The name or short description that's used to identify the agreement.\n")
    status: typing.Optional[str] = pydantic.Field(None, description='The current status of the agreement, either ``ACTIVE`` or ``INACTIVE`` .\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for agreements.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-transfer-agreement.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    cfn_agreement_props = transfer.CfnAgreementProps(\n        access_role="accessRole",\n        base_directory="baseDirectory",\n        local_profile_id="localProfileId",\n        partner_profile_id="partnerProfileId",\n        server_id="serverId",\n\n        # the properties below are optional\n        description="description",\n        status="status",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['access_role', 'base_directory', 'local_profile_id', 'partner_profile_id', 'server_id', 'description', 'status', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnAgreementProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnCertificateProps
class CfnCertificatePropsDef(BaseCfnProperty):
    certificate: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The file name for the certificate.\n')
    usage: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies whether this certificate is used for signing or encryption.\n')
    active_date: typing.Optional[str] = pydantic.Field(None, description='An optional date that specifies when the certificate becomes active.\n')
    certificate_chain: typing.Optional[str] = pydantic.Field(None, description='The list of certificates that make up the chain for the certificate.\n')
    description: typing.Optional[str] = pydantic.Field(None, description="The name or description that's used to identity the certificate.\n")
    inactive_date: typing.Optional[str] = pydantic.Field(None, description='An optional date that specifies when the certificate becomes inactive.\n')
    private_key: typing.Optional[str] = pydantic.Field(None, description="The file that contains the private key for the certificate that's being imported.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for certificates.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-transfer-certificate.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    cfn_certificate_props = transfer.CfnCertificateProps(\n        certificate="certificate",\n        usage="usage",\n\n        # the properties below are optional\n        active_date="activeDate",\n        certificate_chain="certificateChain",\n        description="description",\n        inactive_date="inactiveDate",\n        private_key="privateKey",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['certificate', 'usage', 'active_date', 'certificate_chain', 'description', 'inactive_date', 'private_key', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnCertificateProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnConnectorProps
class CfnConnectorPropsDef(BaseCfnProperty):
    access_role: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="Connectors are used to send files using either the AS2 or SFTP protocol. For the access role, provide the Amazon Resource Name (ARN) of the AWS Identity and Access Management role to use. *For AS2 connectors* With AS2, you can send files by calling ``StartFileTransfer`` and specifying the file paths in the request parameter, ``SendFilePaths`` . We use the file’s parent directory (for example, for ``--send-file-paths /bucket/dir/file.txt`` , parent directory is ``/bucket/dir/`` ) to temporarily store a processed AS2 message file, store the MDN when we receive them from the partner, and write a final JSON file containing relevant metadata of the transmission. So, the ``AccessRole`` needs to provide read and write access to the parent directory of the file location used in the ``StartFileTransfer`` request. Additionally, you need to provide read and write access to the parent directory of the files that you intend to send with ``StartFileTransfer`` . If you are using Basic authentication for your AS2 connector, the access role requires the ``secretsmanager:GetSecretValue`` permission for the secret. If the secret is encrypted using a customer-managed key instead of the AWS managed key in Secrets Manager, then the role also needs the ``kms:Decrypt`` permission for that key. *For SFTP connectors* Make sure that the access role provides read and write access to the parent directory of the file location that's used in the ``StartFileTransfer`` request. Additionally, make sure that the role provides ``secretsmanager:GetSecretValue`` permission to AWS Secrets Manager .\n")
    url: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The URL of the partner's AS2 or SFTP endpoint.\n")
    as2_config: typing.Any = pydantic.Field(None, description='A structure that contains the parameters for an AS2 connector object.\n')
    logging_role: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows a connector to turn on CloudWatch logging for Amazon S3 events. When set, you can view connector activity in your CloudWatch logs.\n')
    sftp_config: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnConnector_SftpConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A structure that contains the parameters for an SFTP connector object.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for connectors.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-transfer-connector.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    # as2_config: Any\n\n    cfn_connector_props = transfer.CfnConnectorProps(\n        access_role="accessRole",\n        url="url",\n\n        # the properties below are optional\n        as2_config=as2_config,\n        logging_role="loggingRole",\n        sftp_config=transfer.CfnConnector.SftpConfigProperty(\n            trusted_host_keys=["trustedHostKeys"],\n            user_secret_id="userSecretId"\n        ),\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['access_role', 'url', 'as2_config', 'logging_role', 'sftp_config', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnConnectorProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnProfileProps
class CfnProfilePropsDef(BaseCfnProperty):
    as2_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ``As2Id`` is the *AS2-name* , as defined in the `RFC 4130 <https://docs.aws.amazon.com/https://datatracker.ietf.org/doc/html/rfc4130>`_ . For inbound transfers, this is the ``AS2-From`` header for the AS2 messages sent from the partner. For outbound connectors, this is the ``AS2-To`` header for the AS2 messages sent to the partner using the ``StartFileTransfer`` API operation. This ID cannot include spaces.\n')
    profile_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Indicates whether to list only ``LOCAL`` type profiles or only ``PARTNER`` type profiles. If not supplied in the request, the command lists all types of profiles.\n')
    certificate_ids: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='An array of identifiers for the imported certificates. You use this identifier for working with profiles and partner profiles.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for profiles.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-transfer-profile.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    cfn_profile_props = transfer.CfnProfileProps(\n        as2_id="as2Id",\n        profile_type="profileType",\n\n        # the properties below are optional\n        certificate_ids=["certificateIds"],\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['as2_id', 'profile_type', 'certificate_ids', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnProfileProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnServerProps
class CfnServerPropsDef(BaseCfnProperty):
    certificate: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the AWS Certificate Manager (ACM) certificate. Required when ``Protocols`` is set to ``FTPS`` . To request a new public certificate, see `Request a public certificate <https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-request-public.html>`_ in the *AWS Certificate Manager User Guide* . To import an existing certificate into ACM, see `Importing certificates into ACM <https://docs.aws.amazon.com/acm/latest/userguide/import-certificate.html>`_ in the *AWS Certificate Manager User Guide* . To request a private certificate to use FTPS through private IP addresses, see `Request a private certificate <https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-request-private.html>`_ in the *AWS Certificate Manager User Guide* . Certificates with the following cryptographic algorithms and key sizes are supported: - 2048-bit RSA (RSA_2048) - 4096-bit RSA (RSA_4096) - Elliptic Prime Curve 256 bit (EC_prime256v1) - Elliptic Prime Curve 384 bit (EC_secp384r1) - Elliptic Prime Curve 521 bit (EC_secp521r1) .. epigraph:: The certificate must be a valid SSL/TLS X.509 version 3 certificate with FQDN or IP address specified and information about the issuer.\n')
    domain: typing.Optional[str] = pydantic.Field(None, description='Specifies the domain of the storage system that is used for file transfers.\n')
    endpoint_details: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_EndpointDetailsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="The virtual private cloud (VPC) endpoint settings that are configured for your server. When you host your endpoint within your VPC, you can make your endpoint accessible only to resources within your VPC, or you can attach Elastic IP addresses and make your endpoint accessible to clients over the internet. Your VPC's default security groups are automatically assigned to your endpoint.\n")
    endpoint_type: typing.Optional[str] = pydantic.Field(None, description="The type of endpoint that you want your server to use. You can choose to make your server's endpoint publicly accessible (PUBLIC) or host it inside your VPC. With an endpoint that is hosted in a VPC, you can restrict access to your server and resources only within your VPC or choose to make it internet facing by attaching Elastic IP addresses directly to it. .. epigraph:: After May 19, 2021, you won't be able to create a server using ``EndpointType=VPC_ENDPOINT`` in your AWS account if your account hasn't already done so before May 19, 2021. If you have already created servers with ``EndpointType=VPC_ENDPOINT`` in your AWS account on or before May 19, 2021, you will not be affected. After this date, use ``EndpointType`` = ``VPC`` . For more information, see `Discontinuing the use of VPC_ENDPOINT <https://docs.aws.amazon.com//transfer/latest/userguide/create-server-in-vpc.html#deprecate-vpc-endpoint>`_ . It is recommended that you use ``VPC`` as the ``EndpointType`` . With this endpoint type, you have the option to directly associate up to three Elastic IPv4 addresses (BYO IP included) with your server's endpoint and use VPC security groups to restrict traffic by the client's public IP address. This is not possible with ``EndpointType`` set to ``VPC_ENDPOINT`` .\n")
    identity_provider_details: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_IdentityProviderDetailsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Required when ``IdentityProviderType`` is set to ``AWS_DIRECTORY_SERVICE`` , ``AWS _LAMBDA`` or ``API_GATEWAY`` . Accepts an array containing all of the information required to use a directory in ``AWS_DIRECTORY_SERVICE`` or invoke a customer-supplied authentication API, including the API Gateway URL. Not required when ``IdentityProviderType`` is set to ``SERVICE_MANAGED`` .\n')
    identity_provider_type: typing.Optional[str] = pydantic.Field(None, description='The mode of authentication for a server. The default value is ``SERVICE_MANAGED`` , which allows you to store and access user credentials within the AWS Transfer Family service. Use ``AWS_DIRECTORY_SERVICE`` to provide access to Active Directory groups in AWS Directory Service for Microsoft Active Directory or Microsoft Active Directory in your on-premises environment or in AWS using AD Connector. This option also requires you to provide a Directory ID by using the ``IdentityProviderDetails`` parameter. Use the ``API_GATEWAY`` value to integrate with an identity provider of your choosing. The ``API_GATEWAY`` setting requires you to provide an Amazon API Gateway endpoint URL to call for authentication by using the ``IdentityProviderDetails`` parameter. Use the ``AWS_LAMBDA`` value to directly use an AWS Lambda function as your identity provider. If you choose this value, you must specify the ARN for the Lambda function in the ``Function`` parameter for the ``IdentityProviderDetails`` data type.\n')
    logging_role: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows a server to turn on Amazon CloudWatch logging for Amazon S3 or Amazon EFSevents. When set, you can view user activity in your CloudWatch logs.\n')
    post_authentication_login_banner: typing.Optional[str] = pydantic.Field(None, description='Specifies a string to display when users connect to a server. This string is displayed after the user authenticates. .. epigraph:: The SFTP protocol does not support post-authentication display banners.\n')
    pre_authentication_login_banner: typing.Optional[str] = pydantic.Field(None, description='Specifies a string to display when users connect to a server. This string is displayed before the user authenticates. For example, the following banner displays details about using the system: ``This system is for the use of authorized users only. Individuals using this computer system without authority, or in excess of their authority, are subject to having all of their activities on this system monitored and recorded by system personnel.``\n')
    protocol_details: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_ProtocolDetailsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The protocol settings that are configured for your server. - To indicate passive mode (for FTP and FTPS protocols), use the ``PassiveIp`` parameter. Enter a single dotted-quad IPv4 address, such as the external IP address of a firewall, router, or load balancer. - To ignore the error that is generated when the client attempts to use the ``SETSTAT`` command on a file that you are uploading to an Amazon S3 bucket, use the ``SetStatOption`` parameter. To have the AWS Transfer Family server ignore the ``SETSTAT`` command and upload files without needing to make any changes to your SFTP client, set the value to ``ENABLE_NO_OP`` . If you set the ``SetStatOption`` parameter to ``ENABLE_NO_OP`` , Transfer Family generates a log entry to Amazon CloudWatch Logs, so that you can determine when the client is making a ``SETSTAT`` call. - To determine whether your AWS Transfer Family server resumes recent, negotiated sessions through a unique session ID, use the ``TlsSessionResumptionMode`` parameter. - ``As2Transports`` indicates the transport method for the AS2 messages. Currently, only HTTP is supported. The ``Protocols`` parameter is an array of strings. *Allowed values* : One or more of ``SFTP`` , ``FTPS`` , ``FTP`` , ``AS2``\n')
    protocols: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description="Specifies the file transfer protocol or protocols over which your file transfer protocol client can connect to your server's endpoint. The available protocols are: - ``SFTP`` (Secure Shell (SSH) File Transfer Protocol): File transfer over SSH - ``FTPS`` (File Transfer Protocol Secure): File transfer with TLS encryption - ``FTP`` (File Transfer Protocol): Unencrypted file transfer - ``AS2`` (Applicability Statement 2): used for transporting structured business-to-business data .. epigraph:: - If you select ``FTPS`` , you must choose a certificate stored in AWS Certificate Manager (ACM) which is used to identify your server when clients connect to it over FTPS. - If ``Protocol`` includes either ``FTP`` or ``FTPS`` , then the ``EndpointType`` must be ``VPC`` and the ``IdentityProviderType`` must be either ``AWS_DIRECTORY_SERVICE`` , ``AWS_LAMBDA`` , or ``API_GATEWAY`` . - If ``Protocol`` includes ``FTP`` , then ``AddressAllocationIds`` cannot be associated. - If ``Protocol`` is set only to ``SFTP`` , the ``EndpointType`` can be set to ``PUBLIC`` and the ``IdentityProviderType`` can be set any of the supported identity types: ``SERVICE_MANAGED`` , ``AWS_DIRECTORY_SERVICE`` , ``AWS_LAMBDA`` , or ``API_GATEWAY`` . - If ``Protocol`` includes ``AS2`` , then the ``EndpointType`` must be ``VPC`` , and domain must be Amazon S3. The ``Protocols`` parameter is an array of strings. *Allowed values* : One or more of ``SFTP`` , ``FTPS`` , ``FTP`` , ``AS2``\n")
    security_policy_name: typing.Optional[str] = pydantic.Field(None, description='Specifies the name of the security policy that is attached to the server.\n')
    structured_log_destinations: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Specifies the log groups to which your server logs are sent. To specify a log group, you must provide the ARN for an existing log group. In this case, the format of the log group is as follows: ``arn:aws:logs:region-name:amazon-account-id:log-group:log-group-name:*`` For example, ``arn:aws:logs:us-east-1:111122223333:log-group:mytestgroup:*`` If you have previously specified a log group for a server, you can clear it, and in effect turn off structured logging, by providing an empty value for this parameter in an ``update-server`` call. For example: ``update-server --server-id s-1234567890abcdef0 --structured-log-destinations``\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for servers.\n')
    workflow_details: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnServer_WorkflowDetailsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the workflow ID for the workflow to assign and the execution role that\'s used for executing the workflow. In addition to a workflow to execute when a file is uploaded completely, ``WorkflowDetails`` can also contain a workflow ID (and execution role) for a workflow to execute on partial upload. A partial upload occurs when a file is open when the session disconnects.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-transfer-server.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    cfn_server_props = transfer.CfnServerProps(\n        certificate="certificate",\n        domain="domain",\n        endpoint_details=transfer.CfnServer.EndpointDetailsProperty(\n            address_allocation_ids=["addressAllocationIds"],\n            security_group_ids=["securityGroupIds"],\n            subnet_ids=["subnetIds"],\n            vpc_endpoint_id="vpcEndpointId",\n            vpc_id="vpcId"\n        ),\n        endpoint_type="endpointType",\n        identity_provider_details=transfer.CfnServer.IdentityProviderDetailsProperty(\n            directory_id="directoryId",\n            function="function",\n            invocation_role="invocationRole",\n            sftp_authentication_methods="sftpAuthenticationMethods",\n            url="url"\n        ),\n        identity_provider_type="identityProviderType",\n        logging_role="loggingRole",\n        post_authentication_login_banner="postAuthenticationLoginBanner",\n        pre_authentication_login_banner="preAuthenticationLoginBanner",\n        protocol_details=transfer.CfnServer.ProtocolDetailsProperty(\n            as2_transports=["as2Transports"],\n            passive_ip="passiveIp",\n            set_stat_option="setStatOption",\n            tls_session_resumption_mode="tlsSessionResumptionMode"\n        ),\n        protocols=["protocols"],\n        security_policy_name="securityPolicyName",\n        structured_log_destinations=["structuredLogDestinations"],\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        workflow_details=transfer.CfnServer.WorkflowDetailsProperty(\n            on_partial_upload=[transfer.CfnServer.WorkflowDetailProperty(\n                execution_role="executionRole",\n                workflow_id="workflowId"\n            )],\n            on_upload=[transfer.CfnServer.WorkflowDetailProperty(\n                execution_role="executionRole",\n                workflow_id="workflowId"\n            )]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['certificate', 'domain', 'endpoint_details', 'endpoint_type', 'identity_provider_details', 'identity_provider_type', 'logging_role', 'post_authentication_login_banner', 'pre_authentication_login_banner', 'protocol_details', 'protocols', 'security_policy_name', 'structured_log_destinations', 'tags', 'workflow_details']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnServerProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnUserProps
class CfnUserPropsDef(BaseCfnProperty):
    role: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that controls your users' access to your Amazon S3 bucket or Amazon EFS file system. The policies attached to this role determine the level of access that you want to provide your users when transferring files into and out of your Amazon S3 bucket or Amazon EFS file system. The IAM role should also contain a trust relationship that allows the server to access your resources when servicing your users' transfer requests.\n")
    server_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A system-assigned unique identifier for a server instance. This is the specific server that you added your user to.\n')
    user_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="A unique string that identifies a user and is associated with a ``ServerId`` . This user name must be a minimum of 3 and a maximum of 100 characters long. The following are valid characters: a-z, A-Z, 0-9, underscore '_', hyphen '-', period '.', and at sign '@'. The user name can't start with a hyphen, period, or at sign.\n")
    home_directory: typing.Optional[str] = pydantic.Field(None, description='The landing directory (folder) for a user when they log in to the server using the client. A ``HomeDirectory`` example is ``/bucket_name/home/mydirectory`` . .. epigraph:: The ``HomeDirectory`` parameter is only used if ``HomeDirectoryType`` is set to ``PATH`` .\n')
    home_directory_mappings: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_transfer.CfnUser_HomeDirectoryMapEntryPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Logical directory mappings that specify what Amazon S3 or Amazon EFS paths and keys should be visible to your user and how you want to make them visible. You must specify the ``Entry`` and ``Target`` pair, where ``Entry`` shows how the path is made visible and ``Target`` is the actual Amazon S3 or Amazon EFS path. If you only specify a target, it is displayed as is. You also must ensure that your AWS Identity and Access Management (IAM) role provides access to paths in ``Target`` . This value can be set only when ``HomeDirectoryType`` is set to *LOGICAL* . The following is an ``Entry`` and ``Target`` pair example. ``[ { "Entry": "/directory1", "Target": "/bucket_name/home/mydirectory" } ]`` In most cases, you can use this value instead of the session policy to lock your user down to the designated home directory (" ``chroot`` "). To do this, you can set ``Entry`` to ``/`` and set ``Target`` to the value the user should see for their home directory when they log in. The following is an ``Entry`` and ``Target`` pair example for ``chroot`` . ``[ { "Entry": "/", "Target": "/bucket_name/home/mydirectory" } ]``\n')
    home_directory_type: typing.Optional[str] = pydantic.Field(None, description="The type of landing directory (folder) that you want your users' home directory to be when they log in to the server. If you set it to ``PATH`` , the user will see the absolute Amazon S3 bucket or Amazon EFS path as is in their file transfer protocol clients. If you set it to ``LOGICAL`` , you need to provide mappings in the ``HomeDirectoryMappings`` for how you want to make Amazon S3 or Amazon EFS paths visible to your users. .. epigraph:: If ``HomeDirectoryType`` is ``LOGICAL`` , you must provide mappings, using the ``HomeDirectoryMappings`` parameter. If, on the other hand, ``HomeDirectoryType`` is ``PATH`` , you provide an absolute path using the ``HomeDirectory`` parameter. You cannot have both ``HomeDirectory`` and ``HomeDirectoryMappings`` in your template.\n")
    policy: typing.Optional[str] = pydantic.Field(None, description='A session policy for your user so you can use the same IAM role across multiple users. This policy restricts user access to portions of their Amazon S3 bucket. Variables that you can use inside this policy include ``${Transfer:UserName}`` , ``${Transfer:HomeDirectory}`` , and ``${Transfer:HomeBucket}`` . .. epigraph:: For session policies, AWS Transfer Family stores the policy as a JSON blob, instead of the Amazon Resource Name (ARN) of the policy. You save the policy as a JSON blob and pass it in the ``Policy`` argument. For an example of a session policy, see `Example session policy <https://docs.aws.amazon.com/transfer/latest/userguide/session-policy.html>`_ . For more information, see `AssumeRole <https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html>`_ in the *AWS Security Token Service API Reference* .\n')
    posix_profile: typing.Union[models.UnsupportedResource, models.aws_transfer.CfnUser_PosixProfilePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="Specifies the full POSIX identity, including user ID ( ``Uid`` ), group ID ( ``Gid`` ), and any secondary groups IDs ( ``SecondaryGids`` ), that controls your users' access to your Amazon Elastic File System (Amazon EFS) file systems. The POSIX permissions that are set on files and directories in your file system determine the level of access your users get when transferring files into and out of your Amazon EFS file systems.\n")
    ssh_public_keys: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Specifies the public key portion of the Secure Shell (SSH) keys stored for the described user.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for users. Tags are metadata attached to users for any purpose.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-transfer-user.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    cfn_user_props = transfer.CfnUserProps(\n        role="role",\n        server_id="serverId",\n        user_name="userName",\n\n        # the properties below are optional\n        home_directory="homeDirectory",\n        home_directory_mappings=[transfer.CfnUser.HomeDirectoryMapEntryProperty(\n            entry="entry",\n            target="target"\n        )],\n        home_directory_type="homeDirectoryType",\n        policy="policy",\n        posix_profile=transfer.CfnUser.PosixProfileProperty(\n            gid=123,\n            uid=123,\n\n            # the properties below are optional\n            secondary_gids=[123]\n        ),\n        ssh_public_keys=["sshPublicKeys"],\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['role', 'server_id', 'user_name', 'home_directory', 'home_directory_mappings', 'home_directory_type', 'policy', 'posix_profile', 'ssh_public_keys', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnUserProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_transfer.CfnWorkflowProps
class CfnWorkflowPropsDef(BaseCfnProperty):
    steps: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_WorkflowStepPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the details for the steps that are in the specified workflow.\n')
    description: typing.Optional[str] = pydantic.Field(None, description='Specifies the text description for the workflow.\n')
    on_exception_steps: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_transfer.CfnWorkflow_WorkflowStepPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Specifies the steps (actions) to take if errors are encountered during execution of the workflow.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Key-value pairs that can be used to group and search for workflows. Tags are metadata attached to workflows for any purpose.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-transfer-workflow.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_transfer as transfer\n\n    # copy_step_details: Any\n    # custom_step_details: Any\n    # delete_step_details: Any\n    # tag_step_details: Any\n\n    cfn_workflow_props = transfer.CfnWorkflowProps(\n        steps=[transfer.CfnWorkflow.WorkflowStepProperty(\n            copy_step_details=copy_step_details,\n            custom_step_details=custom_step_details,\n            decrypt_step_details=transfer.CfnWorkflow.DecryptStepDetailsProperty(\n                destination_file_location=transfer.CfnWorkflow.InputFileLocationProperty(\n                    efs_file_location=transfer.CfnWorkflow.EfsInputFileLocationProperty(\n                        file_system_id="fileSystemId",\n                        path="path"\n                    ),\n                    s3_file_location=transfer.CfnWorkflow.S3InputFileLocationProperty(\n                        bucket="bucket",\n                        key="key"\n                    )\n                ),\n                name="name",\n                overwrite_existing="overwriteExisting",\n                source_file_location="sourceFileLocation",\n                type="type"\n            ),\n            delete_step_details=delete_step_details,\n            tag_step_details=tag_step_details,\n            type="type"\n        )],\n\n        # the properties below are optional\n        description="description",\n        on_exception_steps=[transfer.CfnWorkflow.WorkflowStepProperty(\n            copy_step_details=copy_step_details,\n            custom_step_details=custom_step_details,\n            decrypt_step_details=transfer.CfnWorkflow.DecryptStepDetailsProperty(\n                destination_file_location=transfer.CfnWorkflow.InputFileLocationProperty(\n                    efs_file_location=transfer.CfnWorkflow.EfsInputFileLocationProperty(\n                        file_system_id="fileSystemId",\n                        path="path"\n                    ),\n                    s3_file_location=transfer.CfnWorkflow.S3InputFileLocationProperty(\n                        bucket="bucket",\n                        key="key"\n                    )\n                ),\n                name="name",\n                overwrite_existing="overwriteExisting",\n                source_file_location="sourceFileLocation",\n                type="type"\n            ),\n            delete_step_details=delete_step_details,\n            tag_step_details=tag_step_details,\n            type="type"\n        )],\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['steps', 'description', 'on_exception_steps', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_transfer.CfnWorkflowProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




import models

class ModuleModel(pydantic.BaseModel):
    CfnConnector_As2ConfigProperty: typing.Optional[dict[str, CfnConnector_As2ConfigPropertyDef]] = pydantic.Field(None)
    CfnConnector_SftpConfigProperty: typing.Optional[dict[str, CfnConnector_SftpConfigPropertyDef]] = pydantic.Field(None)
    CfnServer_EndpointDetailsProperty: typing.Optional[dict[str, CfnServer_EndpointDetailsPropertyDef]] = pydantic.Field(None)
    CfnServer_IdentityProviderDetailsProperty: typing.Optional[dict[str, CfnServer_IdentityProviderDetailsPropertyDef]] = pydantic.Field(None)
    CfnServer_ProtocolDetailsProperty: typing.Optional[dict[str, CfnServer_ProtocolDetailsPropertyDef]] = pydantic.Field(None)
    CfnServer_WorkflowDetailProperty: typing.Optional[dict[str, CfnServer_WorkflowDetailPropertyDef]] = pydantic.Field(None)
    CfnServer_WorkflowDetailsProperty: typing.Optional[dict[str, CfnServer_WorkflowDetailsPropertyDef]] = pydantic.Field(None)
    CfnUser_HomeDirectoryMapEntryProperty: typing.Optional[dict[str, CfnUser_HomeDirectoryMapEntryPropertyDef]] = pydantic.Field(None)
    CfnUser_PosixProfileProperty: typing.Optional[dict[str, CfnUser_PosixProfilePropertyDef]] = pydantic.Field(None)
    CfnWorkflow_CopyStepDetailsProperty: typing.Optional[dict[str, CfnWorkflow_CopyStepDetailsPropertyDef]] = pydantic.Field(None)
    CfnWorkflow_CustomStepDetailsProperty: typing.Optional[dict[str, CfnWorkflow_CustomStepDetailsPropertyDef]] = pydantic.Field(None)
    CfnWorkflow_DecryptStepDetailsProperty: typing.Optional[dict[str, CfnWorkflow_DecryptStepDetailsPropertyDef]] = pydantic.Field(None)
    CfnWorkflow_DeleteStepDetailsProperty: typing.Optional[dict[str, CfnWorkflow_DeleteStepDetailsPropertyDef]] = pydantic.Field(None)
    CfnWorkflow_EfsInputFileLocationProperty: typing.Optional[dict[str, CfnWorkflow_EfsInputFileLocationPropertyDef]] = pydantic.Field(None)
    CfnWorkflow_InputFileLocationProperty: typing.Optional[dict[str, CfnWorkflow_InputFileLocationPropertyDef]] = pydantic.Field(None)
    CfnWorkflow_S3FileLocationProperty: typing.Optional[dict[str, CfnWorkflow_S3FileLocationPropertyDef]] = pydantic.Field(None)
    CfnWorkflow_S3InputFileLocationProperty: typing.Optional[dict[str, CfnWorkflow_S3InputFileLocationPropertyDef]] = pydantic.Field(None)
    CfnWorkflow_S3TagProperty: typing.Optional[dict[str, CfnWorkflow_S3TagPropertyDef]] = pydantic.Field(None)
    CfnWorkflow_TagStepDetailsProperty: typing.Optional[dict[str, CfnWorkflow_TagStepDetailsPropertyDef]] = pydantic.Field(None)
    CfnWorkflow_WorkflowStepProperty: typing.Optional[dict[str, CfnWorkflow_WorkflowStepPropertyDef]] = pydantic.Field(None)
    CfnAgreement: typing.Optional[dict[str, CfnAgreementDef]] = pydantic.Field(None)
    CfnCertificate: typing.Optional[dict[str, CfnCertificateDef]] = pydantic.Field(None)
    CfnConnector: typing.Optional[dict[str, CfnConnectorDef]] = pydantic.Field(None)
    CfnProfile: typing.Optional[dict[str, CfnProfileDef]] = pydantic.Field(None)
    CfnServer: typing.Optional[dict[str, CfnServerDef]] = pydantic.Field(None)
    CfnUser: typing.Optional[dict[str, CfnUserDef]] = pydantic.Field(None)
    CfnWorkflow: typing.Optional[dict[str, CfnWorkflowDef]] = pydantic.Field(None)
    CfnAgreementProps: typing.Optional[dict[str, CfnAgreementPropsDef]] = pydantic.Field(None)
    CfnCertificateProps: typing.Optional[dict[str, CfnCertificatePropsDef]] = pydantic.Field(None)
    CfnConnectorProps: typing.Optional[dict[str, CfnConnectorPropsDef]] = pydantic.Field(None)
    CfnProfileProps: typing.Optional[dict[str, CfnProfilePropsDef]] = pydantic.Field(None)
    CfnServerProps: typing.Optional[dict[str, CfnServerPropsDef]] = pydantic.Field(None)
    CfnUserProps: typing.Optional[dict[str, CfnUserPropsDef]] = pydantic.Field(None)
    CfnWorkflowProps: typing.Optional[dict[str, CfnWorkflowPropsDef]] = pydantic.Field(None)
    ...
