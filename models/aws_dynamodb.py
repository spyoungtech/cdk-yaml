from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_dynamodb.Billing
class BillingDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['on_demand', 'provisioned']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.Billing'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_dynamodb.BillingDefConfig] = pydantic.Field(None)


class BillingDefConfig(pydantic.BaseModel):
    on_demand: typing.Optional[list[models.aws_dynamodb.BillingDefOnDemandParams]] = pydantic.Field(None, description='Flexible billing option capable of serving requests without capacity planning.\nNote: Billing mode will be PAY_PER_REQUEST.')
    provisioned: typing.Optional[list[models.aws_dynamodb.BillingDefProvisionedParams]] = pydantic.Field(None, description='Specify the number of reads and writes per second that you need for your application.')

class BillingDefOnDemandParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_dynamodb.BillingDefConfig]] = pydantic.Field(None)
    ...

class BillingDefProvisionedParams(pydantic.BaseModel):
    read_capacity: models.aws_dynamodb.CapacityDef = pydantic.Field(..., description='The read capacity.\n')
    write_capacity: models.aws_dynamodb.CapacityDef = pydantic.Field(..., description='The write capacity.')
    return_config: typing.Optional[list[models.aws_dynamodb.BillingDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_dynamodb.Capacity
class CapacityDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['autoscaled', 'fixed']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.Capacity'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_dynamodb.CapacityDefConfig] = pydantic.Field(None)


class CapacityDefConfig(pydantic.BaseModel):
    autoscaled: typing.Optional[list[models.aws_dynamodb.CapacityDefAutoscaledParams]] = pydantic.Field(None, description='Dynamically adjusts provisioned throughput capacity on your behalf in response to actual traffic patterns.')
    fixed: typing.Optional[list[models.aws_dynamodb.CapacityDefFixedParams]] = pydantic.Field(None, description='Provisioned throughput capacity is configured with fixed capacity units.\nNote: You cannot configure write capacity using fixed capacity mode.')

class CapacityDefAutoscaledParams(pydantic.BaseModel):
    max_capacity: typing.Union[int, float] = pydantic.Field(..., description='The maximum allowable capacity.\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum allowable capacity. Default: 1\n')
    seed_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="If you want to switch a table's billing mode from on-demand to provisioned or from provisioned to on-demand, you must specify a value for this property for each autoscaled resource. Default: no seed capacity\n")
    target_utilization_percent: typing.Union[int, float, None] = pydantic.Field(None, description='The ratio of consumed capacity units to provisioned capacity units. Note: Target utilization percent cannot be less than 20 and cannot be greater than 90. Default: 70')
    return_config: typing.Optional[list[models.aws_dynamodb.CapacityDefConfig]] = pydantic.Field(None)
    ...

class CapacityDefFixedParams(pydantic.BaseModel):
    iops: typing.Union[int, float] = pydantic.Field(..., description='the number of I/O operations per second.')
    return_config: typing.Optional[list[models.aws_dynamodb.CapacityDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_dynamodb.TableBase
class TableBaseDef(BaseClass):
    account: typing.Optional[str] = pydantic.Field(None, description='The AWS account ID this resource belongs to. Default: - the resource is in the same account as the stack it belongs to\n')
    environment_from_arn: typing.Optional[str] = pydantic.Field(None, description='ARN to deduce region and account from. The ARN is parsed and the account and region are taken from the ARN. This should be used for imported resources. Cannot be supplied together with either ``account`` or ``region``. Default: - take environment from ``account``, ``region`` parameters, or use Stack environment.\n')
    physical_name: typing.Optional[str] = pydantic.Field(None, description='The value passed in by users to the physical name prop of the resource. - ``undefined`` implies that a physical name will be allocated by CloudFormation during deployment. - a concrete value implies a specific physical name - ``PhysicalName.GENERATE_IF_NEEDED`` is a marker that indicates that a physical will only be generated by the CDK if it is needed for cross-environment references. Otherwise, it will be allocated by CloudFormation. Default: - The physical name will be allocated by CloudFormation at deployment time\n')
    region: typing.Optional[str] = pydantic.Field(None, description='The AWS region this resource belongs to. Default: - the resource is in the same region as the stack it belongs to')
    _init_params: typing.ClassVar[list[str]] = ['account', 'environment_from_arn', 'physical_name', 'region']
    _method_names: typing.ClassVar[list[str]] = ['apply_removal_policy', 'grant', 'grant_full_access', 'grant_read_data', 'grant_read_write_data', 'grant_stream', 'grant_stream_read', 'grant_table_list_streams', 'grant_write_data', 'metric', 'metric_conditional_check_failed_requests', 'metric_consumed_read_capacity_units', 'metric_consumed_write_capacity_units', 'metric_successful_request_latency', 'metric_system_errors', 'metric_system_errors_for_operations', 'metric_throttled_requests', 'metric_throttled_requests_for_operation', 'metric_throttled_requests_for_operations', 'metric_user_errors']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.TableBase'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_dynamodb.TableBaseDefConfig] = pydantic.Field(None)


class TableBaseDefConfig(pydantic.BaseModel):
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    grant: typing.Optional[list[models.aws_dynamodb.TableBaseDefGrantParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this table to an IAM principal's policy.\nIf ``encryptionKey`` is present, appropriate grants to the key needs to be added\nseparately using the ``table.encryptionKey.grant*`` methods.")
    grant_full_access: typing.Optional[list[models.aws_dynamodb.TableBaseDefGrantFullAccessParams]] = pydantic.Field(None, description='Permits all DynamoDB operations ("dynamodb:*") to an IAM principal.\nAppropriate grants will also be added to the customer-managed KMS key\nif one was configured.')
    grant_read_data: typing.Optional[list[models.aws_dynamodb.TableBaseDefGrantReadDataParams]] = pydantic.Field(None, description='Permits an IAM principal all data read operations from this table: BatchGetItem, GetRecords, GetShardIterator, Query, GetItem, Scan, DescribeTable.\nAppropriate grants will also be added to the customer-managed KMS key\nif one was configured.')
    grant_read_write_data: typing.Optional[list[models.aws_dynamodb.TableBaseDefGrantReadWriteDataParams]] = pydantic.Field(None, description='Permits an IAM principal to all data read/write operations to this table.\nBatchGetItem, GetRecords, GetShardIterator, Query, GetItem, Scan,\nBatchWriteItem, PutItem, UpdateItem, DeleteItem, DescribeTable\n\nAppropriate grants will also be added to the customer-managed KMS key\nif one was configured.')
    grant_stream: typing.Optional[list[models.aws_dynamodb.TableBaseDefGrantStreamParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this table's stream to an IAM principal's policy.\nIf ``encryptionKey`` is present, appropriate grants to the key needs to be added\nseparately using the ``table.encryptionKey.grant*`` methods.")
    grant_stream_read: typing.Optional[list[models.aws_dynamodb.TableBaseDefGrantStreamReadParams]] = pydantic.Field(None, description="Permits an IAM principal all stream data read operations for this table's stream: DescribeStream, GetRecords, GetShardIterator, ListStreams.\nAppropriate grants will also be added to the customer-managed KMS key\nif one was configured.")
    grant_table_list_streams: typing.Optional[list[models.aws_dynamodb.TableBaseDefGrantTableListStreamsParams]] = pydantic.Field(None, description='Permits an IAM Principal to list streams attached to current dynamodb table.')
    grant_write_data: typing.Optional[list[models.aws_dynamodb.TableBaseDefGrantWriteDataParams]] = pydantic.Field(None, description='Permits an IAM principal all data write operations to this table: BatchWriteItem, PutItem, UpdateItem, DeleteItem, DescribeTable.\nAppropriate grants will also be added to the customer-managed KMS key\nif one was configured.')
    metric: typing.Optional[list[models.aws_dynamodb.TableBaseDefMetricParams]] = pydantic.Field(None, description='Return the given named metric for this Table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_conditional_check_failed_requests: typing.Optional[list[models.aws_dynamodb.TableBaseDefMetricConditionalCheckFailedRequestsParams]] = pydantic.Field(None, description='Metric for the conditional check failed requests this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_consumed_read_capacity_units: typing.Optional[list[models.aws_dynamodb.TableBaseDefMetricConsumedReadCapacityUnitsParams]] = pydantic.Field(None, description='Metric for the consumed read capacity units this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_consumed_write_capacity_units: typing.Optional[list[models.aws_dynamodb.TableBaseDefMetricConsumedWriteCapacityUnitsParams]] = pydantic.Field(None, description='Metric for the consumed write capacity units this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_successful_request_latency: typing.Optional[list[models.aws_dynamodb.TableBaseDefMetricSuccessfulRequestLatencyParams]] = pydantic.Field(None, description='Metric for the successful request latency this table.\nBy default, the metric will be calculated as an average over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_system_errors: typing.Optional[list[models.aws_dynamodb.TableBaseDefMetricSystemErrorsParams]] = pydantic.Field(None, description='(deprecated) Metric for the system errors this table.')
    metric_system_errors_for_operations: typing.Optional[list[models.aws_dynamodb.TableBaseDefMetricSystemErrorsForOperationsParams]] = pydantic.Field(None, description='Metric for the system errors this table.\nThis will sum errors across all possible operations.\nNote that by default, each individual metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_throttled_requests: typing.Optional[list[models.aws_dynamodb.TableBaseDefMetricThrottledRequestsParams]] = pydantic.Field(None, description='(deprecated) How many requests are throttled on this table.\nDefault: sum over 5 minutes')
    metric_throttled_requests_for_operation: typing.Optional[list[models.aws_dynamodb.TableBaseDefMetricThrottledRequestsForOperationParams]] = pydantic.Field(None, description='How many requests are throttled on this table, for the given operation.\nDefault: sum over 5 minutes')
    metric_throttled_requests_for_operations: typing.Optional[list[models.aws_dynamodb.TableBaseDefMetricThrottledRequestsForOperationsParams]] = pydantic.Field(None, description='How many requests are throttled on this table.\nThis will sum errors across all possible operations.\nNote that by default, each individual metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_user_errors: typing.Optional[list[models.aws_dynamodb.TableBaseDefMetricUserErrorsParams]] = pydantic.Field(None, description='Metric for the user errors.\nNote that this metric reports user errors across all\nthe tables in the account and region the table resides in.\n\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')

class TableBaseDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class TableBaseDefGrantParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal (no-op if undefined).\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefGrantFullAccessParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefGrantReadDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefGrantReadWriteDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefGrantStreamParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal (no-op if undefined).\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefGrantStreamReadParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefGrantTableListStreamsParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal (no-op if undefined).')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefGrantWriteDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefMetricParams(pydantic.BaseModel):
    metric_name: str = pydantic.Field(..., description='-\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefMetricConditionalCheckFailedRequestsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefMetricConsumedReadCapacityUnitsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefMetricConsumedWriteCapacityUnitsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefMetricSuccessfulRequestLatencyParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefMetricSystemErrorsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:deprecated: use ``metricSystemErrorsForOperations``.\n\n:stability: deprecated\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefMetricSystemErrorsForOperationsParams(pydantic.BaseModel):
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    ...

class TableBaseDefMetricThrottledRequestsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:deprecated: Do not use this function. It returns an invalid metric. Use ``metricThrottledRequestsForOperation`` instead.\n\n:stability: deprecated\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefMetricThrottledRequestsForOperationParams(pydantic.BaseModel):
    operation: str = pydantic.Field(..., description='-\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseDefMetricThrottledRequestsForOperationsParams(pydantic.BaseModel):
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    ...

class TableBaseDefMetricUserErrorsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_dynamodb.TableBaseV2
class TableBaseV2Def(BaseClass):
    account: typing.Optional[str] = pydantic.Field(None, description='The AWS account ID this resource belongs to. Default: - the resource is in the same account as the stack it belongs to\n')
    environment_from_arn: typing.Optional[str] = pydantic.Field(None, description='ARN to deduce region and account from. The ARN is parsed and the account and region are taken from the ARN. This should be used for imported resources. Cannot be supplied together with either ``account`` or ``region``. Default: - take environment from ``account``, ``region`` parameters, or use Stack environment.\n')
    physical_name: typing.Optional[str] = pydantic.Field(None, description='The value passed in by users to the physical name prop of the resource. - ``undefined`` implies that a physical name will be allocated by CloudFormation during deployment. - a concrete value implies a specific physical name - ``PhysicalName.GENERATE_IF_NEEDED`` is a marker that indicates that a physical will only be generated by the CDK if it is needed for cross-environment references. Otherwise, it will be allocated by CloudFormation. Default: - The physical name will be allocated by CloudFormation at deployment time\n')
    region: typing.Optional[str] = pydantic.Field(None, description='The AWS region this resource belongs to. Default: - the resource is in the same region as the stack it belongs to')
    _init_params: typing.ClassVar[list[str]] = ['account', 'environment_from_arn', 'physical_name', 'region']
    _method_names: typing.ClassVar[list[str]] = ['apply_removal_policy', 'grant', 'grant_full_access', 'grant_read_data', 'grant_read_write_data', 'grant_stream', 'grant_stream_read', 'grant_table_list_streams', 'grant_write_data', 'metric', 'metric_conditional_check_failed_requests', 'metric_consumed_read_capacity_units', 'metric_consumed_write_capacity_units', 'metric_successful_request_latency', 'metric_system_errors', 'metric_system_errors_for_operations', 'metric_throttled_requests', 'metric_throttled_requests_for_operation', 'metric_throttled_requests_for_operations', 'metric_user_errors']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.TableBaseV2'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_dynamodb.TableBaseV2DefConfig] = pydantic.Field(None)


class TableBaseV2DefConfig(pydantic.BaseModel):
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    grant: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefGrantParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this table to an IAM principal's policy.\nNote: If ``encryptionKey`` is present, appropriate grants to the key needs to be added\nseparately using the ``table.encryptionKey.grant*`` methods.")
    grant_full_access: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefGrantFullAccessParams]] = pydantic.Field(None, description="Permits an IAM principal to all DynamoDB operations ('dynamodb:*') on this table.\nNote: Appropriate grants will also be added to the customer-managed KMS keys associated with this\ntable if one was configured.")
    grant_read_data: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefGrantReadDataParams]] = pydantic.Field(None, description='Permits an IAM principal all data read operations on this table.\nActions: BatchGetItem, GetRecords, GetShardIterator, Query, GetItem, Scan, DescribeTable.\n\nNote: Appropriate grants will also be added to the customer-managed KMS keys associated with this\ntable if one was configured.')
    grant_read_write_data: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefGrantReadWriteDataParams]] = pydantic.Field(None, description='Permits an IAM principal to all data read/write operations on this table.\nActions: BatchGetItem, GetRecords, GetShardIterator, Query, GetItem, Scan, BatchWriteItem, PutItem, UpdateItem,\nDeleteItem, DescribeTable.\n\nNote: Appropriate grants will also be added to the customer-managed KMS keys associated with this\ntable if one was configured.')
    grant_stream: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefGrantStreamParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this table to an IAM principal's policy.\nNote: If ``encryptionKey`` is present, appropriate grants to the key needs to be added\nseparately using the ``table.encryptionKey.grant*`` methods.")
    grant_stream_read: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefGrantStreamReadParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this table to an IAM principal's policy.\nActions: DescribeStream, GetRecords, GetShardIterator, ListStreams.\n\nNote: Appropriate grants will also be added to the customer-managed KMS keys associated with this\ntable if one was configured.")
    grant_table_list_streams: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefGrantTableListStreamsParams]] = pydantic.Field(None, description='Permits an IAM principal to list streams attached to this table.')
    grant_write_data: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefGrantWriteDataParams]] = pydantic.Field(None, description='Permits an IAM principal all data write operations on this table.\nActions: BatchWriteItem, PutItem, UpdateItem, DeleteItem, DescribeTable.\n\nNote: Appropriate grants will also be added to the customer-managed KMS keys associated with this\ntable if one was configured.')
    metric: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefMetricParams]] = pydantic.Field(None, description='Return the given named metric for this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_conditional_check_failed_requests: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefMetricConditionalCheckFailedRequestsParams]] = pydantic.Field(None, description='Metric for the conditional check failed requests for this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_consumed_read_capacity_units: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefMetricConsumedReadCapacityUnitsParams]] = pydantic.Field(None, description='Metric for the consumed read capacity units for this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_consumed_write_capacity_units: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefMetricConsumedWriteCapacityUnitsParams]] = pydantic.Field(None, description='Metric for the consumed write capacity units for this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_successful_request_latency: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefMetricSuccessfulRequestLatencyParams]] = pydantic.Field(None, description='Metric for the successful request latency for this table.\nBy default, the metric will be calculated as an average over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_system_errors: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefMetricSystemErrorsParams]] = pydantic.Field(None, description='(deprecated) Metric for the system errors this table.')
    metric_system_errors_for_operations: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefMetricSystemErrorsForOperationsParams]] = pydantic.Field(None, description='Metric for the system errors for this table. This will sum errors across all possible operations.\nBy default, each individual metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_throttled_requests: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefMetricThrottledRequestsParams]] = pydantic.Field(None, description='(deprecated) How many requests are throttled on this table.\nBy default, each individual metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_throttled_requests_for_operation: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefMetricThrottledRequestsForOperationParams]] = pydantic.Field(None, description='How many requests are throttled on this table for the given operation.\nBy default, the metric will be calculated as an average over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_throttled_requests_for_operations: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefMetricThrottledRequestsForOperationsParams]] = pydantic.Field(None, description='How many requests are throttled on this table. This will sum errors across all possible operations.\nBy default, each individual metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_user_errors: typing.Optional[list[models.aws_dynamodb.TableBaseV2DefMetricUserErrorsParams]] = pydantic.Field(None, description='Metric for the user errors for this table.\nNote: This metric reports user errors across all the tables in the account and region the table\nresides in.\n\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')

class TableBaseV2DefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class TableBaseV2DefGrantParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal (no-op if undefined).\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefGrantFullAccessParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefGrantReadDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefGrantReadWriteDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefGrantStreamParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal (no-op if undefined).\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefGrantStreamReadParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefGrantTableListStreamsParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefGrantWriteDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefMetricParams(pydantic.BaseModel):
    metric_name: str = pydantic.Field(..., description='-\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefMetricConditionalCheckFailedRequestsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefMetricConsumedReadCapacityUnitsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefMetricConsumedWriteCapacityUnitsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefMetricSuccessfulRequestLatencyParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefMetricSystemErrorsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:deprecated: use ``metricSystemErrorsForOperations``.\n\n:stability: deprecated\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefMetricSystemErrorsForOperationsParams(pydantic.BaseModel):
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    ...

class TableBaseV2DefMetricThrottledRequestsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:deprecated: Do not use this function. It returns an invalid metric. Use ``metricThrottledRequestsForOperation`` instead.\n\n:stability: deprecated\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableBaseV2DefMetricThrottledRequestsForOperationParams(pydantic.BaseModel):
    operation: str = pydantic.Field(..., description='-\n')
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    ...

class TableBaseV2DefMetricThrottledRequestsForOperationsParams(pydantic.BaseModel):
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    ...

class TableBaseV2DefMetricUserErrorsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_dynamodb.TableEncryptionV2
class TableEncryptionV2Def(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['aws_managed_key', 'customer_managed_key', 'dynamo_owned_key']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.TableEncryptionV2'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_dynamodb.TableEncryptionV2DefConfig] = pydantic.Field(None)


class TableEncryptionV2DefConfig(pydantic.BaseModel):
    aws_managed_key: typing.Optional[list[models.aws_dynamodb.TableEncryptionV2DefAwsManagedKeyParams]] = pydantic.Field(None, description='Configure server-side encryption using a DynamoDB owned key.')
    customer_managed_key: typing.Optional[list[models.aws_dynamodb.TableEncryptionV2DefCustomerManagedKeyParams]] = pydantic.Field(None, description='Configure server-side encryption using customer managed keys.')
    dynamo_owned_key: typing.Optional[list[models.aws_dynamodb.TableEncryptionV2DefDynamoOwnedKeyParams]] = pydantic.Field(None, description='Configure server-side encryption using a DynamoDB owned key.')

class TableEncryptionV2DefAwsManagedKeyParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_dynamodb.TableEncryptionV2DefConfig]] = pydantic.Field(None)
    ...

class TableEncryptionV2DefCustomerManagedKeyParams(pydantic.BaseModel):
    table_key: typing.Union[models.aws_kms.KeyDef] = pydantic.Field(..., description='the KMS key for the primary table.\n')
    replica_key_arns: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='an object containing the ARN of the KMS key to use for each replica table.')
    return_config: typing.Optional[list[models.aws_dynamodb.TableEncryptionV2DefConfig]] = pydantic.Field(None)
    ...

class TableEncryptionV2DefDynamoOwnedKeyParams(pydantic.BaseModel):
    return_config: typing.Optional[list[models.aws_dynamodb.TableEncryptionV2DefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_dynamodb.Table
class TableDef(BaseConstruct):
    kinesis_stream: typing.Optional[typing.Union[models.aws_kinesis.StreamDef]] = pydantic.Field(None, description='Kinesis Data Stream to capture item-level changes for the table. Default: - no Kinesis Data Stream\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description='Enforces a particular physical table name. Default:\n')
    billing_mode: typing.Optional[aws_cdk.aws_dynamodb.BillingMode] = pydantic.Field(None, description='Specify how you are charged for read and write throughput and how you manage capacity. Default: PROVISIONED if ``replicationRegions`` is not specified, PAY_PER_REQUEST otherwise\n')
    contributor_insights_enabled: typing.Optional[bool] = pydantic.Field(None, description='Whether CloudWatch contributor insights is enabled. Default: false\n')
    deletion_protection: typing.Optional[bool] = pydantic.Field(None, description='Enables deletion protection for the table. Default: false\n')
    encryption: typing.Optional[aws_cdk.aws_dynamodb.TableEncryption] = pydantic.Field(None, description='Whether server-side encryption with an AWS managed customer master key is enabled. This property cannot be set if ``serverSideEncryption`` is set. .. epigraph:: **NOTE**: if you set this to ``CUSTOMER_MANAGED`` and ``encryptionKey`` is not specified, the key that the Tablet generates for you will be created with default permissions. If you are using CDKv2, these permissions will be sufficient to enable the key for use with DynamoDB tables. If you are using CDKv1, make sure the feature flag ``@aws-cdk/aws-kms:defaultKeyPolicies`` is set to ``true`` in your ``cdk.json``. Default: - The table is encrypted with an encryption key managed by DynamoDB, and you are not charged any fee for using it.\n')
    encryption_key: typing.Optional[typing.Union[models.aws_kms.KeyDef]] = pydantic.Field(None, description='External KMS key to use for table encryption. This property can only be set if ``encryption`` is set to ``TableEncryption.CUSTOMER_MANAGED``. Default: - If ``encryption`` is set to ``TableEncryption.CUSTOMER_MANAGED`` and this property is undefined, a new KMS key will be created and associated with this table. If ``encryption`` and this property are both undefined, then the table is encrypted with an encryption key managed by DynamoDB, and you are not charged any fee for using it.\n')
    point_in_time_recovery: typing.Optional[bool] = pydantic.Field(None, description='Whether point-in-time recovery is enabled. Default: - point-in-time recovery is disabled\n')
    read_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="The read capacity for the table. Careful if you add Global Secondary Indexes, as those will share the table's provisioned throughput. Can only be provided if billingMode is Provisioned. Default: 5\n")
    removal_policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='The removal policy to apply to the DynamoDB Table. Default: RemovalPolicy.RETAIN\n')
    replication_regions: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Regions where replica tables will be created. Default: - no replica tables are created\n')
    replication_timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The timeout for a table replication operation in a single region. Default: Duration.minutes(30)\n')
    stream: typing.Optional[aws_cdk.aws_dynamodb.StreamViewType] = pydantic.Field(None, description='When an item in the table is modified, StreamViewType determines what information is written to the stream for this table. Default: - streams are disabled unless ``replicationRegions`` is specified\n')
    table_class: typing.Optional[aws_cdk.aws_dynamodb.TableClass] = pydantic.Field(None, description='Specify the table class. Default: STANDARD\n')
    time_to_live_attribute: typing.Optional[str] = pydantic.Field(None, description='The name of TTL attribute. Default: - TTL is disabled\n')
    wait_for_replication_to_finish: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether CloudFormation stack waits for replication to finish. If set to false, the CloudFormation resource will mark the resource as created and replication will be completed asynchronously. This property is ignored if replicationRegions property is not set. WARNING: DO NOT UNSET this property if adding/removing multiple replicationRegions in one deployment, as CloudFormation only supports one region replication at a time. CDK overcomes this limitation by waiting for replication to finish before starting new replicationRegion. If the custom resource which handles replication has a physical resource ID with the format ``region`` instead of ``tablename-region`` (this would happen if the custom resource hasn't received an event since v1.91.0), DO NOT SET this property to false without making a change to the table name. This will cause the existing replicas to be deleted. Default: true\n")
    write_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="The write capacity for the table. Careful if you add Global Secondary Indexes, as those will share the table's provisioned throughput. Can only be provided if billingMode is Provisioned. Default: 5\n")
    partition_key: typing.Union[_REQUIRED_INIT_PARAM, models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Partition key attribute definition.\n')
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Sort key attribute definition. Default: no sort key')
    _init_params: typing.ClassVar[list[str]] = ['kinesis_stream', 'table_name', 'billing_mode', 'contributor_insights_enabled', 'deletion_protection', 'encryption', 'encryption_key', 'point_in_time_recovery', 'read_capacity', 'removal_policy', 'replication_regions', 'replication_timeout', 'stream', 'table_class', 'time_to_live_attribute', 'wait_for_replication_to_finish', 'write_capacity', 'partition_key', 'sort_key']
    _method_names: typing.ClassVar[list[str]] = ['add_global_secondary_index', 'add_local_secondary_index', 'apply_removal_policy', 'auto_scale_global_secondary_index_read_capacity', 'auto_scale_global_secondary_index_write_capacity', 'auto_scale_read_capacity', 'auto_scale_write_capacity', 'grant', 'grant_full_access', 'grant_read_data', 'grant_read_write_data', 'grant_stream', 'grant_stream_read', 'grant_table_list_streams', 'grant_write_data', 'metric', 'metric_conditional_check_failed_requests', 'metric_consumed_read_capacity_units', 'metric_consumed_write_capacity_units', 'metric_successful_request_latency', 'metric_system_errors', 'metric_system_errors_for_operations', 'metric_throttled_requests', 'metric_throttled_requests_for_operation', 'metric_throttled_requests_for_operations', 'metric_user_errors', 'schema']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_table_arn', 'from_table_attributes', 'from_table_name']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.Table'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_table_arn', 'from_table_attributes', 'from_table_name']
    ...


    from_table_arn: typing.Optional[models.aws_dynamodb.TableDefFromTableArnParams] = pydantic.Field(None, description='Creates a Table construct that represents an external table via table arn.')
    from_table_attributes: typing.Optional[models.aws_dynamodb.TableDefFromTableAttributesParams] = pydantic.Field(None, description='Creates a Table construct that represents an external table.')
    from_table_name: typing.Optional[models.aws_dynamodb.TableDefFromTableNameParams] = pydantic.Field(None, description='Creates a Table construct that represents an external table via table name.')
    resource_config: typing.Optional[models.aws_dynamodb.TableDefConfig] = pydantic.Field(None)


class TableDefConfig(pydantic.BaseModel):
    add_global_secondary_index: typing.Optional[list[models.aws_dynamodb.TableDefAddGlobalSecondaryIndexParams]] = pydantic.Field(None, description='Add a global secondary index of table.')
    add_local_secondary_index: typing.Optional[list[models.aws_dynamodb.TableDefAddLocalSecondaryIndexParams]] = pydantic.Field(None, description='Add a local secondary index of table.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    auto_scale_global_secondary_index_read_capacity: typing.Optional[list[models.aws_dynamodb.TableDefAutoScaleGlobalSecondaryIndexReadCapacityParams]] = pydantic.Field(None, description='Enable read capacity scaling for the given GSI.')
    auto_scale_global_secondary_index_write_capacity: typing.Optional[list[models.aws_dynamodb.TableDefAutoScaleGlobalSecondaryIndexWriteCapacityParams]] = pydantic.Field(None, description='Enable write capacity scaling for the given GSI.')
    auto_scale_read_capacity: typing.Optional[list[models.aws_dynamodb.TableDefAutoScaleReadCapacityParams]] = pydantic.Field(None, description='Enable read capacity scaling for this table.')
    auto_scale_write_capacity: typing.Optional[list[models.aws_dynamodb.TableDefAutoScaleWriteCapacityParams]] = pydantic.Field(None, description='Enable write capacity scaling for this table.')
    grant: typing.Optional[list[models.aws_dynamodb.TableDefGrantParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this table to an IAM principal's policy.\nIf ``encryptionKey`` is present, appropriate grants to the key needs to be added\nseparately using the ``table.encryptionKey.grant*`` methods.")
    grant_full_access: typing.Optional[list[models.aws_dynamodb.TableDefGrantFullAccessParams]] = pydantic.Field(None, description='Permits all DynamoDB operations ("dynamodb:*") to an IAM principal.\nAppropriate grants will also be added to the customer-managed KMS key\nif one was configured.')
    grant_read_data: typing.Optional[list[models.aws_dynamodb.TableDefGrantReadDataParams]] = pydantic.Field(None, description='Permits an IAM principal all data read operations from this table: BatchGetItem, GetRecords, GetShardIterator, Query, GetItem, Scan, DescribeTable.\nAppropriate grants will also be added to the customer-managed KMS key\nif one was configured.')
    grant_read_write_data: typing.Optional[list[models.aws_dynamodb.TableDefGrantReadWriteDataParams]] = pydantic.Field(None, description='Permits an IAM principal to all data read/write operations to this table.\nBatchGetItem, GetRecords, GetShardIterator, Query, GetItem, Scan,\nBatchWriteItem, PutItem, UpdateItem, DeleteItem, DescribeTable\n\nAppropriate grants will also be added to the customer-managed KMS key\nif one was configured.')
    grant_stream: typing.Optional[list[models.aws_dynamodb.TableDefGrantStreamParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this table's stream to an IAM principal's policy.\nIf ``encryptionKey`` is present, appropriate grants to the key needs to be added\nseparately using the ``table.encryptionKey.grant*`` methods.")
    grant_stream_read: typing.Optional[list[models.aws_dynamodb.TableDefGrantStreamReadParams]] = pydantic.Field(None, description="Permits an IAM principal all stream data read operations for this table's stream: DescribeStream, GetRecords, GetShardIterator, ListStreams.\nAppropriate grants will also be added to the customer-managed KMS key\nif one was configured.")
    grant_table_list_streams: typing.Optional[list[models.aws_dynamodb.TableDefGrantTableListStreamsParams]] = pydantic.Field(None, description='Permits an IAM Principal to list streams attached to current dynamodb table.')
    grant_write_data: typing.Optional[list[models.aws_dynamodb.TableDefGrantWriteDataParams]] = pydantic.Field(None, description='Permits an IAM principal all data write operations to this table: BatchWriteItem, PutItem, UpdateItem, DeleteItem, DescribeTable.\nAppropriate grants will also be added to the customer-managed KMS key\nif one was configured.')
    metric: typing.Optional[list[models.aws_dynamodb.TableDefMetricParams]] = pydantic.Field(None, description='Return the given named metric for this Table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_conditional_check_failed_requests: typing.Optional[list[models.aws_dynamodb.TableDefMetricConditionalCheckFailedRequestsParams]] = pydantic.Field(None, description='Metric for the conditional check failed requests this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_consumed_read_capacity_units: typing.Optional[list[models.aws_dynamodb.TableDefMetricConsumedReadCapacityUnitsParams]] = pydantic.Field(None, description='Metric for the consumed read capacity units this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_consumed_write_capacity_units: typing.Optional[list[models.aws_dynamodb.TableDefMetricConsumedWriteCapacityUnitsParams]] = pydantic.Field(None, description='Metric for the consumed write capacity units this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_successful_request_latency: typing.Optional[list[models.aws_dynamodb.TableDefMetricSuccessfulRequestLatencyParams]] = pydantic.Field(None, description='Metric for the successful request latency this table.\nBy default, the metric will be calculated as an average over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_system_errors: typing.Optional[list[models.aws_dynamodb.TableDefMetricSystemErrorsParams]] = pydantic.Field(None, description='(deprecated) Metric for the system errors this table.')
    metric_system_errors_for_operations: typing.Optional[list[models.aws_dynamodb.TableDefMetricSystemErrorsForOperationsParams]] = pydantic.Field(None, description='Metric for the system errors this table.\nThis will sum errors across all possible operations.\nNote that by default, each individual metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_throttled_requests: typing.Optional[list[models.aws_dynamodb.TableDefMetricThrottledRequestsParams]] = pydantic.Field(None, description='(deprecated) How many requests are throttled on this table.\nDefault: sum over 5 minutes')
    metric_throttled_requests_for_operation: typing.Optional[list[models.aws_dynamodb.TableDefMetricThrottledRequestsForOperationParams]] = pydantic.Field(None, description='How many requests are throttled on this table, for the given operation.\nDefault: sum over 5 minutes')
    metric_throttled_requests_for_operations: typing.Optional[list[models.aws_dynamodb.TableDefMetricThrottledRequestsForOperationsParams]] = pydantic.Field(None, description='How many requests are throttled on this table.\nThis will sum errors across all possible operations.\nNote that by default, each individual metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_user_errors: typing.Optional[list[models.aws_dynamodb.TableDefMetricUserErrorsParams]] = pydantic.Field(None, description='Metric for the user errors.\nNote that this metric reports user errors across all\nthe tables in the account and region the table resides in.\n\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    schema_: typing.Optional[list[models.aws_dynamodb.TableDefSchemaParams]] = pydantic.Field(None, description='Get schema attributes of table or index.', alias='schema')

class TableDefAddGlobalSecondaryIndexParams(pydantic.BaseModel):
    read_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The read capacity for the global secondary index. Can only be provided if table billingMode is Provisioned or undefined. Default: 5\n')
    write_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The write capacity for the global secondary index. Can only be provided if table billingMode is Provisioned or undefined. Default: 5\n')
    index_name: str = pydantic.Field(..., description='The name of the secondary index.\n')
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The non-key attributes that are projected into the secondary index. Default: - No additional attributes\n')
    projection_type: typing.Optional[aws_cdk.aws_dynamodb.ProjectionType] = pydantic.Field(None, description='The set of attributes that are projected into the secondary index. Default: ALL\n')
    partition_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(..., description='Partition key attribute definition.\n')
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Sort key attribute definition. Default: no sort key')
    ...

class TableDefAddLocalSecondaryIndexParams(pydantic.BaseModel):
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(..., description='The attribute of a sort key for the local secondary index.\n')
    index_name: str = pydantic.Field(..., description='The name of the secondary index.\n')
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The non-key attributes that are projected into the secondary index. Default: - No additional attributes\n')
    projection_type: typing.Optional[aws_cdk.aws_dynamodb.ProjectionType] = pydantic.Field(None, description='The set of attributes that are projected into the secondary index. Default: ALL')
    ...

class TableDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class TableDefAutoScaleGlobalSecondaryIndexReadCapacityParams(pydantic.BaseModel):
    index_name: str = pydantic.Field(..., description='-\n')
    max_capacity: typing.Union[int, float] = pydantic.Field(..., description='Maximum capacity to scale to.\n')
    min_capacity: typing.Union[int, float] = pydantic.Field(..., description='Minimum capacity to scale to.\n')
    return_config: typing.Optional[list[models._interface_methods.AwsDynamodbIScalableTableAttributeDefConfig]] = pydantic.Field(None)
    ...

class TableDefAutoScaleGlobalSecondaryIndexWriteCapacityParams(pydantic.BaseModel):
    index_name: str = pydantic.Field(..., description='-\n')
    max_capacity: typing.Union[int, float] = pydantic.Field(..., description='Maximum capacity to scale to.\n')
    min_capacity: typing.Union[int, float] = pydantic.Field(..., description='Minimum capacity to scale to.\n')
    return_config: typing.Optional[list[models._interface_methods.AwsDynamodbIScalableTableAttributeDefConfig]] = pydantic.Field(None)
    ...

class TableDefAutoScaleReadCapacityParams(pydantic.BaseModel):
    max_capacity: typing.Union[int, float] = pydantic.Field(..., description='Maximum capacity to scale to.\n')
    min_capacity: typing.Union[int, float] = pydantic.Field(..., description='Minimum capacity to scale to.\n')
    return_config: typing.Optional[list[models._interface_methods.AwsDynamodbIScalableTableAttributeDefConfig]] = pydantic.Field(None)
    ...

class TableDefAutoScaleWriteCapacityParams(pydantic.BaseModel):
    max_capacity: typing.Union[int, float] = pydantic.Field(..., description='Maximum capacity to scale to.\n')
    min_capacity: typing.Union[int, float] = pydantic.Field(..., description='Minimum capacity to scale to.\n')
    return_config: typing.Optional[list[models._interface_methods.AwsDynamodbIScalableTableAttributeDefConfig]] = pydantic.Field(None)
    ...

class TableDefFromTableArnParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='The parent creating construct (usually ``this``).\n')
    id: str = pydantic.Field(..., description="The construct's name.\n")
    table_arn: str = pydantic.Field(..., description="The table's ARN.")
    ...

class TableDefFromTableAttributesParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='The parent creating construct (usually ``this``).\n')
    id: str = pydantic.Field(..., description="The construct's name.\n")
    encryption_key: typing.Optional[typing.Union[models.aws_kms.KeyDef]] = pydantic.Field(None, description='KMS encryption key, if this table uses a customer-managed encryption key. Default: - no key\n')
    global_indexes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The name of the global indexes set for this Table. Note that you need to set either this property, or ``localIndexes``, if you want methods like grantReadData() to grant permissions for indexes as well as the table itself. Default: - no global indexes\n')
    grant_index_permissions: typing.Optional[bool] = pydantic.Field(None, description='If set to true, grant methods always grant permissions for all indexes. If false is provided, grant methods grant the permissions only when ``globalIndexes`` or ``localIndexes`` is specified. Default: - false\n')
    local_indexes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The name of the local indexes set for this Table. Note that you need to set either this property, or ``globalIndexes``, if you want methods like grantReadData() to grant permissions for indexes as well as the table itself. Default: - no local indexes\n')
    table_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the dynamodb table. One of this, or ``tableName``, is required. Default: - no table arn\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description='The table name of the dynamodb table. One of this, or ``tableArn``, is required. Default: - no table name\n')
    table_stream_arn: typing.Optional[str] = pydantic.Field(None, description="The ARN of the table's stream. Default: - no table stream")
    ...

class TableDefFromTableNameParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='The parent creating construct (usually ``this``).\n')
    id: str = pydantic.Field(..., description="The construct's name.\n")
    table_name: str = pydantic.Field(..., description="The table's name.")
    ...

class TableDefGrantParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal (no-op if undefined).\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableDefGrantFullAccessParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableDefGrantReadDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableDefGrantReadWriteDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableDefGrantStreamParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal (no-op if undefined).\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableDefGrantStreamReadParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableDefGrantTableListStreamsParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal (no-op if undefined).')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableDefGrantWriteDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='The principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableDefMetricParams(pydantic.BaseModel):
    metric_name: str = pydantic.Field(..., description='-\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableDefMetricConditionalCheckFailedRequestsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableDefMetricConsumedReadCapacityUnitsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableDefMetricConsumedWriteCapacityUnitsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableDefMetricSuccessfulRequestLatencyParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableDefMetricSystemErrorsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:deprecated: use ``metricSystemErrorsForOperations``.\n\n:stability: deprecated\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableDefMetricSystemErrorsForOperationsParams(pydantic.BaseModel):
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    ...

class TableDefMetricThrottledRequestsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:deprecated: Do not use this function. It returns an invalid metric. Use ``metricThrottledRequestsForOperation`` instead.\n\n:stability: deprecated\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableDefMetricThrottledRequestsForOperationParams(pydantic.BaseModel):
    operation: str = pydantic.Field(..., description='-\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableDefMetricThrottledRequestsForOperationsParams(pydantic.BaseModel):
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    ...

class TableDefMetricUserErrorsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableDefSchemaParams(pydantic.BaseModel):
    index_name: typing.Optional[str] = pydantic.Field(None, description='-\n')
    ...


#  autogenerated from aws_cdk.aws_dynamodb.TableV2
class TableV2Def(BaseConstruct):
    partition_key: typing.Union[_REQUIRED_INIT_PARAM, models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Partition key attribute definition.\n')
    billing: typing.Optional[models.aws_dynamodb.BillingDef] = pydantic.Field(None, description='The billing mode and capacity settings to apply to the table. Default: Billing.onDemand()\n')
    dynamo_stream: typing.Optional[aws_cdk.aws_dynamodb.StreamViewType] = pydantic.Field(None, description='When an item in the table is modified, StreamViewType determines what information is written to the stream. Default: - streams are disabled if replicas are not configured and this property is not specified. If this property is not specified when replicas are configured, then NEW_AND_OLD_IMAGES will be the StreamViewType for all replicas\n')
    encryption: typing.Optional[models.aws_dynamodb.TableEncryptionV2Def] = pydantic.Field(None, description='The server-side encryption. Default: TableEncryptionV2.dynamoOwnedKey()\n')
    global_secondary_indexes: typing.Optional[typing.Sequence[typing.Union[models.aws_dynamodb.GlobalSecondaryIndexPropsV2Def, dict[str, typing.Any]]]] = pydantic.Field(None, description='Global secondary indexes. Note: You can provide a maximum of 20 global secondary indexes. Default: - no global secondary indexes\n')
    local_secondary_indexes: typing.Optional[typing.Sequence[typing.Union[models.aws_dynamodb.LocalSecondaryIndexPropsDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Local secondary indexes. Note: You can only provide a maximum of 5 local secondary indexes. Default: - no local secondary indexes\n')
    removal_policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='The removal policy applied to the table. Default: RemovalPolicy.RETAIN\n')
    replicas: typing.Optional[typing.Sequence[typing.Union[models.aws_dynamodb.ReplicaTablePropsDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Replica tables to deploy with the primary table. Note: Adding replica tables allows you to use your table as a global table. You cannot specify a replica table in the region that the primary table will be deployed to. Replica tables will only be supported if the stack deployment region is defined. Default: - no replica tables\n')
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Sort key attribute definition. Default: - no sort key\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description='The name of the table. Default: - generated by CloudFormation\n')
    time_to_live_attribute: typing.Optional[str] = pydantic.Field(None, description='The name of the TTL attribute. Default: - TTL is disabled\n')
    contributor_insights: typing.Optional[bool] = pydantic.Field(None, description='Whether CloudWatch contributor insights is enabled. Default: false\n')
    deletion_protection: typing.Optional[bool] = pydantic.Field(None, description='Whether deletion protection is enabled. Default: false\n')
    kinesis_stream: typing.Optional[typing.Union[models.aws_kinesis.StreamDef]] = pydantic.Field(None, description='Kinesis Data Stream to capture item level changes. Default: - no Kinesis Data Stream\n')
    point_in_time_recovery: typing.Optional[bool] = pydantic.Field(None, description='Whether point-in-time recovery is enabled. Default: false\n')
    table_class: typing.Optional[aws_cdk.aws_dynamodb.TableClass] = pydantic.Field(None, description='The table class. Default: TableClass.STANDARD\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Tags to be applied to the table or replica table. Default: - no tags')
    _init_params: typing.ClassVar[list[str]] = ['partition_key', 'billing', 'dynamo_stream', 'encryption', 'global_secondary_indexes', 'local_secondary_indexes', 'removal_policy', 'replicas', 'sort_key', 'table_name', 'time_to_live_attribute', 'contributor_insights', 'deletion_protection', 'kinesis_stream', 'point_in_time_recovery', 'table_class', 'tags']
    _method_names: typing.ClassVar[list[str]] = ['add_global_secondary_index', 'add_local_secondary_index', 'add_replica', 'apply_removal_policy', 'grant', 'grant_full_access', 'grant_read_data', 'grant_read_write_data', 'grant_stream', 'grant_stream_read', 'grant_table_list_streams', 'grant_write_data', 'metric', 'metric_conditional_check_failed_requests', 'metric_consumed_read_capacity_units', 'metric_consumed_write_capacity_units', 'metric_successful_request_latency', 'metric_system_errors', 'metric_system_errors_for_operations', 'metric_throttled_requests', 'metric_throttled_requests_for_operation', 'metric_throttled_requests_for_operations', 'metric_user_errors', 'replica']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_table_arn', 'from_table_attributes', 'from_table_name']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.TableV2'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_table_arn', 'from_table_attributes', 'from_table_name']
    ...


    from_table_arn: typing.Optional[models.aws_dynamodb.TableV2DefFromTableArnParams] = pydantic.Field(None, description='Creates a Table construct that represents an external table via table ARN.')
    from_table_attributes: typing.Optional[models.aws_dynamodb.TableV2DefFromTableAttributesParams] = pydantic.Field(None, description='Creates a Table construct that represents an external table.')
    from_table_name: typing.Optional[models.aws_dynamodb.TableV2DefFromTableNameParams] = pydantic.Field(None, description='Creates a Table construct that represents an external table via table name.')
    resource_config: typing.Optional[models.aws_dynamodb.TableV2DefConfig] = pydantic.Field(None)


class TableV2DefConfig(pydantic.BaseModel):
    add_global_secondary_index: typing.Optional[list[models.aws_dynamodb.TableV2DefAddGlobalSecondaryIndexParams]] = pydantic.Field(None, description='Add a global secondary index to the table.\nNote: Global secondary indexes will be inherited by all replica tables.')
    add_local_secondary_index: typing.Optional[list[models.aws_dynamodb.TableV2DefAddLocalSecondaryIndexParams]] = pydantic.Field(None, description='Add a local secondary index to the table.\nNote: Local secondary indexes will be inherited by all replica tables.')
    add_replica: typing.Optional[list[models.aws_dynamodb.TableV2DefAddReplicaParams]] = pydantic.Field(None, description='Add a replica table.\nNote: Adding a replica table will allow you to use your table as a global table.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    grant: typing.Optional[list[models.aws_dynamodb.TableV2DefGrantParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this table to an IAM principal's policy.\nNote: If ``encryptionKey`` is present, appropriate grants to the key needs to be added\nseparately using the ``table.encryptionKey.grant*`` methods.")
    grant_full_access: typing.Optional[list[models.aws_dynamodb.TableV2DefGrantFullAccessParams]] = pydantic.Field(None, description="Permits an IAM principal to all DynamoDB operations ('dynamodb:*') on this table.\nNote: Appropriate grants will also be added to the customer-managed KMS keys associated with this\ntable if one was configured.")
    grant_read_data: typing.Optional[list[models.aws_dynamodb.TableV2DefGrantReadDataParams]] = pydantic.Field(None, description='Permits an IAM principal all data read operations on this table.\nActions: BatchGetItem, GetRecords, GetShardIterator, Query, GetItem, Scan, DescribeTable.\n\nNote: Appropriate grants will also be added to the customer-managed KMS keys associated with this\ntable if one was configured.')
    grant_read_write_data: typing.Optional[list[models.aws_dynamodb.TableV2DefGrantReadWriteDataParams]] = pydantic.Field(None, description='Permits an IAM principal to all data read/write operations on this table.\nActions: BatchGetItem, GetRecords, GetShardIterator, Query, GetItem, Scan, BatchWriteItem, PutItem, UpdateItem,\nDeleteItem, DescribeTable.\n\nNote: Appropriate grants will also be added to the customer-managed KMS keys associated with this\ntable if one was configured.')
    grant_stream: typing.Optional[list[models.aws_dynamodb.TableV2DefGrantStreamParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this table to an IAM principal's policy.\nNote: If ``encryptionKey`` is present, appropriate grants to the key needs to be added\nseparately using the ``table.encryptionKey.grant*`` methods.")
    grant_stream_read: typing.Optional[list[models.aws_dynamodb.TableV2DefGrantStreamReadParams]] = pydantic.Field(None, description="Adds an IAM policy statement associated with this table to an IAM principal's policy.\nActions: DescribeStream, GetRecords, GetShardIterator, ListStreams.\n\nNote: Appropriate grants will also be added to the customer-managed KMS keys associated with this\ntable if one was configured.")
    grant_table_list_streams: typing.Optional[list[models.aws_dynamodb.TableV2DefGrantTableListStreamsParams]] = pydantic.Field(None, description='Permits an IAM principal to list streams attached to this table.')
    grant_write_data: typing.Optional[list[models.aws_dynamodb.TableV2DefGrantWriteDataParams]] = pydantic.Field(None, description='Permits an IAM principal all data write operations on this table.\nActions: BatchWriteItem, PutItem, UpdateItem, DeleteItem, DescribeTable.\n\nNote: Appropriate grants will also be added to the customer-managed KMS keys associated with this\ntable if one was configured.')
    metric: typing.Optional[list[models.aws_dynamodb.TableV2DefMetricParams]] = pydantic.Field(None, description='Return the given named metric for this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_conditional_check_failed_requests: typing.Optional[list[models.aws_dynamodb.TableV2DefMetricConditionalCheckFailedRequestsParams]] = pydantic.Field(None, description='Metric for the conditional check failed requests for this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_consumed_read_capacity_units: typing.Optional[list[models.aws_dynamodb.TableV2DefMetricConsumedReadCapacityUnitsParams]] = pydantic.Field(None, description='Metric for the consumed read capacity units for this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_consumed_write_capacity_units: typing.Optional[list[models.aws_dynamodb.TableV2DefMetricConsumedWriteCapacityUnitsParams]] = pydantic.Field(None, description='Metric for the consumed write capacity units for this table.\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_successful_request_latency: typing.Optional[list[models.aws_dynamodb.TableV2DefMetricSuccessfulRequestLatencyParams]] = pydantic.Field(None, description='Metric for the successful request latency for this table.\nBy default, the metric will be calculated as an average over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_system_errors: typing.Optional[list[models.aws_dynamodb.TableV2DefMetricSystemErrorsParams]] = pydantic.Field(None, description='(deprecated) Metric for the system errors this table.')
    metric_system_errors_for_operations: typing.Optional[list[models.aws_dynamodb.TableV2DefMetricSystemErrorsForOperationsParams]] = pydantic.Field(None, description='Metric for the system errors for this table. This will sum errors across all possible operations.\nBy default, each individual metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_throttled_requests: typing.Optional[list[models.aws_dynamodb.TableV2DefMetricThrottledRequestsParams]] = pydantic.Field(None, description='(deprecated) How many requests are throttled on this table.\nBy default, each individual metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_throttled_requests_for_operation: typing.Optional[list[models.aws_dynamodb.TableV2DefMetricThrottledRequestsForOperationParams]] = pydantic.Field(None, description='How many requests are throttled on this table for the given operation.\nBy default, the metric will be calculated as an average over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_throttled_requests_for_operations: typing.Optional[list[models.aws_dynamodb.TableV2DefMetricThrottledRequestsForOperationsParams]] = pydantic.Field(None, description='How many requests are throttled on this table. This will sum errors across all possible operations.\nBy default, each individual metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    metric_user_errors: typing.Optional[list[models.aws_dynamodb.TableV2DefMetricUserErrorsParams]] = pydantic.Field(None, description='Metric for the user errors for this table.\nNote: This metric reports user errors across all the tables in the account and region the table\nresides in.\n\nBy default, the metric will be calculated as a sum over a period of 5 minutes.\nYou can customize this by using the ``statistic`` and ``period`` properties.')
    replica: typing.Optional[list[models.aws_dynamodb.TableV2DefReplicaParams]] = pydantic.Field(None, description='Retrieve a replica table.\nNote: Replica tables are not supported in a region agnostic stack.')

class TableV2DefAddGlobalSecondaryIndexParams(pydantic.BaseModel):
    partition_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(..., description='Partition key attribute definition.\n')
    read_capacity: typing.Optional[models.aws_dynamodb.CapacityDef] = pydantic.Field(None, description='The read capacity. Note: This can only be configured if the primary table billing is provisioned. Default: - inherited from the primary table.\n')
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Sort key attribute definition. Default: - no sort key\n')
    write_capacity: typing.Optional[models.aws_dynamodb.CapacityDef] = pydantic.Field(None, description='The write capacity. Note: This can only be configured if the primary table billing is provisioned. Default: - inherited from the primary table.\n')
    index_name: str = pydantic.Field(..., description='The name of the secondary index.\n')
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The non-key attributes that are projected into the secondary index. Default: - No additional attributes\n')
    projection_type: typing.Optional[aws_cdk.aws_dynamodb.ProjectionType] = pydantic.Field(None, description='The set of attributes that are projected into the secondary index. Default: ALL')
    ...

class TableV2DefAddLocalSecondaryIndexParams(pydantic.BaseModel):
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(..., description='The attribute of a sort key for the local secondary index.\n')
    index_name: str = pydantic.Field(..., description='The name of the secondary index.\n')
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The non-key attributes that are projected into the secondary index. Default: - No additional attributes\n')
    projection_type: typing.Optional[aws_cdk.aws_dynamodb.ProjectionType] = pydantic.Field(None, description='The set of attributes that are projected into the secondary index. Default: ALL')
    ...

class TableV2DefAddReplicaParams(pydantic.BaseModel):
    region: str = pydantic.Field(..., description='The region that the replica table will be created in.\n')
    global_secondary_index_options: typing.Optional[typing.Mapping[str, typing.Union[models.aws_dynamodb.ReplicaGlobalSecondaryIndexOptionsDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Options used to configure global secondary index properties. Default: - inherited from the primary table\n')
    read_capacity: typing.Optional[models.aws_dynamodb.CapacityDef] = pydantic.Field(None, description='The read capacity. Note: This can only be configured if the primary table billing is provisioned. Default: - inherited from the primary table\n')
    contributor_insights: typing.Optional[bool] = pydantic.Field(None, description='Whether CloudWatch contributor insights is enabled. Default: false\n')
    deletion_protection: typing.Optional[bool] = pydantic.Field(None, description='Whether deletion protection is enabled. Default: false\n')
    kinesis_stream: typing.Optional[typing.Union[models.aws_kinesis.StreamDef]] = pydantic.Field(None, description='Kinesis Data Stream to capture item level changes. Default: - no Kinesis Data Stream\n')
    point_in_time_recovery: typing.Optional[bool] = pydantic.Field(None, description='Whether point-in-time recovery is enabled. Default: false\n')
    table_class: typing.Optional[aws_cdk.aws_dynamodb.TableClass] = pydantic.Field(None, description='The table class. Default: TableClass.STANDARD\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Tags to be applied to the table or replica table. Default: - no tags')
    ...

class TableV2DefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class TableV2DefFromTableArnParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='the parent creating construct (usually ``this``).\n')
    id: str = pydantic.Field(..., description="the construct's name.\n")
    table_arn: str = pydantic.Field(..., description="the table's ARN.")
    ...

class TableV2DefFromTableAttributesParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='the parent creating construct (usually ``this``).\n')
    id: str = pydantic.Field(..., description="the construct's name.\n")
    encryption_key: typing.Optional[typing.Union[models.aws_kms.KeyDef]] = pydantic.Field(None, description='KMS encryption key for the table. Default: - no KMS encryption key\n')
    global_indexes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The name of the global indexes set for the table. Note: You must set either this property or ``localIndexes`` if you want permissions to be granted for indexes as well as the table itself. Default: - no global indexes\n')
    grant_index_permissions: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to grant permissions for all indexes of the table. Note: If false, permissions will only be granted to indexes when ``globalIndexes`` or ``localIndexes`` is specified. Default: false\n')
    local_indexes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The name of the local indexes set for the table. Note: You must set either this property or ``globalIndexes`` if you want permissions to be granted for indexes as well as the table itself. Default: - no local indexes\n')
    table_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the table. Note: You must specify this or the ``tableName``. Default: - table arn generated using ``tableName`` and region of stack\n')
    table_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the table. Default: - no table id\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description='The name of the table. Note: You must specify this or the ``tableArn``. Default: - table name retrieved from provided ``tableArn``\n')
    table_stream_arn: typing.Optional[str] = pydantic.Field(None, description='The stream ARN of the table. Default: - no table stream ARN')
    ...

class TableV2DefFromTableNameParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='the parent creating construct (usually ``this``).\n')
    id: str = pydantic.Field(..., description="the construct's name.\n")
    table_name: str = pydantic.Field(..., description="the table's name.")
    ...

class TableV2DefGrantParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal (no-op if undefined).\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefGrantFullAccessParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefGrantReadDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefGrantReadWriteDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefGrantStreamParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal (no-op if undefined).\n')
    actions: list[str] = pydantic.Field(...)
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefGrantStreamReadParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefGrantTableListStreamsParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefGrantWriteDataParams(pydantic.BaseModel):
    grantee: models.AnyResource = pydantic.Field(..., description='the principal to grant access to.')
    return_config: typing.Optional[list[models.aws_iam.GrantDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefMetricParams(pydantic.BaseModel):
    metric_name: str = pydantic.Field(..., description='-\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefMetricConditionalCheckFailedRequestsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefMetricConsumedReadCapacityUnitsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefMetricConsumedWriteCapacityUnitsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefMetricSuccessfulRequestLatencyParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefMetricSystemErrorsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:deprecated: use ``metricSystemErrorsForOperations``.\n\n:stability: deprecated\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefMetricSystemErrorsForOperationsParams(pydantic.BaseModel):
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    ...

class TableV2DefMetricThrottledRequestsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n\n:deprecated: Do not use this function. It returns an invalid metric. Use ``metricThrottledRequestsForOperation`` instead.\n\n:stability: deprecated\n')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefMetricThrottledRequestsForOperationParams(pydantic.BaseModel):
    operation: str = pydantic.Field(..., description='-\n')
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    ...

class TableV2DefMetricThrottledRequestsForOperationsParams(pydantic.BaseModel):
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n')
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    ...

class TableV2DefMetricUserErrorsParams(pydantic.BaseModel):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream')
    return_config: typing.Optional[list[models.aws_cloudwatch.MetricDefConfig]] = pydantic.Field(None)
    ...

class TableV2DefReplicaParams(pydantic.BaseModel):
    region: str = pydantic.Field(..., description='the region of the replica table.')
    return_config: typing.Optional[list[models._interface_methods.AwsDynamodbITableV2DefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_dynamodb.Attribute
class AttributeDef(BaseStruct):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of an attribute.\n')
    type: typing.Union[aws_cdk.aws_dynamodb.AttributeType, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The data type of an attribute.\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk as cdk\n\n\n    app = cdk.App()\n    stack = cdk.Stack(app, "Stack", env=cdk.Environment(region="us-west-2"))\n\n    global_table = dynamodb.TableV2(stack, "GlobalTable",\n        partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING),\n        # applys to all replicas, i.e., us-west-2, us-east-1, us-east-2\n        removal_policy=cdk.RemovalPolicy.DESTROY,\n        replicas=[dynamodb.ReplicaTableProps(region="us-east-1"), dynamodb.ReplicaTableProps(region="us-east-2")\n        ]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.Attribute'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.AutoscaledCapacityOptions
class AutoscaledCapacityOptionsDef(BaseStruct):
    max_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The maximum allowable capacity.\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum allowable capacity. Default: 1\n')
    seed_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="If you want to switch a table's billing mode from on-demand to provisioned or from provisioned to on-demand, you must specify a value for this property for each autoscaled resource. Default: no seed capacity\n")
    target_utilization_percent: typing.Union[int, float, None] = pydantic.Field(None, description='The ratio of consumed capacity units to provisioned capacity units. Note: Target utilization percent cannot be less than 20 and cannot be greater than 90. Default: 70\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk as cdk\n\n\n    app = cdk.App()\n    stack = cdk.Stack(app, "Stack", env=cdk.Environment(region="us-west-2"))\n\n    global_table = dynamodb.TableV2(stack, "GlobalTable",\n        partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING),\n        billing=dynamodb.Billing.provisioned(\n            read_capacity=dynamodb.Capacity.fixed(10),\n            write_capacity=dynamodb.Capacity.autoscaled(max_capacity=15)\n        ),\n        replicas=[dynamodb.ReplicaTableProps(\n            region="us-east-1"\n        ), dynamodb.ReplicaTableProps(\n            region="us-east-2",\n            read_capacity=dynamodb.Capacity.autoscaled(max_capacity=20, target_utilization_percent=50)\n        )\n        ]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_capacity', 'min_capacity', 'seed_capacity', 'target_utilization_percent']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.AutoscaledCapacityOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.AttributeDefinitionProperty
class CfnGlobalTable_AttributeDefinitionPropertyDef(BaseStruct):
    attribute_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A name for the attribute.\n')
    attribute_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The data type for the attribute, where:. - ``S`` - the attribute is of type String - ``N`` - the attribute is of type Number - ``B`` - the attribute is of type Binary\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-attributedefinition.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    attribute_definition_property = dynamodb.CfnGlobalTable.AttributeDefinitionProperty(\n        attribute_name="attributeName",\n        attribute_type="attributeType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['attribute_name', 'attribute_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.AttributeDefinitionProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty
class CfnGlobalTable_CapacityAutoScalingSettingsPropertyDef(BaseStruct):
    max_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The maximum provisioned capacity units for the global table.\n')
    min_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The minimum provisioned capacity units for the global table.\n')
    target_tracking_scaling_policy_configuration: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_TargetTrackingScalingPolicyConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Defines a target tracking scaling policy.\n')
    seed_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="When switching billing mode from ``PAY_PER_REQUEST`` to ``PROVISIONED`` , DynamoDB requires you to specify read and write capacity unit values for the table and for each global secondary index. These values will be applied to all replicas. The table will use these provisioned values until CloudFormation creates the autoscaling policies you configured in your template. CloudFormation cannot determine what capacity the table and its global secondary indexes will require in this time period, since they are application-dependent. If you want to switch a table's billing mode from ``PAY_PER_REQUEST`` to ``PROVISIONED`` , you must specify a value for this property for each autoscaled resource. If you specify different values for the same resource in different regions, CloudFormation will use the highest value found in either the ``SeedCapacity`` or ``ReadCapacityUnits`` properties. For example, if your global secondary index ``myGSI`` has a ``SeedCapacity`` of 10 in us-east-1 and a fixed ``ReadCapacityUnits`` of 20 in eu-west-1, CloudFormation will initially set the read capacity for ``myGSI`` to 20. Note that if you disable ``ScaleIn`` for ``myGSI`` in us-east-1, its read capacity units might not be set back to 10. You must also specify a value for ``SeedCapacity`` when you plan to switch a table's billing mode from ``PROVISIONED`` to ``PAY_PER_REQUEST`` , because CloudFormation might need to roll back the operation (reverting the billing mode to ``PROVISIONED`` ) and this cannot succeed without specifying a value for ``SeedCapacity`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-capacityautoscalingsettings.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    capacity_auto_scaling_settings_property = dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty(\n        max_capacity=123,\n        min_capacity=123,\n        target_tracking_scaling_policy_configuration=dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n            target_value=123,\n\n            # the properties below are optional\n            disable_scale_in=False,\n            scale_in_cooldown=123,\n            scale_out_cooldown=123\n        ),\n\n        # the properties below are optional\n        seed_capacity=123\n    )\n")
    _init_params: typing.ClassVar[list[str]] = ['max_capacity', 'min_capacity', 'target_tracking_scaling_policy_configuration', 'seed_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.ContributorInsightsSpecificationProperty
class CfnGlobalTable_ContributorInsightsSpecificationPropertyDef(BaseStruct):
    enabled: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Indicates whether CloudWatch Contributor Insights are to be enabled (true) or disabled (false).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-contributorinsightsspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    contributor_insights_specification_property = dynamodb.CfnGlobalTable.ContributorInsightsSpecificationProperty(\n        enabled=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['enabled']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.ContributorInsightsSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.GlobalSecondaryIndexProperty
class CfnGlobalTable_GlobalSecondaryIndexPropertyDef(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the global secondary index. The name must be unique among all other indexes on this table.\n')
    key_schema: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The complete key schema for a global secondary index, which consists of one or more pairs of attribute names and key types: - ``HASH`` - partition key - ``RANGE`` - sort key > The partition key of an item is also known as its *hash attribute* . The term "hash attribute" derives from DynamoDB\'s usage of an internal hash function to evenly distribute data items across partitions, based on their partition key values. .. epigraph:: The sort key of an item is also known as its *range attribute* . The term "range attribute" derives from the way DynamoDB stores items with the same partition key physically close together, in sorted order by the sort key value.\n')
    projection: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ProjectionPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Represents attributes that are copied (projected) from the table into the global secondary index. These are in addition to the primary key attributes and index key attributes, which are automatically projected.\n')
    write_provisioned_throughput_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_WriteProvisionedThroughputSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines write capacity settings for the global secondary index. You must specify a value for this property if the table\'s ``BillingMode`` is ``PROVISIONED`` . All replicas will have the same write capacity settings for this global secondary index.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-globalsecondaryindex.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    global_secondary_index_property = dynamodb.CfnGlobalTable.GlobalSecondaryIndexProperty(\n        index_name="indexName",\n        key_schema=[dynamodb.CfnGlobalTable.KeySchemaProperty(\n            attribute_name="attributeName",\n            key_type="keyType"\n        )],\n        projection=dynamodb.CfnGlobalTable.ProjectionProperty(\n            non_key_attributes=["nonKeyAttributes"],\n            projection_type="projectionType"\n        ),\n\n        # the properties below are optional\n        write_provisioned_throughput_settings=dynamodb.CfnGlobalTable.WriteProvisionedThroughputSettingsProperty(\n            write_capacity_auto_scaling_settings=dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty(\n                max_capacity=123,\n                min_capacity=123,\n                target_tracking_scaling_policy_configuration=dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n                    target_value=123,\n\n                    # the properties below are optional\n                    disable_scale_in=False,\n                    scale_in_cooldown=123,\n                    scale_out_cooldown=123\n                ),\n\n                # the properties below are optional\n                seed_capacity=123\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'key_schema', 'projection', 'write_provisioned_throughput_settings']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.GlobalSecondaryIndexProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.KeySchemaProperty
class CfnGlobalTable_KeySchemaPropertyDef(BaseStruct):
    attribute_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of a key attribute.\n')
    key_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The role that this key attribute will assume:. - ``HASH`` - partition key - ``RANGE`` - sort key .. epigraph:: The partition key of an item is also known as its *hash attribute* . The term "hash attribute" derives from DynamoDB\'s usage of an internal hash function to evenly distribute data items across partitions, based on their partition key values. The sort key of an item is also known as its *range attribute* . The term "range attribute" derives from the way DynamoDB stores items with the same partition key physically close together, in sorted order by the sort key value.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-keyschema.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    key_schema_property = dynamodb.CfnGlobalTable.KeySchemaProperty(\n        attribute_name="attributeName",\n        key_type="keyType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['attribute_name', 'key_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.KeySchemaProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.KinesisStreamSpecificationProperty
class CfnGlobalTable_KinesisStreamSpecificationPropertyDef(BaseStruct):
    stream_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN for a specific Kinesis data stream.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-kinesisstreamspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    kinesis_stream_specification_property = dynamodb.CfnGlobalTable.KinesisStreamSpecificationProperty(\n        stream_arn="streamArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['stream_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.KinesisStreamSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.LocalSecondaryIndexProperty
class CfnGlobalTable_LocalSecondaryIndexPropertyDef(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the local secondary index. The name must be unique among all other indexes on this table.\n')
    key_schema: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The complete key schema for the local secondary index, consisting of one or more pairs of attribute names and key types: - ``HASH`` - partition key - ``RANGE`` - sort key > The partition key of an item is also known as its *hash attribute* . The term "hash attribute" derives from DynamoDB\'s usage of an internal hash function to evenly distribute data items across partitions, based on their partition key values. .. epigraph:: The sort key of an item is also known as its *range attribute* . The term "range attribute" derives from the way DynamoDB stores items with the same partition key physically close together, in sorted order by the sort key value.\n')
    projection: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ProjectionPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Represents attributes that are copied (projected) from the table into the local secondary index. These are in addition to the primary key attributes and index key attributes, which are automatically projected.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-localsecondaryindex.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    local_secondary_index_property = dynamodb.CfnGlobalTable.LocalSecondaryIndexProperty(\n        index_name="indexName",\n        key_schema=[dynamodb.CfnGlobalTable.KeySchemaProperty(\n            attribute_name="attributeName",\n            key_type="keyType"\n        )],\n        projection=dynamodb.CfnGlobalTable.ProjectionProperty(\n            non_key_attributes=["nonKeyAttributes"],\n            projection_type="projectionType"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'key_schema', 'projection']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.LocalSecondaryIndexProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.PointInTimeRecoverySpecificationProperty
class CfnGlobalTable_PointInTimeRecoverySpecificationPropertyDef(BaseStruct):
    point_in_time_recovery_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether point in time recovery is enabled (true) or disabled (false) on the table.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-pointintimerecoveryspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    point_in_time_recovery_specification_property = dynamodb.CfnGlobalTable.PointInTimeRecoverySpecificationProperty(\n        point_in_time_recovery_enabled=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['point_in_time_recovery_enabled']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.PointInTimeRecoverySpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.ProjectionProperty
class CfnGlobalTable_ProjectionPropertyDef(BaseStruct):
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Represents the non-key attribute names which will be projected into the index. For local secondary indexes, the total count of ``NonKeyAttributes`` summed across all of the local secondary indexes, must not exceed 100. If you project the same attribute into two different indexes, this counts as two distinct attributes when determining the total.\n')
    projection_type: typing.Optional[str] = pydantic.Field(None, description='The set of attributes that are projected into the index:. - ``KEYS_ONLY`` - Only the index and primary keys are projected into the index. - ``INCLUDE`` - In addition to the attributes described in ``KEYS_ONLY`` , the secondary index will include other non-key attributes that you specify. - ``ALL`` - All of the table attributes are projected into the index.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-projection.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    projection_property = dynamodb.CfnGlobalTable.ProjectionProperty(\n        non_key_attributes=["nonKeyAttributes"],\n        projection_type="projectionType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['non_key_attributes', 'projection_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.ProjectionProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.ReadProvisionedThroughputSettingsProperty
class CfnGlobalTable_ReadProvisionedThroughputSettingsPropertyDef(BaseStruct):
    read_capacity_auto_scaling_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_CapacityAutoScalingSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies auto scaling settings for the replica table or global secondary index.\n')
    read_capacity_units: typing.Union[int, float, None] = pydantic.Field(None, description='Specifies a fixed read capacity for the replica table or global secondary index.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-readprovisionedthroughputsettings.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    read_provisioned_throughput_settings_property = dynamodb.CfnGlobalTable.ReadProvisionedThroughputSettingsProperty(\n        read_capacity_auto_scaling_settings=dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty(\n            max_capacity=123,\n            min_capacity=123,\n            target_tracking_scaling_policy_configuration=dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n                target_value=123,\n\n                # the properties below are optional\n                disable_scale_in=False,\n                scale_in_cooldown=123,\n                scale_out_cooldown=123\n            ),\n\n            # the properties below are optional\n            seed_capacity=123\n        ),\n        read_capacity_units=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['read_capacity_auto_scaling_settings', 'read_capacity_units']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.ReadProvisionedThroughputSettingsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.ReplicaGlobalSecondaryIndexSpecificationProperty
class CfnGlobalTable_ReplicaGlobalSecondaryIndexSpecificationPropertyDef(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the global secondary index. The name must be unique among all other indexes on this table.\n')
    contributor_insights_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ContributorInsightsSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Updates the status for contributor insights for a specific table or index. CloudWatch Contributor Insights for DynamoDB graphs display the partition key and (if applicable) sort key of frequently accessed items and frequently throttled items in plaintext. If you require the use of AWS Key Management Service (KMS) to encrypt this table’s partition key and sort key data with an AWS managed key or customer managed key, you should not enable CloudWatch Contributor Insights for DynamoDB for this table.\n')
    read_provisioned_throughput_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ReadProvisionedThroughputSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Allows you to specify the read capacity settings for a replica global secondary index when the ``BillingMode`` is set to ``PROVISIONED`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-replicaglobalsecondaryindexspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    replica_global_secondary_index_specification_property = dynamodb.CfnGlobalTable.ReplicaGlobalSecondaryIndexSpecificationProperty(\n        index_name="indexName",\n\n        # the properties below are optional\n        contributor_insights_specification=dynamodb.CfnGlobalTable.ContributorInsightsSpecificationProperty(\n            enabled=False\n        ),\n        read_provisioned_throughput_settings=dynamodb.CfnGlobalTable.ReadProvisionedThroughputSettingsProperty(\n            read_capacity_auto_scaling_settings=dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty(\n                max_capacity=123,\n                min_capacity=123,\n                target_tracking_scaling_policy_configuration=dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n                    target_value=123,\n\n                    # the properties below are optional\n                    disable_scale_in=False,\n                    scale_in_cooldown=123,\n                    scale_out_cooldown=123\n                ),\n\n                # the properties below are optional\n                seed_capacity=123\n            ),\n            read_capacity_units=123\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'contributor_insights_specification', 'read_provisioned_throughput_settings']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.ReplicaGlobalSecondaryIndexSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.ReplicaSpecificationProperty
class CfnGlobalTable_ReplicaSpecificationPropertyDef(BaseStruct):
    region: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The region in which this replica exists.\n')
    contributor_insights_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ContributorInsightsSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The settings used to enable or disable CloudWatch Contributor Insights for the specified replica. When not specified, defaults to contributor insights disabled for the replica.\n')
    deletion_protection_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Determines if a replica is protected from deletion. When enabled, the table cannot be deleted by any user or process. This setting is disabled by default. For more information, see `Using deletion protection <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithTables.Basics.html#WorkingWithTables.Basics.DeletionProtection>`_ in the *Amazon DynamoDB Developer Guide* .\n')
    global_secondary_indexes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ReplicaGlobalSecondaryIndexSpecificationPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Defines additional settings for the global secondary indexes of this replica.\n')
    kinesis_stream_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_KinesisStreamSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines the Kinesis Data Streams configuration for the specified replica.\n')
    point_in_time_recovery_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_PointInTimeRecoverySpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The settings used to enable point in time recovery. When not specified, defaults to point in time recovery disabled for the replica.\n')
    read_provisioned_throughput_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ReadProvisionedThroughputSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Defines read capacity settings for the replica table.\n')
    sse_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ReplicaSSESpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Allows you to specify a customer-managed key for the replica. When using customer-managed keys for server-side encryption, this property must have a value in all replicas.\n')
    table_class: typing.Optional[str] = pydantic.Field(None, description='The table class of the specified table. Valid values are ``STANDARD`` and ``STANDARD_INFREQUENT_ACCESS`` .\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='An array of key-value pairs to apply to this replica. For more information, see `Tag <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-replicaspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    replica_specification_property = dynamodb.CfnGlobalTable.ReplicaSpecificationProperty(\n        region="region",\n\n        # the properties below are optional\n        contributor_insights_specification=dynamodb.CfnGlobalTable.ContributorInsightsSpecificationProperty(\n            enabled=False\n        ),\n        deletion_protection_enabled=False,\n        global_secondary_indexes=[dynamodb.CfnGlobalTable.ReplicaGlobalSecondaryIndexSpecificationProperty(\n            index_name="indexName",\n\n            # the properties below are optional\n            contributor_insights_specification=dynamodb.CfnGlobalTable.ContributorInsightsSpecificationProperty(\n                enabled=False\n            ),\n            read_provisioned_throughput_settings=dynamodb.CfnGlobalTable.ReadProvisionedThroughputSettingsProperty(\n                read_capacity_auto_scaling_settings=dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty(\n                    max_capacity=123,\n                    min_capacity=123,\n                    target_tracking_scaling_policy_configuration=dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n                        target_value=123,\n\n                        # the properties below are optional\n                        disable_scale_in=False,\n                        scale_in_cooldown=123,\n                        scale_out_cooldown=123\n                    ),\n\n                    # the properties below are optional\n                    seed_capacity=123\n                ),\n                read_capacity_units=123\n            )\n        )],\n        kinesis_stream_specification=dynamodb.CfnGlobalTable.KinesisStreamSpecificationProperty(\n            stream_arn="streamArn"\n        ),\n        point_in_time_recovery_specification=dynamodb.CfnGlobalTable.PointInTimeRecoverySpecificationProperty(\n            point_in_time_recovery_enabled=False\n        ),\n        read_provisioned_throughput_settings=dynamodb.CfnGlobalTable.ReadProvisionedThroughputSettingsProperty(\n            read_capacity_auto_scaling_settings=dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty(\n                max_capacity=123,\n                min_capacity=123,\n                target_tracking_scaling_policy_configuration=dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n                    target_value=123,\n\n                    # the properties below are optional\n                    disable_scale_in=False,\n                    scale_in_cooldown=123,\n                    scale_out_cooldown=123\n                ),\n\n                # the properties below are optional\n                seed_capacity=123\n            ),\n            read_capacity_units=123\n        ),\n        sse_specification=dynamodb.CfnGlobalTable.ReplicaSSESpecificationProperty(\n            kms_master_key_id="kmsMasterKeyId"\n        ),\n        table_class="tableClass",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['region', 'contributor_insights_specification', 'deletion_protection_enabled', 'global_secondary_indexes', 'kinesis_stream_specification', 'point_in_time_recovery_specification', 'read_provisioned_throughput_settings', 'sse_specification', 'table_class', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.ReplicaSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.ReplicaSSESpecificationProperty
class CfnGlobalTable_ReplicaSSESpecificationPropertyDef(BaseStruct):
    kms_master_key_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The AWS KMS key that should be used for the AWS KMS encryption. To specify a key, use its key ID, Amazon Resource Name (ARN), alias name, or alias ARN. Note that you should only provide this parameter if the key is different from the default DynamoDB key ``alias/aws/dynamodb`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-replicassespecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    replica_sSESpecification_property = dynamodb.CfnGlobalTable.ReplicaSSESpecificationProperty(\n        kms_master_key_id="kmsMasterKeyId"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['kms_master_key_id']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.ReplicaSSESpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.SSESpecificationProperty
class CfnGlobalTable_SSESpecificationPropertyDef(BaseStruct):
    sse_enabled: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Indicates whether server-side encryption is performed using an AWS managed key or an AWS owned key. If enabled (true), server-side encryption type is set to KMS and an AWS managed key is used ( AWS KMS charges apply). If disabled (false) or not specified,server-side encryption is set to an AWS owned key. If you choose to use KMS encryption, you can also use customer managed KMS keys by specifying them in the ``ReplicaSpecification.SSESpecification`` object. You cannot mix AWS managed and customer managed KMS keys.\n')
    sse_type: typing.Optional[str] = pydantic.Field(None, description='Server-side encryption type. The only supported value is:. - ``KMS`` - Server-side encryption that uses AWS Key Management Service . The key is stored in your account and is managed by AWS KMS ( AWS KMS charges apply).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-ssespecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    s_sESpecification_property = dynamodb.CfnGlobalTable.SSESpecificationProperty(\n        sse_enabled=False,\n\n        # the properties below are optional\n        sse_type="sseType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['sse_enabled', 'sse_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.SSESpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.StreamSpecificationProperty
class CfnGlobalTable_StreamSpecificationPropertyDef(BaseStruct):
    stream_view_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='When an item in the table is modified, ``StreamViewType`` determines what information is written to the stream for this table. Valid values for ``StreamViewType`` are: - ``KEYS_ONLY`` - Only the key attributes of the modified item are written to the stream. - ``NEW_IMAGE`` - The entire item, as it appears after it was modified, is written to the stream. - ``OLD_IMAGE`` - The entire item, as it appeared before it was modified, is written to the stream. - ``NEW_AND_OLD_IMAGES`` - Both the new and the old item images of the item are written to the stream.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-streamspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    stream_specification_property = dynamodb.CfnGlobalTable.StreamSpecificationProperty(\n        stream_view_type="streamViewType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['stream_view_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.StreamSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty
class CfnGlobalTable_TargetTrackingScalingPolicyConfigurationPropertyDef(BaseStruct):
    target_value: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='Defines a target value for the scaling policy.\n')
    disable_scale_in: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether scale in by the target tracking scaling policy is disabled. The default value is ``false`` .\n')
    scale_in_cooldown: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time, in seconds, after a scale-in activity completes before another scale-in activity can start.\n')
    scale_out_cooldown: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time, in seconds, after a scale-out activity completes before another scale-out activity can start.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-targettrackingscalingpolicyconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    target_tracking_scaling_policy_configuration_property = dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n        target_value=123,\n\n        # the properties below are optional\n        disable_scale_in=False,\n        scale_in_cooldown=123,\n        scale_out_cooldown=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['target_value', 'disable_scale_in', 'scale_in_cooldown', 'scale_out_cooldown']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.TimeToLiveSpecificationProperty
class CfnGlobalTable_TimeToLiveSpecificationPropertyDef(BaseStruct):
    enabled: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Indicates whether TTL is to be enabled (true) or disabled (false) on the table.\n')
    attribute_name: typing.Optional[str] = pydantic.Field(None, description='The name of the attribute used to store the expiration time for items in the table. Currently, you cannot directly change the attribute name used to evaluate time to live. In order to do so, you must first disable time to live, and then re-enable it with the new attribute name. It can take up to one hour for changes to time to live to take effect. If you attempt to modify time to live within that time window, your stack operation might be delayed.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-timetolivespecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    time_to_live_specification_property = dynamodb.CfnGlobalTable.TimeToLiveSpecificationProperty(\n        enabled=False,\n\n        # the properties below are optional\n        attribute_name="attributeName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['enabled', 'attribute_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.TimeToLiveSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable.WriteProvisionedThroughputSettingsProperty
class CfnGlobalTable_WriteProvisionedThroughputSettingsPropertyDef(BaseStruct):
    write_capacity_auto_scaling_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_CapacityAutoScalingSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies auto scaling settings for the replica table or global secondary index.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-globaltable-writeprovisionedthroughputsettings.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    write_provisioned_throughput_settings_property = dynamodb.CfnGlobalTable.WriteProvisionedThroughputSettingsProperty(\n        write_capacity_auto_scaling_settings=dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty(\n            max_capacity=123,\n            min_capacity=123,\n            target_tracking_scaling_policy_configuration=dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n                target_value=123,\n\n                # the properties below are optional\n                disable_scale_in=False,\n                scale_in_cooldown=123,\n                scale_out_cooldown=123\n            ),\n\n            # the properties below are optional\n            seed_capacity=123\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['write_capacity_auto_scaling_settings']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable.WriteProvisionedThroughputSettingsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.AttributeDefinitionProperty
class CfnTable_AttributeDefinitionPropertyDef(BaseStruct):
    attribute_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='A name for the attribute.\n')
    attribute_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The data type for the attribute, where:. - ``S`` - the attribute is of type String - ``N`` - the attribute is of type Number - ``B`` - the attribute is of type Binary\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-attributedefinition.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    attribute_definition_property = dynamodb.CfnTable.AttributeDefinitionProperty(\n        attribute_name="attributeName",\n        attribute_type="attributeType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['attribute_name', 'attribute_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.AttributeDefinitionProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.ContributorInsightsSpecificationProperty
class CfnTable_ContributorInsightsSpecificationPropertyDef(BaseStruct):
    enabled: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Indicates whether CloudWatch Contributor Insights are to be enabled (true) or disabled (false).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-contributorinsightsspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    contributor_insights_specification_property = dynamodb.CfnTable.ContributorInsightsSpecificationProperty(\n        enabled=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['enabled']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.ContributorInsightsSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.CsvProperty
class CfnTable_CsvPropertyDef(BaseStruct):
    delimiter: typing.Optional[str] = pydantic.Field(None, description='The delimiter used for separating items in the CSV file being imported.\n')
    header_list: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='List of the headers used to specify a common header for all source CSV files being imported. If this field is specified then the first line of each CSV file is treated as data instead of the header. If this field is not specified the the first line of each CSV file is treated as the header.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-csv.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    csv_property = dynamodb.CfnTable.CsvProperty(\n        delimiter="delimiter",\n        header_list=["headerList"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['delimiter', 'header_list']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.CsvProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.GlobalSecondaryIndexProperty
class CfnTable_GlobalSecondaryIndexPropertyDef(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the global secondary index. The name must be unique among all other indexes on this table.\n')
    key_schema: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The complete key schema for a global secondary index, which consists of one or more pairs of attribute names and key types: - ``HASH`` - partition key - ``RANGE`` - sort key > The partition key of an item is also known as its *hash attribute* . The term "hash attribute" derives from DynamoDB\'s usage of an internal hash function to evenly distribute data items across partitions, based on their partition key values. .. epigraph:: The sort key of an item is also known as its *range attribute* . The term "range attribute" derives from the way DynamoDB stores items with the same partition key physically close together, in sorted order by the sort key value.\n')
    projection: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_dynamodb.CfnTable_ProjectionPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Represents attributes that are copied (projected) from the table into the global secondary index. These are in addition to the primary key attributes and index key attributes, which are automatically projected.\n')
    contributor_insights_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ContributorInsightsSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The settings used to enable or disable CloudWatch Contributor Insights for the specified global secondary index.\n')
    provisioned_throughput: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ProvisionedThroughputPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Represents the provisioned throughput settings for the specified global secondary index. For current minimum and maximum provisioned throughput values, see `Service, Account, and Table Quotas <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html>`_ in the *Amazon DynamoDB Developer Guide* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-globalsecondaryindex.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    global_secondary_index_property = dynamodb.CfnTable.GlobalSecondaryIndexProperty(\n        index_name="indexName",\n        key_schema=[dynamodb.CfnTable.KeySchemaProperty(\n            attribute_name="attributeName",\n            key_type="keyType"\n        )],\n        projection=dynamodb.CfnTable.ProjectionProperty(\n            non_key_attributes=["nonKeyAttributes"],\n            projection_type="projectionType"\n        ),\n\n        # the properties below are optional\n        contributor_insights_specification=dynamodb.CfnTable.ContributorInsightsSpecificationProperty(\n            enabled=False\n        ),\n        provisioned_throughput=dynamodb.CfnTable.ProvisionedThroughputProperty(\n            read_capacity_units=123,\n            write_capacity_units=123\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'key_schema', 'projection', 'contributor_insights_specification', 'provisioned_throughput']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.GlobalSecondaryIndexProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.ImportSourceSpecificationProperty
class CfnTable_ImportSourceSpecificationPropertyDef(BaseStruct):
    input_format: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The format of the source data. Valid values for ``ImportFormat`` are ``CSV`` , ``DYNAMODB_JSON`` or ``ION`` .\n')
    s3_bucket_source: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_dynamodb.CfnTable_S3BucketSourcePropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The S3 bucket that provides the source for the import.\n')
    input_compression_type: typing.Optional[str] = pydantic.Field(None, description='Type of compression to be used on the input coming from the imported table.\n')
    input_format_options: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_InputFormatOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Additional properties that specify how the input is formatted,.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-importsourcespecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    import_source_specification_property = dynamodb.CfnTable.ImportSourceSpecificationProperty(\n        input_format="inputFormat",\n        s3_bucket_source=dynamodb.CfnTable.S3BucketSourceProperty(\n            s3_bucket="s3Bucket",\n\n            # the properties below are optional\n            s3_bucket_owner="s3BucketOwner",\n            s3_key_prefix="s3KeyPrefix"\n        ),\n\n        # the properties below are optional\n        input_compression_type="inputCompressionType",\n        input_format_options=dynamodb.CfnTable.InputFormatOptionsProperty(\n            csv=dynamodb.CfnTable.CsvProperty(\n                delimiter="delimiter",\n                header_list=["headerList"]\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['input_format', 's3_bucket_source', 'input_compression_type', 'input_format_options']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.ImportSourceSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.InputFormatOptionsProperty
class CfnTable_InputFormatOptionsPropertyDef(BaseStruct):
    csv: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_CsvPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The options for imported source files in CSV format. The values are Delimiter and HeaderList.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-inputformatoptions.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    input_format_options_property = dynamodb.CfnTable.InputFormatOptionsProperty(\n        csv=dynamodb.CfnTable.CsvProperty(\n            delimiter="delimiter",\n            header_list=["headerList"]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['csv']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.InputFormatOptionsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.KeySchemaProperty
class CfnTable_KeySchemaPropertyDef(BaseStruct):
    attribute_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of a key attribute.\n')
    key_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The role that this key attribute will assume:. - ``HASH`` - partition key - ``RANGE`` - sort key .. epigraph:: The partition key of an item is also known as its *hash attribute* . The term "hash attribute" derives from DynamoDB\'s usage of an internal hash function to evenly distribute data items across partitions, based on their partition key values. The sort key of an item is also known as its *range attribute* . The term "range attribute" derives from the way DynamoDB stores items with the same partition key physically close together, in sorted order by the sort key value.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-keyschema.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    key_schema_property = dynamodb.CfnTable.KeySchemaProperty(\n        attribute_name="attributeName",\n        key_type="keyType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['attribute_name', 'key_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.KeySchemaProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.KinesisStreamSpecificationProperty
class CfnTable_KinesisStreamSpecificationPropertyDef(BaseStruct):
    stream_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN for a specific Kinesis data stream. Length Constraints: Minimum length of 37. Maximum length of 1024.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-kinesisstreamspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    kinesis_stream_specification_property = dynamodb.CfnTable.KinesisStreamSpecificationProperty(\n        stream_arn="streamArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['stream_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.KinesisStreamSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.LocalSecondaryIndexProperty
class CfnTable_LocalSecondaryIndexPropertyDef(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the local secondary index. The name must be unique among all other indexes on this table.\n')
    key_schema: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The complete key schema for the local secondary index, consisting of one or more pairs of attribute names and key types: - ``HASH`` - partition key - ``RANGE`` - sort key > The partition key of an item is also known as its *hash attribute* . The term "hash attribute" derives from DynamoDB\'s usage of an internal hash function to evenly distribute data items across partitions, based on their partition key values. .. epigraph:: The sort key of an item is also known as its *range attribute* . The term "range attribute" derives from the way DynamoDB stores items with the same partition key physically close together, in sorted order by the sort key value.\n')
    projection: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_dynamodb.CfnTable_ProjectionPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Represents attributes that are copied (projected) from the table into the local secondary index. These are in addition to the primary key attributes and index key attributes, which are automatically projected.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-localsecondaryindex.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    local_secondary_index_property = dynamodb.CfnTable.LocalSecondaryIndexProperty(\n        index_name="indexName",\n        key_schema=[dynamodb.CfnTable.KeySchemaProperty(\n            attribute_name="attributeName",\n            key_type="keyType"\n        )],\n        projection=dynamodb.CfnTable.ProjectionProperty(\n            non_key_attributes=["nonKeyAttributes"],\n            projection_type="projectionType"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'key_schema', 'projection']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.LocalSecondaryIndexProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.PointInTimeRecoverySpecificationProperty
class CfnTable_PointInTimeRecoverySpecificationPropertyDef(BaseStruct):
    point_in_time_recovery_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Indicates whether point in time recovery is enabled (true) or disabled (false) on the table.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-pointintimerecoveryspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    point_in_time_recovery_specification_property = dynamodb.CfnTable.PointInTimeRecoverySpecificationProperty(\n        point_in_time_recovery_enabled=False\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['point_in_time_recovery_enabled']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.PointInTimeRecoverySpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.ProjectionProperty
class CfnTable_ProjectionPropertyDef(BaseStruct):
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Represents the non-key attribute names which will be projected into the index. For local secondary indexes, the total count of ``NonKeyAttributes`` summed across all of the local secondary indexes, must not exceed 100. If you project the same attribute into two different indexes, this counts as two distinct attributes when determining the total.\n')
    projection_type: typing.Optional[str] = pydantic.Field(None, description='The set of attributes that are projected into the index:. - ``KEYS_ONLY`` - Only the index and primary keys are projected into the index. - ``INCLUDE`` - In addition to the attributes described in ``KEYS_ONLY`` , the secondary index will include other non-key attributes that you specify. - ``ALL`` - All of the table attributes are projected into the index.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-projection.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    projection_property = dynamodb.CfnTable.ProjectionProperty(\n        non_key_attributes=["nonKeyAttributes"],\n        projection_type="projectionType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['non_key_attributes', 'projection_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.ProjectionProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.ProvisionedThroughputProperty
class CfnTable_ProvisionedThroughputPropertyDef(BaseStruct):
    read_capacity_units: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The maximum number of strongly consistent reads consumed per second before DynamoDB returns a ``ThrottlingException`` . For more information, see `Specifying Read and Write Requirements <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ProvisionedThroughput.html>`_ in the *Amazon DynamoDB Developer Guide* . If read/write capacity mode is ``PAY_PER_REQUEST`` the value is set to 0.\n')
    write_capacity_units: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The maximum number of writes consumed per second before DynamoDB returns a ``ThrottlingException`` . For more information, see `Specifying Read and Write Requirements <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ProvisionedThroughput.html>`_ in the *Amazon DynamoDB Developer Guide* . If read/write capacity mode is ``PAY_PER_REQUEST`` the value is set to 0.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-provisionedthroughput.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    provisioned_throughput_property = dynamodb.CfnTable.ProvisionedThroughputProperty(\n        read_capacity_units=123,\n        write_capacity_units=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['read_capacity_units', 'write_capacity_units']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.ProvisionedThroughputProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.S3BucketSourceProperty
class CfnTable_S3BucketSourcePropertyDef(BaseStruct):
    s3_bucket: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The S3 bucket that is being imported from.\n')
    s3_bucket_owner: typing.Optional[str] = pydantic.Field(None, description='The account number of the S3 bucket that is being imported from. If the bucket is owned by the requester this is optional.\n')
    s3_key_prefix: typing.Optional[str] = pydantic.Field(None, description='The key prefix shared by all S3 Objects that are being imported.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-s3bucketsource.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    s3_bucket_source_property = dynamodb.CfnTable.S3BucketSourceProperty(\n        s3_bucket="s3Bucket",\n\n        # the properties below are optional\n        s3_bucket_owner="s3BucketOwner",\n        s3_key_prefix="s3KeyPrefix"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['s3_bucket', 's3_bucket_owner', 's3_key_prefix']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.S3BucketSourceProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.SSESpecificationProperty
class CfnTable_SSESpecificationPropertyDef(BaseStruct):
    sse_enabled: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Indicates whether server-side encryption is done using an AWS managed key or an AWS owned key. If enabled (true), server-side encryption type is set to ``KMS`` and an AWS managed key is used ( AWS KMS charges apply). If disabled (false) or not specified, server-side encryption is set to AWS owned key.\n')
    kms_master_key_id: typing.Optional[str] = pydantic.Field(None, description='The AWS KMS key that should be used for the AWS KMS encryption. To specify a key, use its key ID, Amazon Resource Name (ARN), alias name, or alias ARN. Note that you should only provide this parameter if the key is different from the default DynamoDB key ``alias/aws/dynamodb`` .\n')
    sse_type: typing.Optional[str] = pydantic.Field(None, description='Server-side encryption type. The only supported value is:. - ``KMS`` - Server-side encryption that uses AWS Key Management Service . The key is stored in your account and is managed by AWS KMS ( AWS KMS charges apply).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-ssespecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    s_sESpecification_property = dynamodb.CfnTable.SSESpecificationProperty(\n        sse_enabled=False,\n\n        # the properties below are optional\n        kms_master_key_id="kmsMasterKeyId",\n        sse_type="sseType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['sse_enabled', 'kms_master_key_id', 'sse_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.SSESpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.StreamSpecificationProperty
class CfnTable_StreamSpecificationPropertyDef(BaseStruct):
    stream_view_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='When an item in the table is modified, ``StreamViewType`` determines what information is written to the stream for this table. Valid values for ``StreamViewType`` are: - ``KEYS_ONLY`` - Only the key attributes of the modified item are written to the stream. - ``NEW_IMAGE`` - The entire item, as it appears after it was modified, is written to the stream. - ``OLD_IMAGE`` - The entire item, as it appeared before it was modified, is written to the stream. - ``NEW_AND_OLD_IMAGES`` - Both the new and the old item images of the item are written to the stream.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-streamspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    stream_specification_property = dynamodb.CfnTable.StreamSpecificationProperty(\n        stream_view_type="streamViewType"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['stream_view_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.StreamSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTable.TimeToLiveSpecificationProperty
class CfnTable_TimeToLiveSpecificationPropertyDef(BaseStruct):
    enabled: typing.Union[_REQUIRED_INIT_PARAM, bool, models.UnsupportedResource] = pydantic.Field(REQUIRED_INIT_PARAM, description='Indicates whether TTL is to be enabled (true) or disabled (false) on the table.\n')
    attribute_name: typing.Optional[str] = pydantic.Field(None, description='The name of the TTL attribute used to store the expiration time for items in the table. .. epigraph:: - The ``AttributeName`` property is required when enabling the TTL, or when TTL is already enabled. - To update this property, you must first disable TTL and then enable TTL with the new attribute name.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-timetolivespecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    time_to_live_specification_property = dynamodb.CfnTable.TimeToLiveSpecificationProperty(\n        enabled=False,\n\n        # the properties below are optional\n        attribute_name="attributeName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['enabled', 'attribute_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable.TimeToLiveSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.EnableScalingProps
class EnableScalingPropsDef(BaseStruct):
    max_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='Maximum capacity to scale to.\n')
    min_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='Minimum capacity to scale to.\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_dynamodb as dynamodb\n\n    # table: dynamodb.Table\n\n\n    read_capacity = table.auto_scale_read_capacity(\n        min_capacity=10,\n        max_capacity=1000\n    )\n    read_capacity.scale_on_utilization(\n        target_utilization_percent=60\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_capacity', 'min_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.EnableScalingProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.GlobalSecondaryIndexProps
class GlobalSecondaryIndexPropsDef(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the secondary index.\n')
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The non-key attributes that are projected into the secondary index. Default: - No additional attributes\n')
    projection_type: typing.Optional[aws_cdk.aws_dynamodb.ProjectionType] = pydantic.Field(None, description='The set of attributes that are projected into the secondary index. Default: ALL\n')
    partition_key: typing.Union[_REQUIRED_INIT_PARAM, models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Partition key attribute definition.\n')
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Sort key attribute definition. Default: no sort key\n')
    read_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The read capacity for the global secondary index. Can only be provided if table billingMode is Provisioned or undefined. Default: 5\n')
    write_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The write capacity for the global secondary index. Can only be provided if table billingMode is Provisioned or undefined. Default: 5\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    global_secondary_index_props = dynamodb.GlobalSecondaryIndexProps(\n        index_name="indexName",\n        partition_key=dynamodb.Attribute(\n            name="name",\n            type=dynamodb.AttributeType.BINARY\n        ),\n\n        # the properties below are optional\n        non_key_attributes=["nonKeyAttributes"],\n        projection_type=dynamodb.ProjectionType.KEYS_ONLY,\n        read_capacity=123,\n        sort_key=dynamodb.Attribute(\n            name="name",\n            type=dynamodb.AttributeType.BINARY\n        ),\n        write_capacity=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'non_key_attributes', 'projection_type', 'partition_key', 'sort_key', 'read_capacity', 'write_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.GlobalSecondaryIndexProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.GlobalSecondaryIndexPropsV2
class GlobalSecondaryIndexPropsV2Def(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the secondary index.\n')
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The non-key attributes that are projected into the secondary index. Default: - No additional attributes\n')
    projection_type: typing.Optional[aws_cdk.aws_dynamodb.ProjectionType] = pydantic.Field(None, description='The set of attributes that are projected into the secondary index. Default: ALL\n')
    partition_key: typing.Union[_REQUIRED_INIT_PARAM, models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Partition key attribute definition.\n')
    read_capacity: typing.Optional[models.aws_dynamodb.CapacityDef] = pydantic.Field(None, description='The read capacity. Note: This can only be configured if the primary table billing is provisioned. Default: - inherited from the primary table.\n')
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Sort key attribute definition. Default: - no sort key\n')
    write_capacity: typing.Optional[models.aws_dynamodb.CapacityDef] = pydantic.Field(None, description='The write capacity. Note: This can only be configured if the primary table billing is provisioned. Default: - inherited from the primary table.\n\n:exampleMetadata: infused\n\nExample::\n\n    table = dynamodb.TableV2(self, "Table",\n        partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING),\n        global_secondary_indexes=[dynamodb.GlobalSecondaryIndexPropsV2(\n            index_name="gsi1",\n            partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING)\n        )\n        ]\n    )\n\n    table.add_global_secondary_index(\n        index_name="gsi2",\n        partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'non_key_attributes', 'projection_type', 'partition_key', 'read_capacity', 'sort_key', 'write_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.GlobalSecondaryIndexPropsV2'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.LocalSecondaryIndexProps
class LocalSecondaryIndexPropsDef(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the secondary index.\n')
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The non-key attributes that are projected into the secondary index. Default: - No additional attributes\n')
    projection_type: typing.Optional[aws_cdk.aws_dynamodb.ProjectionType] = pydantic.Field(None, description='The set of attributes that are projected into the secondary index. Default: ALL\n')
    sort_key: typing.Union[_REQUIRED_INIT_PARAM, models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='The attribute of a sort key for the local secondary index.\n\n:exampleMetadata: infused\n\nExample::\n\n    table = dynamodb.TableV2(self, "Table",\n        partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING),\n        sort_key=dynamodb.Attribute(name="sk", type=dynamodb.AttributeType.NUMBER),\n        local_secondary_indexes=[dynamodb.LocalSecondaryIndexProps(\n            index_name="lsi1",\n            sort_key=dynamodb.Attribute(name="sk", type=dynamodb.AttributeType.NUMBER)\n        )\n        ]\n    )\n\n    table.add_local_secondary_index(\n        index_name="lsi2",\n        sort_key=dynamodb.Attribute(name="sk", type=dynamodb.AttributeType.NUMBER)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'non_key_attributes', 'projection_type', 'sort_key']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.LocalSecondaryIndexProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.OperationsMetricOptions
class OperationsMetricOptionsDef(BaseStruct):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n')
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_cloudwatch as cloudwatch\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    operations_metric_options = dynamodb.OperationsMetricOptions(\n        account="account",\n        color="color",\n        dimensions_map={\n            "dimensions_map_key": "dimensionsMap"\n        },\n        label="label",\n        operations=[dynamodb.Operation.GET_ITEM],\n        period=cdk.Duration.minutes(30),\n        region="region",\n        statistic="statistic",\n        unit=cloudwatch.Unit.SECONDS\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['account', 'color', 'dimensions_map', 'label', 'period', 'region', 'statistic', 'unit', 'operations']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.OperationsMetricOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.ReplicaGlobalSecondaryIndexOptions
class ReplicaGlobalSecondaryIndexOptionsDef(BaseStruct):
    contributor_insights: typing.Optional[bool] = pydantic.Field(None, description='Whether CloudWatch contributor insights is enabled for a specific global secondary index on a replica table. Default: - inherited from the primary table\n')
    read_capacity: typing.Optional[models.aws_dynamodb.CapacityDef] = pydantic.Field(None, description='The read capacity for a specific global secondary index on a replica table. Note: This can only be configured if primary table billing is provisioned. Default: - inherited from the primary table\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk as cdk\n\n\n    app = cdk.App()\n    stack = cdk.Stack(app, "Stack", env=cdk.Environment(region="us-west-2"))\n\n    global_table = dynamodb.TableV2(stack, "GlobalTable",\n        partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING),\n        contributor_insights=True,\n        billing=dynamodb.Billing.provisioned(\n            read_capacity=dynamodb.Capacity.fixed(10),\n            write_capacity=dynamodb.Capacity.autoscaled(max_capacity=10)\n        ),\n        # each global secondary index will inherit contributor insights as true\n        global_secondary_indexes=[dynamodb.GlobalSecondaryIndexPropsV2(\n            index_name="gsi1",\n            partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING),\n            read_capacity=dynamodb.Capacity.fixed(15)\n        ), dynamodb.GlobalSecondaryIndexPropsV2(\n            index_name="gsi2",\n            partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING),\n            write_capacity=dynamodb.Capacity.autoscaled(min_capacity=5, max_capacity=20)\n        )\n        ],\n        replicas=[dynamodb.ReplicaTableProps(\n            region="us-east-1",\n            global_secondary_index_options={\n                "gsi1": dynamodb.ReplicaGlobalSecondaryIndexOptions(\n                    read_capacity=dynamodb.Capacity.autoscaled(min_capacity=1, max_capacity=10)\n                )\n            }\n        ), dynamodb.ReplicaTableProps(\n            region="us-east-2",\n            global_secondary_index_options={\n                "gsi2": dynamodb.ReplicaGlobalSecondaryIndexOptions(\n                    contributor_insights=False\n                )\n            }\n        )\n        ]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['contributor_insights', 'read_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.ReplicaGlobalSecondaryIndexOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.ReplicaTableProps
class ReplicaTablePropsDef(BaseStruct):
    contributor_insights: typing.Optional[bool] = pydantic.Field(None, description='Whether CloudWatch contributor insights is enabled. Default: false\n')
    deletion_protection: typing.Optional[bool] = pydantic.Field(None, description='Whether deletion protection is enabled. Default: false\n')
    kinesis_stream: typing.Optional[typing.Union[models.aws_kinesis.StreamDef]] = pydantic.Field(None, description='Kinesis Data Stream to capture item level changes. Default: - no Kinesis Data Stream\n')
    point_in_time_recovery: typing.Optional[bool] = pydantic.Field(None, description='Whether point-in-time recovery is enabled. Default: false\n')
    table_class: typing.Optional[aws_cdk.aws_dynamodb.TableClass] = pydantic.Field(None, description='The table class. Default: TableClass.STANDARD\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Tags to be applied to the table or replica table. Default: - no tags\n')
    region: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The region that the replica table will be created in.\n')
    global_secondary_index_options: typing.Optional[typing.Mapping[str, typing.Union[models.aws_dynamodb.ReplicaGlobalSecondaryIndexOptionsDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Options used to configure global secondary index properties. Default: - inherited from the primary table\n')
    read_capacity: typing.Optional[models.aws_dynamodb.CapacityDef] = pydantic.Field(None, description='The read capacity. Note: This can only be configured if the primary table billing is provisioned. Default: - inherited from the primary table\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk as cdk\n\n\n    app = cdk.App()\n    stack = cdk.Stack(app, "Stack", env=cdk.Environment(region="us-west-2"))\n\n    global_table = dynamodb.TableV2(stack, "GlobalTable",\n        partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING),\n        replicas=[dynamodb.ReplicaTableProps(region="us-east-1")]\n    )\n\n    global_table.add_replica(region="us-east-2", deletion_protection=True)\n')
    _init_params: typing.ClassVar[list[str]] = ['contributor_insights', 'deletion_protection', 'kinesis_stream', 'point_in_time_recovery', 'table_class', 'tags', 'region', 'global_secondary_index_options', 'read_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.ReplicaTableProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.SchemaOptions
class SchemaOptionsDef(BaseStruct):
    partition_key: typing.Union[_REQUIRED_INIT_PARAM, models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Partition key attribute definition.\n')
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Sort key attribute definition. Default: no sort key\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    schema_options = dynamodb.SchemaOptions(\n        partition_key=dynamodb.Attribute(\n            name="name",\n            type=dynamodb.AttributeType.BINARY\n        ),\n\n        # the properties below are optional\n        sort_key=dynamodb.Attribute(\n            name="name",\n            type=dynamodb.AttributeType.BINARY\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['partition_key', 'sort_key']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.SchemaOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.SecondaryIndexProps
class SecondaryIndexPropsDef(BaseStruct):
    index_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the secondary index.\n')
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The non-key attributes that are projected into the secondary index. Default: - No additional attributes\n')
    projection_type: typing.Optional[aws_cdk.aws_dynamodb.ProjectionType] = pydantic.Field(None, description='The set of attributes that are projected into the secondary index. Default: ALL\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    secondary_index_props = dynamodb.SecondaryIndexProps(\n        index_name="indexName",\n\n        # the properties below are optional\n        non_key_attributes=["nonKeyAttributes"],\n        projection_type=dynamodb.ProjectionType.KEYS_ONLY\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['index_name', 'non_key_attributes', 'projection_type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.SecondaryIndexProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.SystemErrorsForOperationsMetricOptions
class SystemErrorsForOperationsMetricOptionsDef(BaseStruct):
    account: typing.Optional[str] = pydantic.Field(None, description='Account which this metric comes from. Default: - Deployment account.\n')
    color: typing.Optional[str] = pydantic.Field(None, description="The hex color code, prefixed with '#' (e.g. '#00ff00'), to use when this metric is rendered on a graph. The ``Color`` class has a set of standard colors that can be used here. Default: - Automatic color\n")
    dimensions_map: typing.Optional[typing.Mapping[str, str]] = pydantic.Field(None, description='Dimensions of the metric. Default: - No dimensions.\n')
    label: typing.Optional[str] = pydantic.Field(None, description="Label for this metric when added to a Graph in a Dashboard. You can use `dynamic labels <https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph-dynamic-labels.html>`_ to show summary information about the entire displayed time series in the legend. For example, if you use:: [max: ${MAX}] MyMetric As the metric label, the maximum value in the visible range will be shown next to the time series name in the graph's legend. Default: - No label\n")
    period: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The period over which the specified statistic is applied. Default: Duration.minutes(5)\n')
    region: typing.Optional[str] = pydantic.Field(None, description='Region which this metric comes from. Default: - Deployment region.\n')
    statistic: typing.Optional[str] = pydantic.Field(None, description='What function to use for aggregating. Use the ``aws_cloudwatch.Stats`` helper class to construct valid input strings. Can be one of the following: - "Minimum" | "min" - "Maximum" | "max" - "Average" | "avg" - "Sum" | "sum" - "SampleCount | "n" - "pNN.NN" - "tmNN.NN" | "tm(NN.NN%:NN.NN%)" - "iqm" - "wmNN.NN" | "wm(NN.NN%:NN.NN%)" - "tcNN.NN" | "tc(NN.NN%:NN.NN%)" - "tsNN.NN" | "ts(NN.NN%:NN.NN%)" Default: Average\n')
    unit: typing.Optional[aws_cdk.aws_cloudwatch.Unit] = pydantic.Field(None, description='Unit used to filter the metric stream. Only refer to datums emitted to the metric stream with the given unit and ignore all others. Only useful when datums are being emitted to the same metric stream under different units. The default is to use all matric datums in the stream, regardless of unit, which is recommended in nearly all cases. CloudWatch does not honor this property for graphs. Default: - All metric datums in the given metric stream\n')
    operations: typing.Optional[typing.Sequence[aws_cdk.aws_dynamodb.Operation]] = pydantic.Field(None, description='The operations to apply the metric to. Default: - All operations available by DynamoDB tables will be considered.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_cloudwatch as cloudwatch\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    system_errors_for_operations_metric_options = dynamodb.SystemErrorsForOperationsMetricOptions(\n        account="account",\n        color="color",\n        dimensions_map={\n            "dimensions_map_key": "dimensionsMap"\n        },\n        label="label",\n        operations=[dynamodb.Operation.GET_ITEM],\n        period=cdk.Duration.minutes(30),\n        region="region",\n        statistic="statistic",\n        unit=cloudwatch.Unit.SECONDS\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['account', 'color', 'dimensions_map', 'label', 'period', 'region', 'statistic', 'unit', 'operations']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.SystemErrorsForOperationsMetricOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.TableAttributes
class TableAttributesDef(BaseStruct):
    encryption_key: typing.Optional[typing.Union[models.aws_kms.KeyDef]] = pydantic.Field(None, description='KMS encryption key, if this table uses a customer-managed encryption key. Default: - no key\n')
    global_indexes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The name of the global indexes set for this Table. Note that you need to set either this property, or ``localIndexes``, if you want methods like grantReadData() to grant permissions for indexes as well as the table itself. Default: - no global indexes\n')
    grant_index_permissions: typing.Optional[bool] = pydantic.Field(None, description='If set to true, grant methods always grant permissions for all indexes. If false is provided, grant methods grant the permissions only when ``globalIndexes`` or ``localIndexes`` is specified. Default: - false\n')
    local_indexes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The name of the local indexes set for this Table. Note that you need to set either this property, or ``globalIndexes``, if you want methods like grantReadData() to grant permissions for indexes as well as the table itself. Default: - no local indexes\n')
    table_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the dynamodb table. One of this, or ``tableName``, is required. Default: - no table arn\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description='The table name of the dynamodb table. One of this, or ``tableArn``, is required. Default: - no table name\n')
    table_stream_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the table\'s stream. Default: - no table stream\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n    from aws_cdk import aws_kms as kms\n\n    # key: kms.Key\n\n    table_attributes = dynamodb.TableAttributes(\n        encryption_key=key,\n        global_indexes=["globalIndexes"],\n        grant_index_permissions=False,\n        local_indexes=["localIndexes"],\n        table_arn="tableArn",\n        table_name="tableName",\n        table_stream_arn="tableStreamArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['encryption_key', 'global_indexes', 'grant_index_permissions', 'local_indexes', 'table_arn', 'table_name', 'table_stream_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.TableAttributes'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.TableAttributesV2
class TableAttributesV2Def(BaseStruct):
    encryption_key: typing.Optional[typing.Union[models.aws_kms.KeyDef]] = pydantic.Field(None, description='KMS encryption key for the table. Default: - no KMS encryption key\n')
    global_indexes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The name of the global indexes set for the table. Note: You must set either this property or ``localIndexes`` if you want permissions to be granted for indexes as well as the table itself. Default: - no global indexes\n')
    grant_index_permissions: typing.Optional[bool] = pydantic.Field(None, description='Whether or not to grant permissions for all indexes of the table. Note: If false, permissions will only be granted to indexes when ``globalIndexes`` or ``localIndexes`` is specified. Default: false\n')
    local_indexes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The name of the local indexes set for the table. Note: You must set either this property or ``globalIndexes`` if you want permissions to be granted for indexes as well as the table itself. Default: - no local indexes\n')
    table_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the table. Note: You must specify this or the ``tableName``. Default: - table arn generated using ``tableName`` and region of stack\n')
    table_id: typing.Optional[str] = pydantic.Field(None, description='The ID of the table. Default: - no table id\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description='The name of the table. Note: You must specify this or the ``tableArn``. Default: - table name retrieved from provided ``tableArn``\n')
    table_stream_arn: typing.Optional[str] = pydantic.Field(None, description='The stream ARN of the table. Default: - no table stream ARN\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n    from aws_cdk import aws_kms as kms\n\n    # key: kms.Key\n\n    table_attributes_v2 = dynamodb.TableAttributesV2(\n        encryption_key=key,\n        global_indexes=["globalIndexes"],\n        grant_index_permissions=False,\n        local_indexes=["localIndexes"],\n        table_arn="tableArn",\n        table_id="tableId",\n        table_name="tableName",\n        table_stream_arn="tableStreamArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['encryption_key', 'global_indexes', 'grant_index_permissions', 'local_indexes', 'table_arn', 'table_id', 'table_name', 'table_stream_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.TableAttributesV2'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.TableOptions
class TableOptionsDef(BaseStruct):
    partition_key: typing.Union[_REQUIRED_INIT_PARAM, models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Partition key attribute definition.\n')
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Sort key attribute definition. Default: no sort key\n')
    billing_mode: typing.Optional[aws_cdk.aws_dynamodb.BillingMode] = pydantic.Field(None, description='Specify how you are charged for read and write throughput and how you manage capacity. Default: PROVISIONED if ``replicationRegions`` is not specified, PAY_PER_REQUEST otherwise\n')
    contributor_insights_enabled: typing.Optional[bool] = pydantic.Field(None, description='Whether CloudWatch contributor insights is enabled. Default: false\n')
    deletion_protection: typing.Optional[bool] = pydantic.Field(None, description='Enables deletion protection for the table. Default: false\n')
    encryption: typing.Optional[aws_cdk.aws_dynamodb.TableEncryption] = pydantic.Field(None, description='Whether server-side encryption with an AWS managed customer master key is enabled. This property cannot be set if ``serverSideEncryption`` is set. .. epigraph:: **NOTE**: if you set this to ``CUSTOMER_MANAGED`` and ``encryptionKey`` is not specified, the key that the Tablet generates for you will be created with default permissions. If you are using CDKv2, these permissions will be sufficient to enable the key for use with DynamoDB tables. If you are using CDKv1, make sure the feature flag ``@aws-cdk/aws-kms:defaultKeyPolicies`` is set to ``true`` in your ``cdk.json``. Default: - The table is encrypted with an encryption key managed by DynamoDB, and you are not charged any fee for using it.\n')
    encryption_key: typing.Optional[typing.Union[models.aws_kms.KeyDef]] = pydantic.Field(None, description='External KMS key to use for table encryption. This property can only be set if ``encryption`` is set to ``TableEncryption.CUSTOMER_MANAGED``. Default: - If ``encryption`` is set to ``TableEncryption.CUSTOMER_MANAGED`` and this property is undefined, a new KMS key will be created and associated with this table. If ``encryption`` and this property are both undefined, then the table is encrypted with an encryption key managed by DynamoDB, and you are not charged any fee for using it.\n')
    point_in_time_recovery: typing.Optional[bool] = pydantic.Field(None, description='Whether point-in-time recovery is enabled. Default: - point-in-time recovery is disabled\n')
    read_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="The read capacity for the table. Careful if you add Global Secondary Indexes, as those will share the table's provisioned throughput. Can only be provided if billingMode is Provisioned. Default: 5\n")
    removal_policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='The removal policy to apply to the DynamoDB Table. Default: RemovalPolicy.RETAIN\n')
    replication_regions: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Regions where replica tables will be created. Default: - no replica tables are created\n')
    replication_timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The timeout for a table replication operation in a single region. Default: Duration.minutes(30)\n')
    stream: typing.Optional[aws_cdk.aws_dynamodb.StreamViewType] = pydantic.Field(None, description='When an item in the table is modified, StreamViewType determines what information is written to the stream for this table. Default: - streams are disabled unless ``replicationRegions`` is specified\n')
    table_class: typing.Optional[aws_cdk.aws_dynamodb.TableClass] = pydantic.Field(None, description='Specify the table class. Default: STANDARD\n')
    time_to_live_attribute: typing.Optional[str] = pydantic.Field(None, description='The name of TTL attribute. Default: - TTL is disabled\n')
    wait_for_replication_to_finish: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether CloudFormation stack waits for replication to finish. If set to false, the CloudFormation resource will mark the resource as created and replication will be completed asynchronously. This property is ignored if replicationRegions property is not set. WARNING: DO NOT UNSET this property if adding/removing multiple replicationRegions in one deployment, as CloudFormation only supports one region replication at a time. CDK overcomes this limitation by waiting for replication to finish before starting new replicationRegion. If the custom resource which handles replication has a physical resource ID with the format ``region`` instead of ``tablename-region`` (this would happen if the custom resource hasn't received an event since v1.91.0), DO NOT SET this property to false without making a change to the table name. This will cause the existing replicas to be deleted. Default: true\n")
    write_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The write capacity for the table. Careful if you add Global Secondary Indexes, as those will share the table\'s provisioned throughput. Can only be provided if billingMode is Provisioned. Default: 5\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_dynamodb as dynamodb\n    from aws_cdk import aws_kms as kms\n\n    # key: kms.Key\n\n    table_options = dynamodb.TableOptions(\n        partition_key=dynamodb.Attribute(\n            name="name",\n            type=dynamodb.AttributeType.BINARY\n        ),\n\n        # the properties below are optional\n        billing_mode=dynamodb.BillingMode.PAY_PER_REQUEST,\n        contributor_insights_enabled=False,\n        deletion_protection=False,\n        encryption=dynamodb.TableEncryption.DEFAULT,\n        encryption_key=key,\n        point_in_time_recovery=False,\n        read_capacity=123,\n        removal_policy=cdk.RemovalPolicy.DESTROY,\n        replication_regions=["replicationRegions"],\n        replication_timeout=cdk.Duration.minutes(30),\n        sort_key=dynamodb.Attribute(\n            name="name",\n            type=dynamodb.AttributeType.BINARY\n        ),\n        stream=dynamodb.StreamViewType.NEW_IMAGE,\n        table_class=dynamodb.TableClass.STANDARD,\n        time_to_live_attribute="timeToLiveAttribute",\n        wait_for_replication_to_finish=False,\n        write_capacity=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['partition_key', 'sort_key', 'billing_mode', 'contributor_insights_enabled', 'deletion_protection', 'encryption', 'encryption_key', 'point_in_time_recovery', 'read_capacity', 'removal_policy', 'replication_regions', 'replication_timeout', 'stream', 'table_class', 'time_to_live_attribute', 'wait_for_replication_to_finish', 'write_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.TableOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.TableOptionsV2
class TableOptionsV2Def(BaseStruct):
    contributor_insights: typing.Optional[bool] = pydantic.Field(None, description='Whether CloudWatch contributor insights is enabled. Default: false\n')
    deletion_protection: typing.Optional[bool] = pydantic.Field(None, description='Whether deletion protection is enabled. Default: false\n')
    kinesis_stream: typing.Optional[typing.Union[models.aws_kinesis.StreamDef]] = pydantic.Field(None, description='Kinesis Data Stream to capture item level changes. Default: - no Kinesis Data Stream\n')
    point_in_time_recovery: typing.Optional[bool] = pydantic.Field(None, description='Whether point-in-time recovery is enabled. Default: false\n')
    table_class: typing.Optional[aws_cdk.aws_dynamodb.TableClass] = pydantic.Field(None, description='The table class. Default: TableClass.STANDARD\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Tags to be applied to the table or replica table. Default: - no tags\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n    from aws_cdk import aws_kinesis as kinesis\n\n    # stream: kinesis.Stream\n\n    table_options_v2 = dynamodb.TableOptionsV2(\n        contributor_insights=False,\n        deletion_protection=False,\n        kinesis_stream=stream,\n        point_in_time_recovery=False,\n        table_class=dynamodb.TableClass.STANDARD,\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['contributor_insights', 'deletion_protection', 'kinesis_stream', 'point_in_time_recovery', 'table_class', 'tags']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.TableOptionsV2'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.TableProps
class TablePropsDef(BaseStruct):
    partition_key: typing.Union[_REQUIRED_INIT_PARAM, models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Partition key attribute definition.\n')
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Sort key attribute definition. Default: no sort key\n')
    billing_mode: typing.Optional[aws_cdk.aws_dynamodb.BillingMode] = pydantic.Field(None, description='Specify how you are charged for read and write throughput and how you manage capacity. Default: PROVISIONED if ``replicationRegions`` is not specified, PAY_PER_REQUEST otherwise\n')
    contributor_insights_enabled: typing.Optional[bool] = pydantic.Field(None, description='Whether CloudWatch contributor insights is enabled. Default: false\n')
    deletion_protection: typing.Optional[bool] = pydantic.Field(None, description='Enables deletion protection for the table. Default: false\n')
    encryption: typing.Optional[aws_cdk.aws_dynamodb.TableEncryption] = pydantic.Field(None, description='Whether server-side encryption with an AWS managed customer master key is enabled. This property cannot be set if ``serverSideEncryption`` is set. .. epigraph:: **NOTE**: if you set this to ``CUSTOMER_MANAGED`` and ``encryptionKey`` is not specified, the key that the Tablet generates for you will be created with default permissions. If you are using CDKv2, these permissions will be sufficient to enable the key for use with DynamoDB tables. If you are using CDKv1, make sure the feature flag ``@aws-cdk/aws-kms:defaultKeyPolicies`` is set to ``true`` in your ``cdk.json``. Default: - The table is encrypted with an encryption key managed by DynamoDB, and you are not charged any fee for using it.\n')
    encryption_key: typing.Optional[typing.Union[models.aws_kms.KeyDef]] = pydantic.Field(None, description='External KMS key to use for table encryption. This property can only be set if ``encryption`` is set to ``TableEncryption.CUSTOMER_MANAGED``. Default: - If ``encryption`` is set to ``TableEncryption.CUSTOMER_MANAGED`` and this property is undefined, a new KMS key will be created and associated with this table. If ``encryption`` and this property are both undefined, then the table is encrypted with an encryption key managed by DynamoDB, and you are not charged any fee for using it.\n')
    point_in_time_recovery: typing.Optional[bool] = pydantic.Field(None, description='Whether point-in-time recovery is enabled. Default: - point-in-time recovery is disabled\n')
    read_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="The read capacity for the table. Careful if you add Global Secondary Indexes, as those will share the table's provisioned throughput. Can only be provided if billingMode is Provisioned. Default: 5\n")
    removal_policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='The removal policy to apply to the DynamoDB Table. Default: RemovalPolicy.RETAIN\n')
    replication_regions: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Regions where replica tables will be created. Default: - no replica tables are created\n')
    replication_timeout: typing.Optional[models.DurationDef] = pydantic.Field(None, description='The timeout for a table replication operation in a single region. Default: Duration.minutes(30)\n')
    stream: typing.Optional[aws_cdk.aws_dynamodb.StreamViewType] = pydantic.Field(None, description='When an item in the table is modified, StreamViewType determines what information is written to the stream for this table. Default: - streams are disabled unless ``replicationRegions`` is specified\n')
    table_class: typing.Optional[aws_cdk.aws_dynamodb.TableClass] = pydantic.Field(None, description='Specify the table class. Default: STANDARD\n')
    time_to_live_attribute: typing.Optional[str] = pydantic.Field(None, description='The name of TTL attribute. Default: - TTL is disabled\n')
    wait_for_replication_to_finish: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether CloudFormation stack waits for replication to finish. If set to false, the CloudFormation resource will mark the resource as created and replication will be completed asynchronously. This property is ignored if replicationRegions property is not set. WARNING: DO NOT UNSET this property if adding/removing multiple replicationRegions in one deployment, as CloudFormation only supports one region replication at a time. CDK overcomes this limitation by waiting for replication to finish before starting new replicationRegion. If the custom resource which handles replication has a physical resource ID with the format ``region`` instead of ``tablename-region`` (this would happen if the custom resource hasn't received an event since v1.91.0), DO NOT SET this property to false without making a change to the table name. This will cause the existing replicas to be deleted. Default: true\n")
    write_capacity: typing.Union[int, float, None] = pydantic.Field(None, description="The write capacity for the table. Careful if you add Global Secondary Indexes, as those will share the table's provisioned throughput. Can only be provided if billingMode is Provisioned. Default: 5\n")
    kinesis_stream: typing.Optional[typing.Union[models.aws_kinesis.StreamDef]] = pydantic.Field(None, description='Kinesis Data Stream to capture item-level changes for the table. Default: - no Kinesis Data Stream\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description='Enforces a particular physical table name. Default:\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_dynamodb as dynamodb\n\n\n    # create a table\n    table = dynamodb.Table(self, "montable",\n        partition_key=dynamodb.Attribute(\n            name="id",\n            type=dynamodb.AttributeType.STRING\n        )\n    )\n\n    final_status = sfn.Pass(self, "final step")\n\n    # States language JSON to put an item into DynamoDB\n    # snippet generated from https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-code-snippet.html#tutorial-code-snippet-1\n    state_json = {\n        "Type": "Task",\n        "Resource": "arn:aws:states:::dynamodb:putItem",\n        "Parameters": {\n            "TableName": table.table_name,\n            "Item": {\n                "id": {\n                    "S": "MyEntry"\n                }\n            }\n        },\n        "ResultPath": null\n    }\n\n    # custom state which represents a task to insert data into DynamoDB\n    custom = sfn.CustomState(self, "my custom task",\n        state_json=state_json\n    )\n\n    chain = sfn.Chain.start(custom).next(final_status)\n\n    sm = sfn.StateMachine(self, "StateMachine",\n        definition_body=sfn.DefinitionBody.from_chainable(chain),\n        timeout=Duration.seconds(30),\n        comment="a super cool state machine"\n    )\n\n    # don\'t forget permissions. You need to assign them\n    table.grant_write_data(sm)\n')
    _init_params: typing.ClassVar[list[str]] = ['partition_key', 'sort_key', 'billing_mode', 'contributor_insights_enabled', 'deletion_protection', 'encryption', 'encryption_key', 'point_in_time_recovery', 'read_capacity', 'removal_policy', 'replication_regions', 'replication_timeout', 'stream', 'table_class', 'time_to_live_attribute', 'wait_for_replication_to_finish', 'write_capacity', 'kinesis_stream', 'table_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.TableProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.TablePropsV2
class TablePropsV2Def(BaseStruct):
    contributor_insights: typing.Optional[bool] = pydantic.Field(None, description='Whether CloudWatch contributor insights is enabled. Default: false\n')
    deletion_protection: typing.Optional[bool] = pydantic.Field(None, description='Whether deletion protection is enabled. Default: false\n')
    kinesis_stream: typing.Optional[typing.Union[models.aws_kinesis.StreamDef]] = pydantic.Field(None, description='Kinesis Data Stream to capture item level changes. Default: - no Kinesis Data Stream\n')
    point_in_time_recovery: typing.Optional[bool] = pydantic.Field(None, description='Whether point-in-time recovery is enabled. Default: false\n')
    table_class: typing.Optional[aws_cdk.aws_dynamodb.TableClass] = pydantic.Field(None, description='The table class. Default: TableClass.STANDARD\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Tags to be applied to the table or replica table. Default: - no tags\n')
    partition_key: typing.Union[_REQUIRED_INIT_PARAM, models.aws_dynamodb.AttributeDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Partition key attribute definition.\n')
    billing: typing.Optional[models.aws_dynamodb.BillingDef] = pydantic.Field(None, description='The billing mode and capacity settings to apply to the table. Default: Billing.onDemand()\n')
    dynamo_stream: typing.Optional[aws_cdk.aws_dynamodb.StreamViewType] = pydantic.Field(None, description='When an item in the table is modified, StreamViewType determines what information is written to the stream. Default: - streams are disabled if replicas are not configured and this property is not specified. If this property is not specified when replicas are configured, then NEW_AND_OLD_IMAGES will be the StreamViewType for all replicas\n')
    encryption: typing.Optional[models.aws_dynamodb.TableEncryptionV2Def] = pydantic.Field(None, description='The server-side encryption. Default: TableEncryptionV2.dynamoOwnedKey()\n')
    global_secondary_indexes: typing.Optional[typing.Sequence[typing.Union[models.aws_dynamodb.GlobalSecondaryIndexPropsV2Def, dict[str, typing.Any]]]] = pydantic.Field(None, description='Global secondary indexes. Note: You can provide a maximum of 20 global secondary indexes. Default: - no global secondary indexes\n')
    local_secondary_indexes: typing.Optional[typing.Sequence[typing.Union[models.aws_dynamodb.LocalSecondaryIndexPropsDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Local secondary indexes. Note: You can only provide a maximum of 5 local secondary indexes. Default: - no local secondary indexes\n')
    removal_policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='The removal policy applied to the table. Default: RemovalPolicy.RETAIN\n')
    replicas: typing.Optional[typing.Sequence[typing.Union[models.aws_dynamodb.ReplicaTablePropsDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Replica tables to deploy with the primary table. Note: Adding replica tables allows you to use your table as a global table. You cannot specify a replica table in the region that the primary table will be deployed to. Replica tables will only be supported if the stack deployment region is defined. Default: - no replica tables\n')
    sort_key: typing.Union[models.aws_dynamodb.AttributeDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Sort key attribute definition. Default: - no sort key\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description='The name of the table. Default: - generated by CloudFormation\n')
    time_to_live_attribute: typing.Optional[str] = pydantic.Field(None, description='The name of the TTL attribute. Default: - TTL is disabled\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk as cdk\n\n\n    app = cdk.App()\n    stack = cdk.Stack(app, "Stack", env=cdk.Environment(region="us-west-2"))\n\n    global_table = dynamodb.TableV2(stack, "GlobalTable",\n        partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING),\n        # applys to all replicas, i.e., us-west-2, us-east-1, us-east-2\n        removal_policy=cdk.RemovalPolicy.DESTROY,\n        replicas=[dynamodb.ReplicaTableProps(region="us-east-1"), dynamodb.ReplicaTableProps(region="us-east-2")\n        ]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['contributor_insights', 'deletion_protection', 'kinesis_stream', 'point_in_time_recovery', 'table_class', 'tags', 'partition_key', 'billing', 'dynamo_stream', 'encryption', 'global_secondary_indexes', 'local_secondary_indexes', 'removal_policy', 'replicas', 'sort_key', 'table_name', 'time_to_live_attribute']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.TablePropsV2'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.ThroughputProps
class ThroughputPropsDef(BaseStruct):
    read_capacity: typing.Union[models.aws_dynamodb.CapacityDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The read capacity.\n')
    write_capacity: typing.Union[models.aws_dynamodb.CapacityDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The write capacity.\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk as cdk\n\n\n    app = cdk.App()\n    stack = cdk.Stack(app, "Stack", env=cdk.Environment(region="us-west-2"))\n\n    global_table = dynamodb.TableV2(stack, "GlobalTable",\n        partition_key=dynamodb.Attribute(name="pk", type=dynamodb.AttributeType.STRING),\n        billing=dynamodb.Billing.provisioned(\n            read_capacity=dynamodb.Capacity.fixed(10),\n            write_capacity=dynamodb.Capacity.autoscaled(max_capacity=15)\n        ),\n        replicas=[dynamodb.ReplicaTableProps(\n            region="us-east-1"\n        ), dynamodb.ReplicaTableProps(\n            region="us-east-2",\n            read_capacity=dynamodb.Capacity.autoscaled(max_capacity=20, target_utilization_percent=50)\n        )\n        ]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['read_capacity', 'write_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.ThroughputProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_dynamodb.ThroughputPropsDefConfig] = pydantic.Field(None)


class ThroughputPropsDefConfig(pydantic.BaseModel):
    read_capacity_config: typing.Optional[models.aws_dynamodb.CapacityDefConfig] = pydantic.Field(None)
    write_capacity_config: typing.Optional[models.aws_dynamodb.CapacityDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_dynamodb.UtilizationScalingProps
class UtilizationScalingPropsDef(BaseStruct):
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the scalable resource. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the scalable resource. Default: false\n")
    policy_name: typing.Optional[str] = pydantic.Field(None, description='A name for the scaling policy. Default: - Automatically generated name.\n')
    scale_in_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale in activity completes before another scale in activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency\n')
    scale_out_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale out activity completes before another scale out activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency\n')
    target_utilization_percent: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='Target utilization percentage for the attribute.\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_dynamodb as dynamodb\n\n    # table: dynamodb.Table\n\n\n    read_capacity = table.auto_scale_read_capacity(\n        min_capacity=10,\n        max_capacity=1000\n    )\n    read_capacity.scale_on_utilization(\n        target_utilization_percent=60\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['disable_scale_in', 'policy_name', 'scale_in_cooldown', 'scale_out_cooldown', 'target_utilization_percent']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.UtilizationScalingProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.AttributeType
# skipping emum

#  autogenerated from aws_cdk.aws_dynamodb.BillingMode
# skipping emum

#  autogenerated from aws_cdk.aws_dynamodb.CapacityMode
# skipping emum

#  autogenerated from aws_cdk.aws_dynamodb.Operation
# skipping emum

#  autogenerated from aws_cdk.aws_dynamodb.ProjectionType
# skipping emum

#  autogenerated from aws_cdk.aws_dynamodb.StreamViewType
# skipping emum

#  autogenerated from aws_cdk.aws_dynamodb.TableClass
# skipping emum

#  autogenerated from aws_cdk.aws_dynamodb.TableEncryption
# skipping emum

#  autogenerated from aws_cdk.aws_dynamodb.IScalableTableAttribute
#  skipping Interface

#  autogenerated from aws_cdk.aws_dynamodb.ITable
#  skipping Interface

#  autogenerated from aws_cdk.aws_dynamodb.ITableV2
#  skipping Interface

#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTable
class CfnGlobalTableDef(BaseCfnResource):
    attribute_definitions: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_AttributeDefinitionPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='A list of attributes that describe the key schema for the global table and indexes.\n')
    key_schema: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the attributes that make up the primary key for the table. The attributes in the ``KeySchema`` property must also be defined in the ``AttributeDefinitions`` property.\n')
    replicas: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ReplicaSpecificationPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies the list of replicas for your global table. The list must contain at least one element, the region where the stack defining the global table is deployed. For example, if you define your table in a stack deployed to us-east-1, you must have an entry in ``Replicas`` with the region us-east-1. You cannot remove the replica in the stack region. .. epigraph:: Adding a replica might take a few minutes for an empty table, or up to several hours for large tables. If you want to add or remove a replica, we recommend submitting an ``UpdateStack`` operation containing only that change. If you add or delete a replica during an update, we recommend that you don't update any other resources. If your stack fails to update and is rolled back while adding a new replica, you might need to manually delete the replica. You can create a new global table with as many replicas as needed. You can add or remove replicas after table creation, but you can only add or remove a single replica in each update.\n")
    billing_mode: typing.Optional[str] = pydantic.Field(None, description='Specifies how you are charged for read and write throughput and how you manage capacity. Valid values are:. - ``PAY_PER_REQUEST`` - ``PROVISIONED`` All replicas in your global table will have the same billing mode. If you use ``PROVISIONED`` billing mode, you must provide an auto scaling configuration via the ``WriteProvisionedThroughputSettings`` property. The default value of this property is ``PROVISIONED`` .\n')
    global_secondary_indexes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_GlobalSecondaryIndexPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Global secondary indexes to be created on the global table. You can create up to 20 global secondary indexes. Each replica in your global table will have the same global secondary index settings. You can only create or delete one global secondary index in a single stack operation. Since the backfilling of an index could take a long time, CloudFormation does not wait for the index to become active. If a stack operation rolls back, CloudFormation might not delete an index that has been added. In that case, you will need to delete the index manually.\n')
    local_secondary_indexes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_LocalSecondaryIndexPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Local secondary indexes to be created on the table. You can create up to five local secondary indexes. Each index is scoped to a given hash key value. The size of each hash key can be up to 10 gigabytes. Each replica in your global table will have the same local secondary index settings.\n')
    sse_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_SSESpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the settings to enable server-side encryption. These settings will be applied to all replicas. If you plan to use customer-managed KMS keys, you must provide a key for each replica using the ``ReplicaSpecification.ReplicaSSESpecification`` property.\n')
    stream_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_StreamSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the streams settings on your global table. You must provide a value for this property if your global table contains more than one replica. You can only change the streams settings if your global table has only one replica.\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description="A name for the global table. If you don't specify a name, AWS CloudFormation generates a unique ID and uses that ID as the table name. For more information, see `Name type <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-name.html>`_ . .. epigraph:: If you specify a name, you cannot perform updates that require replacement of this resource. You can perform updates that require no or some interruption. If you must replace the resource, specify a new name.\n")
    time_to_live_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_TimeToLiveSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the time to live (TTL) settings for the table. This setting will be applied to all replicas.\n')
    write_provisioned_throughput_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_WriteProvisionedThroughputSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies an auto scaling policy for write capacity. This policy will be applied to all replicas. This setting must be specified if ``BillingMode`` is set to ``PROVISIONED`` .')
    _init_params: typing.ClassVar[list[str]] = ['attribute_definitions', 'key_schema', 'replicas', 'billing_mode', 'global_secondary_indexes', 'local_secondary_indexes', 'sse_specification', 'stream_specification', 'table_name', 'time_to_live_specification', 'write_provisioned_throughput_settings']
    _method_names: typing.ClassVar[list[str]] = ['AttributeDefinitionProperty', 'CapacityAutoScalingSettingsProperty', 'ContributorInsightsSpecificationProperty', 'GlobalSecondaryIndexProperty', 'KeySchemaProperty', 'KinesisStreamSpecificationProperty', 'LocalSecondaryIndexProperty', 'PointInTimeRecoverySpecificationProperty', 'ProjectionProperty', 'ReadProvisionedThroughputSettingsProperty', 'ReplicaGlobalSecondaryIndexSpecificationProperty', 'ReplicaSSESpecificationProperty', 'ReplicaSpecificationProperty', 'SSESpecificationProperty', 'StreamSpecificationProperty', 'TargetTrackingScalingPolicyConfigurationProperty', 'TimeToLiveSpecificationProperty', 'WriteProvisionedThroughputSettingsProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTable'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_dynamodb.CfnGlobalTableDefConfig] = pydantic.Field(None)


class CfnGlobalTableDefConfig(pydantic.BaseModel):
    AttributeDefinitionProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefAttributedefinitionpropertyParams]] = pydantic.Field(None, description='')
    CapacityAutoScalingSettingsProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefCapacityautoscalingsettingspropertyParams]] = pydantic.Field(None, description='')
    ContributorInsightsSpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefContributorinsightsspecificationpropertyParams]] = pydantic.Field(None, description='')
    GlobalSecondaryIndexProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefGlobalsecondaryindexpropertyParams]] = pydantic.Field(None, description='')
    KeySchemaProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefKeyschemapropertyParams]] = pydantic.Field(None, description='')
    KinesisStreamSpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefKinesisstreamspecificationpropertyParams]] = pydantic.Field(None, description='')
    LocalSecondaryIndexProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefLocalsecondaryindexpropertyParams]] = pydantic.Field(None, description='')
    PointInTimeRecoverySpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefPointintimerecoveryspecificationpropertyParams]] = pydantic.Field(None, description='')
    ProjectionProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefProjectionpropertyParams]] = pydantic.Field(None, description='')
    ReadProvisionedThroughputSettingsProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefReadprovisionedthroughputsettingspropertyParams]] = pydantic.Field(None, description='')
    ReplicaGlobalSecondaryIndexSpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefReplicaglobalsecondaryindexspecificationpropertyParams]] = pydantic.Field(None, description='')
    ReplicaSSESpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefReplicassespecificationpropertyParams]] = pydantic.Field(None, description='')
    ReplicaSpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefReplicaspecificationpropertyParams]] = pydantic.Field(None, description='')
    SSESpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefSsespecificationpropertyParams]] = pydantic.Field(None, description='')
    StreamSpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefStreamspecificationpropertyParams]] = pydantic.Field(None, description='')
    TargetTrackingScalingPolicyConfigurationProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefTargettrackingscalingpolicyconfigurationpropertyParams]] = pydantic.Field(None, description='')
    TimeToLiveSpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefTimetolivespecificationpropertyParams]] = pydantic.Field(None, description='')
    WriteProvisionedThroughputSettingsProperty: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefWriteprovisionedthroughputsettingspropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_dynamodb.CfnGlobalTableDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnGlobalTableDefAttributedefinitionpropertyParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='')
    attribute_type: str = pydantic.Field(..., description='')
    ...

class CfnGlobalTableDefCapacityautoscalingsettingspropertyParams(pydantic.BaseModel):
    max_capacity: typing.Union[int, float] = pydantic.Field(..., description='')
    min_capacity: typing.Union[int, float] = pydantic.Field(..., description='')
    target_tracking_scaling_policy_configuration: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_TargetTrackingScalingPolicyConfigurationPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    seed_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnGlobalTableDefContributorinsightsspecificationpropertyParams(pydantic.BaseModel):
    enabled: typing.Union[bool, models.UnsupportedResource] = pydantic.Field(..., description='')
    ...

class CfnGlobalTableDefGlobalsecondaryindexpropertyParams(pydantic.BaseModel):
    index_name: str = pydantic.Field(..., description='')
    key_schema: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    projection: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ProjectionPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    write_provisioned_throughput_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_WriteProvisionedThroughputSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnGlobalTableDefKeyschemapropertyParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='')
    key_type: str = pydantic.Field(..., description='')
    ...

class CfnGlobalTableDefKinesisstreamspecificationpropertyParams(pydantic.BaseModel):
    stream_arn: str = pydantic.Field(..., description='')
    ...

class CfnGlobalTableDefLocalsecondaryindexpropertyParams(pydantic.BaseModel):
    index_name: str = pydantic.Field(..., description='')
    key_schema: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    projection: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ProjectionPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    ...

class CfnGlobalTableDefPointintimerecoveryspecificationpropertyParams(pydantic.BaseModel):
    point_in_time_recovery_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnGlobalTableDefProjectionpropertyParams(pydantic.BaseModel):
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    projection_type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnGlobalTableDefReadprovisionedthroughputsettingspropertyParams(pydantic.BaseModel):
    read_capacity_auto_scaling_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_CapacityAutoScalingSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    read_capacity_units: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnGlobalTableDefReplicaglobalsecondaryindexspecificationpropertyParams(pydantic.BaseModel):
    index_name: str = pydantic.Field(..., description='')
    contributor_insights_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ContributorInsightsSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    read_provisioned_throughput_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ReadProvisionedThroughputSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnGlobalTableDefReplicassespecificationpropertyParams(pydantic.BaseModel):
    kms_master_key_id: str = pydantic.Field(..., description='')
    ...

class CfnGlobalTableDefReplicaspecificationpropertyParams(pydantic.BaseModel):
    region: str = pydantic.Field(..., description='')
    contributor_insights_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ContributorInsightsSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    deletion_protection_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    global_secondary_indexes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ReplicaGlobalSecondaryIndexSpecificationPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    kinesis_stream_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_KinesisStreamSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    point_in_time_recovery_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_PointInTimeRecoverySpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    read_provisioned_throughput_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ReadProvisionedThroughputSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    sse_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ReplicaSSESpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    table_class: typing.Optional[str] = pydantic.Field(None, description='')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='')
    ...

class CfnGlobalTableDefSsespecificationpropertyParams(pydantic.BaseModel):
    sse_enabled: typing.Union[bool, models.UnsupportedResource] = pydantic.Field(..., description='')
    sse_type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnGlobalTableDefStreamspecificationpropertyParams(pydantic.BaseModel):
    stream_view_type: str = pydantic.Field(..., description='')
    ...

class CfnGlobalTableDefTargettrackingscalingpolicyconfigurationpropertyParams(pydantic.BaseModel):
    target_value: typing.Union[int, float] = pydantic.Field(..., description='')
    disable_scale_in: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    scale_in_cooldown: typing.Union[int, float, None] = pydantic.Field(None, description='')
    scale_out_cooldown: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnGlobalTableDefTimetolivespecificationpropertyParams(pydantic.BaseModel):
    enabled: typing.Union[bool, models.UnsupportedResource] = pydantic.Field(..., description='')
    attribute_name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnGlobalTableDefWriteprovisionedthroughputsettingspropertyParams(pydantic.BaseModel):
    write_capacity_auto_scaling_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_CapacityAutoScalingSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnGlobalTableDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnGlobalTableDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnGlobalTableDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnGlobalTableDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnGlobalTableDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnGlobalTableDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnGlobalTableDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnGlobalTableDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnGlobalTableDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnGlobalTableDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnGlobalTableDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnGlobalTableDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnGlobalTableDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnGlobalTableDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_dynamodb.CfnTable
class CfnTableDef(BaseCfnResource):
    key_schema: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the attributes that make up the primary key for the table. The attributes in the ``KeySchema`` property must also be defined in the ``AttributeDefinitions`` property.\n')
    attribute_definitions: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_AttributeDefinitionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A list of attributes that describe the key schema for the table and indexes. This property is required to create a DynamoDB table. Update requires: `Some interruptions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-some-interrupt>`_ . Replacement if you edit an existing AttributeDefinition.\n')
    billing_mode: typing.Optional[str] = pydantic.Field(None, description='Specify how you are charged for read and write throughput and how you manage capacity. Valid values include: - ``PROVISIONED`` - We recommend using ``PROVISIONED`` for predictable workloads. ``PROVISIONED`` sets the billing mode to `Provisioned Mode <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.ProvisionedThroughput.Manual>`_ . - ``PAY_PER_REQUEST`` - We recommend using ``PAY_PER_REQUEST`` for unpredictable workloads. ``PAY_PER_REQUEST`` sets the billing mode to `On-Demand Mode <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.OnDemand>`_ . If not specified, the default is ``PROVISIONED`` .\n')
    contributor_insights_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ContributorInsightsSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The settings used to enable or disable CloudWatch Contributor Insights for the specified table.\n')
    deletion_protection_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Determines if a table is protected from deletion. When enabled, the table cannot be deleted by any user or process. This setting is disabled by default. For more information, see `Using deletion protection <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithTables.Basics.html#WorkingWithTables.Basics.DeletionProtection>`_ in the *Amazon DynamoDB Developer Guide* .\n')
    global_secondary_indexes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_GlobalSecondaryIndexPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="Global secondary indexes to be created on the table. You can create up to 20 global secondary indexes. .. epigraph:: If you update a table to include a new global secondary index, AWS CloudFormation initiates the index creation and then proceeds with the stack update. AWS CloudFormation doesn't wait for the index to complete creation because the backfilling phase can take a long time, depending on the size of the table. You can't use the index or update the table until the index's status is ``ACTIVE`` . You can track its status by using the DynamoDB `DescribeTable <https://docs.aws.amazon.com/cli/latest/reference/dynamodb/describe-table.html>`_ command. If you add or delete an index during an update, we recommend that you don't update any other resources. If your stack fails to update and is rolled back while adding a new index, you must manually delete the index. Updates are not supported. The following are exceptions: - If you update either the contributor insights specification or the provisioned throughput values of global secondary indexes, you can update the table without interruption. - You can delete or add one global secondary index without interruption. If you do both in the same update (for example, by changing the index's logical ID), the update fails.\n")
    import_source_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ImportSourceSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the properties of data being imported from the S3 bucket source to the table. .. epigraph:: If you specify the ``ImportSourceSpecification`` property, and also specify either the ``StreamSpecification`` , the ``TableClass`` property, or the ``DeletionProtectionEnabled`` property, the IAM entity creating/updating stack must have ``UpdateTable`` permission.\n')
    kinesis_stream_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_KinesisStreamSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Kinesis Data Streams configuration for the specified table.\n')
    local_secondary_indexes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_LocalSecondaryIndexPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Local secondary indexes to be created on the table. You can create up to 5 local secondary indexes. Each index is scoped to a given hash key value. The size of each hash key can be up to 10 gigabytes.\n')
    point_in_time_recovery_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_PointInTimeRecoverySpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The settings used to enable point in time recovery.\n')
    provisioned_throughput: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ProvisionedThroughputPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Throughput for the specified table, which consists of values for ``ReadCapacityUnits`` and ``WriteCapacityUnits`` . For more information about the contents of a provisioned throughput structure, see `Amazon DynamoDB Table ProvisionedThroughput <https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_ProvisionedThroughput.html>`_ . If you set ``BillingMode`` as ``PROVISIONED`` , you must specify this property. If you set ``BillingMode`` as ``PAY_PER_REQUEST`` , you cannot specify this property.\n')
    sse_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_SSESpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the settings to enable server-side encryption.\n')
    stream_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_StreamSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The settings for the DynamoDB table stream, which capture changes to items stored in the table.\n')
    table_class: typing.Optional[str] = pydantic.Field(None, description='The table class of the new table. Valid values are ``STANDARD`` and ``STANDARD_INFREQUENT_ACCESS`` .\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description="A name for the table. If you don't specify a name, AWS CloudFormation generates a unique physical ID and uses that ID for the table name. For more information, see `Name Type <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-name.html>`_ . .. epigraph:: If you specify a name, you cannot perform updates that require replacement of this resource. You can perform updates that require no or some interruption. If you must replace the resource, specify a new name.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='An array of key-value pairs to apply to this resource. For more information, see `Tag <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html>`_ .\n')
    time_to_live_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_TimeToLiveSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the Time to Live (TTL) settings for the table. .. epigraph:: For detailed information about the limits in DynamoDB, see `Limits in Amazon DynamoDB <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html>`_ in the Amazon DynamoDB Developer Guide.')
    _init_params: typing.ClassVar[list[str]] = ['key_schema', 'attribute_definitions', 'billing_mode', 'contributor_insights_specification', 'deletion_protection_enabled', 'global_secondary_indexes', 'import_source_specification', 'kinesis_stream_specification', 'local_secondary_indexes', 'point_in_time_recovery_specification', 'provisioned_throughput', 'sse_specification', 'stream_specification', 'table_class', 'table_name', 'tags', 'time_to_live_specification']
    _method_names: typing.ClassVar[list[str]] = ['AttributeDefinitionProperty', 'ContributorInsightsSpecificationProperty', 'CsvProperty', 'GlobalSecondaryIndexProperty', 'ImportSourceSpecificationProperty', 'InputFormatOptionsProperty', 'KeySchemaProperty', 'KinesisStreamSpecificationProperty', 'LocalSecondaryIndexProperty', 'PointInTimeRecoverySpecificationProperty', 'ProjectionProperty', 'ProvisionedThroughputProperty', 'S3BucketSourceProperty', 'SSESpecificationProperty', 'StreamSpecificationProperty', 'TimeToLiveSpecificationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTable'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_dynamodb.CfnTableDefConfig] = pydantic.Field(None)


class CfnTableDefConfig(pydantic.BaseModel):
    AttributeDefinitionProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefAttributedefinitionpropertyParams]] = pydantic.Field(None, description='')
    ContributorInsightsSpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefContributorinsightsspecificationpropertyParams]] = pydantic.Field(None, description='')
    CsvProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefCsvpropertyParams]] = pydantic.Field(None, description='')
    GlobalSecondaryIndexProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefGlobalsecondaryindexpropertyParams]] = pydantic.Field(None, description='')
    ImportSourceSpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefImportsourcespecificationpropertyParams]] = pydantic.Field(None, description='')
    InputFormatOptionsProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefInputformatoptionspropertyParams]] = pydantic.Field(None, description='')
    KeySchemaProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefKeyschemapropertyParams]] = pydantic.Field(None, description='')
    KinesisStreamSpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefKinesisstreamspecificationpropertyParams]] = pydantic.Field(None, description='')
    LocalSecondaryIndexProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefLocalsecondaryindexpropertyParams]] = pydantic.Field(None, description='')
    PointInTimeRecoverySpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefPointintimerecoveryspecificationpropertyParams]] = pydantic.Field(None, description='')
    ProjectionProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefProjectionpropertyParams]] = pydantic.Field(None, description='')
    ProvisionedThroughputProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefProvisionedthroughputpropertyParams]] = pydantic.Field(None, description='')
    S3BucketSourceProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefS3BucketsourcepropertyParams]] = pydantic.Field(None, description='')
    SSESpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefSsespecificationpropertyParams]] = pydantic.Field(None, description='')
    StreamSpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefStreamspecificationpropertyParams]] = pydantic.Field(None, description='')
    TimeToLiveSpecificationProperty: typing.Optional[list[models.aws_dynamodb.CfnTableDefTimetolivespecificationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_dynamodb.CfnTableDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_dynamodb.CfnTableDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_dynamodb.CfnTableDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_dynamodb.CfnTableDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_dynamodb.CfnTableDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_dynamodb.CfnTableDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_dynamodb.CfnTableDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_dynamodb.CfnTableDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_dynamodb.CfnTableDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_dynamodb.CfnTableDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_dynamodb.CfnTableDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_dynamodb.CfnTableDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_dynamodb.CfnTableDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnTableDefAttributedefinitionpropertyParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='')
    attribute_type: str = pydantic.Field(..., description='')
    ...

class CfnTableDefContributorinsightsspecificationpropertyParams(pydantic.BaseModel):
    enabled: typing.Union[bool, models.UnsupportedResource] = pydantic.Field(..., description='')
    ...

class CfnTableDefCsvpropertyParams(pydantic.BaseModel):
    delimiter: typing.Optional[str] = pydantic.Field(None, description='')
    header_list: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnTableDefGlobalsecondaryindexpropertyParams(pydantic.BaseModel):
    index_name: str = pydantic.Field(..., description='')
    key_schema: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    projection: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ProjectionPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    contributor_insights_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ContributorInsightsSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    provisioned_throughput: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ProvisionedThroughputPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnTableDefImportsourcespecificationpropertyParams(pydantic.BaseModel):
    input_format: str = pydantic.Field(..., description='')
    s3_bucket_source: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_S3BucketSourcePropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    input_compression_type: typing.Optional[str] = pydantic.Field(None, description='')
    input_format_options: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_InputFormatOptionsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnTableDefInputformatoptionspropertyParams(pydantic.BaseModel):
    csv: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_CsvPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnTableDefKeyschemapropertyParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='')
    key_type: str = pydantic.Field(..., description='')
    ...

class CfnTableDefKinesisstreamspecificationpropertyParams(pydantic.BaseModel):
    stream_arn: str = pydantic.Field(..., description='')
    ...

class CfnTableDefLocalsecondaryindexpropertyParams(pydantic.BaseModel):
    index_name: str = pydantic.Field(..., description='')
    key_schema: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(..., description='')
    projection: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ProjectionPropertyDef, dict[str, typing.Any]] = pydantic.Field(..., description='')
    ...

class CfnTableDefPointintimerecoveryspecificationpropertyParams(pydantic.BaseModel):
    point_in_time_recovery_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnTableDefProjectionpropertyParams(pydantic.BaseModel):
    non_key_attributes: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    projection_type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTableDefProvisionedthroughputpropertyParams(pydantic.BaseModel):
    read_capacity_units: typing.Union[int, float] = pydantic.Field(..., description='')
    write_capacity_units: typing.Union[int, float] = pydantic.Field(..., description='')
    ...

class CfnTableDefS3BucketsourcepropertyParams(pydantic.BaseModel):
    s3_bucket: str = pydantic.Field(..., description='')
    s3_bucket_owner: typing.Optional[str] = pydantic.Field(None, description='')
    s3_key_prefix: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTableDefSsespecificationpropertyParams(pydantic.BaseModel):
    sse_enabled: typing.Union[bool, models.UnsupportedResource] = pydantic.Field(..., description='')
    kms_master_key_id: typing.Optional[str] = pydantic.Field(None, description='')
    sse_type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTableDefStreamspecificationpropertyParams(pydantic.BaseModel):
    stream_view_type: str = pydantic.Field(..., description='')
    ...

class CfnTableDefTimetolivespecificationpropertyParams(pydantic.BaseModel):
    enabled: typing.Union[bool, models.UnsupportedResource] = pydantic.Field(..., description='')
    attribute_name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnTableDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnTableDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnTableDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnTableDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnTableDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnTableDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnTableDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnTableDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnTableDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnTableDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnTableDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnTableDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnTableDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnTableDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_dynamodb.CfnGlobalTableProps
class CfnGlobalTablePropsDef(BaseCfnProperty):
    attribute_definitions: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_AttributeDefinitionPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='A list of attributes that describe the key schema for the global table and indexes.\n')
    key_schema: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the attributes that make up the primary key for the table. The attributes in the ``KeySchema`` property must also be defined in the ``AttributeDefinitions`` property.\n')
    replicas: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_ReplicaSpecificationPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description="Specifies the list of replicas for your global table. The list must contain at least one element, the region where the stack defining the global table is deployed. For example, if you define your table in a stack deployed to us-east-1, you must have an entry in ``Replicas`` with the region us-east-1. You cannot remove the replica in the stack region. .. epigraph:: Adding a replica might take a few minutes for an empty table, or up to several hours for large tables. If you want to add or remove a replica, we recommend submitting an ``UpdateStack`` operation containing only that change. If you add or delete a replica during an update, we recommend that you don't update any other resources. If your stack fails to update and is rolled back while adding a new replica, you might need to manually delete the replica. You can create a new global table with as many replicas as needed. You can add or remove replicas after table creation, but you can only add or remove a single replica in each update.\n")
    billing_mode: typing.Optional[str] = pydantic.Field(None, description='Specifies how you are charged for read and write throughput and how you manage capacity. Valid values are:. - ``PAY_PER_REQUEST`` - ``PROVISIONED`` All replicas in your global table will have the same billing mode. If you use ``PROVISIONED`` billing mode, you must provide an auto scaling configuration via the ``WriteProvisionedThroughputSettings`` property. The default value of this property is ``PROVISIONED`` .\n')
    global_secondary_indexes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_GlobalSecondaryIndexPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Global secondary indexes to be created on the global table. You can create up to 20 global secondary indexes. Each replica in your global table will have the same global secondary index settings. You can only create or delete one global secondary index in a single stack operation. Since the backfilling of an index could take a long time, CloudFormation does not wait for the index to become active. If a stack operation rolls back, CloudFormation might not delete an index that has been added. In that case, you will need to delete the index manually.\n')
    local_secondary_indexes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_LocalSecondaryIndexPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Local secondary indexes to be created on the table. You can create up to five local secondary indexes. Each index is scoped to a given hash key value. The size of each hash key can be up to 10 gigabytes. Each replica in your global table will have the same local secondary index settings.\n')
    sse_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_SSESpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the settings to enable server-side encryption. These settings will be applied to all replicas. If you plan to use customer-managed KMS keys, you must provide a key for each replica using the ``ReplicaSpecification.ReplicaSSESpecification`` property.\n')
    stream_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_StreamSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the streams settings on your global table. You must provide a value for this property if your global table contains more than one replica. You can only change the streams settings if your global table has only one replica.\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description="A name for the global table. If you don't specify a name, AWS CloudFormation generates a unique ID and uses that ID as the table name. For more information, see `Name type <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-name.html>`_ . .. epigraph:: If you specify a name, you cannot perform updates that require replacement of this resource. You can perform updates that require no or some interruption. If you must replace the resource, specify a new name.\n")
    time_to_live_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_TimeToLiveSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the time to live (TTL) settings for the table. This setting will be applied to all replicas.\n')
    write_provisioned_throughput_settings: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnGlobalTable_WriteProvisionedThroughputSettingsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies an auto scaling policy for write capacity. This policy will be applied to all replicas. This setting must be specified if ``BillingMode`` is set to ``PROVISIONED`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-dynamodb-globaltable.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    cfn_global_table_props = dynamodb.CfnGlobalTableProps(\n        attribute_definitions=[dynamodb.CfnGlobalTable.AttributeDefinitionProperty(\n            attribute_name="attributeName",\n            attribute_type="attributeType"\n        )],\n        key_schema=[dynamodb.CfnGlobalTable.KeySchemaProperty(\n            attribute_name="attributeName",\n            key_type="keyType"\n        )],\n        replicas=[dynamodb.CfnGlobalTable.ReplicaSpecificationProperty(\n            region="region",\n\n            # the properties below are optional\n            contributor_insights_specification=dynamodb.CfnGlobalTable.ContributorInsightsSpecificationProperty(\n                enabled=False\n            ),\n            deletion_protection_enabled=False,\n            global_secondary_indexes=[dynamodb.CfnGlobalTable.ReplicaGlobalSecondaryIndexSpecificationProperty(\n                index_name="indexName",\n\n                # the properties below are optional\n                contributor_insights_specification=dynamodb.CfnGlobalTable.ContributorInsightsSpecificationProperty(\n                    enabled=False\n                ),\n                read_provisioned_throughput_settings=dynamodb.CfnGlobalTable.ReadProvisionedThroughputSettingsProperty(\n                    read_capacity_auto_scaling_settings=dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty(\n                        max_capacity=123,\n                        min_capacity=123,\n                        target_tracking_scaling_policy_configuration=dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n                            target_value=123,\n\n                            # the properties below are optional\n                            disable_scale_in=False,\n                            scale_in_cooldown=123,\n                            scale_out_cooldown=123\n                        ),\n\n                        # the properties below are optional\n                        seed_capacity=123\n                    ),\n                    read_capacity_units=123\n                )\n            )],\n            kinesis_stream_specification=dynamodb.CfnGlobalTable.KinesisStreamSpecificationProperty(\n                stream_arn="streamArn"\n            ),\n            point_in_time_recovery_specification=dynamodb.CfnGlobalTable.PointInTimeRecoverySpecificationProperty(\n                point_in_time_recovery_enabled=False\n            ),\n            read_provisioned_throughput_settings=dynamodb.CfnGlobalTable.ReadProvisionedThroughputSettingsProperty(\n                read_capacity_auto_scaling_settings=dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty(\n                    max_capacity=123,\n                    min_capacity=123,\n                    target_tracking_scaling_policy_configuration=dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n                        target_value=123,\n\n                        # the properties below are optional\n                        disable_scale_in=False,\n                        scale_in_cooldown=123,\n                        scale_out_cooldown=123\n                    ),\n\n                    # the properties below are optional\n                    seed_capacity=123\n                ),\n                read_capacity_units=123\n            ),\n            sse_specification=dynamodb.CfnGlobalTable.ReplicaSSESpecificationProperty(\n                kms_master_key_id="kmsMasterKeyId"\n            ),\n            table_class="tableClass",\n            tags=[CfnTag(\n                key="key",\n                value="value"\n            )]\n        )],\n\n        # the properties below are optional\n        billing_mode="billingMode",\n        global_secondary_indexes=[dynamodb.CfnGlobalTable.GlobalSecondaryIndexProperty(\n            index_name="indexName",\n            key_schema=[dynamodb.CfnGlobalTable.KeySchemaProperty(\n                attribute_name="attributeName",\n                key_type="keyType"\n            )],\n            projection=dynamodb.CfnGlobalTable.ProjectionProperty(\n                non_key_attributes=["nonKeyAttributes"],\n                projection_type="projectionType"\n            ),\n\n            # the properties below are optional\n            write_provisioned_throughput_settings=dynamodb.CfnGlobalTable.WriteProvisionedThroughputSettingsProperty(\n                write_capacity_auto_scaling_settings=dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty(\n                    max_capacity=123,\n                    min_capacity=123,\n                    target_tracking_scaling_policy_configuration=dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n                        target_value=123,\n\n                        # the properties below are optional\n                        disable_scale_in=False,\n                        scale_in_cooldown=123,\n                        scale_out_cooldown=123\n                    ),\n\n                    # the properties below are optional\n                    seed_capacity=123\n                )\n            )\n        )],\n        local_secondary_indexes=[dynamodb.CfnGlobalTable.LocalSecondaryIndexProperty(\n            index_name="indexName",\n            key_schema=[dynamodb.CfnGlobalTable.KeySchemaProperty(\n                attribute_name="attributeName",\n                key_type="keyType"\n            )],\n            projection=dynamodb.CfnGlobalTable.ProjectionProperty(\n                non_key_attributes=["nonKeyAttributes"],\n                projection_type="projectionType"\n            )\n        )],\n        sse_specification=dynamodb.CfnGlobalTable.SSESpecificationProperty(\n            sse_enabled=False,\n\n            # the properties below are optional\n            sse_type="sseType"\n        ),\n        stream_specification=dynamodb.CfnGlobalTable.StreamSpecificationProperty(\n            stream_view_type="streamViewType"\n        ),\n        table_name="tableName",\n        time_to_live_specification=dynamodb.CfnGlobalTable.TimeToLiveSpecificationProperty(\n            enabled=False,\n\n            # the properties below are optional\n            attribute_name="attributeName"\n        ),\n        write_provisioned_throughput_settings=dynamodb.CfnGlobalTable.WriteProvisionedThroughputSettingsProperty(\n            write_capacity_auto_scaling_settings=dynamodb.CfnGlobalTable.CapacityAutoScalingSettingsProperty(\n                max_capacity=123,\n                min_capacity=123,\n                target_tracking_scaling_policy_configuration=dynamodb.CfnGlobalTable.TargetTrackingScalingPolicyConfigurationProperty(\n                    target_value=123,\n\n                    # the properties below are optional\n                    disable_scale_in=False,\n                    scale_in_cooldown=123,\n                    scale_out_cooldown=123\n                ),\n\n                # the properties below are optional\n                seed_capacity=123\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['attribute_definitions', 'key_schema', 'replicas', 'billing_mode', 'global_secondary_indexes', 'local_secondary_indexes', 'sse_specification', 'stream_specification', 'table_name', 'time_to_live_specification', 'write_provisioned_throughput_settings']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnGlobalTableProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_dynamodb.CfnTableProps
class CfnTablePropsDef(BaseCfnProperty):
    key_schema: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_KeySchemaPropertyDef, dict[str, typing.Any]]]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the attributes that make up the primary key for the table. The attributes in the ``KeySchema`` property must also be defined in the ``AttributeDefinitions`` property.\n')
    attribute_definitions: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_AttributeDefinitionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A list of attributes that describe the key schema for the table and indexes. This property is required to create a DynamoDB table. Update requires: `Some interruptions <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-some-interrupt>`_ . Replacement if you edit an existing AttributeDefinition.\n')
    billing_mode: typing.Optional[str] = pydantic.Field(None, description='Specify how you are charged for read and write throughput and how you manage capacity. Valid values include: - ``PROVISIONED`` - We recommend using ``PROVISIONED`` for predictable workloads. ``PROVISIONED`` sets the billing mode to `Provisioned Mode <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.ProvisionedThroughput.Manual>`_ . - ``PAY_PER_REQUEST`` - We recommend using ``PAY_PER_REQUEST`` for unpredictable workloads. ``PAY_PER_REQUEST`` sets the billing mode to `On-Demand Mode <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.OnDemand>`_ . If not specified, the default is ``PROVISIONED`` .\n')
    contributor_insights_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ContributorInsightsSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The settings used to enable or disable CloudWatch Contributor Insights for the specified table.\n')
    deletion_protection_enabled: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Determines if a table is protected from deletion. When enabled, the table cannot be deleted by any user or process. This setting is disabled by default. For more information, see `Using deletion protection <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithTables.Basics.html#WorkingWithTables.Basics.DeletionProtection>`_ in the *Amazon DynamoDB Developer Guide* .\n')
    global_secondary_indexes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_GlobalSecondaryIndexPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="Global secondary indexes to be created on the table. You can create up to 20 global secondary indexes. .. epigraph:: If you update a table to include a new global secondary index, AWS CloudFormation initiates the index creation and then proceeds with the stack update. AWS CloudFormation doesn't wait for the index to complete creation because the backfilling phase can take a long time, depending on the size of the table. You can't use the index or update the table until the index's status is ``ACTIVE`` . You can track its status by using the DynamoDB `DescribeTable <https://docs.aws.amazon.com/cli/latest/reference/dynamodb/describe-table.html>`_ command. If you add or delete an index during an update, we recommend that you don't update any other resources. If your stack fails to update and is rolled back while adding a new index, you must manually delete the index. Updates are not supported. The following are exceptions: - If you update either the contributor insights specification or the provisioned throughput values of global secondary indexes, you can update the table without interruption. - You can delete or add one global secondary index without interruption. If you do both in the same update (for example, by changing the index's logical ID), the update fails.\n")
    import_source_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ImportSourceSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the properties of data being imported from the S3 bucket source to the table. .. epigraph:: If you specify the ``ImportSourceSpecification`` property, and also specify either the ``StreamSpecification`` , the ``TableClass`` property, or the ``DeletionProtectionEnabled`` property, the IAM entity creating/updating stack must have ``UpdateTable`` permission.\n')
    kinesis_stream_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_KinesisStreamSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The Kinesis Data Streams configuration for the specified table.\n')
    local_secondary_indexes: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_LocalSecondaryIndexPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Local secondary indexes to be created on the table. You can create up to 5 local secondary indexes. Each index is scoped to a given hash key value. The size of each hash key can be up to 10 gigabytes.\n')
    point_in_time_recovery_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_PointInTimeRecoverySpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The settings used to enable point in time recovery.\n')
    provisioned_throughput: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_ProvisionedThroughputPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Throughput for the specified table, which consists of values for ``ReadCapacityUnits`` and ``WriteCapacityUnits`` . For more information about the contents of a provisioned throughput structure, see `Amazon DynamoDB Table ProvisionedThroughput <https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_ProvisionedThroughput.html>`_ . If you set ``BillingMode`` as ``PROVISIONED`` , you must specify this property. If you set ``BillingMode`` as ``PAY_PER_REQUEST`` , you cannot specify this property.\n')
    sse_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_SSESpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the settings to enable server-side encryption.\n')
    stream_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_StreamSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The settings for the DynamoDB table stream, which capture changes to items stored in the table.\n')
    table_class: typing.Optional[str] = pydantic.Field(None, description='The table class of the new table. Valid values are ``STANDARD`` and ``STANDARD_INFREQUENT_ACCESS`` .\n')
    table_name: typing.Optional[str] = pydantic.Field(None, description="A name for the table. If you don't specify a name, AWS CloudFormation generates a unique physical ID and uses that ID for the table name. For more information, see `Name Type <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-name.html>`_ . .. epigraph:: If you specify a name, you cannot perform updates that require replacement of this resource. You can perform updates that require no or some interruption. If you must replace the resource, specify a new name.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='An array of key-value pairs to apply to this resource. For more information, see `Tag <https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html>`_ .\n')
    time_to_live_specification: typing.Union[models.UnsupportedResource, models.aws_dynamodb.CfnTable_TimeToLiveSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Specifies the Time to Live (TTL) settings for the table. .. epigraph:: For detailed information about the limits in DynamoDB, see `Limits in Amazon DynamoDB <https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html>`_ in the Amazon DynamoDB Developer Guide.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-dynamodb-table.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_dynamodb as dynamodb\n\n    cfn_table_props = dynamodb.CfnTableProps(\n        key_schema=[dynamodb.CfnTable.KeySchemaProperty(\n            attribute_name="attributeName",\n            key_type="keyType"\n        )],\n\n        # the properties below are optional\n        attribute_definitions=[dynamodb.CfnTable.AttributeDefinitionProperty(\n            attribute_name="attributeName",\n            attribute_type="attributeType"\n        )],\n        billing_mode="billingMode",\n        contributor_insights_specification=dynamodb.CfnTable.ContributorInsightsSpecificationProperty(\n            enabled=False\n        ),\n        deletion_protection_enabled=False,\n        global_secondary_indexes=[dynamodb.CfnTable.GlobalSecondaryIndexProperty(\n            index_name="indexName",\n            key_schema=[dynamodb.CfnTable.KeySchemaProperty(\n                attribute_name="attributeName",\n                key_type="keyType"\n            )],\n            projection=dynamodb.CfnTable.ProjectionProperty(\n                non_key_attributes=["nonKeyAttributes"],\n                projection_type="projectionType"\n            ),\n\n            # the properties below are optional\n            contributor_insights_specification=dynamodb.CfnTable.ContributorInsightsSpecificationProperty(\n                enabled=False\n            ),\n            provisioned_throughput=dynamodb.CfnTable.ProvisionedThroughputProperty(\n                read_capacity_units=123,\n                write_capacity_units=123\n            )\n        )],\n        import_source_specification=dynamodb.CfnTable.ImportSourceSpecificationProperty(\n            input_format="inputFormat",\n            s3_bucket_source=dynamodb.CfnTable.S3BucketSourceProperty(\n                s3_bucket="s3Bucket",\n\n                # the properties below are optional\n                s3_bucket_owner="s3BucketOwner",\n                s3_key_prefix="s3KeyPrefix"\n            ),\n\n            # the properties below are optional\n            input_compression_type="inputCompressionType",\n            input_format_options=dynamodb.CfnTable.InputFormatOptionsProperty(\n                csv=dynamodb.CfnTable.CsvProperty(\n                    delimiter="delimiter",\n                    header_list=["headerList"]\n                )\n            )\n        ),\n        kinesis_stream_specification=dynamodb.CfnTable.KinesisStreamSpecificationProperty(\n            stream_arn="streamArn"\n        ),\n        local_secondary_indexes=[dynamodb.CfnTable.LocalSecondaryIndexProperty(\n            index_name="indexName",\n            key_schema=[dynamodb.CfnTable.KeySchemaProperty(\n                attribute_name="attributeName",\n                key_type="keyType"\n            )],\n            projection=dynamodb.CfnTable.ProjectionProperty(\n                non_key_attributes=["nonKeyAttributes"],\n                projection_type="projectionType"\n            )\n        )],\n        point_in_time_recovery_specification=dynamodb.CfnTable.PointInTimeRecoverySpecificationProperty(\n            point_in_time_recovery_enabled=False\n        ),\n        provisioned_throughput=dynamodb.CfnTable.ProvisionedThroughputProperty(\n            read_capacity_units=123,\n            write_capacity_units=123\n        ),\n        sse_specification=dynamodb.CfnTable.SSESpecificationProperty(\n            sse_enabled=False,\n\n            # the properties below are optional\n            kms_master_key_id="kmsMasterKeyId",\n            sse_type="sseType"\n        ),\n        stream_specification=dynamodb.CfnTable.StreamSpecificationProperty(\n            stream_view_type="streamViewType"\n        ),\n        table_class="tableClass",\n        table_name="tableName",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        time_to_live_specification=dynamodb.CfnTable.TimeToLiveSpecificationProperty(\n            enabled=False,\n\n            # the properties below are optional\n            attribute_name="attributeName"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['key_schema', 'attribute_definitions', 'billing_mode', 'contributor_insights_specification', 'deletion_protection_enabled', 'global_secondary_indexes', 'import_source_specification', 'kinesis_stream_specification', 'local_secondary_indexes', 'point_in_time_recovery_specification', 'provisioned_throughput', 'sse_specification', 'stream_specification', 'table_class', 'table_name', 'tags', 'time_to_live_specification']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_dynamodb.CfnTableProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




class ModuleModel(pydantic.BaseModel):
    Billing: typing.Optional[dict[str, models.aws_dynamodb.BillingDef]] = pydantic.Field(None)
    Capacity: typing.Optional[dict[str, models.aws_dynamodb.CapacityDef]] = pydantic.Field(None)
    TableBase: typing.Optional[dict[str, models.aws_dynamodb.TableBaseDef]] = pydantic.Field(None)
    TableBaseV2: typing.Optional[dict[str, models.aws_dynamodb.TableBaseV2Def]] = pydantic.Field(None)
    TableEncryptionV2: typing.Optional[dict[str, models.aws_dynamodb.TableEncryptionV2Def]] = pydantic.Field(None)
    Table: typing.Optional[dict[str, models.aws_dynamodb.TableDef]] = pydantic.Field(None)
    TableV2: typing.Optional[dict[str, models.aws_dynamodb.TableV2Def]] = pydantic.Field(None)
    Attribute: typing.Optional[dict[str, models.aws_dynamodb.AttributeDef]] = pydantic.Field(None)
    AutoscaledCapacityOptions: typing.Optional[dict[str, models.aws_dynamodb.AutoscaledCapacityOptionsDef]] = pydantic.Field(None)
    CfnGlobalTable_AttributeDefinitionProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_AttributeDefinitionPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_CapacityAutoScalingSettingsProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_CapacityAutoScalingSettingsPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_ContributorInsightsSpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_ContributorInsightsSpecificationPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_GlobalSecondaryIndexProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_GlobalSecondaryIndexPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_KeySchemaProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_KeySchemaPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_KinesisStreamSpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_KinesisStreamSpecificationPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_LocalSecondaryIndexProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_LocalSecondaryIndexPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_PointInTimeRecoverySpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_PointInTimeRecoverySpecificationPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_ProjectionProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_ProjectionPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_ReadProvisionedThroughputSettingsProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_ReadProvisionedThroughputSettingsPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_ReplicaGlobalSecondaryIndexSpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_ReplicaGlobalSecondaryIndexSpecificationPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_ReplicaSpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_ReplicaSpecificationPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_ReplicaSSESpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_ReplicaSSESpecificationPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_SSESpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_SSESpecificationPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_StreamSpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_StreamSpecificationPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_TargetTrackingScalingPolicyConfigurationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_TargetTrackingScalingPolicyConfigurationPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_TimeToLiveSpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_TimeToLiveSpecificationPropertyDef]] = pydantic.Field(None)
    CfnGlobalTable_WriteProvisionedThroughputSettingsProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTable_WriteProvisionedThroughputSettingsPropertyDef]] = pydantic.Field(None)
    CfnTable_AttributeDefinitionProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_AttributeDefinitionPropertyDef]] = pydantic.Field(None)
    CfnTable_ContributorInsightsSpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_ContributorInsightsSpecificationPropertyDef]] = pydantic.Field(None)
    CfnTable_CsvProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_CsvPropertyDef]] = pydantic.Field(None)
    CfnTable_GlobalSecondaryIndexProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_GlobalSecondaryIndexPropertyDef]] = pydantic.Field(None)
    CfnTable_ImportSourceSpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_ImportSourceSpecificationPropertyDef]] = pydantic.Field(None)
    CfnTable_InputFormatOptionsProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_InputFormatOptionsPropertyDef]] = pydantic.Field(None)
    CfnTable_KeySchemaProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_KeySchemaPropertyDef]] = pydantic.Field(None)
    CfnTable_KinesisStreamSpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_KinesisStreamSpecificationPropertyDef]] = pydantic.Field(None)
    CfnTable_LocalSecondaryIndexProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_LocalSecondaryIndexPropertyDef]] = pydantic.Field(None)
    CfnTable_PointInTimeRecoverySpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_PointInTimeRecoverySpecificationPropertyDef]] = pydantic.Field(None)
    CfnTable_ProjectionProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_ProjectionPropertyDef]] = pydantic.Field(None)
    CfnTable_ProvisionedThroughputProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_ProvisionedThroughputPropertyDef]] = pydantic.Field(None)
    CfnTable_S3BucketSourceProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_S3BucketSourcePropertyDef]] = pydantic.Field(None)
    CfnTable_SSESpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_SSESpecificationPropertyDef]] = pydantic.Field(None)
    CfnTable_StreamSpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_StreamSpecificationPropertyDef]] = pydantic.Field(None)
    CfnTable_TimeToLiveSpecificationProperty: typing.Optional[dict[str, models.aws_dynamodb.CfnTable_TimeToLiveSpecificationPropertyDef]] = pydantic.Field(None)
    EnableScalingProps: typing.Optional[dict[str, models.aws_dynamodb.EnableScalingPropsDef]] = pydantic.Field(None)
    GlobalSecondaryIndexProps: typing.Optional[dict[str, models.aws_dynamodb.GlobalSecondaryIndexPropsDef]] = pydantic.Field(None)
    GlobalSecondaryIndexPropsV2: typing.Optional[dict[str, models.aws_dynamodb.GlobalSecondaryIndexPropsV2Def]] = pydantic.Field(None)
    LocalSecondaryIndexProps: typing.Optional[dict[str, models.aws_dynamodb.LocalSecondaryIndexPropsDef]] = pydantic.Field(None)
    OperationsMetricOptions: typing.Optional[dict[str, models.aws_dynamodb.OperationsMetricOptionsDef]] = pydantic.Field(None)
    ReplicaGlobalSecondaryIndexOptions: typing.Optional[dict[str, models.aws_dynamodb.ReplicaGlobalSecondaryIndexOptionsDef]] = pydantic.Field(None)
    ReplicaTableProps: typing.Optional[dict[str, models.aws_dynamodb.ReplicaTablePropsDef]] = pydantic.Field(None)
    SchemaOptions: typing.Optional[dict[str, models.aws_dynamodb.SchemaOptionsDef]] = pydantic.Field(None)
    SecondaryIndexProps: typing.Optional[dict[str, models.aws_dynamodb.SecondaryIndexPropsDef]] = pydantic.Field(None)
    SystemErrorsForOperationsMetricOptions: typing.Optional[dict[str, models.aws_dynamodb.SystemErrorsForOperationsMetricOptionsDef]] = pydantic.Field(None)
    TableAttributes: typing.Optional[dict[str, models.aws_dynamodb.TableAttributesDef]] = pydantic.Field(None)
    TableAttributesV2: typing.Optional[dict[str, models.aws_dynamodb.TableAttributesV2Def]] = pydantic.Field(None)
    TableOptions: typing.Optional[dict[str, models.aws_dynamodb.TableOptionsDef]] = pydantic.Field(None)
    TableOptionsV2: typing.Optional[dict[str, models.aws_dynamodb.TableOptionsV2Def]] = pydantic.Field(None)
    TableProps: typing.Optional[dict[str, models.aws_dynamodb.TablePropsDef]] = pydantic.Field(None)
    TablePropsV2: typing.Optional[dict[str, models.aws_dynamodb.TablePropsV2Def]] = pydantic.Field(None)
    ThroughputProps: typing.Optional[dict[str, models.aws_dynamodb.ThroughputPropsDef]] = pydantic.Field(None)
    UtilizationScalingProps: typing.Optional[dict[str, models.aws_dynamodb.UtilizationScalingPropsDef]] = pydantic.Field(None)
    CfnGlobalTable: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTableDef]] = pydantic.Field(None)
    CfnTable: typing.Optional[dict[str, models.aws_dynamodb.CfnTableDef]] = pydantic.Field(None)
    CfnGlobalTableProps: typing.Optional[dict[str, models.aws_dynamodb.CfnGlobalTablePropsDef]] = pydantic.Field(None)
    CfnTableProps: typing.Optional[dict[str, models.aws_dynamodb.CfnTablePropsDef]] = pydantic.Field(None)
    ...

import models
