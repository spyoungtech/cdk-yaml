from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_comprehend.CfnDocumentClassifier.AugmentedManifestsListItemProperty
class CfnDocumentClassifier_AugmentedManifestsListItemPropertyDef(BaseStruct):
    attribute_names: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The JSON attribute that contains the annotations for your training documents. The number of attribute names that you specify depends on whether your augmented manifest file is the output of a single labeling job or a chained labeling job. If your file is the output of a single labeling job, specify the LabelAttributeName key that was used when the job was created in Ground Truth. If your file is the output of a chained labeling job, specify the LabelAttributeName key for one or more jobs in the chain. Each LabelAttributeName key provides the annotations from an individual job.\n')
    s3_uri: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon S3 location of the augmented manifest file.\n')
    split: typing.Optional[str] = pydantic.Field(None, description='The purpose of the data you\'ve provided in the augmented manifest. You can either train or test this data. If you don\'t specify, the default is train. TRAIN - all of the documents in the manifest will be used for training. If no test documents are provided, Amazon Comprehend will automatically reserve a portion of the training documents for testing. TEST - all of the documents in the manifest will be used for testing.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-documentclassifier-augmentedmanifestslistitem.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    augmented_manifests_list_item_property = comprehend.CfnDocumentClassifier.AugmentedManifestsListItemProperty(\n        attribute_names=["attributeNames"],\n        s3_uri="s3Uri",\n\n        # the properties below are optional\n        split="split"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['attribute_names', 's3_uri', 'split']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnDocumentClassifier.AugmentedManifestsListItemProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnDocumentClassifier.DocumentClassifierDocumentsProperty
class CfnDocumentClassifier_DocumentClassifierDocumentsPropertyDef(BaseStruct):
    s3_uri: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The S3 URI location of the training documents specified in the S3Uri CSV file.\n')
    test_s3_uri: typing.Optional[str] = pydantic.Field(None, description='The S3 URI location of the test documents included in the TestS3Uri CSV file. This field is not required if you do not specify a test CSV file.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-documentclassifier-documentclassifierdocuments.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    document_classifier_documents_property = comprehend.CfnDocumentClassifier.DocumentClassifierDocumentsProperty(\n        s3_uri="s3Uri",\n\n        # the properties below are optional\n        test_s3_uri="testS3Uri"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['s3_uri', 'test_s3_uri']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnDocumentClassifier.DocumentClassifierDocumentsProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnDocumentClassifier.DocumentClassifierInputDataConfigProperty
class CfnDocumentClassifier_DocumentClassifierInputDataConfigPropertyDef(BaseStruct):
    augmented_manifests: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_AugmentedManifestsListItemPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A list of augmented manifest files that provide training data for your custom model. An augmented manifest file is a labeled dataset that is produced by Amazon SageMaker Ground Truth. This parameter is required if you set ``DataFormat`` to ``AUGMENTED_MANIFEST`` .\n')
    data_format: typing.Optional[str] = pydantic.Field(None, description="The format of your training data:. - ``COMPREHEND_CSV`` : A two-column CSV file, where labels are provided in the first column, and documents are provided in the second. If you use this value, you must provide the ``S3Uri`` parameter in your request. - ``AUGMENTED_MANIFEST`` : A labeled dataset that is produced by Amazon SageMaker Ground Truth. This file is in JSON lines format. Each line is a complete JSON object that contains a training document and its associated labels. If you use this value, you must provide the ``AugmentedManifests`` parameter in your request. If you don't specify a value, Amazon Comprehend uses ``COMPREHEND_CSV`` as the default.\n")
    document_reader_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_DocumentReaderConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    documents: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_DocumentClassifierDocumentsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The S3 location of the training documents. This parameter is required in a request to create a native document model.\n')
    document_type: typing.Optional[str] = pydantic.Field(None, description='The type of input documents for training the model. Provide plain-text documents to create a plain-text model, and provide semi-structured documents to create a native document model.\n')
    label_delimiter: typing.Optional[str] = pydantic.Field(None, description="Indicates the delimiter used to separate each label for training a multi-label classifier. The default delimiter between labels is a pipe (|). You can use a different character as a delimiter (if it's an allowed character) by specifying it under Delimiter for labels. If the training documents use a delimiter other than the default or the delimiter you specify, the labels on that line will be combined to make a single unique label, such as LABELLABELLABEL.\n")
    s3_uri: typing.Optional[str] = pydantic.Field(None, description='The Amazon S3 URI for the input data. The S3 bucket must be in the same Region as the API endpoint that you are calling. The URI can point to a single input file or it can provide the prefix for a collection of input files. For example, if you use the URI ``S3://bucketName/prefix`` , if the prefix is a single file, Amazon Comprehend uses that file as input. If more than one file begins with the prefix, Amazon Comprehend uses all of them as input. This parameter is required if you set ``DataFormat`` to ``COMPREHEND_CSV`` .\n')
    test_s3_uri: typing.Optional[str] = pydantic.Field(None, description='This specifies the Amazon S3 location that contains the test annotations for the document classifier. The URI must be in the same AWS Region as the API endpoint that you are calling.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-documentclassifier-documentclassifierinputdataconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    document_classifier_input_data_config_property = comprehend.CfnDocumentClassifier.DocumentClassifierInputDataConfigProperty(\n        augmented_manifests=[comprehend.CfnDocumentClassifier.AugmentedManifestsListItemProperty(\n            attribute_names=["attributeNames"],\n            s3_uri="s3Uri",\n\n            # the properties below are optional\n            split="split"\n        )],\n        data_format="dataFormat",\n        document_reader_config=comprehend.CfnDocumentClassifier.DocumentReaderConfigProperty(\n            document_read_action="documentReadAction",\n\n            # the properties below are optional\n            document_read_mode="documentReadMode",\n            feature_types=["featureTypes"]\n        ),\n        documents=comprehend.CfnDocumentClassifier.DocumentClassifierDocumentsProperty(\n            s3_uri="s3Uri",\n\n            # the properties below are optional\n            test_s3_uri="testS3Uri"\n        ),\n        document_type="documentType",\n        label_delimiter="labelDelimiter",\n        s3_uri="s3Uri",\n        test_s3_uri="testS3Uri"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['augmented_manifests', 'data_format', 'document_reader_config', 'documents', 'document_type', 'label_delimiter', 's3_uri', 'test_s3_uri']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnDocumentClassifier.DocumentClassifierInputDataConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnDocumentClassifier.DocumentClassifierOutputDataConfigProperty
class CfnDocumentClassifier_DocumentClassifierOutputDataConfigPropertyDef(BaseStruct):
    kms_key_id: typing.Optional[str] = pydantic.Field(None, description='ID for the AWS Key Management Service (KMS) key that Amazon Comprehend uses to encrypt the output results from an analysis job. The KmsKeyId can be one of the following formats: - KMS Key ID: ``"1234abcd-12ab-34cd-56ef-1234567890ab"`` - Amazon Resource Name (ARN) of a KMS Key: ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"`` - KMS Key Alias: ``"alias/ExampleAlias"`` - ARN of a KMS Key Alias: ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``\n')
    s3_uri: typing.Optional[str] = pydantic.Field(None, description='When you use the ``OutputDataConfig`` object while creating a custom classifier, you specify the Amazon S3 location where you want to write the confusion matrix and other output files. The URI must be in the same Region as the API endpoint that you are calling. The location is used as the prefix for the actual location of this output file. When the custom classifier job is finished, the service creates the output file in a directory specific to the job. The ``S3Uri`` field contains the location of the output file, called ``output.tar.gz`` . It is a compressed archive that contains the confusion matrix.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-documentclassifier-documentclassifieroutputdataconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    document_classifier_output_data_config_property = comprehend.CfnDocumentClassifier.DocumentClassifierOutputDataConfigProperty(\n        kms_key_id="kmsKeyId",\n        s3_uri="s3Uri"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['kms_key_id', 's3_uri']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnDocumentClassifier.DocumentClassifierOutputDataConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnDocumentClassifier.DocumentReaderConfigProperty
class CfnDocumentClassifier_DocumentReaderConfigPropertyDef(BaseStruct):
    document_read_action: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='This field defines the Amazon Textract API operation that Amazon Comprehend uses to extract text from PDF files and image files. Enter one of the following values: - ``TEXTRACT_DETECT_DOCUMENT_TEXT`` - The Amazon Comprehend service uses the ``DetectDocumentText`` API operation. - ``TEXTRACT_ANALYZE_DOCUMENT`` - The Amazon Comprehend service uses the ``AnalyzeDocument`` API operation.\n')
    document_read_mode: typing.Optional[str] = pydantic.Field(None, description='Determines the text extraction actions for PDF files. Enter one of the following values:. - ``SERVICE_DEFAULT`` - use the Amazon Comprehend service defaults for PDF files. - ``FORCE_DOCUMENT_READ_ACTION`` - Amazon Comprehend uses the Textract API specified by DocumentReadAction for all PDF files, including digital PDF files.\n')
    feature_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='Specifies the type of Amazon Textract features to apply. If you chose ``TEXTRACT_ANALYZE_DOCUMENT`` as the read action, you must specify one or both of the following values: - ``TABLES`` - Returns information about any tables that are detected in the input document. - ``FORMS`` - Returns information and the data from any forms that are detected in the input document.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-documentclassifier-documentreaderconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    document_reader_config_property = comprehend.CfnDocumentClassifier.DocumentReaderConfigProperty(\n        document_read_action="documentReadAction",\n\n        # the properties below are optional\n        document_read_mode="documentReadMode",\n        feature_types=["featureTypes"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['document_read_action', 'document_read_mode', 'feature_types']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnDocumentClassifier.DocumentReaderConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnDocumentClassifier.VpcConfigProperty
class CfnDocumentClassifier_VpcConfigPropertyDef(BaseStruct):
    security_group_ids: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ID number for a security group on an instance of your private VPC. Security groups on your VPC function serve as a virtual firewall to control inbound and outbound traffic and provides security for the resources that you’ll be accessing on the VPC. This ID number is preceded by "sg-", for instance: "sg-03b388029b0a285ea". For more information, see `Security Groups for your VPC <https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html>`_ .\n')
    subnets: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ID for each subnet being used in your private VPC. This subnet is a subset of the a range of IPv4 addresses used by the VPC and is specific to a given availability zone in the VPC’s Region. This ID number is preceded by "subnet-", for instance: "subnet-04ccf456919e69055". For more information, see `VPCs and Subnets <https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-documentclassifier-vpcconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    vpc_config_property = comprehend.CfnDocumentClassifier.VpcConfigProperty(\n        security_group_ids=["securityGroupIds"],\n        subnets=["subnets"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['security_group_ids', 'subnets']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnDocumentClassifier.VpcConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnFlywheel.DataSecurityConfigProperty
class CfnFlywheel_DataSecurityConfigPropertyDef(BaseStruct):
    data_lake_kms_key_id: typing.Optional[str] = pydantic.Field(None, description='ID for the AWS KMS key that Amazon Comprehend uses to encrypt the data in the data lake.\n')
    model_kms_key_id: typing.Optional[str] = pydantic.Field(None, description='ID for the AWS KMS key that Amazon Comprehend uses to encrypt trained custom models. The ModelKmsKeyId can be either of the following formats: - KMS Key ID: ``"1234abcd-12ab-34cd-56ef-1234567890ab"`` - Amazon Resource Name (ARN) of a KMS Key: ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``\n')
    volume_kms_key_id: typing.Optional[str] = pydantic.Field(None, description='ID for the AWS KMS key that Amazon Comprehend uses to encrypt the volume.\n')
    vpc_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_VpcConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configuration parameters for an optional private Virtual Private Cloud (VPC) containing the resources you are using for the job. For more information, see `Amazon VPC <https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-flywheel-datasecurityconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    data_security_config_property = comprehend.CfnFlywheel.DataSecurityConfigProperty(\n        data_lake_kms_key_id="dataLakeKmsKeyId",\n        model_kms_key_id="modelKmsKeyId",\n        volume_kms_key_id="volumeKmsKeyId",\n        vpc_config=comprehend.CfnFlywheel.VpcConfigProperty(\n            security_group_ids=["securityGroupIds"],\n            subnets=["subnets"]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['data_lake_kms_key_id', 'model_kms_key_id', 'volume_kms_key_id', 'vpc_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnFlywheel.DataSecurityConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnFlywheel.DocumentClassificationConfigProperty
class CfnFlywheel_DocumentClassificationConfigPropertyDef(BaseStruct):
    mode: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Classification mode indicates whether the documents are ``MULTI_CLASS`` or ``MULTI_LABEL`` .\n')
    labels: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='One or more labels to associate with the custom classifier.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-flywheel-documentclassificationconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    document_classification_config_property = comprehend.CfnFlywheel.DocumentClassificationConfigProperty(\n        mode="mode",\n\n        # the properties below are optional\n        labels=["labels"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['mode', 'labels']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnFlywheel.DocumentClassificationConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnFlywheel.EntityRecognitionConfigProperty
class CfnFlywheel_EntityRecognitionConfigPropertyDef(BaseStruct):
    entity_types: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_EntityTypesListItemPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Up to 25 entity types that the model is trained to recognize.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-flywheel-entityrecognitionconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    entity_recognition_config_property = comprehend.CfnFlywheel.EntityRecognitionConfigProperty(\n        entity_types=[comprehend.CfnFlywheel.EntityTypesListItemProperty(\n            type="type"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['entity_types']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnFlywheel.EntityRecognitionConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnFlywheel.EntityTypesListItemProperty
class CfnFlywheel_EntityTypesListItemPropertyDef(BaseStruct):
    type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='An entity type within a labeled training dataset that Amazon Comprehend uses to train a custom entity recognizer. Entity types must not contain the following invalid characters: \\n (line break), \\n (escaped line break, \\r (carriage return), \\r (escaped carriage return), \\t (tab), \\t (escaped tab), space, and , (comma).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-flywheel-entitytypeslistitem.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    entity_types_list_item_property = comprehend.CfnFlywheel.EntityTypesListItemProperty(\n        type="type"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnFlywheel.EntityTypesListItemProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnFlywheel.TaskConfigProperty
class CfnFlywheel_TaskConfigPropertyDef(BaseStruct):
    language_code: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Language code for the language that the model supports.\n')
    document_classification_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_DocumentClassificationConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configuration required for a document classification model.\n')
    entity_recognition_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_EntityRecognitionConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configuration required for an entity recognition model.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-flywheel-taskconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    task_config_property = comprehend.CfnFlywheel.TaskConfigProperty(\n        language_code="languageCode",\n\n        # the properties below are optional\n        document_classification_config=comprehend.CfnFlywheel.DocumentClassificationConfigProperty(\n            mode="mode",\n\n            # the properties below are optional\n            labels=["labels"]\n        ),\n        entity_recognition_config=comprehend.CfnFlywheel.EntityRecognitionConfigProperty(\n            entity_types=[comprehend.CfnFlywheel.EntityTypesListItemProperty(\n                type="type"\n            )]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['language_code', 'document_classification_config', 'entity_recognition_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnFlywheel.TaskConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnFlywheel.VpcConfigProperty
class CfnFlywheel_VpcConfigPropertyDef(BaseStruct):
    security_group_ids: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ID number for a security group on an instance of your private VPC. Security groups on your VPC function serve as a virtual firewall to control inbound and outbound traffic and provides security for the resources that you’ll be accessing on the VPC. This ID number is preceded by "sg-", for instance: "sg-03b388029b0a285ea". For more information, see `Security Groups for your VPC <https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html>`_ .\n')
    subnets: typing.Union[typing.Sequence[str], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ID for each subnet being used in your private VPC. This subnet is a subset of the a range of IPv4 addresses used by the VPC and is specific to a given availability zone in the VPC’s Region. This ID number is preceded by "subnet-", for instance: "subnet-04ccf456919e69055". For more information, see `VPCs and Subnets <https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-comprehend-flywheel-vpcconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    vpc_config_property = comprehend.CfnFlywheel.VpcConfigProperty(\n        security_group_ids=["securityGroupIds"],\n        subnets=["subnets"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['security_group_ids', 'subnets']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnFlywheel.VpcConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnDocumentClassifier
class CfnDocumentClassifierDef(BaseCfnResource):
    data_access_role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the IAM role that grants Amazon Comprehend read access to your input data.\n')
    document_classifier_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the document classifier.\n')
    input_data_config: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_DocumentClassifierInputDataConfigPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the format and location of the input data for the job.\n')
    language_code: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The language of the input documents. You can specify any of the languages supported by Amazon Comprehend. All documents must be in the same language.\n')
    mode: typing.Optional[str] = pydantic.Field(None, description='Indicates the mode in which the classifier will be trained. The classifier can be trained in multi-class mode, which identifies one and only one class for each document, or multi-label mode, which identifies one or more labels for each document. In multi-label mode, multiple labels for an individual document are separated by a delimiter. The default delimiter between labels is a pipe (|).\n')
    model_kms_key_id: typing.Optional[str] = pydantic.Field(None, description='ID for the AWS KMS key that Amazon Comprehend uses to encrypt trained custom models. The ModelKmsKeyId can be either of the following formats: - KMS Key ID: ``"1234abcd-12ab-34cd-56ef-1234567890ab"`` - Amazon Resource Name (ARN) of a KMS Key: ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``\n')
    model_policy: typing.Optional[str] = pydantic.Field(None, description='The resource-based policy to attach to your custom document classifier model. You can use this policy to allow another AWS account to import your custom model. Provide your policy as a JSON body that you enter as a UTF-8 encoded string without line breaks. To provide valid JSON, enclose the attribute names and values in double quotes. If the JSON body is also enclosed in double quotes, then you must escape the double quotes that are inside the policy: ``"{\\"attribute\\": \\"value\\", \\"attribute\\": [\\"value\\"]}"`` To avoid escaping quotes, you can use single quotes to enclose the policy and double quotes to enclose the JSON names and values: ``\'{"attribute": "value", "attribute": ["value"]}\'``\n')
    output_data_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_DocumentClassifierOutputDataConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Provides output results configuration parameters for custom classifier jobs.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Tags to associate with the document classifier. A tag is a key-value pair that adds as a metadata to a resource used by Amazon Comprehend. For example, a tag with "Sales" as the key might be added to a resource to indicate its use by the sales department.\n')
    version_name: typing.Optional[str] = pydantic.Field(None, description='The version name given to the newly created classifier. Version names can have a maximum of 256 characters. Alphanumeric characters, hyphens (-) and underscores (_) are allowed. The version name must be unique among all models with the same classifier name in the AWS account / AWS Region .\n')
    volume_kms_key_id: typing.Optional[str] = pydantic.Field(None, description='ID for the AWS Key Management Service (KMS) key that Amazon Comprehend uses to encrypt data on the storage volume attached to the ML compute instance(s) that process the analysis job. The VolumeKmsKeyId can be either of the following formats: - KMS Key ID: ``"1234abcd-12ab-34cd-56ef-1234567890ab"`` - Amazon Resource Name (ARN) of a KMS Key: ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``\n')
    vpc_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_VpcConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configuration parameters for a private Virtual Private Cloud (VPC) containing the resources you are using for your custom classifier. For more information, see `Amazon VPC <https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html>`_ .')
    _init_params: typing.ClassVar[list[str]] = ['data_access_role_arn', 'document_classifier_name', 'input_data_config', 'language_code', 'mode', 'model_kms_key_id', 'model_policy', 'output_data_config', 'tags', 'version_name', 'volume_kms_key_id', 'vpc_config']
    _method_names: typing.ClassVar[list[str]] = ['AugmentedManifestsListItemProperty', 'DocumentClassifierDocumentsProperty', 'DocumentClassifierInputDataConfigProperty', 'DocumentClassifierOutputDataConfigProperty', 'DocumentReaderConfigProperty', 'VpcConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnDocumentClassifier'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnDocumentClassifierDefConfig] = pydantic.Field(None)


class CfnDocumentClassifierDefConfig(pydantic.BaseModel):
    AugmentedManifestsListItemProperty: typing.Optional[list[CfnDocumentClassifierDefAugmentedmanifestslistitempropertyParams]] = pydantic.Field(None, description='')
    DocumentClassifierDocumentsProperty: typing.Optional[list[CfnDocumentClassifierDefDocumentclassifierdocumentspropertyParams]] = pydantic.Field(None, description='')
    DocumentClassifierInputDataConfigProperty: typing.Optional[list[CfnDocumentClassifierDefDocumentclassifierinputdataconfigpropertyParams]] = pydantic.Field(None, description='')
    DocumentClassifierOutputDataConfigProperty: typing.Optional[list[CfnDocumentClassifierDefDocumentclassifieroutputdataconfigpropertyParams]] = pydantic.Field(None, description='')
    DocumentReaderConfigProperty: typing.Optional[list[CfnDocumentClassifierDefDocumentreaderconfigpropertyParams]] = pydantic.Field(None, description='')
    VpcConfigProperty: typing.Optional[list[CfnDocumentClassifierDefVpcconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnDocumentClassifierDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnDocumentClassifierDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnDocumentClassifierDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnDocumentClassifierDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnDocumentClassifierDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnDocumentClassifierDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnDocumentClassifierDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnDocumentClassifierDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnDocumentClassifierDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnDocumentClassifierDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnDocumentClassifierDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnDocumentClassifierDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnDocumentClassifierDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnDocumentClassifierDefAugmentedmanifestslistitempropertyParams(pydantic.BaseModel):
    attribute_names: typing.Sequence[str] = pydantic.Field(..., description='')
    s3_uri: str = pydantic.Field(..., description='')
    split: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDocumentClassifierDefDocumentclassifierdocumentspropertyParams(pydantic.BaseModel):
    s3_uri: str = pydantic.Field(..., description='')
    test_s3_uri: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDocumentClassifierDefDocumentclassifierinputdataconfigpropertyParams(pydantic.BaseModel):
    augmented_manifests: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_AugmentedManifestsListItemPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    data_format: typing.Optional[str] = pydantic.Field(None, description='')
    document_reader_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_DocumentReaderConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    documents: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_DocumentClassifierDocumentsPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    document_type: typing.Optional[str] = pydantic.Field(None, description='')
    label_delimiter: typing.Optional[str] = pydantic.Field(None, description='')
    s3_uri: typing.Optional[str] = pydantic.Field(None, description='')
    test_s3_uri: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDocumentClassifierDefDocumentclassifieroutputdataconfigpropertyParams(pydantic.BaseModel):
    kms_key_id: typing.Optional[str] = pydantic.Field(None, description='')
    s3_uri: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDocumentClassifierDefDocumentreaderconfigpropertyParams(pydantic.BaseModel):
    document_read_action: str = pydantic.Field(..., description='')
    document_read_mode: typing.Optional[str] = pydantic.Field(None, description='')
    feature_types: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnDocumentClassifierDefVpcconfigpropertyParams(pydantic.BaseModel):
    security_group_ids: typing.Sequence[str] = pydantic.Field(..., description='')
    subnets: typing.Sequence[str] = pydantic.Field(..., description='')
    ...

class CfnDocumentClassifierDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnDocumentClassifierDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDocumentClassifierDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnDocumentClassifierDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDocumentClassifierDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnDocumentClassifierDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnDocumentClassifierDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnDocumentClassifierDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnDocumentClassifierDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnDocumentClassifierDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDocumentClassifierDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnDocumentClassifierDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnDocumentClassifierDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDocumentClassifierDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_comprehend.CfnFlywheel
class CfnFlywheelDef(BaseCfnResource):
    data_access_role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the IAM role that grants Amazon Comprehend permission to access the flywheel data.\n')
    data_lake_s3_uri: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Amazon S3 URI of the data lake location.\n')
    flywheel_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Name for the flywheel.\n')
    active_model_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Number (ARN) of the active model version.\n')
    data_security_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_DataSecurityConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Data security configuration.\n')
    model_type: typing.Optional[str] = pydantic.Field(None, description="Model type of the flywheel's model.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Tags associated with the endpoint being created. A tag is a key-value pair that adds metadata to the endpoint. For example, a tag with "Sales" as the key might be added to an endpoint to indicate its use by the sales department.\n')
    task_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_TaskConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configuration about the model associated with a flywheel.')
    _init_params: typing.ClassVar[list[str]] = ['data_access_role_arn', 'data_lake_s3_uri', 'flywheel_name', 'active_model_arn', 'data_security_config', 'model_type', 'tags', 'task_config']
    _method_names: typing.ClassVar[list[str]] = ['DataSecurityConfigProperty', 'DocumentClassificationConfigProperty', 'EntityRecognitionConfigProperty', 'EntityTypesListItemProperty', 'TaskConfigProperty', 'VpcConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnFlywheel'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnFlywheelDefConfig] = pydantic.Field(None)


class CfnFlywheelDefConfig(pydantic.BaseModel):
    DataSecurityConfigProperty: typing.Optional[list[CfnFlywheelDefDatasecurityconfigpropertyParams]] = pydantic.Field(None, description='')
    DocumentClassificationConfigProperty: typing.Optional[list[CfnFlywheelDefDocumentclassificationconfigpropertyParams]] = pydantic.Field(None, description='')
    EntityRecognitionConfigProperty: typing.Optional[list[CfnFlywheelDefEntityrecognitionconfigpropertyParams]] = pydantic.Field(None, description='')
    EntityTypesListItemProperty: typing.Optional[list[CfnFlywheelDefEntitytypeslistitempropertyParams]] = pydantic.Field(None, description='')
    TaskConfigProperty: typing.Optional[list[CfnFlywheelDefTaskconfigpropertyParams]] = pydantic.Field(None, description='')
    VpcConfigProperty: typing.Optional[list[CfnFlywheelDefVpcconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnFlywheelDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnFlywheelDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnFlywheelDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnFlywheelDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnFlywheelDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnFlywheelDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnFlywheelDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnFlywheelDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnFlywheelDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnFlywheelDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnFlywheelDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnFlywheelDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnFlywheelDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')
    tags_config: typing.Optional[models.core.TagManagerDefConfig] = pydantic.Field(None)

class CfnFlywheelDefDatasecurityconfigpropertyParams(pydantic.BaseModel):
    data_lake_kms_key_id: typing.Optional[str] = pydantic.Field(None, description='')
    model_kms_key_id: typing.Optional[str] = pydantic.Field(None, description='')
    volume_kms_key_id: typing.Optional[str] = pydantic.Field(None, description='')
    vpc_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_VpcConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnFlywheelDefDocumentclassificationconfigpropertyParams(pydantic.BaseModel):
    mode: str = pydantic.Field(..., description='')
    labels: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnFlywheelDefEntityrecognitionconfigpropertyParams(pydantic.BaseModel):
    entity_types: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_EntityTypesListItemPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnFlywheelDefEntitytypeslistitempropertyParams(pydantic.BaseModel):
    type: str = pydantic.Field(..., description='')
    ...

class CfnFlywheelDefTaskconfigpropertyParams(pydantic.BaseModel):
    language_code: str = pydantic.Field(..., description='')
    document_classification_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_DocumentClassificationConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    entity_recognition_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_EntityRecognitionConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnFlywheelDefVpcconfigpropertyParams(pydantic.BaseModel):
    security_group_ids: typing.Sequence[str] = pydantic.Field(..., description='')
    subnets: typing.Sequence[str] = pydantic.Field(..., description='')
    ...

class CfnFlywheelDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnFlywheelDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnFlywheelDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnFlywheelDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnFlywheelDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnFlywheelDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnFlywheelDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnFlywheelDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnFlywheelDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnFlywheelDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnFlywheelDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnFlywheelDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnFlywheelDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnFlywheelDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_comprehend.CfnDocumentClassifierProps
class CfnDocumentClassifierPropsDef(BaseCfnProperty):
    data_access_role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the IAM role that grants Amazon Comprehend read access to your input data.\n')
    document_classifier_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the document classifier.\n')
    input_data_config: typing.Union[_REQUIRED_INIT_PARAM, models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_DocumentClassifierInputDataConfigPropertyDef, dict[str, typing.Any]] = pydantic.Field(REQUIRED_INIT_PARAM, description='Specifies the format and location of the input data for the job.\n')
    language_code: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The language of the input documents. You can specify any of the languages supported by Amazon Comprehend. All documents must be in the same language.\n')
    mode: typing.Optional[str] = pydantic.Field(None, description='Indicates the mode in which the classifier will be trained. The classifier can be trained in multi-class mode, which identifies one and only one class for each document, or multi-label mode, which identifies one or more labels for each document. In multi-label mode, multiple labels for an individual document are separated by a delimiter. The default delimiter between labels is a pipe (|).\n')
    model_kms_key_id: typing.Optional[str] = pydantic.Field(None, description='ID for the AWS KMS key that Amazon Comprehend uses to encrypt trained custom models. The ModelKmsKeyId can be either of the following formats: - KMS Key ID: ``"1234abcd-12ab-34cd-56ef-1234567890ab"`` - Amazon Resource Name (ARN) of a KMS Key: ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``\n')
    model_policy: typing.Optional[str] = pydantic.Field(None, description='The resource-based policy to attach to your custom document classifier model. You can use this policy to allow another AWS account to import your custom model. Provide your policy as a JSON body that you enter as a UTF-8 encoded string without line breaks. To provide valid JSON, enclose the attribute names and values in double quotes. If the JSON body is also enclosed in double quotes, then you must escape the double quotes that are inside the policy: ``"{\\"attribute\\": \\"value\\", \\"attribute\\": [\\"value\\"]}"`` To avoid escaping quotes, you can use single quotes to enclose the policy and double quotes to enclose the JSON names and values: ``\'{"attribute": "value", "attribute": ["value"]}\'``\n')
    output_data_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_DocumentClassifierOutputDataConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Provides output results configuration parameters for custom classifier jobs.\n')
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Tags to associate with the document classifier. A tag is a key-value pair that adds as a metadata to a resource used by Amazon Comprehend. For example, a tag with "Sales" as the key might be added to a resource to indicate its use by the sales department.\n')
    version_name: typing.Optional[str] = pydantic.Field(None, description='The version name given to the newly created classifier. Version names can have a maximum of 256 characters. Alphanumeric characters, hyphens (-) and underscores (_) are allowed. The version name must be unique among all models with the same classifier name in the AWS account / AWS Region .\n')
    volume_kms_key_id: typing.Optional[str] = pydantic.Field(None, description='ID for the AWS Key Management Service (KMS) key that Amazon Comprehend uses to encrypt data on the storage volume attached to the ML compute instance(s) that process the analysis job. The VolumeKmsKeyId can be either of the following formats: - KMS Key ID: ``"1234abcd-12ab-34cd-56ef-1234567890ab"`` - Amazon Resource Name (ARN) of a KMS Key: ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``\n')
    vpc_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnDocumentClassifier_VpcConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configuration parameters for a private Virtual Private Cloud (VPC) containing the resources you are using for your custom classifier. For more information, see `Amazon VPC <https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html>`_ .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-comprehend-documentclassifier.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    cfn_document_classifier_props = comprehend.CfnDocumentClassifierProps(\n        data_access_role_arn="dataAccessRoleArn",\n        document_classifier_name="documentClassifierName",\n        input_data_config=comprehend.CfnDocumentClassifier.DocumentClassifierInputDataConfigProperty(\n            augmented_manifests=[comprehend.CfnDocumentClassifier.AugmentedManifestsListItemProperty(\n                attribute_names=["attributeNames"],\n                s3_uri="s3Uri",\n\n                # the properties below are optional\n                split="split"\n            )],\n            data_format="dataFormat",\n            document_reader_config=comprehend.CfnDocumentClassifier.DocumentReaderConfigProperty(\n                document_read_action="documentReadAction",\n\n                # the properties below are optional\n                document_read_mode="documentReadMode",\n                feature_types=["featureTypes"]\n            ),\n            documents=comprehend.CfnDocumentClassifier.DocumentClassifierDocumentsProperty(\n                s3_uri="s3Uri",\n\n                # the properties below are optional\n                test_s3_uri="testS3Uri"\n            ),\n            document_type="documentType",\n            label_delimiter="labelDelimiter",\n            s3_uri="s3Uri",\n            test_s3_uri="testS3Uri"\n        ),\n        language_code="languageCode",\n\n        # the properties below are optional\n        mode="mode",\n        model_kms_key_id="modelKmsKeyId",\n        model_policy="modelPolicy",\n        output_data_config=comprehend.CfnDocumentClassifier.DocumentClassifierOutputDataConfigProperty(\n            kms_key_id="kmsKeyId",\n            s3_uri="s3Uri"\n        ),\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        version_name="versionName",\n        volume_kms_key_id="volumeKmsKeyId",\n        vpc_config=comprehend.CfnDocumentClassifier.VpcConfigProperty(\n            security_group_ids=["securityGroupIds"],\n            subnets=["subnets"]\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['data_access_role_arn', 'document_classifier_name', 'input_data_config', 'language_code', 'mode', 'model_kms_key_id', 'model_policy', 'output_data_config', 'tags', 'version_name', 'volume_kms_key_id', 'vpc_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnDocumentClassifierProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_comprehend.CfnFlywheelProps
class CfnFlywheelPropsDef(BaseCfnProperty):
    data_access_role_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the IAM role that grants Amazon Comprehend permission to access the flywheel data.\n')
    data_lake_s3_uri: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Amazon S3 URI of the data lake location.\n')
    flywheel_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Name for the flywheel.\n')
    active_model_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Number (ARN) of the active model version.\n')
    data_security_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_DataSecurityConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Data security configuration.\n')
    model_type: typing.Optional[str] = pydantic.Field(None, description="Model type of the flywheel's model.\n")
    tags: typing.Optional[typing.Sequence[typing.Union[models.CfnTagDef, dict[str, typing.Any]]]] = pydantic.Field(None, description='Tags associated with the endpoint being created. A tag is a key-value pair that adds metadata to the endpoint. For example, a tag with "Sales" as the key might be added to an endpoint to indicate its use by the sales department.\n')
    task_config: typing.Union[models.UnsupportedResource, models.aws_comprehend.CfnFlywheel_TaskConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Configuration about the model associated with a flywheel.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-comprehend-flywheel.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_comprehend as comprehend\n\n    cfn_flywheel_props = comprehend.CfnFlywheelProps(\n        data_access_role_arn="dataAccessRoleArn",\n        data_lake_s3_uri="dataLakeS3Uri",\n        flywheel_name="flywheelName",\n\n        # the properties below are optional\n        active_model_arn="activeModelArn",\n        data_security_config=comprehend.CfnFlywheel.DataSecurityConfigProperty(\n            data_lake_kms_key_id="dataLakeKmsKeyId",\n            model_kms_key_id="modelKmsKeyId",\n            volume_kms_key_id="volumeKmsKeyId",\n            vpc_config=comprehend.CfnFlywheel.VpcConfigProperty(\n                security_group_ids=["securityGroupIds"],\n                subnets=["subnets"]\n            )\n        ),\n        model_type="modelType",\n        tags=[CfnTag(\n            key="key",\n            value="value"\n        )],\n        task_config=comprehend.CfnFlywheel.TaskConfigProperty(\n            language_code="languageCode",\n\n            # the properties below are optional\n            document_classification_config=comprehend.CfnFlywheel.DocumentClassificationConfigProperty(\n                mode="mode",\n\n                # the properties below are optional\n                labels=["labels"]\n            ),\n            entity_recognition_config=comprehend.CfnFlywheel.EntityRecognitionConfigProperty(\n                entity_types=[comprehend.CfnFlywheel.EntityTypesListItemProperty(\n                    type="type"\n                )]\n            )\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['data_access_role_arn', 'data_lake_s3_uri', 'flywheel_name', 'active_model_arn', 'data_security_config', 'model_type', 'tags', 'task_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_comprehend.CfnFlywheelProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




import models

class ModuleModel(pydantic.BaseModel):
    CfnDocumentClassifier_AugmentedManifestsListItemProperty: typing.Optional[dict[str, CfnDocumentClassifier_AugmentedManifestsListItemPropertyDef]] = pydantic.Field(None)
    CfnDocumentClassifier_DocumentClassifierDocumentsProperty: typing.Optional[dict[str, CfnDocumentClassifier_DocumentClassifierDocumentsPropertyDef]] = pydantic.Field(None)
    CfnDocumentClassifier_DocumentClassifierInputDataConfigProperty: typing.Optional[dict[str, CfnDocumentClassifier_DocumentClassifierInputDataConfigPropertyDef]] = pydantic.Field(None)
    CfnDocumentClassifier_DocumentClassifierOutputDataConfigProperty: typing.Optional[dict[str, CfnDocumentClassifier_DocumentClassifierOutputDataConfigPropertyDef]] = pydantic.Field(None)
    CfnDocumentClassifier_DocumentReaderConfigProperty: typing.Optional[dict[str, CfnDocumentClassifier_DocumentReaderConfigPropertyDef]] = pydantic.Field(None)
    CfnDocumentClassifier_VpcConfigProperty: typing.Optional[dict[str, CfnDocumentClassifier_VpcConfigPropertyDef]] = pydantic.Field(None)
    CfnFlywheel_DataSecurityConfigProperty: typing.Optional[dict[str, CfnFlywheel_DataSecurityConfigPropertyDef]] = pydantic.Field(None)
    CfnFlywheel_DocumentClassificationConfigProperty: typing.Optional[dict[str, CfnFlywheel_DocumentClassificationConfigPropertyDef]] = pydantic.Field(None)
    CfnFlywheel_EntityRecognitionConfigProperty: typing.Optional[dict[str, CfnFlywheel_EntityRecognitionConfigPropertyDef]] = pydantic.Field(None)
    CfnFlywheel_EntityTypesListItemProperty: typing.Optional[dict[str, CfnFlywheel_EntityTypesListItemPropertyDef]] = pydantic.Field(None)
    CfnFlywheel_TaskConfigProperty: typing.Optional[dict[str, CfnFlywheel_TaskConfigPropertyDef]] = pydantic.Field(None)
    CfnFlywheel_VpcConfigProperty: typing.Optional[dict[str, CfnFlywheel_VpcConfigPropertyDef]] = pydantic.Field(None)
    CfnDocumentClassifier: typing.Optional[dict[str, CfnDocumentClassifierDef]] = pydantic.Field(None)
    CfnFlywheel: typing.Optional[dict[str, CfnFlywheelDef]] = pydantic.Field(None)
    CfnDocumentClassifierProps: typing.Optional[dict[str, CfnDocumentClassifierPropsDef]] = pydantic.Field(None)
    CfnFlywheelProps: typing.Optional[dict[str, CfnFlywheelPropsDef]] = pydantic.Field(None)
    ...
