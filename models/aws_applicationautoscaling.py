from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_applicationautoscaling.BaseScalableAttribute
class BaseScalableAttributeDef(BaseClass):
    dimension: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Scalable dimension of the attribute.\n')
    resource_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Resource ID of the attribute.\n')
    role: typing.Union[_REQUIRED_INIT_PARAM, models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='Role to use for scaling.\n')
    service_namespace: typing.Union[aws_cdk.aws_applicationautoscaling.ServiceNamespace, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Service namespace of the scalable attribute.\n')
    max_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='Maximum capacity to scale to.\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum capacity to scale to. Default: 1')
    _init_params: typing.ClassVar[list[str]] = ['dimension', 'resource_id', 'role', 'service_namespace', 'max_capacity', 'min_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.BaseScalableAttribute'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.Schedule
class ScheduleDef(BaseClass):
    _init_params: typing.ClassVar[list[str]] = []
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = ['at', 'cron', 'expression', 'rate']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.Schedule'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_applicationautoscaling.ScheduleDefConfig] = pydantic.Field(None)


class ScheduleDefConfig(pydantic.BaseModel):
    at: typing.Optional[list[models.aws_applicationautoscaling.ScheduleDefAtParams]] = pydantic.Field(None, description='Construct a Schedule from a moment in time.')
    cron: typing.Optional[list[models.aws_applicationautoscaling.ScheduleDefCronParams]] = pydantic.Field(None, description='Create a schedule from a set of cron fields.')
    expression: typing.Optional[list[models.aws_applicationautoscaling.ScheduleDefExpressionParams]] = pydantic.Field(None, description='Construct a schedule from a literal schedule expression.')
    rate: typing.Optional[list[models.aws_applicationautoscaling.ScheduleDefRateParams]] = pydantic.Field(None, description='Construct a schedule from an interval and a time unit.')

class ScheduleDefAtParams(pydantic.BaseModel):
    moment: datetime.datetime = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_applicationautoscaling.ScheduleDefConfig]] = pydantic.Field(None)
    ...

class ScheduleDefCronParams(pydantic.BaseModel):
    day: typing.Optional[str] = pydantic.Field(None, description='The day of the month to run this rule at. Default: - Every day of the month\n')
    hour: typing.Optional[str] = pydantic.Field(None, description='The hour to run this rule at. Default: - Every hour\n')
    minute: typing.Optional[str] = pydantic.Field(None, description='The minute to run this rule at. Default: - Every minute\n')
    month: typing.Optional[str] = pydantic.Field(None, description='The month to run this rule at. Default: - Every month\n')
    week_day: typing.Optional[str] = pydantic.Field(None, description='The day of the week to run this rule at. Default: - Any day of the week\n')
    year: typing.Optional[str] = pydantic.Field(None, description='The year to run this rule at. Default: - Every year')
    return_config: typing.Optional[list[models.aws_applicationautoscaling.ScheduleDefConfig]] = pydantic.Field(None)
    ...

class ScheduleDefExpressionParams(pydantic.BaseModel):
    expression: str = pydantic.Field(..., description='The expression to use. Must be in a format that Application AutoScaling will recognize')
    return_config: typing.Optional[list[models.aws_applicationautoscaling.ScheduleDefConfig]] = pydantic.Field(None)
    ...

class ScheduleDefRateParams(pydantic.BaseModel):
    duration: models.DurationDef = pydantic.Field(..., description='-')
    return_config: typing.Optional[list[models.aws_applicationautoscaling.ScheduleDefConfig]] = pydantic.Field(None)
    ...


#  autogenerated from aws_cdk.aws_applicationautoscaling.ScalableTarget
class ScalableTargetDef(BaseConstruct):
    max_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The maximum value that Application Auto Scaling can use to scale a target during a scaling activity.\n')
    min_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The minimum value that Application Auto Scaling can use to scale a target during a scaling activity.\n')
    resource_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The resource identifier to associate with this scalable target. This string consists of the resource type and unique identifier. Example value: ``service/ecsStack-MyECSCluster-AB12CDE3F4GH/ecsStack-MyECSService-AB12CDE3F4GH``\n')
    scalable_dimension: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The scalable dimension that's associated with the scalable target. Specify the service namespace, resource type, and scaling property. Example value: ``ecs:service:DesiredCount``\n")
    service_namespace: typing.Union[aws_cdk.aws_applicationautoscaling.ServiceNamespace, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The namespace of the AWS service that provides the resource or custom-resource for a resource provided by your own application or service. For valid AWS service namespace values, see the RegisterScalableTarget action in the Application Auto Scaling API Reference.\n')
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='Role that allows Application Auto Scaling to modify your scalable target. Default: A role is automatically created')
    _init_params: typing.ClassVar[list[str]] = ['max_capacity', 'min_capacity', 'resource_id', 'scalable_dimension', 'service_namespace', 'role']
    _method_names: typing.ClassVar[list[str]] = ['add_to_role_policy', 'apply_removal_policy', 'scale_on_metric', 'scale_on_schedule', 'scale_to_track_metric']
    _classmethod_names: typing.ClassVar[list[str]] = ['from_scalable_target_id']
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.ScalableTarget'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = ['from_scalable_target_id']
    ...


    from_scalable_target_id: typing.Optional[models.aws_applicationautoscaling.ScalableTargetDefFromScalableTargetIdParams] = pydantic.Field(None, description='')
    resource_config: typing.Optional[models.aws_applicationautoscaling.ScalableTargetDefConfig] = pydantic.Field(None)


class ScalableTargetDefConfig(pydantic.BaseModel):
    add_to_role_policy: typing.Optional[list[models.aws_applicationautoscaling.ScalableTargetDefAddToRolePolicyParams]] = pydantic.Field(None, description="Add a policy statement to the role's policy.")
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    scale_on_metric: typing.Optional[list[models.aws_applicationautoscaling.ScalableTargetDefScaleOnMetricParams]] = pydantic.Field(None, description='Scale out or in, in response to a metric.')
    scale_on_schedule: typing.Optional[list[models.aws_applicationautoscaling.ScalableTargetDefScaleOnScheduleParams]] = pydantic.Field(None, description='Scale out or in based on time.')
    scale_to_track_metric: typing.Optional[list[models.aws_applicationautoscaling.ScalableTargetDefScaleToTrackMetricParams]] = pydantic.Field(None, description='Scale out or in in order to keep a metric around a target value.')
    role_config: typing.Optional[models._interface_methods.AwsIamIRoleDefConfig] = pydantic.Field(None)

class ScalableTargetDefAddToRolePolicyParams(pydantic.BaseModel):
    statement: models.aws_iam.PolicyStatementDef = pydantic.Field(..., description='-')
    ...

class ScalableTargetDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: aws_cdk.RemovalPolicy = pydantic.Field(..., description='-')
    ...

class ScalableTargetDefFromScalableTargetIdParams(pydantic.BaseModel):
    scope: models.constructs.ConstructDef = pydantic.Field(..., description='-')
    id: str = pydantic.Field(..., description='-\n')
    scalable_target_id: str = pydantic.Field(..., description='-')
    ...

class ScalableTargetDefScaleOnMetricParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    metric: typing.Union[models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef] = pydantic.Field(..., description='Metric to scale on.\n')
    scaling_steps: typing.Sequence[typing.Union[models.aws_applicationautoscaling.ScalingIntervalDef, dict[str, typing.Any]]] = pydantic.Field(..., description='The intervals for scaling. Maps a range of metric values to a particular scaling behavior. Must be between 2 and 40 steps.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_applicationautoscaling.AdjustmentType] = pydantic.Field(None, description="How the adjustment numbers inside 'intervals' are interpreted. Default: ChangeInCapacity\n")
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Grace period after scaling activity. Subsequent scale outs during the cooldown period are squashed so that only the biggest scale out happens. Subsequent scale ins during the cooldown period are ignored. Default: No cooldown period\n')
    datapoints_to_alarm: typing.Union[int, float, None] = pydantic.Field(None, description='The number of data points out of the evaluation periods that must be breaching to trigger a scaling action. Creates an "M out of N" alarm, where this property is the M and the value set for ``evaluationPeriods`` is the N value. Only has meaning if ``evaluationPeriods != 1``. Default: ``evaluationPeriods``\n')
    evaluation_periods: typing.Union[int, float, None] = pydantic.Field(None, description='How many evaluation periods of the metric to wait before triggering a scaling action. Raising this value can be used to smooth out the metric, at the expense of slower response times. If ``datapointsToAlarm`` is not set, then all data points in the evaluation period must meet the criteria to trigger a scaling action. Default: 1\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_applicationautoscaling.MetricAggregationType] = pydantic.Field(None, description='Aggregation to apply to all data points over the evaluation periods. Only has meaning if ``evaluationPeriods != 1``. Default: - The statistic from the metric if applicable (MIN, MAX, AVERAGE), otherwise AVERAGE.\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect')
    ...

class ScalableTargetDefScaleOnScheduleParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    schedule: models.aws_applicationautoscaling.ScheduleDef = pydantic.Field(..., description='When to perform this action.\n')
    end_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action expires. Default: The rule never expires.\n')
    max_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new maximum capacity. During the scheduled time, the current capacity is above the maximum capacity, Application Auto Scaling scales in to the maximum capacity. At least one of maxCapacity and minCapacity must be supplied. Default: No new maximum capacity\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new minimum capacity. During the scheduled time, if the current capacity is below the minimum capacity, Application Auto Scaling scales out to the minimum capacity. At least one of maxCapacity and minCapacity must be supplied. Default: No new minimum capacity\n')
    start_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action becomes active. Default: The rule is activate immediately')
    ...

class ScalableTargetDefScaleToTrackMetricParams(pydantic.BaseModel):
    id: str = pydantic.Field(..., description='-\n')
    target_value: typing.Union[int, float] = pydantic.Field(..., description='The target value for the metric.\n')
    custom_metric: typing.Optional[typing.Union[models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef]] = pydantic.Field(None, description='A custom metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No custom metric.\n')
    predefined_metric: typing.Optional[aws_cdk.aws_applicationautoscaling.PredefinedMetric] = pydantic.Field(None, description='A predefined metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No predefined metrics.\n')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='Identify the resource associated with the metric type. Only used for predefined metric ALBRequestCountPerTarget. Example value: ``app/<load-balancer-name>/<load-balancer-id>/targetgroup/<target-group-name>/<target-group-id>`` Default: - No resource label.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the scalable resource. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the scalable resource. Default: false\n")
    policy_name: typing.Optional[str] = pydantic.Field(None, description='A name for the scaling policy. Default: - Automatically generated name.\n')
    scale_in_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale in activity completes before another scale in activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency\n')
    scale_out_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale out activity completes before another scale out activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency')
    ...


#  autogenerated from aws_cdk.aws_applicationautoscaling.StepScalingAction
class StepScalingActionDef(BaseConstruct):
    scaling_target: typing.Union[_REQUIRED_INIT_PARAM, models.aws_applicationautoscaling.ScalableTargetDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The scalable target.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_applicationautoscaling.AdjustmentType] = pydantic.Field(None, description='How the adjustment numbers are interpreted. Default: ChangeInCapacity\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Grace period after scaling activity. For scale out policies, multiple scale outs during the cooldown period are squashed so that only the biggest scale out happens. For scale in policies, subsequent scale ins during the cooldown period are ignored. Default: No cooldown period\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_applicationautoscaling.MetricAggregationType] = pydantic.Field(None, description='The aggregation type for the CloudWatch metrics. Default: Average\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect\n')
    policy_name: typing.Optional[str] = pydantic.Field(None, description='A name for the scaling policy. Default: Automatically generated name')
    _init_params: typing.ClassVar[list[str]] = ['scaling_target', 'adjustment_type', 'cooldown', 'metric_aggregation_type', 'min_adjustment_magnitude', 'policy_name']
    _method_names: typing.ClassVar[list[str]] = ['add_adjustment']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.StepScalingAction'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_applicationautoscaling.StepScalingActionDefConfig] = pydantic.Field(None)


class StepScalingActionDefConfig(pydantic.BaseModel):
    add_adjustment: typing.Optional[list[models.aws_applicationautoscaling.StepScalingActionDefAddAdjustmentParams]] = pydantic.Field(None, description='Add an adjusment interval to the ScalingAction.')

class StepScalingActionDefAddAdjustmentParams(pydantic.BaseModel):
    adjustment: typing.Union[int, float] = pydantic.Field(..., description='What number to adjust the capacity with. The number is interpeted as an added capacity, a new fixed capacity or an added percentage depending on the AdjustmentType value of the StepScalingPolicy. Can be positive or negative.\n')
    lower_bound: typing.Union[int, float, None] = pydantic.Field(None, description='Lower bound where this scaling tier applies. The scaling tier applies if the difference between the metric value and its alarm threshold is higher than this value. Default: -Infinity if this is the first tier, otherwise the upperBound of the previous tier\n')
    upper_bound: typing.Union[int, float, None] = pydantic.Field(None, description='Upper bound where this scaling tier applies. The scaling tier applies if the difference between the metric value and its alarm threshold is lower than this value. Default: +Infinity')
    ...


#  autogenerated from aws_cdk.aws_applicationautoscaling.StepScalingPolicy
class StepScalingPolicyDef(BaseConstruct):
    scaling_target: typing.Union[_REQUIRED_INIT_PARAM, models.aws_applicationautoscaling.ScalableTargetDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The scaling target.\n')
    metric: typing.Union[_REQUIRED_INIT_PARAM, models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='Metric to scale on.\n')
    scaling_steps: typing.Union[typing.Sequence[typing.Union[models.aws_applicationautoscaling.ScalingIntervalDef, dict[str, typing.Any]]], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The intervals for scaling. Maps a range of metric values to a particular scaling behavior. Must be between 2 and 40 steps.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_applicationautoscaling.AdjustmentType] = pydantic.Field(None, description="How the adjustment numbers inside 'intervals' are interpreted. Default: ChangeInCapacity\n")
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Grace period after scaling activity. Subsequent scale outs during the cooldown period are squashed so that only the biggest scale out happens. Subsequent scale ins during the cooldown period are ignored. Default: No cooldown period\n')
    datapoints_to_alarm: typing.Union[int, float, None] = pydantic.Field(None, description='The number of data points out of the evaluation periods that must be breaching to trigger a scaling action. Creates an "M out of N" alarm, where this property is the M and the value set for ``evaluationPeriods`` is the N value. Only has meaning if ``evaluationPeriods != 1``. Default: ``evaluationPeriods``\n')
    evaluation_periods: typing.Union[int, float, None] = pydantic.Field(None, description='How many evaluation periods of the metric to wait before triggering a scaling action. Raising this value can be used to smooth out the metric, at the expense of slower response times. If ``datapointsToAlarm`` is not set, then all data points in the evaluation period must meet the criteria to trigger a scaling action. Default: 1\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_applicationautoscaling.MetricAggregationType] = pydantic.Field(None, description='Aggregation to apply to all data points over the evaluation periods. Only has meaning if ``evaluationPeriods != 1``. Default: - The statistic from the metric if applicable (MIN, MAX, AVERAGE), otherwise AVERAGE.\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect')
    _init_params: typing.ClassVar[list[str]] = ['scaling_target', 'metric', 'scaling_steps', 'adjustment_type', 'cooldown', 'datapoints_to_alarm', 'evaluation_periods', 'metric_aggregation_type', 'min_adjustment_magnitude']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.StepScalingPolicy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.TargetTrackingScalingPolicy
class TargetTrackingScalingPolicyDef(BaseConstruct):
    scaling_target: typing.Union[_REQUIRED_INIT_PARAM, models.aws_applicationautoscaling.ScalableTargetDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='')
    target_value: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The target value for the metric.\n')
    custom_metric: typing.Optional[typing.Union[models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef]] = pydantic.Field(None, description='A custom metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No custom metric.\n')
    predefined_metric: typing.Optional[aws_cdk.aws_applicationautoscaling.PredefinedMetric] = pydantic.Field(None, description='A predefined metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No predefined metrics.\n')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='Identify the resource associated with the metric type. Only used for predefined metric ALBRequestCountPerTarget. Example value: ``app/<load-balancer-name>/<load-balancer-id>/targetgroup/<target-group-name>/<target-group-id>`` Default: - No resource label.\n')
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the scalable resource. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the scalable resource. Default: false\n")
    policy_name: typing.Optional[str] = pydantic.Field(None, description='A name for the scaling policy. Default: - Automatically generated name.\n')
    scale_in_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale in activity completes before another scale in activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency\n')
    scale_out_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale out activity completes before another scale out activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency')
    _init_params: typing.ClassVar[list[str]] = ['scaling_target', 'target_value', 'custom_metric', 'predefined_metric', 'resource_label', 'disable_scale_in', 'policy_name', 'scale_in_cooldown', 'scale_out_cooldown']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.TargetTrackingScalingPolicy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.AdjustmentTier
class AdjustmentTierDef(BaseStruct):
    adjustment: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='What number to adjust the capacity with. The number is interpeted as an added capacity, a new fixed capacity or an added percentage depending on the AdjustmentType value of the StepScalingPolicy. Can be positive or negative.\n')
    lower_bound: typing.Union[int, float, None] = pydantic.Field(None, description='Lower bound where this scaling tier applies. The scaling tier applies if the difference between the metric value and its alarm threshold is higher than this value. Default: -Infinity if this is the first tier, otherwise the upperBound of the previous tier\n')
    upper_bound: typing.Union[int, float, None] = pydantic.Field(None, description='Upper bound where this scaling tier applies. The scaling tier applies if the difference between the metric value and its alarm threshold is lower than this value. Default: +Infinity\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    adjustment_tier = appscaling.AdjustmentTier(\n        adjustment=123,\n\n        # the properties below are optional\n        lower_bound=123,\n        upper_bound=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['adjustment', 'lower_bound', 'upper_bound']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.AdjustmentTier'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.BaseScalableAttributeProps
class BaseScalableAttributePropsDef(BaseStruct):
    max_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='Maximum capacity to scale to.\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum capacity to scale to. Default: 1\n')
    dimension: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Scalable dimension of the attribute.\n')
    resource_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Resource ID of the attribute.\n')
    role: typing.Union[_REQUIRED_INIT_PARAM, models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='Role to use for scaling.\n')
    service_namespace: typing.Union[aws_cdk.aws_applicationautoscaling.ServiceNamespace, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='Service namespace of the scalable attribute.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n    from aws_cdk import aws_iam as iam\n\n    # role: iam.Role\n\n    base_scalable_attribute_props = appscaling.BaseScalableAttributeProps(\n        dimension="dimension",\n        max_capacity=123,\n        resource_id="resourceId",\n        role=role,\n        service_namespace=appscaling.ServiceNamespace.ECS,\n\n        # the properties below are optional\n        min_capacity=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_capacity', 'min_capacity', 'dimension', 'resource_id', 'role', 'service_namespace']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.BaseScalableAttributeProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_applicationautoscaling.BaseScalableAttributePropsDefConfig] = pydantic.Field(None)


class BaseScalableAttributePropsDefConfig(pydantic.BaseModel):
    role_config: typing.Optional[models._interface_methods.AwsIamIRoleDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_applicationautoscaling.BaseTargetTrackingProps
class BaseTargetTrackingPropsDef(BaseStruct):
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the scalable resource. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the scalable resource. Default: false\n")
    policy_name: typing.Optional[str] = pydantic.Field(None, description='A name for the scaling policy. Default: - Automatically generated name.\n')
    scale_in_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale in activity completes before another scale in activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency\n')
    scale_out_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale out activity completes before another scale out activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    base_target_tracking_props = appscaling.BaseTargetTrackingProps(\n        disable_scale_in=False,\n        policy_name="policyName",\n        scale_in_cooldown=cdk.Duration.minutes(30),\n        scale_out_cooldown=cdk.Duration.minutes(30)\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['disable_scale_in', 'policy_name', 'scale_in_cooldown', 'scale_out_cooldown']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.BaseTargetTrackingProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.BasicStepScalingPolicyProps
class BasicStepScalingPolicyPropsDef(BaseStruct):
    metric: typing.Union[_REQUIRED_INIT_PARAM, models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='Metric to scale on.')
    scaling_steps: typing.Union[typing.Sequence[typing.Union[models.aws_applicationautoscaling.ScalingIntervalDef, dict[str, typing.Any]]], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The intervals for scaling. Maps a range of metric values to a particular scaling behavior. Must be between 2 and 40 steps.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_applicationautoscaling.AdjustmentType] = pydantic.Field(None, description="How the adjustment numbers inside 'intervals' are interpreted. Default: ChangeInCapacity\n")
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Grace period after scaling activity. Subsequent scale outs during the cooldown period are squashed so that only the biggest scale out happens. Subsequent scale ins during the cooldown period are ignored. Default: No cooldown period\n')
    datapoints_to_alarm: typing.Union[int, float, None] = pydantic.Field(None, description='The number of data points out of the evaluation periods that must be breaching to trigger a scaling action. Creates an "M out of N" alarm, where this property is the M and the value set for ``evaluationPeriods`` is the N value. Only has meaning if ``evaluationPeriods != 1``. Default: ``evaluationPeriods``\n')
    evaluation_periods: typing.Union[int, float, None] = pydantic.Field(None, description='How many evaluation periods of the metric to wait before triggering a scaling action. Raising this value can be used to smooth out the metric, at the expense of slower response times. If ``datapointsToAlarm`` is not set, then all data points in the evaluation period must meet the criteria to trigger a scaling action. Default: 1\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_applicationautoscaling.MetricAggregationType] = pydantic.Field(None, description='Aggregation to apply to all data points over the evaluation periods. Only has meaning if ``evaluationPeriods != 1``. Default: - The statistic from the metric if applicable (MIN, MAX, AVERAGE), otherwise AVERAGE.\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect\n\n:exampleMetadata: infused\n\nExample::\n\n    # capacity: ScalableAttribute\n    # cpu_utilization: cloudwatch.Metric\n\n\n    capacity.scale_on_metric("ScaleToCPU",\n        metric=cpu_utilization,\n        scaling_steps=[appscaling.ScalingInterval(upper=10, change=-1), appscaling.ScalingInterval(lower=50, change=+1), appscaling.ScalingInterval(lower=70, change=+3)\n        ],\n\n        # Change this to AdjustmentType.PercentChangeInCapacity to interpret the\n        # \'change\' numbers before as percentages instead of capacity counts.\n        adjustment_type=appscaling.AdjustmentType.CHANGE_IN_CAPACITY\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric', 'scaling_steps', 'adjustment_type', 'cooldown', 'datapoints_to_alarm', 'evaluation_periods', 'metric_aggregation_type', 'min_adjustment_magnitude']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.BasicStepScalingPolicyProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.BasicTargetTrackingScalingPolicyProps
class BasicTargetTrackingScalingPolicyPropsDef(BaseStruct):
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the scalable resource. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the scalable resource. Default: false\n")
    policy_name: typing.Optional[str] = pydantic.Field(None, description='A name for the scaling policy. Default: - Automatically generated name.\n')
    scale_in_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale in activity completes before another scale in activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency\n')
    scale_out_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale out activity completes before another scale out activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency\n')
    target_value: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The target value for the metric.\n')
    custom_metric: typing.Optional[typing.Union[models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef]] = pydantic.Field(None, description='A custom metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No custom metric.\n')
    predefined_metric: typing.Optional[aws_cdk.aws_applicationautoscaling.PredefinedMetric] = pydantic.Field(None, description='A predefined metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No predefined metrics.\n')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='Identify the resource associated with the metric type. Only used for predefined metric ALBRequestCountPerTarget. Example value: ``app/<load-balancer-name>/<load-balancer-id>/targetgroup/<target-group-name>/<target-group-id>`` Default: - No resource label.\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_lambda as lambda_\n\n    # code: lambda.Code\n\n\n    handler = lambda_.Function(self, "MyFunction",\n        runtime=lambda_.Runtime.PYTHON_3_7,\n        handler="index.handler",\n        code=code,\n\n        reserved_concurrent_executions=2\n    )\n\n    fn_ver = handler.current_version\n\n    target = appscaling.ScalableTarget(self, "ScalableTarget",\n        service_namespace=appscaling.ServiceNamespace.LAMBDA,\n        max_capacity=100,\n        min_capacity=10,\n        resource_id=f"function:{handler.functionName}:{fnVer.version}",\n        scalable_dimension="lambda:function:ProvisionedConcurrency"\n    )\n\n    target.scale_to_track_metric("PceTracking",\n        target_value=0.9,\n        predefined_metric=appscaling.PredefinedMetric.LAMBDA_PROVISIONED_CONCURRENCY_UTILIZATION\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['disable_scale_in', 'policy_name', 'scale_in_cooldown', 'scale_out_cooldown', 'target_value', 'custom_metric', 'predefined_metric', 'resource_label']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.BasicTargetTrackingScalingPolicyProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalableTarget.ScalableTargetActionProperty
class CfnScalableTarget_ScalableTargetActionPropertyDef(BaseStruct):
    max_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum capacity.\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum capacity.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-applicationautoscaling-scalabletarget-scalabletargetaction.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    scalable_target_action_property = appscaling.CfnScalableTarget.ScalableTargetActionProperty(\n        max_capacity=123,\n        min_capacity=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_capacity', 'min_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalableTarget.ScalableTargetActionProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalableTarget.ScheduledActionProperty
class CfnScalableTarget_ScheduledActionPropertyDef(BaseStruct):
    schedule: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The schedule for this action. The following formats are supported:. - At expressions - " ``at( *yyyy* - *mm* - *dd* T *hh* : *mm* : *ss* )`` " - Rate expressions - " ``rate( *value* *unit* )`` " - Cron expressions - " ``cron( *fields* )`` " At expressions are useful for one-time schedules. Cron expressions are useful for scheduled actions that run periodically at a specified date and time, and rate expressions are useful for scheduled actions that run at a regular interval. At and cron expressions use Universal Coordinated Time (UTC) by default. The cron format consists of six fields separated by white spaces: [Minutes] [Hours] [Day_of_Month] [Month] [Day_of_Week] [Year]. For rate expressions, *value* is a positive integer and *unit* is ``minute`` | ``minutes`` | ``hour`` | ``hours`` | ``day`` | ``days`` .\n')
    scheduled_action_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the scheduled action. This name must be unique among all other scheduled actions on the specified scalable target.\n')
    end_time: typing.Union[models.UnsupportedResource, datetime.datetime, None] = pydantic.Field(None, description='The date and time that the action is scheduled to end, in UTC.\n')
    scalable_target_action: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalableTarget_ScalableTargetActionPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The new minimum and maximum capacity. You can set both values or just one. At the scheduled time, if the current capacity is below the minimum capacity, Application Auto Scaling scales out to the minimum capacity. If the current capacity is above the maximum capacity, Application Auto Scaling scales in to the maximum capacity.\n')
    start_time: typing.Union[models.UnsupportedResource, datetime.datetime, None] = pydantic.Field(None, description='The date and time that the action is scheduled to begin, in UTC.\n')
    timezone: typing.Optional[str] = pydantic.Field(None, description='The time zone used when referring to the date and time of a scheduled action, when the scheduled action uses an at or cron expression.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-applicationautoscaling-scalabletarget-scheduledaction.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    scheduled_action_property = appscaling.CfnScalableTarget.ScheduledActionProperty(\n        schedule="schedule",\n        scheduled_action_name="scheduledActionName",\n\n        # the properties below are optional\n        end_time=Date(),\n        scalable_target_action=appscaling.CfnScalableTarget.ScalableTargetActionProperty(\n            max_capacity=123,\n            min_capacity=123\n        ),\n        start_time=Date(),\n        timezone="timezone"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['schedule', 'scheduled_action_name', 'end_time', 'scalable_target_action', 'start_time', 'timezone']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalableTarget.ScheduledActionProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalableTarget.SuspendedStateProperty
class CfnScalableTarget_SuspendedStatePropertyDef(BaseStruct):
    dynamic_scaling_in_suspended: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="Whether scale in by a target tracking scaling policy or a step scaling policy is suspended. Set the value to ``true`` if you don't want Application Auto Scaling to remove capacity when a scaling policy is triggered. The default is ``false`` .\n")
    dynamic_scaling_out_suspended: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="Whether scale out by a target tracking scaling policy or a step scaling policy is suspended. Set the value to ``true`` if you don't want Application Auto Scaling to add capacity when a scaling policy is triggered. The default is ``false`` .\n")
    scheduled_scaling_suspended: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="Whether scheduled scaling is suspended. Set the value to ``true`` if you don't want Application Auto Scaling to add or remove capacity by initiating scheduled actions. The default is ``false`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-applicationautoscaling-scalabletarget-suspendedstate.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    suspended_state_property = appscaling.CfnScalableTarget.SuspendedStateProperty(\n        dynamic_scaling_in_suspended=False,\n        dynamic_scaling_out_suspended=False,\n        scheduled_scaling_suspended=False\n    )\n")
    _init_params: typing.ClassVar[list[str]] = ['dynamic_scaling_in_suspended', 'dynamic_scaling_out_suspended', 'scheduled_scaling_suspended']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalableTarget.SuspendedStateProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.CustomizedMetricSpecificationProperty
class CfnScalingPolicy_CustomizedMetricSpecificationPropertyDef(BaseStruct):
    metric_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The name of the metric. To get the exact metric name, namespace, and dimensions, inspect the `Metric <https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Metric.html>`_ object that's returned by a call to `ListMetrics <https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html>`_ .\n")
    namespace: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The namespace of the metric.\n')
    statistic: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The statistic of the metric.\n')
    dimensions: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_MetricDimensionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='The dimensions of the metric. Conditional: If you published your metric with dimensions, you must specify the same dimensions in your scaling policy.\n')
    unit: typing.Optional[str] = pydantic.Field(None, description='The unit of the metric. For a complete list of the units that CloudWatch supports, see the `MetricDatum <https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDatum.html>`_ data type in the *Amazon CloudWatch API Reference* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-applicationautoscaling-scalingpolicy-customizedmetricspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    customized_metric_specification_property = appscaling.CfnScalingPolicy.CustomizedMetricSpecificationProperty(\n        metric_name="metricName",\n        namespace="namespace",\n        statistic="statistic",\n\n        # the properties below are optional\n        dimensions=[appscaling.CfnScalingPolicy.MetricDimensionProperty(\n            name="name",\n            value="value"\n        )],\n        unit="unit"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric_name', 'namespace', 'statistic', 'dimensions', 'unit']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.CustomizedMetricSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.MetricDimensionProperty
class CfnScalingPolicy_MetricDimensionPropertyDef(BaseStruct):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the dimension.\n')
    value: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The value of the dimension.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-applicationautoscaling-scalingpolicy-metricdimension.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    metric_dimension_property = appscaling.CfnScalingPolicy.MetricDimensionProperty(\n        name="name",\n        value="value"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'value']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.MetricDimensionProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.PredefinedMetricSpecificationProperty
class CfnScalingPolicy_PredefinedMetricSpecificationPropertyDef(BaseStruct):
    predefined_metric_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The metric type. The ``ALBRequestCountPerTarget`` metric type applies only to Spot fleet requests and ECS services.\n')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='Identifies the resource associated with the metric type. You can\'t specify a resource label unless the metric type is ``ALBRequestCountPerTarget`` and there is a target group attached to the Spot Fleet or ECS service. You create the resource label by appending the final portion of the load balancer ARN and the final portion of the target group ARN into a single value, separated by a forward slash (/). The format of the resource label is: ``app/my-alb/778d41231b141a0f/targetgroup/my-alb-target-group/943f017f100becff`` . Where: - app// is the final portion of the load balancer ARN - targetgroup// is the final portion of the target group ARN. To find the ARN for an Application Load Balancer, use the `DescribeLoadBalancers <https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeLoadBalancers.html>`_ API operation. To find the ARN for the target group, use the `DescribeTargetGroups <https://docs.aws.amazon.com/elasticloadbalancing/latest/APIReference/API_DescribeTargetGroups.html>`_ API operation.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-applicationautoscaling-scalingpolicy-predefinedmetricspecification.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    predefined_metric_specification_property = appscaling.CfnScalingPolicy.PredefinedMetricSpecificationProperty(\n        predefined_metric_type="predefinedMetricType",\n\n        # the properties below are optional\n        resource_label="resourceLabel"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['predefined_metric_type', 'resource_label']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.PredefinedMetricSpecificationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.StepAdjustmentProperty
class CfnScalingPolicy_StepAdjustmentPropertyDef(BaseStruct):
    scaling_adjustment: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The amount by which to scale. The adjustment is based on the value that you specified in the ``AdjustmentType`` property (either an absolute number or a percentage). A positive value adds to the current capacity and a negative number subtracts from the current capacity.\n')
    metric_interval_lower_bound: typing.Union[int, float, None] = pydantic.Field(None, description='The lower bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the lower bound is inclusive (the metric must be greater than or equal to the threshold plus the lower bound). Otherwise, it is exclusive (the metric must be greater than the threshold plus the lower bound). A null value indicates negative infinity. You must specify at least one upper or lower bound.\n')
    metric_interval_upper_bound: typing.Union[int, float, None] = pydantic.Field(None, description='The upper bound for the difference between the alarm threshold and the CloudWatch metric. If the metric value is above the breach threshold, the upper bound is exclusive (the metric must be less than the threshold plus the upper bound). Otherwise, it is inclusive (the metric must be less than or equal to the threshold plus the upper bound). A null value indicates positive infinity. You must specify at least one upper or lower bound.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-applicationautoscaling-scalingpolicy-stepadjustment.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    step_adjustment_property = appscaling.CfnScalingPolicy.StepAdjustmentProperty(\n        scaling_adjustment=123,\n\n        # the properties below are optional\n        metric_interval_lower_bound=123,\n        metric_interval_upper_bound=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['scaling_adjustment', 'metric_interval_lower_bound', 'metric_interval_upper_bound']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.StepAdjustmentProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.StepScalingPolicyConfigurationProperty
class CfnScalingPolicy_StepScalingPolicyConfigurationPropertyDef(BaseStruct):
    adjustment_type: typing.Optional[str] = pydantic.Field(None, description='Specifies whether the ``ScalingAdjustment`` value in the ``StepAdjustment`` property is an absolute number or a percentage of the current capacity.\n')
    cooldown: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time, in seconds, to wait for a previous scaling activity to take effect. If not specified, the default value is 300. For more information, see `Cooldown period <https://docs.aws.amazon.com/autoscaling/application/userguide/step-scaling-policy-overview.html#step-scaling-cooldown>`_ in the *Application Auto Scaling User Guide* .\n')
    metric_aggregation_type: typing.Optional[str] = pydantic.Field(None, description='The aggregation type for the CloudWatch metrics. Valid values are ``Minimum`` , ``Maximum`` , and ``Average`` . If the aggregation type is null, the value is treated as ``Average`` .\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum value to scale by when the adjustment type is ``PercentChangeInCapacity`` . For example, suppose that you create a step scaling policy to scale out an Amazon ECS service by 25 percent and you specify a ``MinAdjustmentMagnitude`` of 2. If the service has 4 tasks and the scaling policy is performed, 25 percent of 4 is 1. However, because you specified a ``MinAdjustmentMagnitude`` of 2, Application Auto Scaling scales out the service by 2 tasks.\n')
    step_adjustments: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_StepAdjustmentPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='A set of adjustments that enable you to scale based on the size of the alarm breach. At least one step adjustment is required if you are adding a new step scaling policy configuration.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-applicationautoscaling-scalingpolicy-stepscalingpolicyconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    step_scaling_policy_configuration_property = appscaling.CfnScalingPolicy.StepScalingPolicyConfigurationProperty(\n        adjustment_type="adjustmentType",\n        cooldown=123,\n        metric_aggregation_type="metricAggregationType",\n        min_adjustment_magnitude=123,\n        step_adjustments=[appscaling.CfnScalingPolicy.StepAdjustmentProperty(\n            scaling_adjustment=123,\n\n            # the properties below are optional\n            metric_interval_lower_bound=123,\n            metric_interval_upper_bound=123\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['adjustment_type', 'cooldown', 'metric_aggregation_type', 'min_adjustment_magnitude', 'step_adjustments']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.StepScalingPolicyConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.TargetTrackingScalingPolicyConfigurationProperty
class CfnScalingPolicy_TargetTrackingScalingPolicyConfigurationPropertyDef(BaseStruct):
    target_value: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description="The target value for the metric. Although this property accepts numbers of type Double, it won't accept values that are either too small or too large. Values must be in the range of -2^360 to 2^360. The value must be a valid number based on the choice of metric. For example, if the metric is CPU utilization, then the target value is a percent value that represents how much of the CPU can be used before scaling out.\n")
    customized_metric_specification: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_CustomizedMetricSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A customized metric. You can specify either a predefined metric or a customized metric.\n')
    disable_scale_in: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description="Indicates whether scale in by the target tracking scaling policy is disabled. If the value is ``true`` , scale in is disabled and the target tracking scaling policy won't remove capacity from the scalable target. Otherwise, scale in is enabled and the target tracking scaling policy can remove capacity from the scalable target. The default value is ``false`` .\n")
    predefined_metric_specification: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_PredefinedMetricSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A predefined metric. You can specify either a predefined metric or a customized metric.\n')
    scale_in_cooldown: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time, in seconds, after a scale-in activity completes before another scale-in activity can start. For more information and for default values, see `Define cooldown periods <https://docs.aws.amazon.com/autoscaling/application/userguide/target-tracking-scaling-policy-overview.html#target-tracking-cooldown>`_ in the *Application Auto Scaling User Guide* .\n')
    scale_out_cooldown: typing.Union[int, float, None] = pydantic.Field(None, description='The amount of time, in seconds, to wait for a previous scale-out activity to take effect. For more information and for default values, see `Define cooldown periods <https://docs.aws.amazon.com/autoscaling/application/userguide/target-tracking-scaling-policy-overview.html#target-tracking-cooldown>`_ in the *Application Auto Scaling User Guide* .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-applicationautoscaling-scalingpolicy-targettrackingscalingpolicyconfiguration.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    target_tracking_scaling_policy_configuration_property = appscaling.CfnScalingPolicy.TargetTrackingScalingPolicyConfigurationProperty(\n        target_value=123,\n\n        # the properties below are optional\n        customized_metric_specification=appscaling.CfnScalingPolicy.CustomizedMetricSpecificationProperty(\n            metric_name="metricName",\n            namespace="namespace",\n            statistic="statistic",\n\n            # the properties below are optional\n            dimensions=[appscaling.CfnScalingPolicy.MetricDimensionProperty(\n                name="name",\n                value="value"\n            )],\n            unit="unit"\n        ),\n        disable_scale_in=False,\n        predefined_metric_specification=appscaling.CfnScalingPolicy.PredefinedMetricSpecificationProperty(\n            predefined_metric_type="predefinedMetricType",\n\n            # the properties below are optional\n            resource_label="resourceLabel"\n        ),\n        scale_in_cooldown=123,\n        scale_out_cooldown=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['target_value', 'customized_metric_specification', 'disable_scale_in', 'predefined_metric_specification', 'scale_in_cooldown', 'scale_out_cooldown']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalingPolicy.TargetTrackingScalingPolicyConfigurationProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.CronOptions
class CronOptionsDef(BaseStruct):
    day: typing.Optional[str] = pydantic.Field(None, description='The day of the month to run this rule at. Default: - Every day of the month\n')
    hour: typing.Optional[str] = pydantic.Field(None, description='The hour to run this rule at. Default: - Every hour\n')
    minute: typing.Optional[str] = pydantic.Field(None, description='The minute to run this rule at. Default: - Every minute\n')
    month: typing.Optional[str] = pydantic.Field(None, description='The month to run this rule at. Default: - Every month\n')
    week_day: typing.Optional[str] = pydantic.Field(None, description='The day of the week to run this rule at. Default: - Any day of the week\n')
    year: typing.Optional[str] = pydantic.Field(None, description='The year to run this rule at. Default: - Every year\n\n:see: https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html#CronExpressions\n:exampleMetadata: infused\n\nExample::\n\n    # cluster: ecs.Cluster\n\n    load_balanced_fargate_service = ecs_patterns.ApplicationLoadBalancedFargateService(self, "Service",\n        cluster=cluster,\n        memory_limit_mi_b=1024,\n        desired_count=1,\n        cpu=512,\n        task_image_options=ecsPatterns.ApplicationLoadBalancedTaskImageOptions(\n            image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")\n        )\n    )\n\n    scalable_target = load_balanced_fargate_service.service.auto_scale_task_count(\n        min_capacity=5,\n        max_capacity=20\n    )\n\n    scalable_target.scale_on_schedule("DaytimeScaleDown",\n        schedule=appscaling.Schedule.cron(hour="8", minute="0"),\n        min_capacity=1\n    )\n\n    scalable_target.scale_on_schedule("EveningRushScaleUp",\n        schedule=appscaling.Schedule.cron(hour="20", minute="0"),\n        min_capacity=10\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['day', 'hour', 'minute', 'month', 'week_day', 'year']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CronOptions'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.EnableScalingProps
class EnableScalingPropsDef(BaseStruct):
    max_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='Maximum capacity to scale to.\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum capacity to scale to. Default: 1\n\n:exampleMetadata: infused\n\nExample::\n\n    # cluster: ecs.Cluster\n\n    load_balanced_fargate_service = ecs_patterns.ApplicationLoadBalancedFargateService(self, "Service",\n        cluster=cluster,\n        memory_limit_mi_b=1024,\n        desired_count=1,\n        cpu=512,\n        task_image_options=ecsPatterns.ApplicationLoadBalancedTaskImageOptions(\n            image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")\n        )\n    )\n\n    scalable_target = load_balanced_fargate_service.service.auto_scale_task_count(\n        min_capacity=1,\n        max_capacity=20\n    )\n\n    scalable_target.scale_on_cpu_utilization("CpuScaling",\n        target_utilization_percent=50\n    )\n\n    scalable_target.scale_on_memory_utilization("MemoryScaling",\n        target_utilization_percent=50\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_capacity', 'min_capacity']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.EnableScalingProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.ScalableTargetProps
class ScalableTargetPropsDef(BaseStruct):
    max_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The maximum value that Application Auto Scaling can use to scale a target during a scaling activity.\n')
    min_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The minimum value that Application Auto Scaling can use to scale a target during a scaling activity.\n')
    resource_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The resource identifier to associate with this scalable target. This string consists of the resource type and unique identifier. Example value: ``service/ecsStack-MyECSCluster-AB12CDE3F4GH/ecsStack-MyECSService-AB12CDE3F4GH``\n')
    scalable_dimension: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The scalable dimension that's associated with the scalable target. Specify the service namespace, resource type, and scaling property. Example value: ``ecs:service:DesiredCount``\n")
    service_namespace: typing.Union[aws_cdk.aws_applicationautoscaling.ServiceNamespace, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The namespace of the AWS service that provides the resource or custom-resource for a resource provided by your own application or service. For valid AWS service namespace values, see the RegisterScalableTarget action in the Application Auto Scaling API Reference.\n')
    role: typing.Optional[typing.Union[models.aws_iam.LazyRoleDef, models.aws_iam.RoleDef]] = pydantic.Field(None, description='Role that allows Application Auto Scaling to modify your scalable target. Default: A role is automatically created\n\n:exampleMetadata: infused\n\nExample::\n\n    import aws_cdk.aws_lambda as lambda_\n\n    # code: lambda.Code\n\n\n    handler = lambda_.Function(self, "MyFunction",\n        runtime=lambda_.Runtime.PYTHON_3_7,\n        handler="index.handler",\n        code=code,\n\n        reserved_concurrent_executions=2\n    )\n\n    fn_ver = handler.current_version\n\n    target = appscaling.ScalableTarget(self, "ScalableTarget",\n        service_namespace=appscaling.ServiceNamespace.LAMBDA,\n        max_capacity=100,\n        min_capacity=10,\n        resource_id=f"function:{handler.functionName}:{fnVer.version}",\n        scalable_dimension="lambda:function:ProvisionedConcurrency"\n    )\n\n    target.scale_to_track_metric("PceTracking",\n        target_value=0.9,\n        predefined_metric=appscaling.PredefinedMetric.LAMBDA_PROVISIONED_CONCURRENCY_UTILIZATION\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_capacity', 'min_capacity', 'resource_id', 'scalable_dimension', 'service_namespace', 'role']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.ScalableTargetProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.ScalingInterval
class ScalingIntervalDef(BaseStruct):
    change: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The capacity adjustment to apply in this interval. The number is interpreted differently based on AdjustmentType: - ChangeInCapacity: add the adjustment to the current capacity. The number can be positive or negative. - PercentChangeInCapacity: add or remove the given percentage of the current capacity to itself. The number can be in the range [-100..100]. - ExactCapacity: set the capacity to this number. The number must be positive.\n')
    lower: typing.Union[int, float, None] = pydantic.Field(None, description='The lower bound of the interval. The scaling adjustment will be applied if the metric is higher than this value. Default: Threshold automatically derived from neighbouring intervals\n')
    upper: typing.Union[int, float, None] = pydantic.Field(None, description='The upper bound of the interval. The scaling adjustment will be applied if the metric is lower than this value. Default: Threshold automatically derived from neighbouring intervals\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    scaling_interval = appscaling.ScalingInterval(\n        change=123,\n\n        # the properties below are optional\n        lower=123,\n        upper=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['change', 'lower', 'upper']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.ScalingInterval'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.ScalingSchedule
class ScalingScheduleDef(BaseStruct):
    schedule: typing.Union[models.aws_applicationautoscaling.ScheduleDef, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='When to perform this action.\n')
    end_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action expires. Default: The rule never expires.\n')
    max_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new maximum capacity. During the scheduled time, the current capacity is above the maximum capacity, Application Auto Scaling scales in to the maximum capacity. At least one of maxCapacity and minCapacity must be supplied. Default: No new maximum capacity\n')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='The new minimum capacity. During the scheduled time, if the current capacity is below the minimum capacity, Application Auto Scaling scales out to the minimum capacity. At least one of maxCapacity and minCapacity must be supplied. Default: No new minimum capacity\n')
    start_time: typing.Optional[datetime.datetime] = pydantic.Field(None, description='When this scheduled action becomes active. Default: The rule is activate immediately\n\n:exampleMetadata: infused\n\nExample::\n\n    # cluster: ecs.Cluster\n\n    load_balanced_fargate_service = ecs_patterns.ApplicationLoadBalancedFargateService(self, "Service",\n        cluster=cluster,\n        memory_limit_mi_b=1024,\n        desired_count=1,\n        cpu=512,\n        task_image_options=ecsPatterns.ApplicationLoadBalancedTaskImageOptions(\n            image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")\n        )\n    )\n\n    scalable_target = load_balanced_fargate_service.service.auto_scale_task_count(\n        min_capacity=5,\n        max_capacity=20\n    )\n\n    scalable_target.scale_on_schedule("DaytimeScaleDown",\n        schedule=appscaling.Schedule.cron(hour="8", minute="0"),\n        min_capacity=1\n    )\n\n    scalable_target.scale_on_schedule("EveningRushScaleUp",\n        schedule=appscaling.Schedule.cron(hour="20", minute="0"),\n        min_capacity=10\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['schedule', 'end_time', 'max_capacity', 'min_capacity', 'start_time']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.ScalingSchedule'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.StepScalingActionProps
class StepScalingActionPropsDef(BaseStruct):
    scaling_target: typing.Union[_REQUIRED_INIT_PARAM, models.aws_applicationautoscaling.ScalableTargetDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The scalable target.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_applicationautoscaling.AdjustmentType] = pydantic.Field(None, description='How the adjustment numbers are interpreted. Default: ChangeInCapacity\n')
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Grace period after scaling activity. For scale out policies, multiple scale outs during the cooldown period are squashed so that only the biggest scale out happens. For scale in policies, subsequent scale ins during the cooldown period are ignored. Default: No cooldown period\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_applicationautoscaling.MetricAggregationType] = pydantic.Field(None, description='The aggregation type for the CloudWatch metrics. Default: Average\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect\n')
    policy_name: typing.Optional[str] = pydantic.Field(None, description='A name for the scaling policy. Default: Automatically generated name\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    # scalable_target: appscaling.ScalableTarget\n\n    step_scaling_action_props = appscaling.StepScalingActionProps(\n        scaling_target=scalable_target,\n\n        # the properties below are optional\n        adjustment_type=appscaling.AdjustmentType.CHANGE_IN_CAPACITY,\n        cooldown=cdk.Duration.minutes(30),\n        metric_aggregation_type=appscaling.MetricAggregationType.AVERAGE,\n        min_adjustment_magnitude=123,\n        policy_name="policyName"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['scaling_target', 'adjustment_type', 'cooldown', 'metric_aggregation_type', 'min_adjustment_magnitude', 'policy_name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.StepScalingActionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_applicationautoscaling.StepScalingActionPropsDefConfig] = pydantic.Field(None)


class StepScalingActionPropsDefConfig(pydantic.BaseModel):
    scaling_target_config: typing.Optional[models._interface_methods.AwsApplicationautoscalingIScalableTargetDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_applicationautoscaling.StepScalingPolicyProps
class StepScalingPolicyPropsDef(BaseStruct):
    metric: typing.Union[_REQUIRED_INIT_PARAM, models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='Metric to scale on.')
    scaling_steps: typing.Union[typing.Sequence[typing.Union[models.aws_applicationautoscaling.ScalingIntervalDef, dict[str, typing.Any]]], _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The intervals for scaling. Maps a range of metric values to a particular scaling behavior. Must be between 2 and 40 steps.\n')
    adjustment_type: typing.Optional[aws_cdk.aws_applicationautoscaling.AdjustmentType] = pydantic.Field(None, description="How the adjustment numbers inside 'intervals' are interpreted. Default: ChangeInCapacity\n")
    cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Grace period after scaling activity. Subsequent scale outs during the cooldown period are squashed so that only the biggest scale out happens. Subsequent scale ins during the cooldown period are ignored. Default: No cooldown period\n')
    datapoints_to_alarm: typing.Union[int, float, None] = pydantic.Field(None, description='The number of data points out of the evaluation periods that must be breaching to trigger a scaling action. Creates an "M out of N" alarm, where this property is the M and the value set for ``evaluationPeriods`` is the N value. Only has meaning if ``evaluationPeriods != 1``. Default: ``evaluationPeriods``\n')
    evaluation_periods: typing.Union[int, float, None] = pydantic.Field(None, description='How many evaluation periods of the metric to wait before triggering a scaling action. Raising this value can be used to smooth out the metric, at the expense of slower response times. If ``datapointsToAlarm`` is not set, then all data points in the evaluation period must meet the criteria to trigger a scaling action. Default: 1\n')
    metric_aggregation_type: typing.Optional[aws_cdk.aws_applicationautoscaling.MetricAggregationType] = pydantic.Field(None, description='Aggregation to apply to all data points over the evaluation periods. Only has meaning if ``evaluationPeriods != 1``. Default: - The statistic from the metric if applicable (MIN, MAX, AVERAGE), otherwise AVERAGE.\n')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='Minimum absolute number to adjust capacity with as result of percentage scaling. Only when using AdjustmentType = PercentChangeInCapacity, this number controls the minimum absolute effect size. Default: No minimum scaling effect\n')
    scaling_target: typing.Union[_REQUIRED_INIT_PARAM, models.aws_applicationautoscaling.ScalableTargetDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='The scaling target.\n\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    import aws_cdk as cdk\n    from aws_cdk import aws_applicationautoscaling as appscaling\n    from aws_cdk import aws_cloudwatch as cloudwatch\n\n    # metric: cloudwatch.Metric\n    # scalable_target: appscaling.ScalableTarget\n\n    step_scaling_policy_props = appscaling.StepScalingPolicyProps(\n        metric=metric,\n        scaling_steps=[appscaling.ScalingInterval(\n            change=123,\n\n            # the properties below are optional\n            lower=123,\n            upper=123\n        )],\n        scaling_target=scalable_target,\n\n        # the properties below are optional\n        adjustment_type=appscaling.AdjustmentType.CHANGE_IN_CAPACITY,\n        cooldown=cdk.Duration.minutes(30),\n        datapoints_to_alarm=123,\n        evaluation_periods=123,\n        metric_aggregation_type=appscaling.MetricAggregationType.AVERAGE,\n        min_adjustment_magnitude=123\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric', 'scaling_steps', 'adjustment_type', 'cooldown', 'datapoints_to_alarm', 'evaluation_periods', 'metric_aggregation_type', 'min_adjustment_magnitude', 'scaling_target']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.StepScalingPolicyProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_applicationautoscaling.StepScalingPolicyPropsDefConfig] = pydantic.Field(None)


class StepScalingPolicyPropsDefConfig(pydantic.BaseModel):
    scaling_target_config: typing.Optional[models._interface_methods.AwsApplicationautoscalingIScalableTargetDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_applicationautoscaling.TargetTrackingScalingPolicyProps
class TargetTrackingScalingPolicyPropsDef(BaseStruct):
    disable_scale_in: typing.Optional[bool] = pydantic.Field(None, description="Indicates whether scale in by the target tracking policy is disabled. If the value is true, scale in is disabled and the target tracking policy won't remove capacity from the scalable resource. Otherwise, scale in is enabled and the target tracking policy can remove capacity from the scalable resource. Default: false\n")
    policy_name: typing.Optional[str] = pydantic.Field(None, description='A name for the scaling policy. Default: - Automatically generated name.\n')
    scale_in_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale in activity completes before another scale in activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency\n')
    scale_out_cooldown: typing.Optional[models.DurationDef] = pydantic.Field(None, description='Period after a scale out activity completes before another scale out activity can start. Default: Duration.seconds(300) for the following scalable targets: ECS services, Spot Fleet requests, EMR clusters, AppStream 2.0 fleets, Aurora DB clusters, Amazon SageMaker endpoint variants, Custom resources. For all other scalable targets, the default value is Duration.seconds(0): DynamoDB tables, DynamoDB global secondary indexes, Amazon Comprehend document classification endpoints, Lambda provisioned concurrency\n')
    target_value: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The target value for the metric.\n')
    custom_metric: typing.Optional[typing.Union[models.aws_cloudwatch.MathExpressionDef, models.aws_cloudwatch.MetricDef]] = pydantic.Field(None, description='A custom metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No custom metric.\n')
    predefined_metric: typing.Optional[aws_cdk.aws_applicationautoscaling.PredefinedMetric] = pydantic.Field(None, description='A predefined metric for application autoscaling. The metric must track utilization. Scaling out will happen if the metric is higher than the target value, scaling in will happen in the metric is lower than the target value. Exactly one of customMetric or predefinedMetric must be specified. Default: - No predefined metrics.\n')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='Identify the resource associated with the metric type. Only used for predefined metric ALBRequestCountPerTarget. Example value: ``app/<load-balancer-name>/<load-balancer-id>/targetgroup/<target-group-name>/<target-group-id>`` Default: - No resource label.\n')
    scaling_target: typing.Union[_REQUIRED_INIT_PARAM, models.aws_applicationautoscaling.ScalableTargetDef] = pydantic.Field(REQUIRED_INIT_PARAM, description='')
    _init_params: typing.ClassVar[list[str]] = ['disable_scale_in', 'policy_name', 'scale_in_cooldown', 'scale_out_cooldown', 'target_value', 'custom_metric', 'predefined_metric', 'resource_label', 'scaling_target']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.TargetTrackingScalingPolicyProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_applicationautoscaling.TargetTrackingScalingPolicyPropsDefConfig] = pydantic.Field(None)


class TargetTrackingScalingPolicyPropsDefConfig(pydantic.BaseModel):
    scaling_target_config: typing.Optional[models._interface_methods.AwsApplicationautoscalingIScalableTargetDefConfig] = pydantic.Field(None)


#  autogenerated from aws_cdk.aws_applicationautoscaling.AdjustmentType
# skipping emum

#  autogenerated from aws_cdk.aws_applicationautoscaling.MetricAggregationType
# skipping emum

#  autogenerated from aws_cdk.aws_applicationautoscaling.PredefinedMetric
# skipping emum

#  autogenerated from aws_cdk.aws_applicationautoscaling.ServiceNamespace
# skipping emum

#  autogenerated from aws_cdk.aws_applicationautoscaling.IScalableTarget
#  skipping Interface

#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalableTarget
class CfnScalableTargetDef(BaseCfnResource):
    max_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The maximum value that you plan to scale out to. When a scaling policy is in effect, Application Auto Scaling can scale out (expand) as needed to the maximum capacity limit in response to changing demand.\n')
    min_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The minimum value that you plan to scale in to. When a scaling policy is in effect, Application Auto Scaling can scale in (contract) as needed to the minimum capacity limit in response to changing demand.\n')
    resource_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The identifier of the resource associated with the scalable target. This string consists of the resource type and unique identifier. - ECS service - The resource type is ``service`` and the unique identifier is the cluster name and service name. Example: ``service/default/sample-webapp`` . - Spot Fleet - The resource type is ``spot-fleet-request`` and the unique identifier is the Spot Fleet request ID. Example: ``spot-fleet-request/sfr-73fbd2ce-aa30-494c-8788-1cee4EXAMPLE`` . - EMR cluster - The resource type is ``instancegroup`` and the unique identifier is the cluster ID and instance group ID. Example: ``instancegroup/j-2EEZNYKUA1NTV/ig-1791Y4E1L8YI0`` . - AppStream 2.0 fleet - The resource type is ``fleet`` and the unique identifier is the fleet name. Example: ``fleet/sample-fleet`` . - DynamoDB table - The resource type is ``table`` and the unique identifier is the table name. Example: ``table/my-table`` . - DynamoDB global secondary index - The resource type is ``index`` and the unique identifier is the index name. Example: ``table/my-table/index/my-table-index`` . - Aurora DB cluster - The resource type is ``cluster`` and the unique identifier is the cluster name. Example: ``cluster:my-db-cluster`` . - SageMaker endpoint variant - The resource type is ``variant`` and the unique identifier is the resource ID. Example: ``endpoint/my-end-point/variant/KMeansClustering`` . - Custom resources are not supported with a resource type. This parameter must specify the ``OutputValue`` from the CloudFormation template stack used to access the resources. The unique identifier is defined by the service provider. More information is available in our `GitHub repository <https://docs.aws.amazon.com/https://github.com/aws/aws-auto-scaling-custom-resource>`_ . - Amazon Comprehend document classification endpoint - The resource type and unique identifier are specified using the endpoint ARN. Example: ``arn:aws:comprehend:us-west-2:123456789012:document-classifier-endpoint/EXAMPLE`` . - Amazon Comprehend entity recognizer endpoint - The resource type and unique identifier are specified using the endpoint ARN. Example: ``arn:aws:comprehend:us-west-2:123456789012:entity-recognizer-endpoint/EXAMPLE`` . - Lambda provisioned concurrency - The resource type is ``function`` and the unique identifier is the function name with a function version or alias name suffix that is not ``$LATEST`` . Example: ``function:my-function:prod`` or ``function:my-function:1`` . - Amazon Keyspaces table - The resource type is ``table`` and the unique identifier is the table name. Example: ``keyspace/mykeyspace/table/mytable`` . - Amazon MSK cluster - The resource type and unique identifier are specified using the cluster ARN. Example: ``arn:aws:kafka:us-east-1:123456789012:cluster/demo-cluster-1/6357e0b2-0e6a-4b86-a0b4-70df934c2e31-5`` . - Amazon ElastiCache replication group - The resource type is ``replication-group`` and the unique identifier is the replication group name. Example: ``replication-group/mycluster`` . - Neptune cluster - The resource type is ``cluster`` and the unique identifier is the cluster name. Example: ``cluster:mycluster`` . - SageMaker Serverless endpoint - The resource type is ``variant`` and the unique identifier is the resource ID. Example: ``endpoint/my-end-point/variant/KMeansClustering`` .\n')
    scalable_dimension: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The scalable dimension associated with the scalable target. This string consists of the service namespace, resource type, and scaling property. - ``ecs:service:DesiredCount`` - The desired task count of an ECS service. - ``elasticmapreduce:instancegroup:InstanceCount`` - The instance count of an EMR Instance Group. - ``ec2:spot-fleet-request:TargetCapacity`` - The target capacity of a Spot Fleet. - ``appstream:fleet:DesiredCapacity`` - The desired capacity of an AppStream 2.0 fleet. - ``dynamodb:table:ReadCapacityUnits`` - The provisioned read capacity for a DynamoDB table. - ``dynamodb:table:WriteCapacityUnits`` - The provisioned write capacity for a DynamoDB table. - ``dynamodb:index:ReadCapacityUnits`` - The provisioned read capacity for a DynamoDB global secondary index. - ``dynamodb:index:WriteCapacityUnits`` - The provisioned write capacity for a DynamoDB global secondary index. - ``rds:cluster:ReadReplicaCount`` - The count of Aurora Replicas in an Aurora DB cluster. Available for Aurora MySQL-compatible edition and Aurora PostgreSQL-compatible edition. - ``sagemaker:variant:DesiredInstanceCount`` - The number of EC2 instances for a SageMaker model endpoint variant. - ``custom-resource:ResourceType:Property`` - The scalable dimension for a custom resource provided by your own application or service. - ``comprehend:document-classifier-endpoint:DesiredInferenceUnits`` - The number of inference units for an Amazon Comprehend document classification endpoint. - ``comprehend:entity-recognizer-endpoint:DesiredInferenceUnits`` - The number of inference units for an Amazon Comprehend entity recognizer endpoint. - ``lambda:function:ProvisionedConcurrency`` - The provisioned concurrency for a Lambda function. - ``cassandra:table:ReadCapacityUnits`` - The provisioned read capacity for an Amazon Keyspaces table. - ``cassandra:table:WriteCapacityUnits`` - The provisioned write capacity for an Amazon Keyspaces table. - ``kafka:broker-storage:VolumeSize`` - The provisioned volume size (in GiB) for brokers in an Amazon MSK cluster. - ``elasticache:replication-group:NodeGroups`` - The number of node groups for an Amazon ElastiCache replication group. - ``elasticache:replication-group:Replicas`` - The number of replicas per node group for an Amazon ElastiCache replication group. - ``neptune:cluster:ReadReplicaCount`` - The count of read replicas in an Amazon Neptune DB cluster. - ``sagemaker:variant:DesiredProvisionedConcurrency`` - The provisioned concurrency for a SageMaker Serverless endpoint.\n')
    service_namespace: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The namespace of the AWS service that provides the resource, or a ``custom-resource`` .\n')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='Specify the Amazon Resource Name (ARN) of an Identity and Access Management (IAM) role that allows Application Auto Scaling to modify the scalable target on your behalf. This can be either an IAM service role that Application Auto Scaling can assume to make calls to other AWS resources on your behalf, or a service-linked role for the specified service. For more information, see `How Application Auto Scaling works with IAM <https://docs.aws.amazon.com/autoscaling/application/userguide/security_iam_service-with-iam.html>`_ in the *Application Auto Scaling User Guide* . To automatically create a service-linked role (recommended), specify the full ARN of the service-linked role in your stack template. To find the exact ARN of the service-linked role for your AWS or custom resource, see the `Service-linked roles <https://docs.aws.amazon.com/autoscaling/application/userguide/application-auto-scaling-service-linked-roles.html>`_ topic in the *Application Auto Scaling User Guide* . Look for the ARN in the table at the bottom of the page.\n')
    scheduled_actions: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalableTarget_ScheduledActionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="The scheduled actions for the scalable target. Duplicates aren't allowed.\n")
    suspended_state: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalableTarget_SuspendedStatePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An embedded object that contains attributes and attribute values that are used to suspend and resume automatic scaling. Setting the value of an attribute to ``true`` suspends the specified scaling activities. Setting it to ``false`` (default) resumes the specified scaling activities. *Suspension Outcomes* - For ``DynamicScalingInSuspended`` , while a suspension is in effect, all scale-in activities that are triggered by a scaling policy are suspended. - For ``DynamicScalingOutSuspended`` , while a suspension is in effect, all scale-out activities that are triggered by a scaling policy are suspended. - For ``ScheduledScalingSuspended`` , while a suspension is in effect, all scaling activities that involve scheduled actions are suspended.')
    _init_params: typing.ClassVar[list[str]] = ['max_capacity', 'min_capacity', 'resource_id', 'scalable_dimension', 'service_namespace', 'role_arn', 'scheduled_actions', 'suspended_state']
    _method_names: typing.ClassVar[list[str]] = ['ScalableTargetActionProperty', 'ScheduledActionProperty', 'SuspendedStateProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalableTarget'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_applicationautoscaling.CfnScalableTargetDefConfig] = pydantic.Field(None)


class CfnScalableTargetDefConfig(pydantic.BaseModel):
    ScalableTargetActionProperty: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefScalabletargetactionpropertyParams]] = pydantic.Field(None, description='')
    ScheduledActionProperty: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefScheduledactionpropertyParams]] = pydantic.Field(None, description='')
    SuspendedStateProperty: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefSuspendedstatepropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_applicationautoscaling.CfnScalableTargetDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnScalableTargetDefScalabletargetactionpropertyParams(pydantic.BaseModel):
    max_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min_capacity: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnScalableTargetDefScheduledactionpropertyParams(pydantic.BaseModel):
    schedule: str = pydantic.Field(..., description='')
    scheduled_action_name: str = pydantic.Field(..., description='')
    end_time: typing.Union[models.UnsupportedResource, datetime.datetime, None] = pydantic.Field(None, description='')
    scalable_target_action: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalableTarget_ScalableTargetActionPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    start_time: typing.Union[models.UnsupportedResource, datetime.datetime, None] = pydantic.Field(None, description='')
    timezone: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScalableTargetDefSuspendedstatepropertyParams(pydantic.BaseModel):
    dynamic_scaling_in_suspended: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    dynamic_scaling_out_suspended: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    scheduled_scaling_suspended: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    ...

class CfnScalableTargetDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnScalableTargetDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnScalableTargetDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnScalableTargetDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnScalableTargetDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnScalableTargetDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnScalableTargetDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnScalableTargetDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnScalableTargetDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnScalableTargetDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnScalableTargetDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnScalableTargetDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnScalableTargetDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnScalableTargetDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalingPolicy
class CfnScalingPolicyDef(BaseCfnResource):
    policy_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The name of the scaling policy. Updates to the name of a target tracking scaling policy are not supported, unless you also update the metric used for scaling. To change only a target tracking scaling policy's name, first delete the policy by removing the existing ``AWS::ApplicationAutoScaling::ScalingPolicy`` resource from the template and updating the stack. Then, recreate the resource with the same settings and a different name.\n")
    policy_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The scaling policy type. The following policy types are supported: ``TargetTrackingScaling`` Not supported for Amazon EMR ``StepScaling`` Not supported for DynamoDB, Amazon Comprehend, Lambda, Amazon Keyspaces, Amazon MSK, Amazon ElastiCache, or Neptune.\n')
    resource_id: typing.Optional[str] = pydantic.Field(None, description='The identifier of the resource associated with the scaling policy. This string consists of the resource type and unique identifier. - ECS service - The resource type is ``service`` and the unique identifier is the cluster name and service name. Example: ``service/default/sample-webapp`` . - Spot Fleet - The resource type is ``spot-fleet-request`` and the unique identifier is the Spot Fleet request ID. Example: ``spot-fleet-request/sfr-73fbd2ce-aa30-494c-8788-1cee4EXAMPLE`` . - EMR cluster - The resource type is ``instancegroup`` and the unique identifier is the cluster ID and instance group ID. Example: ``instancegroup/j-2EEZNYKUA1NTV/ig-1791Y4E1L8YI0`` . - AppStream 2.0 fleet - The resource type is ``fleet`` and the unique identifier is the fleet name. Example: ``fleet/sample-fleet`` . - DynamoDB table - The resource type is ``table`` and the unique identifier is the table name. Example: ``table/my-table`` . - DynamoDB global secondary index - The resource type is ``index`` and the unique identifier is the index name. Example: ``table/my-table/index/my-table-index`` . - Aurora DB cluster - The resource type is ``cluster`` and the unique identifier is the cluster name. Example: ``cluster:my-db-cluster`` . - SageMaker endpoint variant - The resource type is ``variant`` and the unique identifier is the resource ID. Example: ``endpoint/my-end-point/variant/KMeansClustering`` . - Custom resources are not supported with a resource type. This parameter must specify the ``OutputValue`` from the CloudFormation template stack used to access the resources. The unique identifier is defined by the service provider. More information is available in our `GitHub repository <https://docs.aws.amazon.com/https://github.com/aws/aws-auto-scaling-custom-resource>`_ . - Amazon Comprehend document classification endpoint - The resource type and unique identifier are specified using the endpoint ARN. Example: ``arn:aws:comprehend:us-west-2:123456789012:document-classifier-endpoint/EXAMPLE`` . - Amazon Comprehend entity recognizer endpoint - The resource type and unique identifier are specified using the endpoint ARN. Example: ``arn:aws:comprehend:us-west-2:123456789012:entity-recognizer-endpoint/EXAMPLE`` . - Lambda provisioned concurrency - The resource type is ``function`` and the unique identifier is the function name with a function version or alias name suffix that is not ``$LATEST`` . Example: ``function:my-function:prod`` or ``function:my-function:1`` . - Amazon Keyspaces table - The resource type is ``table`` and the unique identifier is the table name. Example: ``keyspace/mykeyspace/table/mytable`` . - Amazon MSK cluster - The resource type and unique identifier are specified using the cluster ARN. Example: ``arn:aws:kafka:us-east-1:123456789012:cluster/demo-cluster-1/6357e0b2-0e6a-4b86-a0b4-70df934c2e31-5`` . - Amazon ElastiCache replication group - The resource type is ``replication-group`` and the unique identifier is the replication group name. Example: ``replication-group/mycluster`` . - Neptune cluster - The resource type is ``cluster`` and the unique identifier is the cluster name. Example: ``cluster:mycluster`` . - SageMaker Serverless endpoint - The resource type is ``variant`` and the unique identifier is the resource ID. Example: ``endpoint/my-end-point/variant/KMeansClustering`` .\n')
    scalable_dimension: typing.Optional[str] = pydantic.Field(None, description='The scalable dimension. This string consists of the service namespace, resource type, and scaling property. - ``ecs:service:DesiredCount`` - The desired task count of an ECS service. - ``elasticmapreduce:instancegroup:InstanceCount`` - The instance count of an EMR Instance Group. - ``ec2:spot-fleet-request:TargetCapacity`` - The target capacity of a Spot Fleet. - ``appstream:fleet:DesiredCapacity`` - The desired capacity of an AppStream 2.0 fleet. - ``dynamodb:table:ReadCapacityUnits`` - The provisioned read capacity for a DynamoDB table. - ``dynamodb:table:WriteCapacityUnits`` - The provisioned write capacity for a DynamoDB table. - ``dynamodb:index:ReadCapacityUnits`` - The provisioned read capacity for a DynamoDB global secondary index. - ``dynamodb:index:WriteCapacityUnits`` - The provisioned write capacity for a DynamoDB global secondary index. - ``rds:cluster:ReadReplicaCount`` - The count of Aurora Replicas in an Aurora DB cluster. Available for Aurora MySQL-compatible edition and Aurora PostgreSQL-compatible edition. - ``sagemaker:variant:DesiredInstanceCount`` - The number of EC2 instances for a SageMaker model endpoint variant. - ``custom-resource:ResourceType:Property`` - The scalable dimension for a custom resource provided by your own application or service. - ``comprehend:document-classifier-endpoint:DesiredInferenceUnits`` - The number of inference units for an Amazon Comprehend document classification endpoint. - ``comprehend:entity-recognizer-endpoint:DesiredInferenceUnits`` - The number of inference units for an Amazon Comprehend entity recognizer endpoint. - ``lambda:function:ProvisionedConcurrency`` - The provisioned concurrency for a Lambda function. - ``cassandra:table:ReadCapacityUnits`` - The provisioned read capacity for an Amazon Keyspaces table. - ``cassandra:table:WriteCapacityUnits`` - The provisioned write capacity for an Amazon Keyspaces table. - ``kafka:broker-storage:VolumeSize`` - The provisioned volume size (in GiB) for brokers in an Amazon MSK cluster. - ``elasticache:replication-group:NodeGroups`` - The number of node groups for an Amazon ElastiCache replication group. - ``elasticache:replication-group:Replicas`` - The number of replicas per node group for an Amazon ElastiCache replication group. - ``neptune:cluster:ReadReplicaCount`` - The count of read replicas in an Amazon Neptune DB cluster. - ``sagemaker:variant:DesiredProvisionedConcurrency`` - The provisioned concurrency for a SageMaker Serverless endpoint.\n')
    scaling_target_id: typing.Optional[str] = pydantic.Field(None, description='The CloudFormation-generated ID of an Application Auto Scaling scalable target. For more information about the ID, see the Return Value section of the ``AWS::ApplicationAutoScaling::ScalableTarget`` resource. .. epigraph:: You must specify either the ``ScalingTargetId`` property, or the ``ResourceId`` , ``ScalableDimension`` , and ``ServiceNamespace`` properties, but not both.\n')
    service_namespace: typing.Optional[str] = pydantic.Field(None, description='The namespace of the AWS service that provides the resource, or a ``custom-resource`` .\n')
    step_scaling_policy_configuration: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_StepScalingPolicyConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A step scaling policy.\n')
    target_tracking_scaling_policy_configuration: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_TargetTrackingScalingPolicyConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A target tracking scaling policy.')
    _init_params: typing.ClassVar[list[str]] = ['policy_name', 'policy_type', 'resource_id', 'scalable_dimension', 'scaling_target_id', 'service_namespace', 'step_scaling_policy_configuration', 'target_tracking_scaling_policy_configuration']
    _method_names: typing.ClassVar[list[str]] = ['CustomizedMetricSpecificationProperty', 'MetricDimensionProperty', 'PredefinedMetricSpecificationProperty', 'StepAdjustmentProperty', 'StepScalingPolicyConfigurationProperty', 'TargetTrackingScalingPolicyConfigurationProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalingPolicy'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[models.aws_applicationautoscaling.CfnScalingPolicyDefConfig] = pydantic.Field(None)


class CfnScalingPolicyDefConfig(pydantic.BaseModel):
    CustomizedMetricSpecificationProperty: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefCustomizedmetricspecificationpropertyParams]] = pydantic.Field(None, description='')
    MetricDimensionProperty: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefMetricdimensionpropertyParams]] = pydantic.Field(None, description='')
    PredefinedMetricSpecificationProperty: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefPredefinedmetricspecificationpropertyParams]] = pydantic.Field(None, description='')
    StepAdjustmentProperty: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefStepadjustmentpropertyParams]] = pydantic.Field(None, description='')
    StepScalingPolicyConfigurationProperty: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefStepscalingpolicyconfigurationpropertyParams]] = pydantic.Field(None, description='')
    TargetTrackingScalingPolicyConfigurationProperty: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefTargettrackingscalingpolicyconfigurationpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[models.aws_applicationautoscaling.CfnScalingPolicyDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnScalingPolicyDefCustomizedmetricspecificationpropertyParams(pydantic.BaseModel):
    metric_name: str = pydantic.Field(..., description='')
    namespace: str = pydantic.Field(..., description='')
    statistic: str = pydantic.Field(..., description='')
    dimensions: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_MetricDimensionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    unit: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefMetricdimensionpropertyParams(pydantic.BaseModel):
    name: str = pydantic.Field(..., description='')
    value: str = pydantic.Field(..., description='')
    ...

class CfnScalingPolicyDefPredefinedmetricspecificationpropertyParams(pydantic.BaseModel):
    predefined_metric_type: str = pydantic.Field(..., description='')
    resource_label: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefStepadjustmentpropertyParams(pydantic.BaseModel):
    scaling_adjustment: typing.Union[int, float] = pydantic.Field(..., description='')
    metric_interval_lower_bound: typing.Union[int, float, None] = pydantic.Field(None, description='')
    metric_interval_upper_bound: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefStepscalingpolicyconfigurationpropertyParams(pydantic.BaseModel):
    adjustment_type: typing.Optional[str] = pydantic.Field(None, description='')
    cooldown: typing.Union[int, float, None] = pydantic.Field(None, description='')
    metric_aggregation_type: typing.Optional[str] = pydantic.Field(None, description='')
    min_adjustment_magnitude: typing.Union[int, float, None] = pydantic.Field(None, description='')
    step_adjustments: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_StepAdjustmentPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefTargettrackingscalingpolicyconfigurationpropertyParams(pydantic.BaseModel):
    target_value: typing.Union[int, float] = pydantic.Field(..., description='')
    customized_metric_specification: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_CustomizedMetricSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    disable_scale_in: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='')
    predefined_metric_specification: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_PredefinedMetricSpecificationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    scale_in_cooldown: typing.Union[int, float, None] = pydantic.Field(None, description='')
    scale_out_cooldown: typing.Union[int, float, None] = pydantic.Field(None, description='')
    ...

class CfnScalingPolicyDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnScalingPolicyDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnScalingPolicyDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnScalingPolicyDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnScalingPolicyDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnScalingPolicyDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnScalingPolicyDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnScalingPolicyDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnScalingPolicyDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnScalingPolicyDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnScalingPolicyDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnScalingPolicyDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnScalingPolicyDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnScalingPolicyDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalableTargetProps
class CfnScalableTargetPropsDef(BaseCfnProperty):
    max_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The maximum value that you plan to scale out to. When a scaling policy is in effect, Application Auto Scaling can scale out (expand) as needed to the maximum capacity limit in response to changing demand.\n')
    min_capacity: typing.Union[_REQUIRED_INIT_PARAM, int, float] = pydantic.Field(REQUIRED_INIT_PARAM, description='The minimum value that you plan to scale in to. When a scaling policy is in effect, Application Auto Scaling can scale in (contract) as needed to the minimum capacity limit in response to changing demand.\n')
    resource_id: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The identifier of the resource associated with the scalable target. This string consists of the resource type and unique identifier. - ECS service - The resource type is ``service`` and the unique identifier is the cluster name and service name. Example: ``service/default/sample-webapp`` . - Spot Fleet - The resource type is ``spot-fleet-request`` and the unique identifier is the Spot Fleet request ID. Example: ``spot-fleet-request/sfr-73fbd2ce-aa30-494c-8788-1cee4EXAMPLE`` . - EMR cluster - The resource type is ``instancegroup`` and the unique identifier is the cluster ID and instance group ID. Example: ``instancegroup/j-2EEZNYKUA1NTV/ig-1791Y4E1L8YI0`` . - AppStream 2.0 fleet - The resource type is ``fleet`` and the unique identifier is the fleet name. Example: ``fleet/sample-fleet`` . - DynamoDB table - The resource type is ``table`` and the unique identifier is the table name. Example: ``table/my-table`` . - DynamoDB global secondary index - The resource type is ``index`` and the unique identifier is the index name. Example: ``table/my-table/index/my-table-index`` . - Aurora DB cluster - The resource type is ``cluster`` and the unique identifier is the cluster name. Example: ``cluster:my-db-cluster`` . - SageMaker endpoint variant - The resource type is ``variant`` and the unique identifier is the resource ID. Example: ``endpoint/my-end-point/variant/KMeansClustering`` . - Custom resources are not supported with a resource type. This parameter must specify the ``OutputValue`` from the CloudFormation template stack used to access the resources. The unique identifier is defined by the service provider. More information is available in our `GitHub repository <https://docs.aws.amazon.com/https://github.com/aws/aws-auto-scaling-custom-resource>`_ . - Amazon Comprehend document classification endpoint - The resource type and unique identifier are specified using the endpoint ARN. Example: ``arn:aws:comprehend:us-west-2:123456789012:document-classifier-endpoint/EXAMPLE`` . - Amazon Comprehend entity recognizer endpoint - The resource type and unique identifier are specified using the endpoint ARN. Example: ``arn:aws:comprehend:us-west-2:123456789012:entity-recognizer-endpoint/EXAMPLE`` . - Lambda provisioned concurrency - The resource type is ``function`` and the unique identifier is the function name with a function version or alias name suffix that is not ``$LATEST`` . Example: ``function:my-function:prod`` or ``function:my-function:1`` . - Amazon Keyspaces table - The resource type is ``table`` and the unique identifier is the table name. Example: ``keyspace/mykeyspace/table/mytable`` . - Amazon MSK cluster - The resource type and unique identifier are specified using the cluster ARN. Example: ``arn:aws:kafka:us-east-1:123456789012:cluster/demo-cluster-1/6357e0b2-0e6a-4b86-a0b4-70df934c2e31-5`` . - Amazon ElastiCache replication group - The resource type is ``replication-group`` and the unique identifier is the replication group name. Example: ``replication-group/mycluster`` . - Neptune cluster - The resource type is ``cluster`` and the unique identifier is the cluster name. Example: ``cluster:mycluster`` . - SageMaker Serverless endpoint - The resource type is ``variant`` and the unique identifier is the resource ID. Example: ``endpoint/my-end-point/variant/KMeansClustering`` .\n')
    scalable_dimension: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The scalable dimension associated with the scalable target. This string consists of the service namespace, resource type, and scaling property. - ``ecs:service:DesiredCount`` - The desired task count of an ECS service. - ``elasticmapreduce:instancegroup:InstanceCount`` - The instance count of an EMR Instance Group. - ``ec2:spot-fleet-request:TargetCapacity`` - The target capacity of a Spot Fleet. - ``appstream:fleet:DesiredCapacity`` - The desired capacity of an AppStream 2.0 fleet. - ``dynamodb:table:ReadCapacityUnits`` - The provisioned read capacity for a DynamoDB table. - ``dynamodb:table:WriteCapacityUnits`` - The provisioned write capacity for a DynamoDB table. - ``dynamodb:index:ReadCapacityUnits`` - The provisioned read capacity for a DynamoDB global secondary index. - ``dynamodb:index:WriteCapacityUnits`` - The provisioned write capacity for a DynamoDB global secondary index. - ``rds:cluster:ReadReplicaCount`` - The count of Aurora Replicas in an Aurora DB cluster. Available for Aurora MySQL-compatible edition and Aurora PostgreSQL-compatible edition. - ``sagemaker:variant:DesiredInstanceCount`` - The number of EC2 instances for a SageMaker model endpoint variant. - ``custom-resource:ResourceType:Property`` - The scalable dimension for a custom resource provided by your own application or service. - ``comprehend:document-classifier-endpoint:DesiredInferenceUnits`` - The number of inference units for an Amazon Comprehend document classification endpoint. - ``comprehend:entity-recognizer-endpoint:DesiredInferenceUnits`` - The number of inference units for an Amazon Comprehend entity recognizer endpoint. - ``lambda:function:ProvisionedConcurrency`` - The provisioned concurrency for a Lambda function. - ``cassandra:table:ReadCapacityUnits`` - The provisioned read capacity for an Amazon Keyspaces table. - ``cassandra:table:WriteCapacityUnits`` - The provisioned write capacity for an Amazon Keyspaces table. - ``kafka:broker-storage:VolumeSize`` - The provisioned volume size (in GiB) for brokers in an Amazon MSK cluster. - ``elasticache:replication-group:NodeGroups`` - The number of node groups for an Amazon ElastiCache replication group. - ``elasticache:replication-group:Replicas`` - The number of replicas per node group for an Amazon ElastiCache replication group. - ``neptune:cluster:ReadReplicaCount`` - The count of read replicas in an Amazon Neptune DB cluster. - ``sagemaker:variant:DesiredProvisionedConcurrency`` - The provisioned concurrency for a SageMaker Serverless endpoint.\n')
    service_namespace: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The namespace of the AWS service that provides the resource, or a ``custom-resource`` .\n')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='Specify the Amazon Resource Name (ARN) of an Identity and Access Management (IAM) role that allows Application Auto Scaling to modify the scalable target on your behalf. This can be either an IAM service role that Application Auto Scaling can assume to make calls to other AWS resources on your behalf, or a service-linked role for the specified service. For more information, see `How Application Auto Scaling works with IAM <https://docs.aws.amazon.com/autoscaling/application/userguide/security_iam_service-with-iam.html>`_ in the *Application Auto Scaling User Guide* . To automatically create a service-linked role (recommended), specify the full ARN of the service-linked role in your stack template. To find the exact ARN of the service-linked role for your AWS or custom resource, see the `Service-linked roles <https://docs.aws.amazon.com/autoscaling/application/userguide/application-auto-scaling-service-linked-roles.html>`_ topic in the *Application Auto Scaling User Guide* . Look for the ARN in the table at the bottom of the page.\n')
    scheduled_actions: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalableTarget_ScheduledActionPropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description="The scheduled actions for the scalable target. Duplicates aren't allowed.\n")
    suspended_state: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalableTarget_SuspendedStatePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='An embedded object that contains attributes and attribute values that are used to suspend and resume automatic scaling. Setting the value of an attribute to ``true`` suspends the specified scaling activities. Setting it to ``false`` (default) resumes the specified scaling activities. *Suspension Outcomes* - For ``DynamicScalingInSuspended`` , while a suspension is in effect, all scale-in activities that are triggered by a scaling policy are suspended. - For ``DynamicScalingOutSuspended`` , while a suspension is in effect, all scale-out activities that are triggered by a scaling policy are suspended. - For ``ScheduledScalingSuspended`` , while a suspension is in effect, all scaling activities that involve scheduled actions are suspended.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalabletarget.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    cfn_scalable_target_props = appscaling.CfnScalableTargetProps(\n        max_capacity=123,\n        min_capacity=123,\n        resource_id="resourceId",\n        scalable_dimension="scalableDimension",\n        service_namespace="serviceNamespace",\n\n        # the properties below are optional\n        role_arn="roleArn",\n        scheduled_actions=[appscaling.CfnScalableTarget.ScheduledActionProperty(\n            schedule="schedule",\n            scheduled_action_name="scheduledActionName",\n\n            # the properties below are optional\n            end_time=Date(),\n            scalable_target_action=appscaling.CfnScalableTarget.ScalableTargetActionProperty(\n                max_capacity=123,\n                min_capacity=123\n            ),\n            start_time=Date(),\n            timezone="timezone"\n        )],\n        suspended_state=appscaling.CfnScalableTarget.SuspendedStateProperty(\n            dynamic_scaling_in_suspended=False,\n            dynamic_scaling_out_suspended=False,\n            scheduled_scaling_suspended=False\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_capacity', 'min_capacity', 'resource_id', 'scalable_dimension', 'service_namespace', 'role_arn', 'scheduled_actions', 'suspended_state']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalableTargetProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_applicationautoscaling.CfnScalingPolicyProps
class CfnScalingPolicyPropsDef(BaseCfnProperty):
    policy_name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description="The name of the scaling policy. Updates to the name of a target tracking scaling policy are not supported, unless you also update the metric used for scaling. To change only a target tracking scaling policy's name, first delete the policy by removing the existing ``AWS::ApplicationAutoScaling::ScalingPolicy`` resource from the template and updating the stack. Then, recreate the resource with the same settings and a different name.\n")
    policy_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The scaling policy type. The following policy types are supported: ``TargetTrackingScaling`` Not supported for Amazon EMR ``StepScaling`` Not supported for DynamoDB, Amazon Comprehend, Lambda, Amazon Keyspaces, Amazon MSK, Amazon ElastiCache, or Neptune.\n')
    resource_id: typing.Optional[str] = pydantic.Field(None, description='The identifier of the resource associated with the scaling policy. This string consists of the resource type and unique identifier. - ECS service - The resource type is ``service`` and the unique identifier is the cluster name and service name. Example: ``service/default/sample-webapp`` . - Spot Fleet - The resource type is ``spot-fleet-request`` and the unique identifier is the Spot Fleet request ID. Example: ``spot-fleet-request/sfr-73fbd2ce-aa30-494c-8788-1cee4EXAMPLE`` . - EMR cluster - The resource type is ``instancegroup`` and the unique identifier is the cluster ID and instance group ID. Example: ``instancegroup/j-2EEZNYKUA1NTV/ig-1791Y4E1L8YI0`` . - AppStream 2.0 fleet - The resource type is ``fleet`` and the unique identifier is the fleet name. Example: ``fleet/sample-fleet`` . - DynamoDB table - The resource type is ``table`` and the unique identifier is the table name. Example: ``table/my-table`` . - DynamoDB global secondary index - The resource type is ``index`` and the unique identifier is the index name. Example: ``table/my-table/index/my-table-index`` . - Aurora DB cluster - The resource type is ``cluster`` and the unique identifier is the cluster name. Example: ``cluster:my-db-cluster`` . - SageMaker endpoint variant - The resource type is ``variant`` and the unique identifier is the resource ID. Example: ``endpoint/my-end-point/variant/KMeansClustering`` . - Custom resources are not supported with a resource type. This parameter must specify the ``OutputValue`` from the CloudFormation template stack used to access the resources. The unique identifier is defined by the service provider. More information is available in our `GitHub repository <https://docs.aws.amazon.com/https://github.com/aws/aws-auto-scaling-custom-resource>`_ . - Amazon Comprehend document classification endpoint - The resource type and unique identifier are specified using the endpoint ARN. Example: ``arn:aws:comprehend:us-west-2:123456789012:document-classifier-endpoint/EXAMPLE`` . - Amazon Comprehend entity recognizer endpoint - The resource type and unique identifier are specified using the endpoint ARN. Example: ``arn:aws:comprehend:us-west-2:123456789012:entity-recognizer-endpoint/EXAMPLE`` . - Lambda provisioned concurrency - The resource type is ``function`` and the unique identifier is the function name with a function version or alias name suffix that is not ``$LATEST`` . Example: ``function:my-function:prod`` or ``function:my-function:1`` . - Amazon Keyspaces table - The resource type is ``table`` and the unique identifier is the table name. Example: ``keyspace/mykeyspace/table/mytable`` . - Amazon MSK cluster - The resource type and unique identifier are specified using the cluster ARN. Example: ``arn:aws:kafka:us-east-1:123456789012:cluster/demo-cluster-1/6357e0b2-0e6a-4b86-a0b4-70df934c2e31-5`` . - Amazon ElastiCache replication group - The resource type is ``replication-group`` and the unique identifier is the replication group name. Example: ``replication-group/mycluster`` . - Neptune cluster - The resource type is ``cluster`` and the unique identifier is the cluster name. Example: ``cluster:mycluster`` . - SageMaker Serverless endpoint - The resource type is ``variant`` and the unique identifier is the resource ID. Example: ``endpoint/my-end-point/variant/KMeansClustering`` .\n')
    scalable_dimension: typing.Optional[str] = pydantic.Field(None, description='The scalable dimension. This string consists of the service namespace, resource type, and scaling property. - ``ecs:service:DesiredCount`` - The desired task count of an ECS service. - ``elasticmapreduce:instancegroup:InstanceCount`` - The instance count of an EMR Instance Group. - ``ec2:spot-fleet-request:TargetCapacity`` - The target capacity of a Spot Fleet. - ``appstream:fleet:DesiredCapacity`` - The desired capacity of an AppStream 2.0 fleet. - ``dynamodb:table:ReadCapacityUnits`` - The provisioned read capacity for a DynamoDB table. - ``dynamodb:table:WriteCapacityUnits`` - The provisioned write capacity for a DynamoDB table. - ``dynamodb:index:ReadCapacityUnits`` - The provisioned read capacity for a DynamoDB global secondary index. - ``dynamodb:index:WriteCapacityUnits`` - The provisioned write capacity for a DynamoDB global secondary index. - ``rds:cluster:ReadReplicaCount`` - The count of Aurora Replicas in an Aurora DB cluster. Available for Aurora MySQL-compatible edition and Aurora PostgreSQL-compatible edition. - ``sagemaker:variant:DesiredInstanceCount`` - The number of EC2 instances for a SageMaker model endpoint variant. - ``custom-resource:ResourceType:Property`` - The scalable dimension for a custom resource provided by your own application or service. - ``comprehend:document-classifier-endpoint:DesiredInferenceUnits`` - The number of inference units for an Amazon Comprehend document classification endpoint. - ``comprehend:entity-recognizer-endpoint:DesiredInferenceUnits`` - The number of inference units for an Amazon Comprehend entity recognizer endpoint. - ``lambda:function:ProvisionedConcurrency`` - The provisioned concurrency for a Lambda function. - ``cassandra:table:ReadCapacityUnits`` - The provisioned read capacity for an Amazon Keyspaces table. - ``cassandra:table:WriteCapacityUnits`` - The provisioned write capacity for an Amazon Keyspaces table. - ``kafka:broker-storage:VolumeSize`` - The provisioned volume size (in GiB) for brokers in an Amazon MSK cluster. - ``elasticache:replication-group:NodeGroups`` - The number of node groups for an Amazon ElastiCache replication group. - ``elasticache:replication-group:Replicas`` - The number of replicas per node group for an Amazon ElastiCache replication group. - ``neptune:cluster:ReadReplicaCount`` - The count of read replicas in an Amazon Neptune DB cluster. - ``sagemaker:variant:DesiredProvisionedConcurrency`` - The provisioned concurrency for a SageMaker Serverless endpoint.\n')
    scaling_target_id: typing.Optional[str] = pydantic.Field(None, description='The CloudFormation-generated ID of an Application Auto Scaling scalable target. For more information about the ID, see the Return Value section of the ``AWS::ApplicationAutoScaling::ScalableTarget`` resource. .. epigraph:: You must specify either the ``ScalingTargetId`` property, or the ``ResourceId`` , ``ScalableDimension`` , and ``ServiceNamespace`` properties, but not both.\n')
    service_namespace: typing.Optional[str] = pydantic.Field(None, description='The namespace of the AWS service that provides the resource, or a ``custom-resource`` .\n')
    step_scaling_policy_configuration: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_StepScalingPolicyConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A step scaling policy.\n')
    target_tracking_scaling_policy_configuration: typing.Union[models.UnsupportedResource, models.aws_applicationautoscaling.CfnScalingPolicy_TargetTrackingScalingPolicyConfigurationPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='A target tracking scaling policy.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalingpolicy.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_applicationautoscaling as appscaling\n\n    cfn_scaling_policy_props = appscaling.CfnScalingPolicyProps(\n        policy_name="policyName",\n        policy_type="policyType",\n\n        # the properties below are optional\n        resource_id="resourceId",\n        scalable_dimension="scalableDimension",\n        scaling_target_id="scalingTargetId",\n        service_namespace="serviceNamespace",\n        step_scaling_policy_configuration=appscaling.CfnScalingPolicy.StepScalingPolicyConfigurationProperty(\n            adjustment_type="adjustmentType",\n            cooldown=123,\n            metric_aggregation_type="metricAggregationType",\n            min_adjustment_magnitude=123,\n            step_adjustments=[appscaling.CfnScalingPolicy.StepAdjustmentProperty(\n                scaling_adjustment=123,\n\n                # the properties below are optional\n                metric_interval_lower_bound=123,\n                metric_interval_upper_bound=123\n            )]\n        ),\n        target_tracking_scaling_policy_configuration=appscaling.CfnScalingPolicy.TargetTrackingScalingPolicyConfigurationProperty(\n            target_value=123,\n\n            # the properties below are optional\n            customized_metric_specification=appscaling.CfnScalingPolicy.CustomizedMetricSpecificationProperty(\n                metric_name="metricName",\n                namespace="namespace",\n                statistic="statistic",\n\n                # the properties below are optional\n                dimensions=[appscaling.CfnScalingPolicy.MetricDimensionProperty(\n                    name="name",\n                    value="value"\n                )],\n                unit="unit"\n            ),\n            disable_scale_in=False,\n            predefined_metric_specification=appscaling.CfnScalingPolicy.PredefinedMetricSpecificationProperty(\n                predefined_metric_type="predefinedMetricType",\n\n                # the properties below are optional\n                resource_label="resourceLabel"\n            ),\n            scale_in_cooldown=123,\n            scale_out_cooldown=123\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['policy_name', 'policy_type', 'resource_id', 'scalable_dimension', 'scaling_target_id', 'service_namespace', 'step_scaling_policy_configuration', 'target_tracking_scaling_policy_configuration']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_applicationautoscaling.CfnScalingPolicyProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




class ModuleModel(pydantic.BaseModel):
    BaseScalableAttribute: typing.Optional[dict[str, models.aws_applicationautoscaling.BaseScalableAttributeDef]] = pydantic.Field(None)
    Schedule: typing.Optional[dict[str, models.aws_applicationautoscaling.ScheduleDef]] = pydantic.Field(None)
    ScalableTarget: typing.Optional[dict[str, models.aws_applicationautoscaling.ScalableTargetDef]] = pydantic.Field(None)
    StepScalingAction: typing.Optional[dict[str, models.aws_applicationautoscaling.StepScalingActionDef]] = pydantic.Field(None)
    StepScalingPolicy: typing.Optional[dict[str, models.aws_applicationautoscaling.StepScalingPolicyDef]] = pydantic.Field(None)
    TargetTrackingScalingPolicy: typing.Optional[dict[str, models.aws_applicationautoscaling.TargetTrackingScalingPolicyDef]] = pydantic.Field(None)
    AdjustmentTier: typing.Optional[dict[str, models.aws_applicationautoscaling.AdjustmentTierDef]] = pydantic.Field(None)
    BaseScalableAttributeProps: typing.Optional[dict[str, models.aws_applicationautoscaling.BaseScalableAttributePropsDef]] = pydantic.Field(None)
    BaseTargetTrackingProps: typing.Optional[dict[str, models.aws_applicationautoscaling.BaseTargetTrackingPropsDef]] = pydantic.Field(None)
    BasicStepScalingPolicyProps: typing.Optional[dict[str, models.aws_applicationautoscaling.BasicStepScalingPolicyPropsDef]] = pydantic.Field(None)
    BasicTargetTrackingScalingPolicyProps: typing.Optional[dict[str, models.aws_applicationautoscaling.BasicTargetTrackingScalingPolicyPropsDef]] = pydantic.Field(None)
    CfnScalableTarget_ScalableTargetActionProperty: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalableTarget_ScalableTargetActionPropertyDef]] = pydantic.Field(None)
    CfnScalableTarget_ScheduledActionProperty: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalableTarget_ScheduledActionPropertyDef]] = pydantic.Field(None)
    CfnScalableTarget_SuspendedStateProperty: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalableTarget_SuspendedStatePropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_CustomizedMetricSpecificationProperty: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalingPolicy_CustomizedMetricSpecificationPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_MetricDimensionProperty: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalingPolicy_MetricDimensionPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_PredefinedMetricSpecificationProperty: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalingPolicy_PredefinedMetricSpecificationPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_StepAdjustmentProperty: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalingPolicy_StepAdjustmentPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_StepScalingPolicyConfigurationProperty: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalingPolicy_StepScalingPolicyConfigurationPropertyDef]] = pydantic.Field(None)
    CfnScalingPolicy_TargetTrackingScalingPolicyConfigurationProperty: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalingPolicy_TargetTrackingScalingPolicyConfigurationPropertyDef]] = pydantic.Field(None)
    CronOptions: typing.Optional[dict[str, models.aws_applicationautoscaling.CronOptionsDef]] = pydantic.Field(None)
    EnableScalingProps: typing.Optional[dict[str, models.aws_applicationautoscaling.EnableScalingPropsDef]] = pydantic.Field(None)
    ScalableTargetProps: typing.Optional[dict[str, models.aws_applicationautoscaling.ScalableTargetPropsDef]] = pydantic.Field(None)
    ScalingInterval: typing.Optional[dict[str, models.aws_applicationautoscaling.ScalingIntervalDef]] = pydantic.Field(None)
    ScalingSchedule: typing.Optional[dict[str, models.aws_applicationautoscaling.ScalingScheduleDef]] = pydantic.Field(None)
    StepScalingActionProps: typing.Optional[dict[str, models.aws_applicationautoscaling.StepScalingActionPropsDef]] = pydantic.Field(None)
    StepScalingPolicyProps: typing.Optional[dict[str, models.aws_applicationautoscaling.StepScalingPolicyPropsDef]] = pydantic.Field(None)
    TargetTrackingScalingPolicyProps: typing.Optional[dict[str, models.aws_applicationautoscaling.TargetTrackingScalingPolicyPropsDef]] = pydantic.Field(None)
    CfnScalableTarget: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalableTargetDef]] = pydantic.Field(None)
    CfnScalingPolicy: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalingPolicyDef]] = pydantic.Field(None)
    CfnScalableTargetProps: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalableTargetPropsDef]] = pydantic.Field(None)
    CfnScalingPolicyProps: typing.Optional[dict[str, models.aws_applicationautoscaling.CfnScalingPolicyPropsDef]] = pydantic.Field(None)
    ...

import models
