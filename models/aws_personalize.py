from __future__ import annotations
import typing
import aws_cdk
import constructs
import pydantic
import datetime
from ._base import BaseConstruct, BaseClass, BaseStruct, BaseCfnResource, BaseCfnProperty, ConnectableMixin, BaseMethodParams, GenericApplyRemovalPolicyParams, REQUIRED_INIT_PARAM, _REQUIRED_INIT_PARAM

#  autogenerated from aws_cdk.aws_personalize.CfnDataset.DatasetImportJobProperty
class CfnDataset_DatasetImportJobPropertyDef(BaseStruct):
    dataset_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the dataset that receives the imported data.\n')
    dataset_import_job_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the dataset import job.\n')
    data_source: typing.Any = pydantic.Field(None, description='The Amazon S3 bucket that contains the training data to import.\n')
    job_name: typing.Optional[str] = pydantic.Field(None, description='The name of the import job.\n')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the IAM role that has permissions to read from the Amazon S3 data source.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-personalize-dataset-datasetimportjob.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    # data_source: Any\n\n    dataset_import_job_property = personalize.CfnDataset.DatasetImportJobProperty(\n        dataset_arn="datasetArn",\n        dataset_import_job_arn="datasetImportJobArn",\n        data_source=data_source,\n        job_name="jobName",\n        role_arn="roleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['dataset_arn', 'dataset_import_job_arn', 'data_source', 'job_name', 'role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnDataset.DatasetImportJobProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnDataset.DataSourceProperty
class CfnDataset_DataSourcePropertyDef(BaseStruct):
    data_location: typing.Optional[str] = pydantic.Field(None, description='The path to the Amazon S3 bucket where the data that you want to upload to your dataset is stored. For example: ``s3://bucket-name/folder-name/``\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-personalize-dataset-datasource.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    data_source_property = personalize.CfnDataset.DataSourceProperty(\n        data_location="dataLocation"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['data_location']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnDataset.DataSourceProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnSolution.AlgorithmHyperParameterRangesProperty
class CfnSolution_AlgorithmHyperParameterRangesPropertyDef(BaseStruct):
    categorical_hyper_parameter_ranges: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_CategoricalHyperParameterRangePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Provides the name and range of a categorical hyperparameter.\n')
    continuous_hyper_parameter_ranges: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_ContinuousHyperParameterRangePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Provides the name and range of a continuous hyperparameter.\n')
    integer_hyper_parameter_ranges: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_IntegerHyperParameterRangePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='Provides the name and range of an integer-valued hyperparameter.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-personalize-solution-algorithmhyperparameterranges.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    algorithm_hyper_parameter_ranges_property = personalize.CfnSolution.AlgorithmHyperParameterRangesProperty(\n        categorical_hyper_parameter_ranges=[personalize.CfnSolution.CategoricalHyperParameterRangeProperty(\n            name="name",\n            values=["values"]\n        )],\n        continuous_hyper_parameter_ranges=[personalize.CfnSolution.ContinuousHyperParameterRangeProperty(\n            max_value=123,\n            min_value=123,\n            name="name"\n        )],\n        integer_hyper_parameter_ranges=[personalize.CfnSolution.IntegerHyperParameterRangeProperty(\n            max_value=123,\n            min_value=123,\n            name="name"\n        )]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['categorical_hyper_parameter_ranges', 'continuous_hyper_parameter_ranges', 'integer_hyper_parameter_ranges']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSolution.AlgorithmHyperParameterRangesProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnSolution.AutoMLConfigProperty
class CfnSolution_AutoMLConfigPropertyDef(BaseStruct):
    metric_name: typing.Optional[str] = pydantic.Field(None, description='The metric to optimize.\n')
    recipe_list: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='The list of candidate recipes.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-personalize-solution-automlconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    auto_mLConfig_property = personalize.CfnSolution.AutoMLConfigProperty(\n        metric_name="metricName",\n        recipe_list=["recipeList"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric_name', 'recipe_list']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSolution.AutoMLConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnSolution.CategoricalHyperParameterRangeProperty
class CfnSolution_CategoricalHyperParameterRangePropertyDef(BaseStruct):
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the hyperparameter.\n')
    values: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='A list of the categories for the hyperparameter.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-personalize-solution-categoricalhyperparameterrange.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    categorical_hyper_parameter_range_property = personalize.CfnSolution.CategoricalHyperParameterRangeProperty(\n        name="name",\n        values=["values"]\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'values']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSolution.CategoricalHyperParameterRangeProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnSolution.ContinuousHyperParameterRangeProperty
class CfnSolution_ContinuousHyperParameterRangePropertyDef(BaseStruct):
    max_value: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum allowable value for the hyperparameter.\n')
    min_value: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum allowable value for the hyperparameter.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the hyperparameter.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-personalize-solution-continuoushyperparameterrange.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    continuous_hyper_parameter_range_property = personalize.CfnSolution.ContinuousHyperParameterRangeProperty(\n        max_value=123,\n        min_value=123,\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_value', 'min_value', 'name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSolution.ContinuousHyperParameterRangeProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnSolution.HpoConfigProperty
class CfnSolution_HpoConfigPropertyDef(BaseStruct):
    algorithm_hyper_parameter_ranges: typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_AlgorithmHyperParameterRangesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='The hyperparameters and their allowable ranges.\n')
    hpo_objective: typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_HpoObjectivePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description="The metric to optimize during HPO. .. epigraph:: Amazon Personalize doesn't support configuring the ``hpoObjective`` at this time.\n")
    hpo_resource_config: typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_HpoResourceConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes the resource configuration for HPO.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-personalize-solution-hpoconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    hpo_config_property = personalize.CfnSolution.HpoConfigProperty(\n        algorithm_hyper_parameter_ranges=personalize.CfnSolution.AlgorithmHyperParameterRangesProperty(\n            categorical_hyper_parameter_ranges=[personalize.CfnSolution.CategoricalHyperParameterRangeProperty(\n                name="name",\n                values=["values"]\n            )],\n            continuous_hyper_parameter_ranges=[personalize.CfnSolution.ContinuousHyperParameterRangeProperty(\n                max_value=123,\n                min_value=123,\n                name="name"\n            )],\n            integer_hyper_parameter_ranges=[personalize.CfnSolution.IntegerHyperParameterRangeProperty(\n                max_value=123,\n                min_value=123,\n                name="name"\n            )]\n        ),\n        hpo_objective=personalize.CfnSolution.HpoObjectiveProperty(\n            metric_name="metricName",\n            metric_regex="metricRegex",\n            type="type"\n        ),\n        hpo_resource_config=personalize.CfnSolution.HpoResourceConfigProperty(\n            max_number_of_training_jobs="maxNumberOfTrainingJobs",\n            max_parallel_training_jobs="maxParallelTrainingJobs"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['algorithm_hyper_parameter_ranges', 'hpo_objective', 'hpo_resource_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSolution.HpoConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnSolution.HpoObjectiveProperty
class CfnSolution_HpoObjectivePropertyDef(BaseStruct):
    metric_name: typing.Optional[str] = pydantic.Field(None, description='The name of the metric.\n')
    metric_regex: typing.Optional[str] = pydantic.Field(None, description='A regular expression for finding the metric in the training job logs.\n')
    type: typing.Optional[str] = pydantic.Field(None, description='The type of the metric. Valid values are ``Maximize`` and ``Minimize`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-personalize-solution-hpoobjective.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    hpo_objective_property = personalize.CfnSolution.HpoObjectiveProperty(\n        metric_name="metricName",\n        metric_regex="metricRegex",\n        type="type"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['metric_name', 'metric_regex', 'type']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSolution.HpoObjectiveProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnSolution.HpoResourceConfigProperty
class CfnSolution_HpoResourceConfigPropertyDef(BaseStruct):
    max_number_of_training_jobs: typing.Optional[str] = pydantic.Field(None, description='The maximum number of training jobs when you create a solution version. The maximum value for ``maxNumberOfTrainingJobs`` is ``40`` .\n')
    max_parallel_training_jobs: typing.Optional[str] = pydantic.Field(None, description='The maximum number of parallel training jobs when you create a solution version. The maximum value for ``maxParallelTrainingJobs`` is ``10`` .\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-personalize-solution-hporesourceconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    hpo_resource_config_property = personalize.CfnSolution.HpoResourceConfigProperty(\n        max_number_of_training_jobs="maxNumberOfTrainingJobs",\n        max_parallel_training_jobs="maxParallelTrainingJobs"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_number_of_training_jobs', 'max_parallel_training_jobs']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSolution.HpoResourceConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnSolution.IntegerHyperParameterRangeProperty
class CfnSolution_IntegerHyperParameterRangePropertyDef(BaseStruct):
    max_value: typing.Union[int, float, None] = pydantic.Field(None, description='The maximum allowable value for the hyperparameter.\n')
    min_value: typing.Union[int, float, None] = pydantic.Field(None, description='The minimum allowable value for the hyperparameter.\n')
    name: typing.Optional[str] = pydantic.Field(None, description='The name of the hyperparameter.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-personalize-solution-integerhyperparameterrange.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    integer_hyper_parameter_range_property = personalize.CfnSolution.IntegerHyperParameterRangeProperty(\n        max_value=123,\n        min_value=123,\n        name="name"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['max_value', 'min_value', 'name']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSolution.IntegerHyperParameterRangeProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnSolution.SolutionConfigProperty
class CfnSolution_SolutionConfigPropertyDef(BaseStruct):
    algorithm_hyper_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='Lists the algorithm hyperparameters and their values.\n')
    auto_ml_config: typing.Any = pydantic.Field(None, description='The `AutoMLConfig <https://docs.aws.amazon.com/personalize/latest/dg/API_AutoMLConfig.html>`_ object containing a list of recipes to search when AutoML is performed.\n')
    event_value_threshold: typing.Optional[str] = pydantic.Field(None, description='Only events with a value greater than or equal to this threshold are used for training a model.\n')
    feature_transformation_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='Lists the feature transformation parameters.\n')
    hpo_config: typing.Any = pydantic.Field(None, description='Describes the properties for hyperparameter optimization (HPO).\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-personalize-solution-solutionconfig.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    # auto_ml_config: Any\n    # hpo_config: Any\n\n    solution_config_property = personalize.CfnSolution.SolutionConfigProperty(\n        algorithm_hyper_parameters={\n            "algorithm_hyper_parameters_key": "algorithmHyperParameters"\n        },\n        auto_ml_config=auto_ml_config,\n        event_value_threshold="eventValueThreshold",\n        feature_transformation_parameters={\n            "feature_transformation_parameters_key": "featureTransformationParameters"\n        },\n        hpo_config=hpo_config\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['algorithm_hyper_parameters', 'auto_ml_config', 'event_value_threshold', 'feature_transformation_parameters', 'hpo_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSolution.SolutionConfigProperty'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnDataset
class CfnDatasetDef(BaseCfnResource):
    dataset_group_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the dataset group.\n')
    dataset_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='One of the following values:. - Interactions - Items - Users\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the dataset.\n')
    schema_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the associated schema.\n')
    dataset_import_job: typing.Union[models.UnsupportedResource, models.aws_personalize.CfnDataset_DatasetImportJobPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes a job that imports training data from a data source (Amazon S3 bucket) to an Amazon Personalize dataset. If you specify a dataset import job as part of a dataset, all dataset import job fields are required.')
    _init_params: typing.ClassVar[list[str]] = ['dataset_group_arn', 'dataset_type', 'name', 'schema_arn', 'dataset_import_job']
    _method_names: typing.ClassVar[list[str]] = ['DataSourceProperty', 'DatasetImportJobProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnDataset'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnDatasetDefConfig] = pydantic.Field(None)


class CfnDatasetDefConfig(pydantic.BaseModel):
    DataSourceProperty: typing.Optional[list[CfnDatasetDefDatasourcepropertyParams]] = pydantic.Field(None, description='')
    DatasetImportJobProperty: typing.Optional[list[CfnDatasetDefDatasetimportjobpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnDatasetDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnDatasetDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnDatasetDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnDatasetDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnDatasetDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnDatasetDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnDatasetDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnDatasetDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnDatasetDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnDatasetDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnDatasetDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnDatasetDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnDatasetDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnDatasetDefDatasourcepropertyParams(pydantic.BaseModel):
    data_location: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDatasetDefDatasetimportjobpropertyParams(pydantic.BaseModel):
    dataset_arn: typing.Optional[str] = pydantic.Field(None, description='')
    dataset_import_job_arn: typing.Optional[str] = pydantic.Field(None, description='')
    data_source: typing.Any = pydantic.Field(None, description='')
    job_name: typing.Optional[str] = pydantic.Field(None, description='')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnDatasetDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnDatasetDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDatasetDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnDatasetDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDatasetDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnDatasetDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnDatasetDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnDatasetDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnDatasetDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnDatasetDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDatasetDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnDatasetDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnDatasetDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDatasetDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_personalize.CfnDatasetGroup
class CfnDatasetGroupDef(BaseCfnResource):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the dataset group.\n')
    domain: typing.Optional[str] = pydantic.Field(None, description='The domain of a Domain dataset group.\n')
    kms_key_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the AWS Key Management Service (KMS) key used to encrypt the datasets.\n')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the AWS Identity and Access Management (IAM) role that has permissions to access the AWS Key Management Service (KMS) key. Supplying an IAM role is only valid when also specifying a KMS key.')
    _init_params: typing.ClassVar[list[str]] = ['name', 'domain', 'kms_key_arn', 'role_arn']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnDatasetGroup'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnDatasetGroupDefConfig] = pydantic.Field(None)


class CfnDatasetGroupDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnDatasetGroupDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnDatasetGroupDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnDatasetGroupDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnDatasetGroupDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnDatasetGroupDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnDatasetGroupDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnDatasetGroupDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnDatasetGroupDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnDatasetGroupDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnDatasetGroupDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnDatasetGroupDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnDatasetGroupDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnDatasetGroupDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnDatasetGroupDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnDatasetGroupDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDatasetGroupDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnDatasetGroupDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDatasetGroupDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnDatasetGroupDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnDatasetGroupDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnDatasetGroupDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnDatasetGroupDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnDatasetGroupDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnDatasetGroupDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnDatasetGroupDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnDatasetGroupDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnDatasetGroupDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_personalize.CfnSchema
class CfnSchemaDef(BaseCfnResource):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the schema.\n')
    schema_: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The schema.\n', alias='schema')
    domain: typing.Optional[str] = pydantic.Field(None, description='The domain of a schema that you created for a dataset in a Domain dataset group.')
    _init_params: typing.ClassVar[list[str]] = ['name', 'schema', 'domain']
    _method_names: typing.ClassVar[list[str]] = ['add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSchema'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnSchemaDefConfig] = pydantic.Field(None)


class CfnSchemaDefConfig(pydantic.BaseModel):
    add_deletion_override: typing.Optional[list[CfnSchemaDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnSchemaDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnSchemaDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnSchemaDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnSchemaDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnSchemaDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnSchemaDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnSchemaDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnSchemaDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnSchemaDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnSchemaDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnSchemaDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnSchemaDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnSchemaDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnSchemaDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnSchemaDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnSchemaDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnSchemaDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnSchemaDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnSchemaDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnSchemaDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnSchemaDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnSchemaDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnSchemaDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnSchemaDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnSchemaDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnSchemaDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_personalize.CfnSolution
class CfnSolutionDef(BaseCfnResource):
    dataset_group_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the dataset group that provides the training data.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the solution.\n')
    event_type: typing.Optional[str] = pydantic.Field(None, description="The event type (for example, 'click' or 'like') that is used for training the model. If no ``eventType`` is provided, Amazon Personalize uses all interactions for training with equal weight regardless of type.\n")
    perform_auto_ml: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description=".. epigraph:: We don't recommend enabling automated machine learning. Instead, match your use case to the available Amazon Personalize recipes. For more information, see `Determining your use case. <https://docs.aws.amazon.com/personalize/latest/dg/determining-use-case.html>`_ When true, Amazon Personalize performs a search for the best USER_PERSONALIZATION recipe from the list specified in the solution configuration ( ``recipeArn`` must not be specified). When false (the default), Amazon Personalize uses ``recipeArn`` for training.\n")
    perform_hpo: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to perform hyperparameter optimization (HPO) on the chosen recipe. The default is ``false`` .\n')
    recipe_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the recipe used to create the solution. This is required when ``performAutoML`` is false.\n')
    solution_config: typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_SolutionConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes the configuration properties for the solution.')
    _init_params: typing.ClassVar[list[str]] = ['dataset_group_arn', 'name', 'event_type', 'perform_auto_ml', 'perform_hpo', 'recipe_arn', 'solution_config']
    _method_names: typing.ClassVar[list[str]] = ['AlgorithmHyperParameterRangesProperty', 'AutoMLConfigProperty', 'CategoricalHyperParameterRangeProperty', 'ContinuousHyperParameterRangeProperty', 'HpoConfigProperty', 'HpoObjectiveProperty', 'HpoResourceConfigProperty', 'IntegerHyperParameterRangeProperty', 'SolutionConfigProperty', 'add_deletion_override', 'add_dependency', 'add_depends_on', 'add_metadata', 'add_override', 'add_property_deletion_override', 'add_property_override', 'apply_removal_policy', 'get_att', 'get_metadata', 'inspect', 'obtain_dependencies', 'obtain_resource_dependencies', 'override_logical_id', 'remove_dependency', 'replace_dependency']
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSolution'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...


    resource_config: typing.Optional[CfnSolutionDefConfig] = pydantic.Field(None)


class CfnSolutionDefConfig(pydantic.BaseModel):
    AlgorithmHyperParameterRangesProperty: typing.Optional[list[CfnSolutionDefAlgorithmhyperparameterrangespropertyParams]] = pydantic.Field(None, description='')
    AutoMLConfigProperty: typing.Optional[list[CfnSolutionDefAutomlconfigpropertyParams]] = pydantic.Field(None, description='')
    CategoricalHyperParameterRangeProperty: typing.Optional[list[CfnSolutionDefCategoricalhyperparameterrangepropertyParams]] = pydantic.Field(None, description='')
    ContinuousHyperParameterRangeProperty: typing.Optional[list[CfnSolutionDefContinuoushyperparameterrangepropertyParams]] = pydantic.Field(None, description='')
    HpoConfigProperty: typing.Optional[list[CfnSolutionDefHpoconfigpropertyParams]] = pydantic.Field(None, description='')
    HpoObjectiveProperty: typing.Optional[list[CfnSolutionDefHpoobjectivepropertyParams]] = pydantic.Field(None, description='')
    HpoResourceConfigProperty: typing.Optional[list[CfnSolutionDefHporesourceconfigpropertyParams]] = pydantic.Field(None, description='')
    IntegerHyperParameterRangeProperty: typing.Optional[list[CfnSolutionDefIntegerhyperparameterrangepropertyParams]] = pydantic.Field(None, description='')
    SolutionConfigProperty: typing.Optional[list[CfnSolutionDefSolutionconfigpropertyParams]] = pydantic.Field(None, description='')
    add_deletion_override: typing.Optional[list[CfnSolutionDefAddDeletionOverrideParams]] = pydantic.Field(None, description='Syntactic sugar for ``addOverride(path, undefined)``.')
    add_dependency: typing.Optional[list[CfnSolutionDefAddDependencyParams]] = pydantic.Field(None, description='Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.\nThis can be used for resources across stacks (or nested stack) boundaries\nand the dependency will automatically be transferred to the relevant scope.')
    add_depends_on: typing.Optional[list[CfnSolutionDefAddDependsOnParams]] = pydantic.Field(None, description='(deprecated) Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.')
    add_metadata: typing.Optional[list[CfnSolutionDefAddMetadataParams]] = pydantic.Field(None, description='Add a value to the CloudFormation Resource Metadata.')
    add_override: typing.Optional[list[CfnSolutionDefAddOverrideParams]] = pydantic.Field(None, description='Adds an override to the synthesized CloudFormation resource.\nTo add a\nproperty override, either use ``addPropertyOverride`` or prefix ``path`` with\n"Properties." (i.e. ``Properties.TopicName``).\n\nIf the override is nested, separate each nested level using a dot (.) in the path parameter.\nIf there is an array as part of the nesting, specify the index in the path.\n\nTo include a literal ``.`` in the property name, prefix with a ``\\``. In most\nprogramming languages you will need to write this as ``"\\\\."`` because the\n``\\`` itself will need to be escaped.\n\nFor example::\n\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes", ["myattribute"])\n   cfn_resource.add_override("Properties.GlobalSecondaryIndexes.1.ProjectionType", "INCLUDE")\n\nwould add the overrides Example::\n\n   "Properties": {\n     "GlobalSecondaryIndexes": [\n       {\n         "Projection": {\n           "NonKeyAttributes": [ "myattribute" ]\n           ...\n         }\n         ...\n       },\n       {\n         "ProjectionType": "INCLUDE"\n         ...\n       },\n     ]\n     ...\n   }\n\nThe ``value`` argument to ``addOverride`` will not be processed or translated\nin any way. Pass raw JSON values in here with the correct capitalization\nfor CloudFormation. If you pass CDK classes or structs, they will be\nrendered with lowercased key names, and CloudFormation will reject the\ntemplate.')
    add_property_deletion_override: typing.Optional[list[CfnSolutionDefAddPropertyDeletionOverrideParams]] = pydantic.Field(None, description='Adds an override that deletes the value of a property from the resource definition.')
    add_property_override: typing.Optional[list[CfnSolutionDefAddPropertyOverrideParams]] = pydantic.Field(None, description='Adds an override to a resource property.\nSyntactic sugar for ``addOverride("Properties.<...>", value)``.')
    apply_removal_policy: typing.Optional[list[models.GenericApplyRemovalPolicyParams]] = pydantic.Field(None)
    get_att: typing.Optional[list[CfnSolutionDefGetAttParams]] = pydantic.Field(None, description='Returns a token for an runtime attribute of this resource.\nIdeally, use generated attribute accessors (e.g. ``resource.arn``), but this can be used for future compatibility\nin case there is no generated attribute.')
    get_metadata: typing.Optional[list[CfnSolutionDefGetMetadataParams]] = pydantic.Field(None, description='Retrieve a value value from the CloudFormation Resource Metadata.')
    inspect: typing.Optional[list[CfnSolutionDefInspectParams]] = pydantic.Field(None, description='Examines the CloudFormation resource and discloses attributes.')
    obtain_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Retrieves an array of resources this resource depends on.\nThis assembles dependencies on resources across stacks (including nested stacks)\nautomatically.')
    obtain_resource_dependencies: typing.Optional[bool] = pydantic.Field(None, description='Get a shallow copy of dependencies between this resource and other resources in the same stack.')
    override_logical_id: typing.Optional[list[CfnSolutionDefOverrideLogicalIdParams]] = pydantic.Field(None, description='Overrides the auto-generated logical ID with a specific ID.')
    remove_dependency: typing.Optional[list[CfnSolutionDefRemoveDependencyParams]] = pydantic.Field(None, description='Indicates that this resource no longer depends on another resource.\nThis can be used for resources across stacks (including nested stacks)\nand the dependency will automatically be removed from the relevant scope.')
    replace_dependency: typing.Optional[list[CfnSolutionDefReplaceDependencyParams]] = pydantic.Field(None, description='Replaces one dependency with another.')

class CfnSolutionDefAlgorithmhyperparameterrangespropertyParams(pydantic.BaseModel):
    categorical_hyper_parameter_ranges: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_CategoricalHyperParameterRangePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    continuous_hyper_parameter_ranges: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_ContinuousHyperParameterRangePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    integer_hyper_parameter_ranges: typing.Union[models.UnsupportedResource, typing.Sequence[typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_IntegerHyperParameterRangePropertyDef, dict[str, typing.Any]]], None] = pydantic.Field(None, description='')
    ...

class CfnSolutionDefAutomlconfigpropertyParams(pydantic.BaseModel):
    metric_name: typing.Optional[str] = pydantic.Field(None, description='')
    recipe_list: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnSolutionDefCategoricalhyperparameterrangepropertyParams(pydantic.BaseModel):
    name: typing.Optional[str] = pydantic.Field(None, description='')
    values: typing.Optional[typing.Sequence[str]] = pydantic.Field(None, description='')
    ...

class CfnSolutionDefContinuoushyperparameterrangepropertyParams(pydantic.BaseModel):
    max_value: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min_value: typing.Union[int, float, None] = pydantic.Field(None, description='')
    name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnSolutionDefHpoconfigpropertyParams(pydantic.BaseModel):
    algorithm_hyper_parameter_ranges: typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_AlgorithmHyperParameterRangesPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    hpo_objective: typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_HpoObjectivePropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    hpo_resource_config: typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_HpoResourceConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='')
    ...

class CfnSolutionDefHpoobjectivepropertyParams(pydantic.BaseModel):
    metric_name: typing.Optional[str] = pydantic.Field(None, description='')
    metric_regex: typing.Optional[str] = pydantic.Field(None, description='')
    type: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnSolutionDefHporesourceconfigpropertyParams(pydantic.BaseModel):
    max_number_of_training_jobs: typing.Optional[str] = pydantic.Field(None, description='')
    max_parallel_training_jobs: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnSolutionDefIntegerhyperparameterrangepropertyParams(pydantic.BaseModel):
    max_value: typing.Union[int, float, None] = pydantic.Field(None, description='')
    min_value: typing.Union[int, float, None] = pydantic.Field(None, description='')
    name: typing.Optional[str] = pydantic.Field(None, description='')
    ...

class CfnSolutionDefSolutionconfigpropertyParams(pydantic.BaseModel):
    algorithm_hyper_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    auto_ml_config: typing.Any = pydantic.Field(None, description='')
    event_value_threshold: typing.Optional[str] = pydantic.Field(None, description='')
    feature_transformation_parameters: typing.Union[models.UnsupportedResource, typing.Mapping[str, str], None] = pydantic.Field(None, description='')
    hpo_config: typing.Any = pydantic.Field(None, description='')
    ...

class CfnSolutionDefAddDeletionOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='The path of the value to delete.')
    ...

class CfnSolutionDefAddDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnSolutionDefAddDependsOnParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-\n\n:deprecated: use addDependency\n\n:stability: deprecated\n')
    ...

class CfnSolutionDefAddMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n')
    value: typing.Any = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnSolutionDefAddOverrideParams(pydantic.BaseModel):
    path: str = pydantic.Field(..., description='- The path of the property, you can use dot notation to override values in complex types. Any intermediate keys will be created as needed.\n')
    value: typing.Any = pydantic.Field(..., description='- The value. Could be primitive or complex.')
    ...

class CfnSolutionDefAddPropertyDeletionOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path to the property.')
    ...

class CfnSolutionDefAddPropertyOverrideParams(pydantic.BaseModel):
    property_path: str = pydantic.Field(..., description='The path of the property.\n')
    value: typing.Any = pydantic.Field(..., description='The value.')
    ...

class CfnSolutionDefApplyRemovalPolicyParams(pydantic.BaseModel):
    policy: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description='-\n')
    apply_to_update_replace_policy: typing.Optional[bool] = pydantic.Field(None, description='Apply the same deletion policy to the resource\'s "UpdateReplacePolicy". Default: true\n')
    default: typing.Optional[aws_cdk.RemovalPolicy] = pydantic.Field(None, description="The default policy to apply in case the removal policy is not defined. Default: - Default value is resource specific. To determine the default value for a resource, please consult that specific resource's documentation.\n\n:see: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n")
    ...

class CfnSolutionDefGetAttParams(pydantic.BaseModel):
    attribute_name: str = pydantic.Field(..., description='The name of the attribute.\n')
    type_hint: typing.Optional[aws_cdk.ResolutionTypeHint] = pydantic.Field(None, description='-')
    return_config: typing.Optional[list[models.core.ReferenceDefConfig]] = pydantic.Field(None)
    ...

class CfnSolutionDefGetMetadataParams(pydantic.BaseModel):
    key: str = pydantic.Field(..., description='-\n\n:see:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html\n\nNote that this is a different set of metadata from CDK node metadata; this\nmetadata ends up in the stack template under the resource, whereas CDK\nnode metadata ends up in the Cloud Assembly.\n')
    ...

class CfnSolutionDefInspectParams(pydantic.BaseModel):
    inspector: models.TreeInspectorDef = pydantic.Field(..., description='tree inspector to collect and process attributes.')
    ...

class CfnSolutionDefOverrideLogicalIdParams(pydantic.BaseModel):
    new_logical_id: str = pydantic.Field(..., description='The new logical ID to use for this stack element.')
    ...

class CfnSolutionDefRemoveDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='-')
    ...

class CfnSolutionDefReplaceDependencyParams(pydantic.BaseModel):
    target: models.CfnResourceDef = pydantic.Field(..., description='The dependency to replace.\n')
    new_target: models.CfnResourceDef = pydantic.Field(..., description='The new dependency to add.')
    ...


#  autogenerated from aws_cdk.aws_personalize.CfnDatasetGroupProps
class CfnDatasetGroupPropsDef(BaseCfnProperty):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the dataset group.\n')
    domain: typing.Optional[str] = pydantic.Field(None, description='The domain of a Domain dataset group.\n')
    kms_key_arn: typing.Optional[str] = pydantic.Field(None, description='The Amazon Resource Name (ARN) of the AWS Key Management Service (KMS) key used to encrypt the datasets.\n')
    role_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the AWS Identity and Access Management (IAM) role that has permissions to access the AWS Key Management Service (KMS) key. Supplying an IAM role is only valid when also specifying a KMS key.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-personalize-datasetgroup.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    cfn_dataset_group_props = personalize.CfnDatasetGroupProps(\n        name="name",\n\n        # the properties below are optional\n        domain="domain",\n        kms_key_arn="kmsKeyArn",\n        role_arn="roleArn"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'domain', 'kms_key_arn', 'role_arn']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnDatasetGroupProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnDatasetProps
class CfnDatasetPropsDef(BaseCfnProperty):
    dataset_group_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the dataset group.\n')
    dataset_type: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='One of the following values:. - Interactions - Items - Users\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the dataset.\n')
    schema_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The ARN of the associated schema.\n')
    dataset_import_job: typing.Union[models.UnsupportedResource, models.aws_personalize.CfnDataset_DatasetImportJobPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes a job that imports training data from a data source (Amazon S3 bucket) to an Amazon Personalize dataset. If you specify a dataset import job as part of a dataset, all dataset import job fields are required.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-personalize-dataset.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    # data_source: Any\n\n    cfn_dataset_props = personalize.CfnDatasetProps(\n        dataset_group_arn="datasetGroupArn",\n        dataset_type="datasetType",\n        name="name",\n        schema_arn="schemaArn",\n\n        # the properties below are optional\n        dataset_import_job=personalize.CfnDataset.DatasetImportJobProperty(\n            dataset_arn="datasetArn",\n            dataset_import_job_arn="datasetImportJobArn",\n            data_source=data_source,\n            job_name="jobName",\n            role_arn="roleArn"\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['dataset_group_arn', 'dataset_type', 'name', 'schema_arn', 'dataset_import_job']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnDatasetProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnSchemaProps
class CfnSchemaPropsDef(BaseCfnProperty):
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the schema.\n')
    schema_: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The schema.\n', alias='schema')
    domain: typing.Optional[str] = pydantic.Field(None, description='The domain of a schema that you created for a dataset in a Domain dataset group.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-personalize-schema.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    cfn_schema_props = personalize.CfnSchemaProps(\n        name="name",\n        schema="schema",\n\n        # the properties below are optional\n        domain="domain"\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['name', 'schema', 'domain']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSchemaProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




#  autogenerated from aws_cdk.aws_personalize.CfnSolutionProps
class CfnSolutionPropsDef(BaseCfnProperty):
    dataset_group_arn: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The Amazon Resource Name (ARN) of the dataset group that provides the training data.\n')
    name: typing.Union[str, _REQUIRED_INIT_PARAM] = pydantic.Field(REQUIRED_INIT_PARAM, description='The name of the solution.\n')
    event_type: typing.Optional[str] = pydantic.Field(None, description="The event type (for example, 'click' or 'like') that is used for training the model. If no ``eventType`` is provided, Amazon Personalize uses all interactions for training with equal weight regardless of type.\n")
    perform_auto_ml: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description=".. epigraph:: We don't recommend enabling automated machine learning. Instead, match your use case to the available Amazon Personalize recipes. For more information, see `Determining your use case. <https://docs.aws.amazon.com/personalize/latest/dg/determining-use-case.html>`_ When true, Amazon Personalize performs a search for the best USER_PERSONALIZATION recipe from the list specified in the solution configuration ( ``recipeArn`` must not be specified). When false (the default), Amazon Personalize uses ``recipeArn`` for training.\n")
    perform_hpo: typing.Union[bool, models.UnsupportedResource, None] = pydantic.Field(None, description='Whether to perform hyperparameter optimization (HPO) on the chosen recipe. The default is ``false`` .\n')
    recipe_arn: typing.Optional[str] = pydantic.Field(None, description='The ARN of the recipe used to create the solution. This is required when ``performAutoML`` is false.\n')
    solution_config: typing.Union[models.UnsupportedResource, models.aws_personalize.CfnSolution_SolutionConfigPropertyDef, dict[str, typing.Any], None] = pydantic.Field(None, description='Describes the configuration properties for the solution.\n\n:see: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-personalize-solution.html\n:exampleMetadata: fixture=_generated\n\nExample::\n\n    # The code below shows an example of how to instantiate this type.\n    # The values are placeholders you should change.\n    from aws_cdk import aws_personalize as personalize\n\n    # auto_ml_config: Any\n    # hpo_config: Any\n\n    cfn_solution_props = personalize.CfnSolutionProps(\n        dataset_group_arn="datasetGroupArn",\n        name="name",\n\n        # the properties below are optional\n        event_type="eventType",\n        perform_auto_ml=False,\n        perform_hpo=False,\n        recipe_arn="recipeArn",\n        solution_config=personalize.CfnSolution.SolutionConfigProperty(\n            algorithm_hyper_parameters={\n                "algorithm_hyper_parameters_key": "algorithmHyperParameters"\n            },\n            auto_ml_config=auto_ml_config,\n            event_value_threshold="eventValueThreshold",\n            feature_transformation_parameters={\n                "feature_transformation_parameters_key": "featureTransformationParameters"\n            },\n            hpo_config=hpo_config\n        )\n    )\n')
    _init_params: typing.ClassVar[list[str]] = ['dataset_group_arn', 'name', 'event_type', 'perform_auto_ml', 'perform_hpo', 'recipe_arn', 'solution_config']
    _method_names: typing.ClassVar[list[str]] = []
    _classmethod_names: typing.ClassVar[list[str]] = []
    _cdk_class_fqn: typing.ClassVar[str] = 'aws_cdk.aws_personalize.CfnSolutionProps'
    _alternate_constructor_method_names: typing.ClassVar[list[str]] = []
    ...




import models

class ModuleModel(pydantic.BaseModel):
    CfnDataset_DatasetImportJobProperty: typing.Optional[dict[str, CfnDataset_DatasetImportJobPropertyDef]] = pydantic.Field(None)
    CfnDataset_DataSourceProperty: typing.Optional[dict[str, CfnDataset_DataSourcePropertyDef]] = pydantic.Field(None)
    CfnSolution_AlgorithmHyperParameterRangesProperty: typing.Optional[dict[str, CfnSolution_AlgorithmHyperParameterRangesPropertyDef]] = pydantic.Field(None)
    CfnSolution_AutoMLConfigProperty: typing.Optional[dict[str, CfnSolution_AutoMLConfigPropertyDef]] = pydantic.Field(None)
    CfnSolution_CategoricalHyperParameterRangeProperty: typing.Optional[dict[str, CfnSolution_CategoricalHyperParameterRangePropertyDef]] = pydantic.Field(None)
    CfnSolution_ContinuousHyperParameterRangeProperty: typing.Optional[dict[str, CfnSolution_ContinuousHyperParameterRangePropertyDef]] = pydantic.Field(None)
    CfnSolution_HpoConfigProperty: typing.Optional[dict[str, CfnSolution_HpoConfigPropertyDef]] = pydantic.Field(None)
    CfnSolution_HpoObjectiveProperty: typing.Optional[dict[str, CfnSolution_HpoObjectivePropertyDef]] = pydantic.Field(None)
    CfnSolution_HpoResourceConfigProperty: typing.Optional[dict[str, CfnSolution_HpoResourceConfigPropertyDef]] = pydantic.Field(None)
    CfnSolution_IntegerHyperParameterRangeProperty: typing.Optional[dict[str, CfnSolution_IntegerHyperParameterRangePropertyDef]] = pydantic.Field(None)
    CfnSolution_SolutionConfigProperty: typing.Optional[dict[str, CfnSolution_SolutionConfigPropertyDef]] = pydantic.Field(None)
    CfnDataset: typing.Optional[dict[str, CfnDatasetDef]] = pydantic.Field(None)
    CfnDatasetGroup: typing.Optional[dict[str, CfnDatasetGroupDef]] = pydantic.Field(None)
    CfnSchema: typing.Optional[dict[str, CfnSchemaDef]] = pydantic.Field(None)
    CfnSolution: typing.Optional[dict[str, CfnSolutionDef]] = pydantic.Field(None)
    CfnDatasetGroupProps: typing.Optional[dict[str, CfnDatasetGroupPropsDef]] = pydantic.Field(None)
    CfnDatasetProps: typing.Optional[dict[str, CfnDatasetPropsDef]] = pydantic.Field(None)
    CfnSchemaProps: typing.Optional[dict[str, CfnSchemaPropsDef]] = pydantic.Field(None)
    CfnSolutionProps: typing.Optional[dict[str, CfnSolutionPropsDef]] = pydantic.Field(None)
    ...
